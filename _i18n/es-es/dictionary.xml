<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="summary"></block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">Avisos legales</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="paragraph">Los avisos legales proporcionan acceso a las declaraciones de copyright, marcas comerciales, patentes y mucho más.</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">Derechos de autor</block>
  <block id="52009bb7ee17227f566cd26a02caee56" category="inline-link-macro"><block ref="52009bb7ee17227f566cd26a02caee56" category="inline-link-rx"></block></block>
  <block id="a1a9afcf552a769c282769271829889a" category="paragraph"><block ref="a1a9afcf552a769c282769271829889a" category="inline-link-macro-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">Marcas comerciales</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NETAPP, el logotipo de NETAPP y las marcas enumeradas en la página de marcas comerciales de NetApp son marcas comerciales de NetApp, Inc. Los demás nombres de empresas y productos son marcas comerciales de sus respectivos propietarios.</block>
  <block id="f99aa604031e5049799e73b5c3748a98" category="inline-link-macro"><block ref="f99aa604031e5049799e73b5c3748a98" category="inline-link-rx"></block></block>
  <block id="5d545fe5152641e2ebe654e336e520e5" category="paragraph"><block ref="5d545fe5152641e2ebe654e336e520e5" category="inline-link-macro-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">Estadounidenses</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">Puede encontrar una lista actual de las patentes propiedad de NetApp en:</block>
  <block id="88e5eabd3917048b6927c42496b98f86" category="inline-link-macro"><block ref="88e5eabd3917048b6927c42496b98f86" category="inline-link-rx"></block></block>
  <block id="dd38f906b37d412de7d1c1dcf4cbf31c" category="paragraph"><block ref="dd38f906b37d412de7d1c1dcf4cbf31c" category="inline-link-macro-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">Política de privacidad</block>
  <block id="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-macro"><block ref="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-rx"></block></block>
  <block id="2352c4e1f4d0024ade0869e00e6243f4" category="paragraph"><block ref="2352c4e1f4d0024ade0869e00e6243f4" category="inline-link-macro-rx"></block></block>
  <block id="c0227cef6f07a8cd2ac72f2945b031aa" category="section-title">Código abierto</block>
  <block id="9b73989307c1975dfa4d5e1581e4afe8" category="paragraph">Los archivos de notificación proporcionan información sobre los derechos de autor y las licencias de terceros que se utilizan en software de NetApp.</block>
  <block id="253b40ae359ba25b56231803430c4873" category="section-title">ONTAP</block>
  <block id="856c8958afd787f748a4a025f649154a" category="inline-link-macro">Aviso para ONTAP 9.13.1</block>
  <block id="b22b3b2970d843f99e7e6904bea05207" category="inline-link-macro">Aviso para ONTAP 9.12.1</block>
  <block id="0358f41254df2d512849db5a04b7e3d4" category="inline-link-macro">Aviso para ONTAP 9.12.0</block>
  <block id="28f1290102a277ef2fd452d558c74219" category="inline-link-macro">Aviso para ONTAP 9.11.1</block>
  <block id="57b07f14c8eb4660f94a86d29d53362d" category="inline-link-macro">Aviso para ONTAP 9.10.1</block>
  <block id="396712eb9c1644241047ac30619b2b3e" category="inline-link-macro">Aviso para ONTAP 9.10.0</block>
  <block id="1e6000d4849ef9f3e08d1d9908e9f163" category="inline-link-macro">Aviso para ONTAP 9.9.1</block>
  <block id="6f408b9c999245c7aa32bc9cb1a020f6" category="inline-link-macro">Aviso para ONTAP 9.8</block>
  <block id="04b0bd5b1b4d414fdde93f809162d36d" category="inline-link-macro">Aviso para ONTAP 9,7</block>
  <block id="0c1d7dffcba488555d5eb39b8991e822" category="inline-link-macro">Aviso para ONTAP 9,6</block>
  <block id="a11ac6880e72412c0f54ae19bea3d191" category="inline-link-macro">Aviso para ONTAP 9,5</block>
  <block id="e49c3c01b15761b5f011d0bd2a0661a3" category="inline-link-macro">Aviso para ONTAP 9,4</block>
  <block id="bf7dcf6467a8a03b05b2d37d31d6eccd" category="inline-link-macro">Aviso para ONTAP 9,3</block>
  <block id="0328352fdfda84af6968462d1a67d3a6" category="inline-link-macro">Aviso para ONTAP 9,2</block>
  <block id="83904100c7d6fe0102e8b2b5bd8ec4bb" category="inline-link-macro">Aviso para ONTAP 9,1</block>
  <block id="5672f5979be77bb31dd559817c9e1e76" category="paragraph"><block ref="f7a2b1db149ed9886af0ce846dbc3e14" category="inline-link-macro-rx"></block>
<block ref="b349c509ad858348b30db7e73307e3aa" category="inline-link-macro-rx"></block>
<block ref="0dce234dfded58bd461541473b86e42a" category="inline-link-macro-rx"></block>
<block ref="9760ec4df13f0afbdfec88ae16c871ae" category="inline-link-macro-rx"></block>
<block ref="b6dab2933dfb92cf0c1355707a4aec7c" category="inline-link-macro-rx"></block>
<block ref="1b7c80b26162b03bd0addd587f70df55" category="inline-link-macro-rx"></block>
<block ref="14faf912aa42102a6628af4551e02583" category="inline-link-macro-rx"></block>
<block ref="a90f36d649d3be5d386cc3563ab044fb" category="inline-link-macro-rx"></block>
<block ref="2cd65b4a044075cfd9ad4a91f42fdff4" category="inline-link-macro-rx"></block>
<block ref="5e764cc3fdcc19ff667796e414159bdc" category="inline-link-macro-rx"></block>
<block ref="561451f09c7bca700ea0d7833cd9e92e" category="inline-link-macro-rx"></block>
<block ref="d23d341a344216fbf99a91152429d49c" category="inline-link-macro-rx"></block>
<block ref="b35e8fbd7b0369b23734510994911ec4" category="inline-link-macro-rx"></block>
<block ref="41d4305cf7a6acb595086f123121a781" category="inline-link-macro-rx"></block>
<block ref="ea685649fabe77da53e843fec56f72b8" category="inline-link-macro-rx"></block></block>
  <block id="07ee2fe6f236deffba69a7cf80a680fd" category="section-title">Mediador ONTAP para MCC IP</block>
  <block id="f089ab2b9f25f609795bdd46ae636f18" category="inline-link-macro">9.9.1 Aviso para Mediador ONTAP para IP MCC</block>
  <block id="239794a299abe62705440f2dab3114cb" category="inline-link-macro">9,8 Aviso para Mediador ONTAP para IP MCC</block>
  <block id="51fcca20d278d2d03192c01120f17442" category="inline-link-macro">9,7 Aviso para Mediador ONTAP para IP MCC</block>
  <block id="3ba2aeb22339424d5f5b15dafd2c3eca" category="paragraph"><block ref="c8696a7854fcd089ea112145e4968b10" category="inline-link-macro-rx"></block>
<block ref="4d19e06382f392d0f1a50df789d77c13" category="inline-link-macro-rx"></block>
<block ref="fe4ac88b6b3f1cb9f1dc6d5d4b5086ee" category="inline-link-macro-rx"></block></block>
  <block id="9e476387322a5c250893cf9c5c4ce78c" category="doc">Normativas</block>
  <block id="b9e18a3460bc17eb9ea65b03f0167453" category="paragraph">Esto es común con las bases de datos. Las bases de datos que se sabe que contienen bloques inactivos también son candidatas para la organización en niveles de FabricPool. Por ejemplo, una base de datos de gestión de cadena de suministro puede contener información histórica que debe estar disponible si es necesario, pero que no se puede acceder durante las operaciones normales. FabricPool se puede utilizar para reubicar selectivamente los bloques inactivos.</block>
  <block id="95e955bbbe5dd9520a6bf45b0d8a9d4c" category="paragraph">Por ejemplo, los archivos de datos que se ejecutan en un volumen FabricPool con a.<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> periodo de 90 días: conserva los bloques a los que se ha accedido en los 90 días anteriores en el nivel de rendimiento. Sin embargo, todo lo que no se acceda durante 90 días se reubica al nivel de capacidad. En otros casos, la actividad normal de la aplicación conserva los bloques correctos en el nivel correcto. Por ejemplo, si una base de datos se utiliza normalmente para procesar los 60 días anteriores de datos de forma regular, es mucho menor<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> el período se puede establecer porque la actividad natural de la aplicación garantiza que los bloques no se reubiquen antes de tiempo.</block>
  <block id="c33af7c93d461803ceaf8531e861017d" category="paragraph">La<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la política debe utilizarse con cuidado con las bases de datos. Muchas bases de datos tienen actividades periódicas como el proceso de final del trimestre o las operaciones de reindexación. Si el período de estas operaciones es mayor que el<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> se pueden producir problemas de rendimiento. Por ejemplo, si el procesamiento a final de trimestre requiere 1TB TB de datos que de otro modo no se han modificado, esos datos podrían estar presentes ahora en el nivel de capacidad. Las lecturas del nivel de capacidad a menudo son extremadamente rápidas y pueden no causar problemas de rendimiento, pero los resultados exactos dependerán de la configuración del almacén de objetos.</block>
  <block id="03431a55183cb73a12c1bbc3e1927678" category="paragraph">La<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la política debe establecerse lo suficientemente alta para conservar los archivos que pueden ser necesarios en el nivel de rendimiento. Por ejemplo, una base de datos en la que los 60 días de datos más recientes podrían ser necesarios con un rendimiento óptimo justificaría establecer el<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> periodo hasta 60 días. También se podrían lograr resultados similares en función de los patrones de acceso de los archivos. Por ejemplo, si se requieren los 90 días de datos más recientes y la aplicación accede a ese intervalo de 90 días de datos, los datos permanecerán en el nivel de rendimiento. Ajuste de<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> un periodo de hasta 2 días clasificaría los datos en niveles inmediatamente después de que los datos se vuelvan menos activos.</block>
  <block id="25d9496e96e698b08c4fc713bfc9a5ca" category="paragraph">La<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> se requiere una política para impulsar la organización en niveles de estos bloques porque solo el<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la política afecta a los bloques que están en el sistema de archivos activo.</block>
  <block id="55fad400d892fb6062e67904fa9be485" category="admonition">Cualquier tipo de acceso a los datos restablece los datos del mapa de calor. Por lo tanto, las exploraciones de tablas completas de la base de datos e incluso la actividad de copia de seguridad que lee los archivos de origen impiden la organización en niveles porque es necesario<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> nunca se ha alcanzado el umbral.</block>
  <block id="117c4b6bad0236ab23e0fe29aead8aef" category="paragraph">Aunque el redimensionamiento de LUN es una opción para aumentar la capacidad, generalmente es mejor usar un LVM, incluido Oracle ASM. Uno de los principales motivos por los que existen LVM es evitar la necesidad de cambiar el tamaño de las LUN. Con un LVM, se unen varias LUN en un pool virtual de almacenamiento. Los volúmenes lógicos tallados en este pool son administrados por el LVM y pueden ser fácilmente redimensionados. Otra ventaja es la eliminación de los puntos de sobrecarga en una unidad concreta al distribuir un volumen lógico determinado entre todas las LUN disponibles. Normalmente, la migración transparente puede realizarse utilizando el administrador de volúmenes para reubicar las extensiones subyacentes de un volumen lógico a nuevas LUN.</block>
  <block id="4d4855a15e1f9d6fd8f8bdf1668c537e" category="doc">NVFAIL forzado manualmente</block>
  <block id="8772c1c8bed97f5c942657feeb8bfb6f" category="admonition">En esta sección se amplía la explicación del NVFAIL básico de ONTAP para tratar temas específicos de MetroCluster.</block>
  <block id="14d74316044293d1ebd8c5a01ff90055" category="paragraph">Con MetroCluster, no se reconoce la escritura hasta que se haya iniciado sesión en la NVRAM y NVRAM locales en al menos otra controladora. Este método garantiza que un fallo de hardware o una interrupción del suministro eléctrico no provoquen la pérdida de operaciones de I/O en tránsito Si la NVRAM local falla o la conectividad a otros nodos falla, los datos ya no se reflejarían.</block>
  <block id="d820d86d09ea05a0de19c3aacbfb72b2" category="paragraph">Si la NVRAM local informa de un error, el nodo se apaga. Este apagado hace que se conmute al nodo de respaldo a la controladora asociada cuando se utilizan pares de alta disponibilidad. Con MetroCluster, el comportamiento depende de la configuración general elegida, pero puede dar lugar a una conmutación automática por error a la nota remota. En cualquier caso, no se pierden datos porque la controladora que experimenta el fallo no reconoció la operación de escritura.</block>
  <block id="886174de078cee4595eb8a8d07f81703" category="paragraph">Un fallo de conectividad entre sitios que bloquea la replicación de NVRAM en nodos remotos es una situación más complicada. Las escrituras ya no se replican en los nodos remotos y, de este modo, se crea la posibilidad de perder datos si se produce un error grave en una controladora. Lo que es más importante, si se intenta conmutar a un nodo diferente durante estas condiciones, se pierden datos.</block>
  <block id="790ec042c9b89dac2390ea81b9c29a51" category="paragraph">El factor de control es si NVRAM está sincronizada. Si NVRAM está sincronizada, la conmutación al nodo de respaldo nodo a nodo se realizará de forma segura sin riesgo de pérdida de datos. En una configuración de MetroCluster, si la NVRAM y los complejos de agregado subyacentes están sincronizados, es seguro continuar con la conmutación sin el riesgo de perder los datos.</block>
  <block id="3d936bb059b98a2fc7c177d20eb755c9" category="paragraph">ONTAP no permite una conmutación por error o una conmutación cuando los datos no están sincronizados a menos que se fuercen la conmutación por error o la conmutación. Al forzar un cambio en las condiciones de esta manera, se reconoce que los datos podrían dejarse atrás en la controladora original y que la pérdida de datos es aceptable.</block>
  <block id="3d37a3a8ed77bebc986238aedccecbc9" category="paragraph">Las bases de datos son especialmente vulnerables a los daños si se fuerza una conmutación por error o una conmutación por error porque las bases de datos mantienen cachés internos mayores de los datos en el disco. Si se produce un failover forzado o un switchover forzado, los cambios previamente reconocidos se descartan efectivamente. El contenido de la cabina de almacenamiento retrocede efectivamente en el tiempo y el estado de la caché de base de datos ya no refleja el estado de los datos del disco.</block>
  <block id="7ad23b7fa394c8666b132d78a58b1987" category="paragraph">Para proteger aplicaciones contra esta situación, ONTAP permite configurar volúmenes para obtener protección especial contra un fallo NVRAM. Cuando se activa, este mecanismo de protección hace que un volumen entre en un estado denominado NVFAIL. Este estado provoca errores de I/O que provocan el cierre de la aplicación para que no utilicen datos obsoletos. No se deben perder los datos, ya que aún hay escrituras reconocidas en el sistema de almacenamiento y, con bases de datos, todos los datos de transacciones confirmados deben estar presentes en los registros.</block>
  <block id="99259586124503e22927506a7ed3738d" category="paragraph">Los siguientes pasos habituales son para que un administrador apague completamente los hosts antes de volver a poner manualmente los LUN y los volúmenes de nuevo en línea. Aunque estos pasos pueden implicar cierto trabajo, este enfoque es la manera más segura de garantizar la integridad de los datos. No todos los datos requieren esta protección, por lo que el comportamiento NVFAIL se puede configurar volumen por volumen.</block>
  <block id="13fbc5a220fe8007dcaea69217bba134" category="paragraph">La opción más segura para forzar una conmutación por error con un clúster de aplicaciones (incluido VMware, Oracle RAC y otros) que se distribuye entre los sitios es especificar<block ref="71e644310ff0f1164d905d6e80174023" prefix=" " category="inline-code"></block> en la línea de comandos. Esta opción está disponible como medida de emergencia para garantizar que todos los datos almacenados en caché están vaciados. Si un host utiliza recursos de almacenamiento ubicados originalmente en el sitio afectado por desastres, recibirá errores de I/O o un identificador de archivos obsoleto <block ref="a3c6541ac12f1f06a81cc9b03e6bd094" prefix="(" category="inline-code"></block>) error. Las bases de datos de Oracle se bloquean y los sistemas de archivos se desconectan por completo o cambian al modo de sólo lectura.</block>
  <block id="dc6683d37e50abd82911fa91c036fbb2" category="paragraph">Una vez finalizada la operación de switchover, el<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> La marca debe borrarse y las LUN deben colocarse en línea. Una vez finalizada esta actividad, se puede reiniciar la base de datos. Estas tareas se pueden automatizar para reducir el RTO.</block>
  <block id="a2626552f293b2377efe829e69d14daa" category="section-title">dr-force-nvfail</block>
  <block id="f0cc4bbe3d196251009dbe9f0ac42ffc" category="paragraph">Como medida de seguridad general, configure el<block ref="a2626552f293b2377efe829e69d14daa" prefix=" " category="inline-code"></block> marque todos los volúmenes a los que se pueda acceder desde un sitio remoto durante las operaciones normales, lo que significa que se deben usar antes de la conmutación al respaldo. El resultado de esta configuración es que la selección de volúmenes remotos deja de estar disponible cuando se introducen<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> durante una conmutación de sitios. Una vez finalizada la operación de switchover, el<block ref="6b0a5ec5ecf08db5d4b32d860214d098" prefix=" " category="inline-code"></block> La marca debe borrarse y las LUN deben colocarse en línea. Una vez finalizadas estas actividades, se pueden reiniciar las aplicaciones. Estas tareas se pueden automatizar para reducir el RTO.</block>
  <block id="5f6aa76cc0fe886c07f242f921486ef7" category="paragraph">El resultado es como usar el<block ref="71e644310ff0f1164d905d6e80174023" prefix=" " category="inline-code"></block> indicador para conmutadores manuales. Sin embargo, la cantidad de volúmenes afectados puede limitarse a solo los volúmenes que deben protegerse de aplicaciones o sistemas operativos que tienen caché anticuada.</block>
  <block id="4df566a29b44806612369c0c1f67521b" category="paragraph">Hay dos requisitos críticos para un entorno que no utiliza<block ref="a2626552f293b2377efe829e69d14daa" prefix=" " category="inline-code"></block> en volúmenes de aplicaciones:</block>
  <block id="aaf1cc67bd88c39a71e691d413ded49f" category="list-text">Una conmutación de sitios forzada no debe ocurrir más de 30 segundos después de la pérdida del sitio principal.</block>
  <block id="7f9cc623e2a11875714cf4bc64f148fd" category="list-text">Una conmutación de sitios no debe producirse durante las tareas de mantenimiento ni ninguna otra condición en la que los plexes de SyncMirror o la replicación de NVRAM no estén sincronizados. El primer requisito se puede cumplir con el uso de un software tiebreaker configurado para realizar una conmutación de sitios en un plazo de 30 segundos tras un fallo del sitio. Este requisito no significa que el cambio deba realizarse dentro de los 30 segundos posteriores a la detección de un fallo del centro. Esto significa que ya no es seguro forzar un cambio si han transcurrido 30 segundos desde que se confirmó que un sitio está operativo.</block>
  <block id="0929cc8043c21dcf0163f06424677ede" category="paragraph">El segundo requisito se puede cumplir parcialmente deshabilitando todas las funcionalidades de conmutación automática de sitios cuando se sabe que la configuración de MetroCluster está fuera de sincronización. Mejor opción sería tener una solución tiebreaker que pueda supervisar el estado de la replicación de NVRAM y los plexes de SyncMirror. Si el clúster no está completamente sincronizado, tiebreaker no debería activar una conmutación de sitios.</block>
  <block id="a168430c68d0310385371eabe149a118" category="paragraph">El software NetApp MCTB no puede supervisar el estado de sincronización, por lo que debe desactivarse cuando MetroCluster no está sincronizado por cualquier motivo. ClusterLion incluye funcionalidades de supervisión de NVRAM y supervisión plex, y se puede configurar para no activar la conmutación de sitios a menos que se haya confirmado que el sistema MetroCluster está totalmente sincronizado.</block>
  <block id="baba038803e218b2ac3b2688bc2fd5db" category="doc">Número de LUN</block>
  <block id="b0e4db975ae00108abe9f47db9be5668" category="paragraph">Una LUN es un objeto virtualizado en ONTAP que existe en todas las unidades del agregado host. Como resultado, el rendimiento de la LUN no se ve afectado por su tamaño porque la LUN aprovecha todo el potencial de rendimiento del agregado sin importar el tamaño que se haya elegido.</block>
  <block id="7235d4b71fadc2fe03d09d863c7cdd66" category="paragraph">Para comodidad, es posible que los clientes deseen usar una LUN de un tamaño determinado. Por ejemplo, si una base de datos se crea en un LVM u un grupo de discos de ASM de Oracle compuesto por dos LUN de 1TB GB cada uno, dicho grupo de discos debe aumentar en incrementos de 1TB TB. Es preferible crear el grupo de discos a partir de ocho LUN de 500GB cada uno para que el grupo de discos se pueda aumentar en incrementos menores.</block>
  <block id="4b1ffe65479a23391a2c7f9caf467a35" category="paragraph">Se desaconseja la práctica de establecer un tamaño de LUN estándar universal porque, al hacerlo, se puede complicar la capacidad de gestión. Por ejemplo, un tamaño de LUN estándar de 100GB TB puede funcionar bien cuando una base de datos o un almacén de datos está entre 1TB y 2TB TB, pero el tamaño de una base de datos o un almacén de datos de 20TB TB requeriría 200 LUN. Esto significa que los tiempos de reinicio del servidor son más largos, hay más objetos que gestionar en las distintas interfaces de usuario y productos como SnapCenter deben realizar la detección de muchos objetos. Si se usa menos LUN, de mayor tamaño se evitan estos problemas.</block>
  <block id="4afa3de974c36a09c2055d30989bb405" category="list-text">El número de LUN es más importante que el tamaño de la LUN.</block>
  <block id="691c70133d96d57796a9299359666f80" category="list-text">El tamaño de LUN está controlado principalmente por requisitos del número de LUN.</block>
  <block id="8af9e525c143179b948a11fc382a331e" category="list-text">Evite crear más LUN de las necesarias.</block>
  <block id="407b2218ad77513a7e3964f169d07e66" category="paragraph">A diferencia del tamaño de LUN, el número de LUN afecta al rendimiento. El rendimiento de la aplicación depende a menudo de la capacidad para realizar I/O paralelas mediante la capa SCSI. Como resultado, dos LUN ofrecen mejor rendimiento que una única LUN. El uso de LVM como Veritas VxVM, Linux LVM2 u Oracle ASM es el método más sencillo para aumentar el paralelismo.</block>
  <block id="39143fe6204f383e4ce3bb3b77926455" category="paragraph">Los clientes de NetApp suelen experimentar un beneficio mínimo gracias al aumento del número de LUN por encima de dieciséis, aunque, en pruebas de entornos 100% con unidades de estado sólido con I/O aleatorias muy pesadas, se ha demostrado una mejora adicional de hasta 64 000 LUN.</block>
  <block id="9875f7503e59521e91e519abd87f5c9e" category="paragraph">*NetApp recomienda* lo siguiente:</block>
  <block id="57153ab478a4958250d76ac6bf4e3ac0" category="paragraph">En general, entre cuatro y dieciséis LUN son suficientes para admitir las necesidades de I/O de cualquier carga de trabajo de bases de datos en concreto. Menos de cuatro LUN puede crear limitaciones de rendimiento debido a las limitaciones de las implementaciones SCSI del host.</block>
  <block id="de932976b195d4755fcbea64295fc7cb" category="doc">Configuración del sistema operativo host</block>
  <block id="f62cb371f65c322cd9e17a5c2cecd1c8" category="paragraph">La mayoría de la documentación del proveedor de aplicaciones incluye configuraciones TCP y ethernet específicas para garantizar que la aplicación funcione de manera óptima. Estas mismas configuraciones suelen ser suficientes para ofrecer también un rendimiento óptimo del almacenamiento basado en IP.</block>
  <block id="ae7a0bb210cbd1edb935128116a21c55" category="section-title">Control de flujo Ethernet</block>
  <block id="a3c15fb208efc85bdfe72c57d56c92b8" category="paragraph">Esta tecnología permite a un cliente solicitar que un remitente detenga temporalmente la transmisión de datos. Esto suele hacerse porque el receptor no puede procesar los datos entrantes con la suficiente rapidez. Al mismo tiempo, solicitar que un remitente cesara la transmisión era menos perjudicial que tener un receptor descarte de paquetes porque los buffers estaban llenos. Este ya no es el caso con las pilas TCP utilizadas en los sistemas operativos actualmente. De hecho, el control de flujo causa más problemas de los que resuelve.</block>
  <block id="950d31923e253d170d6c994801ce7cec" category="paragraph">Los problemas de rendimiento causados por el control de flujo de Ethernet han aumentado en los últimos años. Esto se debe a que el control de flujo Ethernet funciona en la capa Physical. Si una configuración de red permite que un sistema operativo del host envíe una solicitud de control de flujo de Ethernet a un sistema de almacenamiento, el resultado es una pausa en las operaciones de I/O de todos los clientes conectados. Debido a que una única controladora de almacenamiento atiende cada vez más a un número de clientes, la probabilidad de que uno o varios de estos clientes envíen solicitudes de control de flujo aumenta. El problema se ha observado con frecuencia en las instalaciones de los clientes con una amplia virtualización del SO.</block>
  <block id="6bfd8563627c68f73c30581843441a74" category="paragraph">Una NIC de un sistema NetApp no debe recibir solicitudes de control de flujo. El método utilizado para lograr este resultado varía según el fabricante del conmutador de red. En la mayoría de los casos, el control de flujo en un conmutador Ethernet se puede establecer en<block ref="a67b5ddb674c9ca32d9c9e1ca81578ee" prefix=" " category="inline-code"></block> o.<block ref="f4eb0bfa09695eb47ff4f3bd3ca4449d" prefix=" " category="inline-code"></block>, lo que significa que una solicitud de control de flujo no se reenvía al controlador de almacenamiento. En otros casos, la conexión de red en la controladora de almacenamiento puede no permitir la deshabilitación de control de flujo. En estos casos, los clientes deben configurarse para que nunca envíen solicitudes de control de flujo, ya sea cambiando a la configuración de NIC en el propio servidor host o a los puertos de switch a los que está conectado el servidor host.</block>
  <block id="7496f3ff64e30d4732c2c64880faf186" category="admonition">*NetApp recomienda* asegurarse de que los controladores de almacenamiento NetApp no reciban paquetes de control de flujo Ethernet. Por lo general, esto puede realizarse mediante la configuración de los puertos del switch a los que está conectada la controladora, pero algunas limitaciones en el hardware del switch pueden requerir cambios en el lado del cliente.</block>
  <block id="ae6d0fc57efaf02ad7dfdacd3575e315" category="section-title">Tamaños de MTU</block>
  <block id="ff13ea04765cd9c9aed7b839f15eb2b4" category="paragraph">Se ha demostrado que el uso de tramas gigantes ofrece alguna mejora del rendimiento en las redes 1GB al reducir la sobrecarga de la CPU y de la red, pero el beneficio no suele ser significativo.</block>
  <block id="ee3f364287a30ef10dfdce2f37d94ed2" category="admonition">*NetApp recomienda* implementar marcos jumbo cuando sea posible, tanto para obtener beneficios potenciales de rendimiento como para preparar la solución para el futuro.</block>
  <block id="2c6ba27b7ed602a9089da6ad9f762c9a" category="paragraph">El uso de tramas gigantes en una red 10Gb es casi obligatorio. Esto se debe a que la mayoría de las implementaciones de 10Gb alcanzan un límite de paquetes por segundo sin tramas gigantes antes de alcanzar la marca de 10Gb. El uso de tramas gigantes mejora la eficiencia del procesamiento TCP/IP porque permite que el sistema operativo, el servidor, las NIC y el sistema de almacenamiento procesen menos paquetes, pero más grandes. La mejora del rendimiento varía de NIC a NIC, pero es significativa.</block>
  <block id="a44be1bbfde97e4a64b50282325165e7" category="paragraph">En las implementaciones de tramas gigantes, existe la creencia común, aunque incorrecta, de que todos los dispositivos conectados deben admitir tramas gigantes y que el tamaño de MTU debe coincidir de extremo a extremo En su lugar, los dos extremos de red negocian el tamaño de trama más alto mutuamente aceptable al establecer una conexión. En un entorno típico, un switch de red se establece con un tamaño de MTU de 9216, la controladora NetApp se establece en 9000 y los clientes se configuran con una combinación de 9000 y 1514. Los clientes que admiten un MTU de 9000 pueden utilizar tramas gigantes, y los clientes que solo puedan admitir 1514 pueden negociar un valor inferior.</block>
  <block id="a31484167f31e1c3f36f7cea821bc581" category="paragraph">Los problemas con esta disposición son raros en un entorno completamente conmutado. Sin embargo, tenga cuidado en un entorno enrutado que ningún enrutador intermedio se vea forzado a fragmentar tramas gigantes.</block>
  <block id="c805e9846e6fca449dbe3233cc5dbdf5" category="paragraph">*NetApp recomienda* configurar lo siguiente:</block>
  <block id="b4446b5ca60d915111af271495bd4c17" category="list-text">Las tramas gigantes son deseables, pero no se requieren con Ethernet de 1GB Gb (GbE).</block>
  <block id="5b1ea13ac12a9c8be0d09303f637dba4" category="list-text">Se requieren tramas gigantes para lograr el máximo rendimiento, con 10GbE y más rápido.</block>
  <block id="08a8dce78637f5dd14ed052163feb9da" category="section-title">Parámetros de TCP</block>
  <block id="1a999618685598bee637262fe589de70" category="paragraph">A menudo hay tres ajustes mal configurados: Marcas de tiempo TCP, reconocimiento selectivo (SACK) y escalado de ventana TCP. Muchos documentos desactualizados en Internet recomiendan deshabilitar uno o varios de estos parámetros para mejorar el rendimiento. Había algo de mérito en esta recomendación hace muchos años, cuando las capacidades de la CPU eran mucho menores y había un beneficio en reducir la sobrecarga en el procesamiento TCP siempre que fuera posible.</block>
  <block id="6a594ec6f0bb742c1d2b0f631cf65ba1" category="paragraph">Sin embargo, con los sistemas operativos modernos, deshabilitar cualquiera de estas características de TCP generalmente no resulta en ningún beneficio detectable, a la vez que también puede dañar el rendimiento. Los daños en el rendimiento son especialmente probables en entornos de red virtualizados, ya que estas características son necesarias para gestionar eficazmente la pérdida de paquetes y los cambios en la calidad de la red.</block>
  <block id="cdc44d05b1633e8a8c7835010c423dd6" category="admonition">*NetApp recomienda* habilitar las marcas de tiempo TCP, EL SACK y el escalado de la ventana TCP en el host, y los tres parámetros deben estar activados por defecto en cualquier sistema operativo actual.</block>
  <block id="72a921ac9177188a9be32ec711fc15d8" category="doc">Acceso a la ruta</block>
  <block id="a73743f15de974052b0640c60f489d90" category="paragraph">En la práctica, es similar a una versión granular de MetroCluster porque permite una replicación síncrona selectiva y granular RPO=0 para cargas de trabajo individuales. El comportamiento de la ruta de bajo nivel es muy diferente del MetroCluster, pero el resultado final desde el punto de vista del host es similar.</block>
  <block id="cbf0bd4f4096570f567049c984f8c9d3" category="paragraph">La ruta de dispositivo que es la más corta para acceder a I/O se considera como rutas activas/optimizadas y el resto de las rutas se consideran rutas activas/no optimizadas.</block>
  <block id="341d84aa26cb4521474864e04ea2a63b" category="inline-image-macro">Error: Falta la imagen gráfica</block>
  <block id="b56265ceb6311e42003e668438136a59" category="section-title">Replicación síncrona</block>
  <block id="0cf4a786acebd750bbfdfc4416c89406" category="section-title">Hardware de almacenamiento</block>
  <block id="ea9f3de5dd21190fbc6bca180b2040f1" category="section-title">Mediador ONTAP</block>
  <block id="0f54fb931dbdeea735f18a8e73f9eab5" category="doc">Protección de datos con SyncMirror</block>
  <block id="d7023f86951b6c3c009891a468c3effd" category="paragraph">En el nivel más sencillo, la replicación síncrona implica que se debe realizar cualquier cambio en ambas partes del almacenamiento reflejado antes de que se reconozca. Por ejemplo, si una base de datos está escribiendo un registro o se está aplicando la revisión a un invitado VMware, no se debe perder nunca una escritura. Como nivel de protocolo, el sistema de almacenamiento no debe reconocer la escritura hasta que se haya comprometido a medios no volátiles en ambos sitios. Solo entonces es seguro proceder sin el riesgo de pérdida de datos.</block>
  <block id="eee4f7a4e0ed3a8646a97bcf3e118fb9" category="paragraph">El uso de una tecnología de replicación síncrona es el primer paso para diseñar y gestionar una solución de replicación síncrona. Lo más importante es comprender qué podría suceder durante varios escenarios de fallos planificados y no planificados. No todas las soluciones de replicación síncrona ofrecen las mismas funcionalidades. Si necesita una solución que proporcione un objetivo de punto de recuperación (RPO) de cero, lo que significa cero pérdida de datos, deben tenerse en cuenta todos los escenarios de fallo. En particular, ¿cuál es el resultado esperado cuando la replicación es imposible debido a la pérdida de conectividad entre sitios?</block>
  <block id="71554672a088c43ab21c759ddd161928" category="section-title">Disponibilidad de datos SyncMirror</block>
  <block id="8646bb558f8f18a200cce2f70602627a" category="paragraph">SyncMirror no solo puede salir del modo síncrono sin problemas si no se puede acceder al sitio remoto, sino que también puede volver a sincronizar rápidamente con un estado RPO = 0 cuando se restaura la conectividad. La copia obsoleta de los datos en el sitio remoto también se puede conservar en estado utilizable durante la resincronización, lo que garantiza la existencia de copias locales y remotas de los datos en todo momento.</block>
  <block id="995f5151d2d1c0a4e8371b2b3c9b6e5b" category="paragraph">Cuando se requiere el modo domino, NetApp ofrece SnapMirror síncrono (SM-S). También existen opciones de nivel de aplicación, como Oracle DataGuard o timeouts ampliados para el mirroring de discos del host. Consulte con su equipo de cuentas de partner o de NetApp para obtener más información y opciones.</block>
  <block id="1d12d7a206d9b5337ae6fa442f23d377" category="doc">Solo Snapshot</block>
  <block id="64c29f2f2feedeb607ff588b13d9758b" category="paragraph">La<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block><block ref="964193481f440d73ce3474a7a09bc3ac" prefix=" " category="inline-code"></block> se aplica sólo a los bloques que no se comparten con el sistema de archivos activo. Básicamente, provoca la organización en niveles de los backups de las bases de datos. Los bloques se convierten en candidatos para organizar por niveles después de que se crea una copia Snapshot y se sobrescribe el bloque, lo que genera un bloque que solo existe dentro de la copia Snapshot. El retraso antes de a.<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> el bloque se considera frío y está controlado por el<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> configuración para el volumen. El intervalo a partir de ONTAP 9,8 es de 2 a 183 días.</block>
  <block id="ebd9889c847a7a3ddeccd2717ead46f2" category="paragraph">Muchos conjuntos de datos tienen tasas de cambio bajas, lo que resulta en un ahorro mínimo de esta política. Por ejemplo, una base de datos típica observada en ONTAP tiene una tasa de cambio inferior al 5% a la semana. Los archive logs de la base de datos pueden ocupar mucho espacio, pero normalmente continúan existiendo en el sistema de archivos activo y, por lo tanto, no serían candidatos para la organización en niveles bajo esta política.</block>
  <block id="06b9281e396db002010bde1de57262eb" category="section-title">Automático</block>
  <block id="ecf602bd5abbd6a605debedbb6c3d4e0" category="paragraph">La<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la política de organización en niveles amplía la clasificación por niveles tanto a bloques específicos de snapshots como a bloques del sistema de archivos activo. El retardo antes de que un bloque se considere frío es controlado por el<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> configuración para el volumen. El intervalo a partir de ONTAP 9,8 es de 2 a 183 días.</block>
  <block id="6256ce48698ff0bde6f818679cdfb382" category="paragraph">Este método permite opciones de organización en niveles que no están disponibles con el<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> política. Por ejemplo, una política de protección de datos puede requerir 90 días de ciertos archivos de registro para ser retenidos. Si se establece un período de enfriamiento de 3 días, los archivos de registro anteriores a 3 días se almacenarán en niveles desde la capa de rendimiento. Esta acción libera espacio considerable en el nivel de rendimiento a la vez que le permite ver y gestionar los 90 días completos de datos.</block>
  <block id="6adf97f83acf6453d4a6a4b1070f3754" category="section-title">Ninguno</block>
  <block id="7026ff5c5d4ab3946ff2d86f0e2cca6f" category="paragraph">La<block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix=" " category="inline-code"></block> la política de organización en niveles evita que cualquier bloque adicional se organice en niveles desde la capa de almacenamiento, pero todos los datos que permanezcan en el nivel de capacidad permanecen en el nivel de capacidad hasta que se leen. Si a continuación se lee el bloque, se retira y se coloca en el nivel de rendimiento.</block>
  <block id="d152c7b0939fb6d35fdb0433de0d6369" category="paragraph">El motivo principal para utilizar el<block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix=" " category="inline-code"></block> la política de organización en niveles es para evitar que los bloques se organicen en niveles, pero podría resultar útil cambiar las políticas con el tiempo. Por ejemplo, pongamos por caso que un conjunto de datos concreto se organiza ampliamente en niveles en la capa de capacidad, pero surge una necesidad inesperada de funcionalidades de rendimiento completas. La política se puede cambiar para evitar cualquier organización en niveles adicional y para confirmar que los bloques que se lean a medida que los aumentos de I/O permanecen en el nivel de rendimiento.</block>
  <block id="b1c94ca2fbc3e78fc30069c8d0f01680" category="section-title">Todo</block>
  <block id="84826d7e23dfac7549819d5115fdcedd" category="paragraph">La<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> la política de organización en niveles reemplaza el<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> Normativa a partir de ONTAP 9,6. La<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> Política aplicada solo a los volúmenes de protección de datos, lo que significa un destino de SnapMirror o NetApp SnapVault. La<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> la política funciona de la misma manera, pero no se limita a los volúmenes de protección de datos.</block>
  <block id="10d8500e282e8bbacd668af6f773f412" category="paragraph">Con esta política, los bloques se consideran inmediatamente inactivos y elegibles para organizarse en niveles en la capa de capacidad de inmediato.</block>
  <block id="ec583de0216b95bc673c84e4ec9356e6" category="paragraph">Esta política resulta especialmente adecuada para backups a largo plazo. También se puede utilizar como una forma de gestión de almacenamiento jerárquico (HSM). Anteriormente, se utilizaba HSM para organizar en niveles los bloques de datos de un archivo en cinta y, al mismo tiempo, mantener el propio archivo visible en el sistema de archivos. Un volumen FabricPool con el<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> la política le permite almacenar archivos en un nivel visible y gestionable pero consume prácticamente ningún espacio en el nivel de almacenamiento local.</block>
  <block id="79768a069a539d4f130e672a660bf45f" category="doc">División en zonas</block>
  <block id="a0bdb98e8b9da585816478d24278e42f" category="paragraph">Una zona de FC nunca debe contener más de un iniciador. Tal arreglo puede parecer funcionar inicialmente, pero la comunicación entre iniciadores finalmente interfiere con el rendimiento y la estabilidad.</block>
  <block id="8ef958d9e25538841b306960ab117626" category="paragraph">Las zonas multidestino se consideran generalmente seguras, aunque en raras ocasiones el comportamiento de los puertos de destino FC de diferentes proveedores ha causado problemas. Por ejemplo, evite incluir los puertos de destino de una cabina de almacenamiento NetApp y otra que no sea de NetApp en la misma zona. Además, es aún más probable que la ubicación de un sistema de almacenamiento NetApp y un dispositivo de cinta en la misma zona cause problemas.</block>
  <block id="642223473862db290604321fe2ebe763" category="doc">SVM</block>
  <block id="47ea917cf14ad91c68c407f90a7a189d" category="paragraph">Una SVM, conocida como Vserver en la interfaz de línea de comandos de ONTAP, es una unidad funcional básica de almacenamiento, lo que resulta útil comparar una SVM con una máquina virtual «guest» en un servidor VMware ESX.</block>
  <block id="13ce2622b2cc2118c44d3aae7df8167d" category="paragraph">Al igual que otros aspectos de la arquitectura de almacenamiento, las mejores opciones para el diseño de SVM y de la interfaz lógica (LIF) dependen en gran medida de los requisitos de escalado y las necesidades del negocio.</block>
  <block id="8fb41a27984f0beba2e12fb920a486aa" category="paragraph">No existe ninguna práctica recomendada oficial para el aprovisionamiento de SVM para ONTAP. El método correcto depende de los requisitos de gestión y seguridad.</block>
  <block id="f4d8541bb6d07f7533a6b5aa6cfb2455" category="paragraph">La mayoría de los clientes operan un SVM principal para la mayoría de sus requisitos diarios y después crean un número pequeño de SVM para necesidades especiales. Por ejemplo, es posible que desee crear:</block>
  <block id="259908e9e431c0fbb9d425249ceb7930" category="list-text">SVM para una base de datos empresarial crítica gestionada por un equipo especializado</block>
  <block id="0e10f2715884f3538282397d69b2cd00" category="list-text">Una SVM para un grupo de desarrollo al que se le ha otorgado un control administrativo completo para que pueda gestionar su propio almacenamiento de forma independiente</block>
  <block id="7624156e307247e4ea1ec8bf574136a1" category="list-text">Una máquina virtual de almacenamiento SVM para datos empresariales confidenciales, como datos de recursos humanos o informes financieros, a los que debe limitarse el equipo administrativo</block>
  <block id="e5e09031843479ef9ef8cbbd4c2f404c" category="inline-link-macro">Hardware Universe de NetApp</block>
  <block id="fb012f1e7970d8285bd5d6c5a7f7d523" category="doc">Agregados SSD, incluidos los sistemas AFF</block>
  <block id="cb8e4651c457f71d5788f38eac01471f" category="paragraph">El espacio libre se define como el espacio que no se usa para datos reales e incluye espacio sin asignar en el propio agregado y el espacio no utilizado dentro de los volúmenes constituyentes. También se debe tener en cuenta el thin provisioning. Por ejemplo, un volumen puede contener 1TB 000 LUN de las cuales solo el 50% es utilizado por datos reales. En un entorno con thin provisioning, parece que esto consume 500GB TB de espacio de manera correcta. Sin embargo, en un entorno totalmente aprovisionado, parece que toda la capacidad de 1TB está en uso. Los 500GB GB de espacio no asignado están ocultos. Los datos reales no utilizan este espacio y, por lo tanto, debe incluirse en el cálculo del espacio libre total.</block>
  <block id="d3487661d9a0702bd5915d49070f62dc" category="paragraph">Las recomendaciones de NetApp para los sistemas de almacenamiento que se utilizan para aplicaciones empresariales son las siguientes:</block>
  <block id="678e476783bceae80094bcb4c1f32969" category="admonition">*NetApp recomienda* un mínimo de 10% de espacio libre. Esto incluye todo el espacio no utilizado, incluido el espacio libre dentro del agregado o un volumen y cualquier espacio libre que se asigne debido al uso de aprovisionamiento completo, pero que los datos reales no usan. El espacio lógico no es importante, la pregunta es cuánto espacio físico libre real está disponible para el almacenamiento de datos.</block>
  <block id="2171d172d184f1202a686849c85dce91" category="paragraph">La recomendación de un 10% de espacio libre es muy conservadora. Los agregados SSD pueden admitir cargas de trabajo con niveles de utilización aún mayores sin afectar en absoluto al rendimiento. No obstante, a medida que aumenta el uso del agregado, también aumenta el riesgo de quedarse sin espacio si no se supervisa el uso de forma cuidadosa. Además, aunque ejecutar un sistema a un 99 % de capacidad puede que no afecte al rendimiento, probablemente se traduciría en un esfuerzo de gestión al intentar evitar que se llene completamente mientras se solicita hardware adicional. Además, la adquisición e instalación de unidades adicionales puede demorar algún tiempo.</block>
  <block id="789243e17acb0b134f435d6c4c1350f2" category="section-title">Agregados de HDD, incluidos los agregados de Flash Pool</block>
  <block id="7302e9f16fb8c5bc30f6035fe4098b52" category="admonition">*NetApp recomienda* un mínimo de 15% de espacio libre cuando se utilizan unidades giratorias. Esto incluye todo el espacio no utilizado, incluido el espacio libre dentro del agregado o un volumen y cualquier espacio libre que se asigne debido al uso de aprovisionamiento completo, pero que los datos reales no usan. El rendimiento se verá afectado en los enfoques de libertad de expresión al 10%.</block>
  <block id="0b0a68e2dedde9c0b9a3ea4276f4b85c" category="paragraph">La<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la política más adecuada para los datos de backup. Esto garantiza la clasificación por niveles de avisos cuando se ha alcanzado el umbral de enfriamiento independientemente de si los archivos se han suprimido o siguen existiendo en el sistema de archivos primario. También simplifica la gestión almacenar todos los archivos potencialmente necesarios en una sola ubicación del sistema de archivos activo. No hay razón para buscar a través de instantáneas para localizar un archivo que necesita ser restaurado.</block>
  <block id="11a75a1257cc68a4a46bc553dabe0c0d" category="paragraph">La<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> la política podría funcionar, pero esa política solo se aplica a los bloques que ya no están en el sistema de archivos activo. Por lo tanto, los archivos en un recurso compartido NFS o SMB deben eliminarse primero para poder organizar los datos en niveles.</block>
  <block id="b4af96e8cea99b56592db816cab30fce" category="paragraph">Esta política sería aún menos eficiente con una configuración de LUN porque la eliminación de un archivo de una LUN solo elimina las referencias de archivos de los metadatos del sistema de archivos. Los bloques reales de las LUN permanecen en su lugar hasta que se sobrescriben. Esta situación puede crear un retraso prolongado entre el momento en que se elimina un archivo y el tiempo que se sobrescriben los bloques y se convierten en candidatos para la organización en niveles. El traslado de la<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> Bloques en el nivel de capacidad pero, en general, la gestión de datos de backup de FabricPool funciona mejor con el<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> política.</block>
  <block id="1c237d1ebcdeff13ae0145c741d9401d" category="admonition">Este enfoque ayuda a los usuarios a gestionar el espacio necesario para los backups de una forma más eficiente, pero el propio FabricPool no es una tecnología de backup. La organización en niveles de los archivos de backup en el almacén de objetos simplifica la gestión, ya que los archivos siguen visibles en el sistema de almacenamiento original, pero los bloques de datos del destino del almacén de objetos dependen del sistema de almacenamiento original. Si se pierde el volumen de origen, los datos del almacén de objetos ya no se pueden usar.</block>
  <block id="a19665c8f7c0210f96ad2934ad0ee361" category="paragraph">En un sistema ONTAP, el almacenamiento se organiza en 4KB unidades. Un bloque 8KB de base de datos o sistema de archivos debe asignarse exactamente a dos bloques de 4KB KB. Si un error de configuración de una LUN cambia la alineación 1KB en cualquier dirección, cada bloque de 8KB KB existiría en tres bloques de almacenamiento de 4KB KB diferentes en lugar de dos. Esta disposición provocaría una mayor latencia y provocaría la realización de I/O adicionales en el sistema de almacenamiento.</block>
  <block id="211a9fe299057fe8665b591dddbac56d" category="paragraph">La alineación también afecta a las arquitecturas LVM. Si se define un volumen físico de un grupo de volúmenes lógicos en todo el dispositivo de la unidad (no se crean particiones), el primer bloque de 4KB KB del LUN se alinea con el primer bloque de 4KB KB del sistema de almacenamiento. Esta es una alineación correcta. Los problemas surgen con las particiones porque cambian la ubicación inicial en la que el sistema operativo utiliza la LUN. Siempre que la compensación se desplaza en unidades enteras de 4KB, la LUN se alinea.</block>
  <block id="7c8a0aad1f59988f8160921a07203bb4" category="paragraph">En entornos Linux, cree grupos de volúmenes lógicos en todo el dispositivo de la unidad. Cuando se necesita una partición, compruebe la alineación ejecutando<block ref="16ae8c2dc7757a3180ce37bad780251a" prefix=" " category="inline-code"></block> y verificando que el inicio de cada partición es un múltiplo de ocho. Esto significa que la partición comienza en un múltiplo de ocho sectores de 512 bytes, que es 4KB.</block>
  <block id="e98a692d783d8d778aab49ed4c55e214" category="doc">Protección contra errores del sitio: NVRAM y MetroCluster</block>
  <block id="186577daf29184ed8a55cf899ba2979c" category="paragraph">MetroCluster amplía la protección de datos de NVRAM de las siguientes formas:</block>
  <block id="679f5a5873d7d3378cf4b3035fd5cb13" category="list-text">En una configuración de dos nodos, los datos de la NVRAM se replican mediante los enlaces Inter-Switch (ISL) al compañero remoto.</block>
  <block id="00bec98f52b9151dd2e0c760becd4ca8" category="list-text">En una configuración de par de alta disponibilidad, los datos de NVRAM se replican tanto en el partner local como en el remoto.</block>
  <block id="94deccfbf8f798c1661000b27a568b18" category="list-text">La escritura no se reconoce hasta que se replica a todos los partners. Esta arquitectura protege la I/O en tránsito de fallos del sitio mediante la replicación de los datos de NVRAM en un partner remoto. Este proceso no está relacionado con la replicación de datos a nivel de unidad. La controladora propietaria de los agregados se encarga de la replicación de datos escribiendo en ambos complejos del agregado, pero seguirá habiendo protección contra la pérdida de I/O en tránsito en caso de pérdida del sitio. Los datos de NVRAM replicados solo se utilizan si una controladora asociada debe asumir el relevo de una controladora que ha fallado.</block>
  <block id="996aa1ed8a906e55c7f157a1643021b7" category="section-title">Protección frente a fallos de sitios y bandejas: SyncMirror y complejos</block>
  <block id="1c114a932963683e04dc7dece97c15c9" category="paragraph">SyncMirror es una tecnología de mirroring que mejora, pero no sustituye, RAID DP ni RAID-TEC. Refleja el contenido de dos grupos RAID independientes. La configuración lógica es la siguiente:</block>
  <block id="b4b4f1d65cb5f1370402220b00584e79" category="list-text">Las unidades se configuran en dos pools según la ubicación. Un pool se compone de todas las unidades en el sitio A, y el segundo pool se compone de todas las unidades en el sitio B.</block>
  <block id="418f0763b76bff8e324f1afdd5456b49" category="list-text">A continuación, se crea un pool de almacenamiento común, conocido como agregado, basado en conjuntos reflejados de grupos RAID. Se extrae un número igual de unidades en cada sitio. Por ejemplo, un agregado SyncMirror de 20 unidades estaría compuesto por 10 unidades del sitio A y 10 unidades del sitio B.</block>
  <block id="51bf74357f742acfa0a7cd11ce52ed7f" category="list-text">Cada conjunto de unidades en un sitio determinado se configura automáticamente como uno o varios grupos RAID DP o RAID-TEC completamente redundantes, independientemente del uso de mirroring. Este uso de RAID debajo del mirroring proporciona protección de datos incluso después de la pérdida de un sitio.</block>
  <block id="8a35ad1e53533c7a3a8ff427bda0deb2" category="paragraph"><block ref="8a35ad1e53533c7a3a8ff427bda0deb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="abf64dbc3ac20af1b4a30150a016ca58" category="paragraph">La figura anterior muestra una configuración de SyncMirror de ejemplo. Se creó un agregado de 24 unidades en la controladora con 12 unidades de una bandeja asignada en el sitio A y 12 unidades de una bandeja asignada en el sitio B. Las unidades se agruparon en dos grupos RAID reflejados. El grupo RAID 0 incluye un plex de 6 unidades en el sitio A reflejado en un plex de 6 unidades en el sitio B. Del mismo modo, el grupo RAID 1 incluye un plex de 6 unidades en el sitio A, duplicado en un plex de 6 unidades en el sitio B.</block>
  <block id="d9945e1dbadc87ba8e52a5e69376005c" category="paragraph">Normalmente, SyncMirror se utiliza para proporcionar mirroring remoto con sistemas MetroCluster, con una copia de los datos de cada sitio. En ocasiones, se ha utilizado para proporcionar un nivel adicional de redundancia en un único sistema. En particular, proporciona redundancia a nivel de bandeja. Una bandeja de unidades ya contiene fuentes de alimentación y controladoras duales y en general es poco más que chapa metálica, pero en algunos casos, la protección adicional puede estar garantizada. Por ejemplo, un cliente de NetApp ha puesto en marcha SyncMirror para una plataforma móvil de análisis en tiempo real que se usa durante las pruebas de automoción. El sistema se separó en dos racks físicos suministrados con fuentes de alimentación independientes y sistemas UPS independientes.</block>
  <block id="f3495a1e6cf563a617c71164f3b11ca3" category="section-title">Fallo de redundancia: NVFAIL</block>
  <block id="c7474a3ed1a224804e4741a256bdd953" category="paragraph">Como hemos visto anteriormente, la escritura no se reconoce hasta que se haya iniciado sesión en la NVRAM local y NVRAM en al menos otra controladora. Este método garantiza que un fallo de hardware o una interrupción del suministro eléctrico no provoquen la pérdida de operaciones de I/O en tránsito Si la NVRAM local falla o la conectividad a otros nodos falla, los datos ya no se reflejarían.</block>
  <block id="4774101e81ea03c43fe20e0d7f2d21d1" category="paragraph">El factor de control es si NVRAM está sincronizada. Si NVRAM está sincronizada, la conmutación al nodo de respaldo nodo a nodo se realizará de forma segura sin riesgo de pérdida de datos. En una configuración de MetroCluster, si la NVRAM y los complejos de agregado subyacentes están sincronizados, es seguro continuar con la conmutación de sitios sin riesgo de pérdida de datos.</block>
  <block id="03e97c023521445cd70307afabdcf0d5" category="paragraph">Las bases de datos y otras aplicaciones son especialmente vulnerables a las corrupción si se fuerza una conmutación al respaldo o conmutación por error porque mantienen cachés internos más grandes de datos en el disco. Si se produce un failover forzado o un switchover forzado, los cambios previamente reconocidos se descartan efectivamente. El contenido de la cabina de almacenamiento retrocede efectivamente en el tiempo y el estado de la caché ya no refleja el estado de los datos del disco.</block>
  <block id="ff7a32ed70b7df57dd29a3ed75e8c787" category="paragraph">Para evitar esta situación, ONTAP permite configurar volúmenes para una protección especial contra un fallo de NVRAM. Cuando se activa, este mecanismo de protección hace que un volumen entre en un estado denominado NVFAIL. Este estado provoca errores de I/O que provocan un bloqueo de la aplicación. Este bloqueo hace que las aplicaciones se cierren para que no utilicen datos obsoletos. No se deben perder los datos porque los datos de transacción confirmados deben estar presentes en los registros. Los siguientes pasos habituales son para que un administrador apague completamente los hosts antes de volver a poner manualmente los LUN y los volúmenes de nuevo en línea. Aunque estos pasos pueden implicar cierto trabajo, este enfoque es la manera más segura de garantizar la integridad de los datos. No todos los datos requieren esta protección, por lo que el comportamiento NVFAIL se puede configurar volumen por volumen.</block>
  <block id="637d4b37868fb7825461df6edd674158" category="section-title">Pares DE ALTA disponibilidad y MetroCluster</block>
  <block id="9d8738f531e6c6a809ba66315beaa2f4" category="paragraph">MetroCluster está disponible en dos configuraciones: De dos nodos y de pareja de alta disponibilidad. La configuración de dos nodos se comporta igual que un par de alta disponibilidad con respecto a NVRAM. En caso de que falle repentinamente, el nodo asociado puede reproducir los datos de NVRAM para hacer que las unidades sean coherentes y asegurarse de que no se ha perdido ninguna escritura reconocida.</block>
  <block id="936f4311b16ee4dc74a5564892f8976d" category="paragraph">La configuración de par de alta disponibilidad replica la NVRAM también en el nodo del partner local. Un fallo de controladora sencillo provoca una reproducción de NVRAM en el nodo de partner, como es el caso con un par de alta disponibilidad independiente sin MetroCluster. En caso de pérdida repentina del sitio completo, el sitio remoto también cuenta con la NVRAM necesaria para hacer que las unidades sean coherentes y empezar a servir datos.</block>
  <block id="83b6c3c3018b913ecf1aca67e0daa35e" category="paragraph">Un aspecto importante de MetroCluster es que los nodos remotos no tienen acceso a los datos de los partners en condiciones operativas normales. Cada sitio funciona esencialmente como un sistema independiente que puede asumir la personalidad del sitio opuesto. Este proceso es conocido como una conmutación de sitios e incluye una conmutación de sitios planificada en la que las operaciones del sitio se migran de forma no disruptiva al sitio opuesto. También incluye situaciones no planificadas en las que se pierde un sitio y se requiere una conmutación por error manual o automática como parte de la recuperación ante desastres.</block>
  <block id="58504b36cfdfd10d5f2802d7b943a379" category="section-title">Conmutación de sitios y conmutación de estado</block>
  <block id="d505751d1708fb5d57b0e23d089507a9" category="paragraph">Los términos conmutación y conmutación de estado hacen referencia al proceso de transición de volúmenes entre controladoras remotas en una configuración de MetroCluster. Este proceso solo se aplica a los nodos remotos. Cuando MetroCluster se utiliza en una configuración de cuatro volúmenes, la conmutación por error de nodo local es el mismo proceso de toma de control y devolución descrito anteriormente.</block>
  <block id="1127608e73df5ede22b149c8f19fc860" category="section-title">Conmutación de sitios y conmutación de estado planificadas</block>
  <block id="a6733335678588619c977608e891e54e" category="paragraph">Una conmutación de sitios o conmutación de estado planificada es similar a una toma de control o una conmutación al nodo primario entre nodos. El proceso tiene varios pasos y puede parecer que requiere varios minutos, pero lo que en realidad está sucediendo es una transición fluida multifase de los recursos de red y almacenamiento. El momento en que las transferencias de control se producen mucho más rápido que el tiempo necesario para que se ejecute el comando complete.</block>
  <block id="4bb5647dcff332f0b53819ecd631303c" category="paragraph">La principal diferencia entre toma de control/retorno al nodo primario y conmutación/conmutación de estado afecta a la conectividad SAN FC. Con la toma de control/devolución local, un host experimenta la pérdida de todas las rutas de FC hacia el nodo local y depende de su MPIO nativo para cambiar a las rutas alternativas disponibles. Los puertos no se reubican. Con la conmutación de sitios y la conmutación de estado, los puertos de destino FC virtuales en las controladoras se transfieren al otro sitio. De hecho, dejan de existir en la SAN durante un momento y luego vuelven a aparecer en una controladora alternativa.</block>
  <block id="0ba902ec3f6ce91c2e801715bb8b96fa" category="section-title">Tiempo de espera de SyncMirror</block>
  <block id="9c8a1814b60b84d1aa68fa7bba69138b" category="paragraph">SyncMirror es una tecnología de mirroring de ONTAP que proporciona protección contra fallos de bandeja. Cuando las bandejas se separan a lo largo de una distancia, el resultado es la protección de datos remota.</block>
  <block id="68cf36f65a7e56ff3b6c0894be3ed9e8" category="paragraph">SyncMirror no ofrece mirroring síncrono universal. El resultado es una mejor disponibilidad. Algunos sistemas de almacenamiento utilizan mirroring constante todo o nada, llamado a veces modo domino. Esta forma de mirroring está limitada en la aplicación porque toda la actividad de escritura debe cesarse si se pierde la conexión con el sitio remoto. De lo contrario, una escritura existiría en un sitio, pero no en el otro. Normalmente, estos entornos están configurados para desconectar las LUN si se pierde la conectividad de sitio a sitio durante más de un breve período (como 30 segundos).</block>
  <block id="84ad4c21def9c355e80ef250d910bfa2" category="paragraph">Este comportamiento es deseable para un pequeño subconjunto de entornos. Sin embargo, la mayoría de las aplicaciones requieren una solución que ofrezca replicación síncrona garantizada en condiciones de funcionamiento normales, pero con la posibilidad de suspender la replicación. Con frecuencia, se considera una pérdida total de conectividad entre sitios como una situación próxima a un desastre. Normalmente, estos entornos se mantienen online y proporcionan datos hasta que se repare la conectividad o se tome una decisión formal para desactivar el entorno para proteger los datos. Un requisito para el apagado automático de la aplicación solo debido a un fallo de replicación remota es inusual.</block>
  <block id="e3bd381a7bbaee6c741aee230972acf4" category="paragraph">SyncMirror admite los requisitos de mirroring síncrono con la flexibilidad de un tiempo de espera agotado. Si se pierde la conectividad con el controlador remoto y/o plex, comienza la cuenta atrás con un temporizador de 30 segundos. Cuando el contador alcanza los 0, el procesamiento de I/O de escritura se reanuda utilizando los datos locales. La copia remota de los datos se puede utilizar, pero se congela en el tiempo hasta que se restaure la conectividad. La resincronización aprovecha las copias Snapshot de nivel agregado para que el sistema vuelva al modo síncrono lo más rápido posible.</block>
  <block id="0c919cd6511df6d83b811234b0448374" category="paragraph">Cabe destacar que, en muchos casos, este tipo de replicación universal modo domino integral se implementa mejor en el nivel de aplicación. Por ejemplo, Oracle DataGuard incluye el modo de protección máxima, que garantiza la replicación de instancias largas en todas las circunstancias. Si el enlace de replicación falla durante un período que supera un tiempo de espera configurable, las bases de datos se cierran.</block>
  <block id="ba92cbe464cfee8aa12c41e6aecd1071" category="section-title">Cambio automático desatendido con Fabric Attached MetroCluster</block>
  <block id="515094655d10031595da776c94b3d710" category="paragraph">La conmutación de sitios automática desatendida (AUSO) es una función MetroCluster conectada a estructuras que ofrece una forma de alta disponibilidad entre sitios. Como hemos visto anteriormente, MetroCluster está disponible en dos tipos: Una sola controladora en cada sitio o un par de alta disponibilidad en cada sitio. La principal ventaja de la opción de alta disponibilidad es que el apagado planificado o no planificado de la controladora sigue permitiendo que todas las operaciones de I/O sean locales. La ventaja de la opción de un único nodo es la reducción de los costes, la complejidad y la infraestructura.</block>
  <block id="29d4da26af76b66db3a172a39edf8367" category="paragraph">El principal valor de AUSO es mejorar las funciones de alta disponibilidad de los sistemas MetroCluster Fabric Attached. Cada sitio monitorea el estado del sitio opuesto y, si no quedan nodos para servir datos, AUSO da como resultado un cambio rápido. Este método es especialmente útil en configuraciones de MetroCluster con solo un solo nodo por sitio porque acerca la configuración a un par de alta disponibilidad en términos de disponibilidad.</block>
  <block id="6b3a5f7923b2d803fd3b28c255fef420" category="paragraph">AUSO no puede ofrecer una supervisión completa a nivel de un par de alta disponibilidad. Un par de alta disponibilidad puede proporcionar una disponibilidad extremadamente alta porque incluye dos cables físicos redundantes para una comunicación directa entre nodos. Además, ambos nodos de un par de alta disponibilidad tienen acceso al mismo conjunto de discos en bucles redundantes, lo cual proporciona otra ruta para un nodo para supervisar el estado de otro.</block>
  <block id="da87dad268507a3523bc38275b1d3fbc" category="paragraph">Los clústeres de MetroCluster existen en todos los sitios en los que tanto la comunicación nodo a nodo como el acceso a disco dependen de la conectividad de red sitio a sitio. La capacidad de supervisar los latidos del resto del clúster es limitada. AUSO tiene que discriminar entre una situación en la que el otro sitio está realmente inactivo en lugar de no disponible debido a un problema de red.</block>
  <block id="e8e4f55c4203e7fb24d4543a7a0f65da" category="paragraph">Como resultado, una controladora de un par de alta disponibilidad puede emitir una toma de control si detecta un fallo de controladora que se produjo por un motivo específico, como un motivo de pánico en el sistema. También puede solicitar una toma de control si hay una pérdida completa de conectividad, a veces conocida como latido del corazón perdido.</block>
  <block id="91aa4ce36cb243281f3777d66c8f89e0" category="paragraph">Un sistema MetroCluster solo puede realizar de forma segura una conmutación automática cuando se detecta una falla específica en el sitio original. Además, la controladora que tome la propiedad del sistema de almacenamiento debe poder garantizar que los datos del disco y NVRAM estén sincronizados. El controlador no puede garantizar la seguridad de un cambio solo porque perdió el contacto con el sitio de origen, que podría estar operativo. Para ver opciones adicionales para automatizar una conmutación de sitios, consulte la información sobre la solución tiebreaker de MetroCluster (MCTB) en la siguiente sección.</block>
  <block id="8e7705fe4aea384d7f6a99ab6dc0f408" category="section-title">Tiebreaker de MetroCluster con MetroCluster estructural</block>
  <block id="897b7698cb343dbc3452e845705ab0f3" category="inline-link">Tiebreaker de NetApp MetroCluster</block>
  <block id="9c093f14319e8253b8c9b37290597239" category="inline-link">Sitio de soporte de NetApp</block>
  <block id="a1d9fc4fb49119a9fe9b39abec0a769b" category="paragraph">La<block ref="9332969062716487f0feefe076babf99" category="inline-link-rx"></block> El software puede ejecutarse en un tercer sitio para supervisar el estado del entorno de MetroCluster, enviar notificaciones y, opcionalmente, forzar una conmutación de sitios en caso de desastre. Puede encontrar una descripción completa del tiebreaker en la<block ref="c21658567f794984b03c21186a56713d" category="inline-link-rx"></block>, Pero el propósito principal del MetroCluster tiebreaker es detectar la pérdida del sitio. También debe discriminar entre la pérdida del sitio y una pérdida de conectividad. Por ejemplo, la conmutación de sitios no debería ocurrir porque el tiebreaker no pudo llegar al sitio principal, por este motivo, tiebreaker también supervisa la capacidad del sitio remoto para comunicarse con el sitio principal.</block>
  <block id="6f29b1849750ceee5eb7f6f02d100e6b" category="paragraph">El cambio automático con AUSO también es compatible con el MCTB. AUSO reacciona muy rápidamente porque está diseñado para detectar eventos de fallo específicos y luego invocar la conmutación de sitios solo cuando NVRAM y SyncMirror plexes están sincronizados.</block>
  <block id="6f5c7ae76595eca2ca83c5dd30cd8e9f" category="paragraph">Por el contrario, el desempate se encuentra de forma remota y, por lo tanto, debe esperar a que transcurra un temporizador antes de declarar un sitio muerto. El tiebreaker eventualmente detecta el tipo de fallo de la controladora cubierto por AUSO, pero en general AUSO ya ha iniciado la conmutación y posiblemente completado la conmutación antes de que actúe el tiebreaker. Se rechazaría el segundo comando de switchover resultante procedente del tiebreaker.</block>
  <block id="842547e1622bb12d9201167b0c39cf6d" category="paragraph">*Precaución: *El software MCTB no verifica que NVRAM estaba y/o los plexes estén sincronizados al forzar un cambio. La conmutación de sitios automática, si se configura, se debe deshabilitar durante actividades de mantenimiento que ocasionen la pérdida de sincronización para complejos de NVRAM o SyncMirror.</block>
  <block id="7110edd59c3d0f25a584723f6fea26a0" category="paragraph">Además, es posible que el MCTB no solucione un desastre que lleve a la siguiente secuencia de eventos:</block>
  <block id="93d732b784eaf1a323f191e75c10f233" category="list-text">La conectividad entre sitios se interrumpe durante más de 30 segundos.</block>
  <block id="81d4275cc3534a9fa8cfdcdb5172eb94" category="list-text">Se agota el tiempo de espera de la replicación de SyncMirror y las operaciones continúan en el sitio principal, dejando la réplica remota obsoleta.</block>
  <block id="44441f68631008a941ce92e985131ff9" category="list-text">Se pierde el sitio principal.El resultado es la presencia de cambios no replicados en el sitio principal. Una conmutación de sitios puede ser indeseable por varios motivos, entre los que se incluyen los siguientes:</block>
  <block id="499527dd40fad77b119b8b33c99cd614" category="list-text">Pueden haber datos cruciales en el sitio principal y esos datos podrían ser recuperables en algún momento. Un cambio que permitiera a la aplicación seguir funcionando descartaría esos datos cruciales.</block>
  <block id="86de4e3737e3d871dacf8ffef353fc31" category="list-text">Una aplicación del sitio superviviente que utilizaba recursos de almacenamiento en el sitio principal en el momento de la pérdida del sitio podría haber almacenado datos en caché. Un switchover introduciría una versión obsoleta de los datos que no coincide con la caché.</block>
  <block id="dbb2a01afe28c8310daf781bb80b795f" category="list-text">Un sistema operativo del sitio superviviente que utilizaba recursos de almacenamiento en el sitio principal en el momento de la pérdida del sitio podría haber almacenado los datos en caché. Un switchover introduciría una versión obsoleta de los datos que no coincide con la caché. La opción más segura es configurar el tiebreaker para que envíe una alerta si detecta un fallo del sitio y luego hacer que una persona tome una decisión sobre si forzar un cambio. Es posible que las aplicaciones o los sistemas operativos deban apagarse primero para borrar cualquier dato almacenado en caché. Además, la configuración NVFAIL puede usarse para agregar más protección y ayudar a simplificar el proceso de conmutación por error.</block>
  <block id="ec6b0ea9c511479c118aa0f028f6519d" category="section-title">Mediador ONTAP con MetroCluster IP</block>
  <block id="8ada6a626a475d631df231bbb3a88ac9" category="paragraph">El Mediador ONTAP se utiliza con MetroCluster IP y otras soluciones ONTAP. Funciona como un servicio tradicional de tiebreaker, muy similar al software MetroCluster tiebreaker de referencia anteriormente, pero también incluye una característica crítica, con la posibilidad de realizar una conmutación de sitios automatizada sin supervisión.</block>
  <block id="991d7d7d7388ccdd87c65ca09aa804f2" category="paragraph">Una MetroCluster conectada a estructura tiene acceso directo a dispositivos de almacenamiento en el sitio opuesto. Esto permite que una controladora MetroCluster supervise el estado de las otras controladoras mediante la lectura de datos de latidos de las unidades. Esto permite que una controladora reconozca el fallo de otra controladora y realizar una conmutación por error.</block>
  <block id="db2e932a11478bcf14c75d38e8b9a170" category="paragraph">Por el contrario, la arquitectura IP de MetroCluster enruta todas las I/O de forma exclusiva a través de la conexión del controlador; no hay acceso directo a los dispositivos de almacenamiento en el sitio remoto. Esto limita la capacidad de un controlador para detectar fallos y realizar una conmutación de sitios. Por lo tanto, el Mediador de ONTAP es necesario como dispositivo tiebreaker para detectar la pérdida del sitio y realizar automáticamente una conmutación.</block>
  <block id="8004e6d63f487a456290225b74768a6c" category="section-title">Tercer sitio virtual con ClusterLion</block>
  <block id="f1d5a7305654a402a719675fbec810e7" category="paragraph">ClusterLion es un dispositivo de supervisión MetroCluster avanzado que funciona como un tercer sitio virtual. Este enfoque permite implementar MetroCluster de forma segura en una configuración de dos sitios con capacidad de conmutación de sitios totalmente automatizada. Además, ClusterLion puede realizar una supervisión de nivel de red adicional y ejecutar operaciones posteriores a la conmutación. La documentación completa está disponible en ProLion.</block>
  <block id="a60b8f728a13371898fea9947ef1e0dc" category="paragraph"><block ref="a60b8f728a13371898fea9947ef1e0dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8aae92ec17ec82868ef9ffc767dbd03" category="list-text">Los dispositivos ClusterLion supervisan el estado de las controladoras con cables Ethernet y serie conectados directamente.</block>
  <block id="c5f8963a91e3d8e7ac0abda2eab9f17d" category="list-text">Los dos aparatos están conectados entre sí con conexiones inalámbricas redundantes de 3G.</block>
  <block id="24de16a13a1b584832d19117982cbfa6" category="list-text">La alimentación al controlador ONTAP se dirige a través de relés internos. En caso de un fallo del sitio, ClusterLion, que contiene un sistema UPS interno, corta las conexiones de alimentación antes de invocar un cambio. Este proceso garantiza que no se produzca ninguna condición cerebral dividida.</block>
  <block id="b2bcd3c3c555e2e4f27d453de4e0f06d" category="list-text">ClusterLion realiza un switchover dentro del tiempo de espera de SyncMirror de 30 segundos o no lo hace en absoluto.</block>
  <block id="390fb5f827a3fbcdc7d05e6e7db03223" category="list-text">ClusterLion no realiza una conmutación de sitios a menos que los estados de NVRAM y los complejos SyncMirror estén sincronizados.</block>
  <block id="f322f850d55e87946f9660e4ccb1bbb6" category="list-text">Dado que ClusterLion solo realiza una operación de switchover si MetroCluster está totalmente sincronizado, no es necesario NVFAIL. Esta configuración permite que los entornos de expansión de sitios, como un Oracle RAC ampliado, permanezcan en línea, incluso durante una conmutación de sitios no planificada.</block>
  <block id="5c132e05fb0e306f56955603619de359" category="list-text">El soporte incluye MetroCluster FAS e MetroCluster IP</block>
  <block id="86bcf99dbc3944da56f06b48074d09f6" category="doc">Funcionamiento normal</block>
  <block id="e48472f7daf781b63506f9e296443027" category="paragraph">En el funcionamiento normal se puede acceder a una LUN desde la réplica local o remota. La línea roja indica la ruta optimizada tal y como anuncia ALUA, y el resultado debe ser que I/O se envíe preferentemente por esta ruta.</block>
  <block id="e139a585510a502bbf1841cf589f5086" category="section-title">Fallo</block>
  <block id="7ed516552b652790c92df0bf237264b2" category="paragraph">Si la copia mirror activa deja de estar disponible, ya sea debido a una conmutación por error planificada o no planificada, obviamente ya no podrá utilizarse. Sin embargo, el sistema remoto posee una réplica síncrona y rutas SAN al sitio remoto ya existen. El sistema remoto puede dar servicio a I/O para esa LUN.</block>
  <block id="7388404ef116c3ff812bfd290b094d9e" category="section-title">Conmutación al respaldo</block>
  <block id="997dfe060d2107e84407cfb41e692c54" category="paragraph">La conmutación por error hace que la copia remota se convierta en la copia activa. Las rutas se cambian de Activo a Activo/Optimizado y el I/O se sigue prestando servicio sin pérdida de datos.</block>
  <block id="0493d27e20d11e356e53e0a730b0ad08" category="section-title">Reparar</block>
  <block id="6d80a3efb80520f47b63dc279e1bea3d" category="section-title">Conmutación tras recuperación</block>
  <block id="d47f47372b9b94d274cceb3638b28845" category="paragraph">Si lo desea, un administrador puede realizar una conmutación de retorno tras recuperación y mover la copia activa de las LUN a las controladoras originales.</block>
  <block id="0c99cedb6f39d8ac16d5b4c01c162c23" category="paragraph">El registro de rehacer/transacciones de bases de datos normalmente genera I/O no alineadas que pueden provocar advertencias engañosas acerca de las LUN mal alineadas en ONTAP.</block>
  <block id="b2f7bb8e75b21ee3e883141c6ac1defe" category="paragraph">El registro realiza una escritura secuencial del archivo log con escrituras de tamaño variable. Una operación de escritura de registro que no se alinea con los límites de 4KB no provoca problemas de rendimiento normalmente, ya que la próxima operación de escritura de registro completa el bloque. El resultado es que ONTAP es capaz de procesar casi todas las escrituras de bloques de 4KB KB completos, aunque los datos de algunos bloques de 4KB KB se hayan escrito en dos operaciones independientes.</block>
  <block id="0e635e1f8ffad809203304cf41ed45c4" category="inline-link-macro">Verificación de la alineación de WAFL</block>
  <block id="bf837d24f10c904e697e3c0092da43b9" category="paragraph">Verifique la alineación mediante el uso de utilidades como<block ref="40883add63f1fbabc7fe6158f93c1246" prefix=" " category="inline-code"></block> o.<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> Que puede generar I/O en un tamaño de bloque definido. Las estadísticas de alineación de I/O del sistema de almacenamiento se pueden ver con<block ref="446501053769c06c565094b26d26e8ef" prefix=" " category="inline-code"></block> comando. Consulte <block ref="ebccec7997af507c87f985ec4ccec634" category="inline-link-macro-rx"></block> si quiere más información.</block>
  <block id="b5ffbfb0c082804ad41d0f61c87525ed" category="paragraph">Muchas aplicaciones están organizadas por fecha, y por lo general es menos probable que se acceda a estos datos a medida que envejecen. Por ejemplo, un banco puede tener un repositorio de archivos PDF que contenga cinco años de extractos de clientes, pero sólo están activos los últimos meses. FabricPool se puede usar para reubicar archivos de datos más antiguos en el nivel de capacidad. Un período de enfriamiento de 14 días garantizaría que los 14 días más recientes de archivos PDF permanezcan en el nivel de rendimiento. Además, los archivos que se leen al menos cada 14 días permanecerán activos y, por consiguiente, permanecerán en el nivel de rendimiento.</block>
  <block id="ed7e2cc7ff107d4b2032fe65cf4e756a" category="paragraph">Para implementar un método de organización en niveles basado en archivos, debe tener archivos que se escriban y no se modifiquen posteriormente. La<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la política debe establecerse lo suficientemente alta para que los archivos que pueda necesitar permanezcan en el nivel de rendimiento. Por ejemplo, un conjunto de datos para los que se requieren los 60 días de datos más recientes y un rendimiento óptimo garantiza configurar el<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> hasta 60. También se pueden obtener resultados similares en función de los patrones de acceso a archivos. Por ejemplo, si se requieren los últimos 90 días de datos y la aplicación accede a ese intervalo de 90 días, los datos permanecerán en el nivel de rendimiento. Mediante la configuración de<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> en el periodo 2, se obtiene una organización en niveles inmediata después de que los datos se vuelven menos activos.</block>
  <block id="8a467b35326e4738b1bd39865c3b21a0" category="admonition">Cualquier tipo de acceso a los datos restablece los datos del mapa de calor. La detección de virus, la indexación e incluso la actividad de backup que lee los archivos de origen evita la segmentación, ya que es necesario<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> nunca se ha alcanzado el umbral.</block>
  <block id="7a1920d61156abc05a60135aefe8bc67" category="doc">Predeterminado</block>
  <block id="5ba46d288640832c345e169b04a7458a" category="paragraph">Inicialmente, todos los volúmenes FabricPool se establecen en<block ref="c21f969b5f03d33d43e04f8f136e7682" prefix=" " category="inline-code"></block>, que significa que el comportamiento está controlado por la `política de recuperación de nubes. `El comportamiento exacto depende de la política de organización en niveles utilizada.</block>
  <block id="5ec354970d7934d92ba67ccaa0de0121" category="list-text"><block ref="9df22f196a33acd0b372fe502de51211" prefix="" category="inline-code"></block>– solo recuperar datos de lectura aleatoria</block>
  <block id="74092cfa5efab8e6ddc5c2991ee2cfc9" category="list-text"><block ref="8805d416ce540c5f2df34af5b18d742b" prefix="" category="inline-code"></block>– recuperar todos los datos de lectura secuencial o aleatoria</block>
  <block id="2de036541477f953c6fd33d14a8db0e8" category="list-text"><block ref="334c4a4c42fdb79d7ebc3e73b517e6f8" prefix="" category="inline-code"></block>– recuperar todos los datos de lectura secuencial o aleatoria</block>
  <block id="b6ffdb7ccf86e99ecf73899ec23bdd46" category="list-text"><block ref="a181a603769c1f98ad927e7367c7aa51" prefix="" category="inline-code"></block>– no recuperar datos del nivel de capacidad</block>
  <block id="d556a0d2cad80695d1d803ebb49de9cd" category="section-title">En lectura</block>
  <block id="7c39eb141ca855e5a211b468bd67636c" category="paragraph">Ajuste<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> en la lectura sobrescribe el comportamiento predeterminado, de modo que la lectura de cualquier dato por niveles provoca que esos datos se devuelvan al nivel de rendimiento.</block>
  <block id="e07df43ea07fecb178484ef278644eb2" category="paragraph">Por ejemplo, es posible que un volumen se haya usado ligeramente durante mucho tiempo en<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la política de organización en niveles y la mayoría de los bloques están ahora organizados en niveles.</block>
  <block id="98c8614a9e0467f220df33a02cf7550a" category="paragraph">Si un cambio inesperado en las necesidades empresariales requirió que algunos de los datos se escanearan repetidamente para preparar un determinado informe, puede ser conveniente cambiar el<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> para<block ref="0ba0dc933ac714a0bef4467360437336" prefix=" " category="inline-code"></block> para garantizar que todos los datos que se leen se devuelven al nivel de rendimiento, incluidos datos de lectura secuencial y aleatoria. Esto mejoraría el rendimiento de I/O secuenciales en el volumen.</block>
  <block id="3ea4ba4aadef21fbda74c9b242c99efa" category="section-title">Promocione</block>
  <block id="cb674c0cbcbaa23bdd3c8e4f6182f865" category="paragraph">El comportamiento de la política de promoción depende de la política de organización en niveles. Si la política de organización en niveles es<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block>, y, a continuación, ajuste el<block ref="723c2b1883eb9949dd821267c2d1b5c7" prefix=" " category="inline-code"></block> devuelve todos los bloques del nivel de capacidad en el siguiente análisis de organización en niveles.</block>
  <block id="452d85cc34fd3a4cf55ac61e732239f4" category="paragraph">Si la política de organización en niveles es<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block>, entonces, los únicos bloques que se devuelven son los bloques asociados al sistema de archivos activo. Normalmente, esto no tendría ningún efecto porque los únicos bloques organizados en niveles en<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> la política sería bloques asociados exclusivamente a las instantáneas. No habría bloques por niveles en el sistema de archivos activo.</block>
  <block id="d6269fb1a970b6c261fedbc79464b3dc" category="paragraph">Sin embargo, si un SnapRestore de volumen o una operación de clonado de archivos se restauraron los datos de un volumen desde una copia Snapshot, es posible que algunos de los bloques organizados en niveles debido a que solo estaban asociados a snapshots ahora sean requeridos por el sistema de archivos activo. Puede ser conveniente cambiar temporalmente el<block ref="d253e682212338dd6cbe577947f0511e" prefix=" " category="inline-code"></block> política a.<block ref="eeefc0add5ccd6e20ac4214923d27fbc" prefix=" " category="inline-code"></block> para recuperar rápidamente todos los bloques necesarios localmente.</block>
  <block id="6e7b34fa59e1bd229b207892956dc41c" category="section-title">Nunca</block>
  <block id="c45e30a0f86af155e2feb17dd7ba6e44" category="paragraph">No recupere bloques del nivel de capacidad.</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="doc">Arquitectura</block>
  <block id="ac30d4a74ecef302adab70e9669a4bf2" category="paragraph">FabricPool es una tecnología de organización en niveles que clasifica los bloques como activos o inactivos y los coloca en el nivel de almacenamiento más adecuado. El nivel de rendimiento con mayor frecuencia se encuentra en el almacenamiento SSD y aloja los bloques de datos activos. El nivel de capacidad está ubicado en un almacén de objetos y aloja los bloques de datos inactivos. La compatibilidad de almacenamiento de objetos incluye NetApp StorageGRID, ONTAP S3, almacenamiento Microsoft Azure Blob, servicio de almacenamiento de objetos en el cloud de Alibaba, almacenamiento de objetos de IBM Cloud, almacenamiento de Google Cloud y Amazon AWS S3.</block>
  <block id="f9f5fe2f7456d37c955f3291744c93b6" category="paragraph">Existen varias políticas de organización en niveles disponibles que controlan la clasificación de los bloques como activos o inactivos, y las políticas se pueden establecer por volumen y modificar según sea necesario. Solo se mueven los bloques de datos entre los niveles de rendimiento y capacidad. Los metadatos que definen la LUN y la estructura del sistema de archivos siempre permanecen en el nivel de rendimiento. Como resultado, la gestión se centraliza en ONTAP. Los archivos y los LUN no aparecen diferentes de los datos almacenados en cualquier otra configuración de ONTAP. La controladora NetApp AFF o FAS aplica las políticas definidas para mover datos al nivel adecuado.</block>
  <block id="156a1cf692c4ba9a4f9574fb16428b01" category="paragraph"><block ref="156a1cf692c4ba9a4f9574fb16428b01" category="inline-image-macro-rx" type="image"></block></block>
  <block id="616ce0475334fe37834d13972a168ca5" category="section-title">Proveedores de almacenes de objetos</block>
  <block id="71e79501cc067e6b35ac3d3e97c940a4" category="paragraph">Los protocolos de almacenamiento de objetos utilizan solicitudes HTTP o HTTPS sencillas para almacenar grandes cantidades de objetos de datos. El acceso al almacenamiento de objetos debe ser fiable, porque el acceso a los datos desde ONTAP depende de atender solicitudes rápidamente. Entre las opciones se incluyen las opciones de acceso estándar y poco frecuente de Amazon S3, y Microsoft Azure Hot and Cool Blob Storage, IBM Cloud y Google Cloud. No se admiten opciones de archivado como Amazon Glacier y Amazon Archive porque el tiempo necesario para recuperar los datos puede superar las tolerancias de las aplicaciones y los sistemas operativos del host.</block>
  <block id="e114e830308285cd9085063fad91662c" category="paragraph">También se ofrece compatibilidad con NetApp StorageGRID y es una solución empresarial óptima. Es un sistema de almacenamiento de objetos de alto rendimiento, escalable y altamente seguro que puede proporcionar redundancia geográfica para los datos de FabricPool, así como otras aplicaciones de almacenamiento de objetos que tienen cada vez más probabilidades de formar parte de entornos de aplicaciones empresariales.</block>
  <block id="fb318c5cd9ed18c79e1f7a298dd96665" category="paragraph">StorageGRID también puede reducir los costes al evitar los cargos por salida que imponen muchos proveedores de cloud público por leer los datos de sus servicios.</block>
  <block id="119d8a1213b5b7cae4bb567153b028cf" category="section-title">Los datos y metadatos</block>
  <block id="b59d6123a3191bd85fe14e57b7a01e11" category="paragraph">Tenga en cuenta que el término «datos» aquí se aplica a los bloques de datos reales, no a los metadatos. Solo los bloques de datos se organizan en niveles, mientras que los metadatos permanecen en el nivel de rendimiento. Además, el estado de un bloque como activo o inactivo solo se ve afectado por la lectura del bloque de datos real. La simple lectura del nombre, la marca de tiempo o los metadatos de propiedad de un archivo no afecta a la ubicación de los bloques de datos subyacentes.</block>
  <block id="1414cdc093d39dd56d0b0d20049e17fc" category="section-title">Completos</block>
  <block id="e0b766a7a0a7633679ecddd0f78a7390" category="paragraph">Aunque FabricPool puede reducir significativamente el espacio físico de almacenamiento, no es por sí misma una solución de backup. Los metadatos de NetApp WAFL siempre permanecen en el nivel de rendimiento. Si un desastre catastrófico destruye el nivel de rendimiento, no se puede crear un nuevo entorno con los datos del nivel de capacidad porque no contiene metadatos de WAFL.</block>
  <block id="7a25ce12890e524732cb71784b5915ab" category="paragraph">Sin embargo, FabricPool puede formar parte de una estrategia de backup. Por ejemplo, FabricPool se puede configurar con la tecnología de replicación SnapMirror de NetApp. Cada mitad del reflejo puede tener su propia conexión con un destino de almacenamiento de objetos. El resultado es dos copias independientes de los datos. La copia primaria consiste en los bloques del nivel de rendimiento y los bloques asociados del nivel de capacidad, y la réplica es un segundo conjunto de bloques de rendimiento y capacidad.</block>
  <block id="82af841589057aa8922b1ac3bb4a28a4" category="doc">Compresión</block>
  <block id="e242ff0701d9ed7d8317b32fd762a100" category="paragraph">Las funciones de eficiencia del espacio, como la compresión, la compactación y la deduplicación están diseñadas para aumentar la cantidad de datos lógicos que se adaptan a una determinada cantidad de almacenamiento físico. El resultado es una reducción de los costes y los gastos generales de gestión.</block>
  <block id="13b992c3d358d786db03341886472c4f" category="paragraph">En un nivel superior, la compresión es un proceso matemático por el cual los patrones en los datos se detectan y codifican de manera que reducen los requisitos de espacio. Por el contrario, la deduplicación detecta bloques de datos repetidos y elimina las copias externas. La compactación permite que varios bloques lógicos de datos compartan el mismo bloque físico en medios.</block>
  <block id="786d7cc1b18aa3d9c3e8d3e30865240e" category="paragraph">Antes de la disponibilidad de sistemas de almacenamiento all-flash, la compresión basada en cabinas era de un valor limitado debido a que la mayoría de las cargas de trabajo con un gran volumen de I/O requerían un gran número de discos para proporcionar un rendimiento aceptable. Los sistemas de almacenamiento contenían invariablemente mucha más capacidad de la necesaria como efecto secundario al gran número de unidades. La situación ha cambiado con el aumento del almacenamiento de estado sólido. Ya no es necesario sobreaprovisionar enormemente las unidades solo para obtener un buen rendimiento. El espacio de las unidades de un sistema de almacenamiento puede coincidir con las necesidades de capacidad reales.</block>
  <block id="b207c460d31fea9e1cfab71057e8152c" category="paragraph">La mayor funcionalidad de IOPS de las unidades de estado sólido (SSD) casi siempre genera ahorro de costes en comparación con las unidades giratorias, pero la compresión puede conseguir un mayor ahorro al aumentar la capacidad efectiva de los medios de estado sólido.</block>
  <block id="6296c8b7406b90d37edf269f1ea6f6ee" category="section-title">Compresión adaptativa</block>
  <block id="1245fef302b5da2c27766d9a98ad358c" category="paragraph">La compresión adaptativa se ha probado minuciosamente en cargas de trabajo empresariales sin que ello afecte al rendimiento, incluso en un entorno all-flash en el que la latencia se mide en microsegundos. Algunos clientes incluso han informado de un aumento del rendimiento con el uso de la compresión, ya que los datos siguen comprimidos en la caché, lo que aumenta efectivamente la cantidad de caché disponible en una controladora.</block>
  <block id="93e0a644c8f1b7f7f378bc071d15d1e9" category="paragraph">ONTAP gestiona bloques físicos en 4KB unidades. La compresión adaptativa usa un tamaño de bloque de compresión predeterminado de 8KB KB, lo que significa que los datos se comprimen en 8KB unidades. Esto coincide con el tamaño de bloque de 8KB KB que suelen utilizar las bases de datos relacionales. Los algoritmos de compresión son más eficientes a medida que se comprimen más datos como una sola unidad. Un tamaño de bloque de compresión de 32KB KB haría más eficiente el espacio que una unidad de bloques de compresión de 8KB KB. Esto significa que la compresión adaptativa con el tamaño de bloque de 8KB KB predeterminado conduce a tasas de eficiencia ligeramente más bajas, pero también ofrece una ventaja significativa si se usa un tamaño de bloque de compresión más pequeño. Las cargas de trabajo de bases de datos incluyen una gran cantidad de actividad de sobrescritura. Para sobrescribir un bloque de datos de 8KB GB de 32KB comprimido, es necesario volver a leer los 32KB TB completos de datos lógicos, descomprimirlos, actualizar la región de 8KB requerida, recomprimir y, a continuación, volver a escribir todo el 32KB en las unidades. Esta es una operación muy cara para un sistema de almacenamiento y es el motivo por el que algunas cabinas de almacenamiento de la competencia basadas en bloques de compresión más grandes también incurren en un impacto significativo en el rendimiento con las cargas de trabajo de base de datos.</block>
  <block id="1f9367b7afff301ee24188d35050ae0a" category="section-title">Eficiencia de almacenamiento sensible a la temperatura</block>
  <block id="78aa8c12abb3bf9f61a08df0f9b403de" category="paragraph">La eficiencia del almacenamiento sensible a la temperatura (TSSE) es un producto disponible en ONTAP 9,8 y versiones posteriores que se basa en mapas de calor de acceso a bloques para identificar los bloques a los que se accede con poca frecuencia y comprimirlos con mayor eficiencia.</block>
  <block id="02e44d620def629a6c145ccd0d9a0fd3" category="section-title">Alineación de la compresión</block>
  <block id="3b6e6c232a02ab9c64199eb9efae012c" category="paragraph">La compresión adaptativa en un entorno de base de datos requiere tener en cuenta algún tipo de aspecto en la alineación de bloques de compresión. Hacerlo solo es una preocupación para los datos sujetos a sobrescrituras aleatorias de bloques muy específicos. Este enfoque es similar en concepto a la alineación general del sistema de archivos, donde el inicio de un sistema de archivos debe alinearse con un límite de dispositivo 4K y el tamaño de bloque de un sistema de archivos debe ser un múltiplo de 4K.</block>
  <block id="1d1a594959ec615f56516f5d0f5e8ddb" category="section-title">NFS</block>
  <block id="62a0282d39568be094470486eaf70c4f" category="section-title">SAN</block>
  <block id="14c3c56ff2a98d1a9c47b63a917f67a3" category="section-title">Compactación de datos</block>
  <block id="0b01f66d49b9df153ee76048de44f6eb" category="paragraph">La compactación de datos permite almacenar varios bloques lógicos en bloques físicos. Por ejemplo, una base de datos con datos altamente comprimibles, como texto o bloques parcialmente completos, puede comprimirse de 8KB a 1KB. Sin compactación, esos 1KB TB de datos seguirían ocupando un bloque completo de 4KB KB. La compactación de datos inline permite almacenar 1KB TB de datos comprimidos en solo 1KB GB de espacio físico junto con otros datos comprimidos. No es una tecnología de compresión; simplemente es una forma más eficaz de asignar espacio en las unidades y, por tanto, no debe crear un efecto de rendimiento detectable.</block>
  <block id="83f45cad5e6f535ff10e564a526baad0" category="section-title">Deduplicación</block>
  <block id="f591ef30da06841378ee7f595e63a93c" category="paragraph">La deduplicación es eliminar los tamaños de bloques duplicados de un conjunto de datos. Por ejemplo, si existiera el mismo bloque de 4KB KB en 10 archivos diferentes, la deduplicación redirigiría ese bloque de 4KB KB en los 10 archivos al mismo bloque físico de 4KB KB. El resultado sería una mejora de 10:1 veces en eficiencia en esos datos.</block>
  <block id="699c85c5df1985b2af588f9e6c1ad353" category="paragraph">Los datos, como las LUN de arranque invitado de VMware, suelen deduplicar muy bien porque constan de varias copias de los mismos archivos del sistema operativo. Se ha observado una eficiencia de 100:1 y mayor.</block>
  <block id="9653a3d4907877aae00bb7d39eeec66d" category="paragraph">En pocos casos, se ha observado un ahorro de espacio de hasta un 15 % en bases de datos con 16KB KB y tamaños de bloque grandes. El primer 4KB de cada bloque contiene el encabezado único a nivel mundial, y el último bloque de 4KB contiene el remolque casi único. Los bloques internos pueden optar a la deduplicación, aunque en la práctica esto se atribuye casi por completo a la deduplicación de datos puestos a cero.</block>
  <block id="32aeb47267cb2045610b468115f3ae0e" category="section-title">Eficiencia y thin provisioning</block>
  <block id="3381946611f34fb44ad8a38a0c44e0a8" category="paragraph">Las funciones de eficiencia son formas de thin provisioning. Por ejemplo, una LUN de 100GB GB que ocupa un volumen de 100GB GB podría comprimirse hasta 50GB 000. Todavía no hay ahorros reales realizados porque el volumen sigue siendo de 100GB GB. Primero se debe reducir el volumen para que el espacio ahorrado se pueda usar en cualquier otro lugar del sistema. Si los cambios realizados en la LUN de 100GB TB más adelante hacen que los datos se puedan comprimir menos, el tamaño de la LUN aumentará y el volumen podría llenarse.</block>
  <block id="38ef8b6f2fc332958c293d93c61d7756" category="paragraph">Algunos clientes prefieren utilizar el aprovisionamiento pesado, ya sea para cargas de trabajo específicas o, por lo general, basándose en prácticas operativas y de adquisición establecidas.</block>
  <block id="f8ea8eaa5ca0e58c6a43ec0117b7bd8d" category="paragraph">*Precaución:* Si un volumen está pesado, se debe tener cuidado para desactivar completamente todas las características de eficiencia para ese volumen, incluida la descompresión y la eliminación de la deduplicación mediante el<block ref="3cfeff511a11b8c5f54ce9749a719a58" prefix=" " category="inline-code"></block> comando. El volumen no debe aparecer en<block ref="df899f2d908ec33afe1d01ee26b3dd47" prefix=" " category="inline-code"></block> salida. Si lo hace, el volumen sigue estando parcialmente configurado para las funciones de eficiencia. Como resultado, la sobrescritura garantiza un funcionamiento diferente, lo que aumenta la posibilidad de que las sobretensiones de la configuración hagan que el volumen se quede sin espacio inesperadamente, lo que producirá errores de I/O de la base de datos.</block>
  <block id="0e7c78164adb6d4650ea685a79d8e99e" category="section-title">Mejores prácticas de eficiencia</block>
  <block id="ec499ad25fa5a765ba43ec2c87819623" category="section-title">Valores predeterminados de AFF</block>
  <block id="9f7127e69d50bf7b844ff3723b86fbd1" category="section-title">Recomendaciones generales</block>
  <block id="2c24e4751310e03f119a4df187a3bc08" category="list-text">Si los volúmenes o LUN no son con thin provisioning, debe deshabilitar todas las configuraciones de eficiencia, ya que el uso de estas funciones no proporciona ahorro y la combinación de aprovisionamiento grueso con la eficiencia de espacio habilitada puede provocar un comportamiento inesperado, incluidos errores de falta de espacio.</block>
  <block id="4922fe547c351d6a121465da036d478e" category="list-text">Si los datos no están sujetos a sobrescrituras, como con backups o registros de transacciones de base de datos, puede lograr una mayor eficiencia habilitando TSSE con un bajo período de enfriamiento.</block>
  <block id="e75fd383e4106eb78482b18896975daf" category="list-text">Es posible que algunos archivos contengan una cantidad significativa de datos que no se puedan comprimir, por ejemplo, cuando la compresión ya está activada en el nivel de aplicación de los archivos está cifrada. Si se da alguna de estas situaciones, considere la posibilidad de deshabilitar la compresión para permitir un funcionamiento más eficiente en otros volúmenes que contengan datos comprimibles.</block>
  <block id="64d5def835c194cac8afe4fafded756e" category="doc">Políticas: Snapshots locales</block>
  <block id="baa596d0db91317fa83739a95649752e" category="paragraph">La versión inicial de FabricPool se dirigía al caso de uso de backup. El único tipo de bloques que se podía organizar en niveles eran bloques que ya no estaban asociados a los datos del sistema de archivos activo. Por lo tanto, solo se pueden mover los bloques de datos de Snapshot al nivel de capacidad. Esta sigue siendo una de las opciones de organización en niveles más seguras cuando hay que garantizar que el rendimiento nunca se vea afectado.</block>
  <block id="b21eb7f0b67c3e27e915183638bf92cf" category="paragraph">Existen dos opciones para organizar en niveles los bloques Snapshot inactivos en el nivel de capacidad. En primer lugar, el<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> la política solo apunta a los bloques de instantáneas. Aunque la<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la política incluye el<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> bloques, también organiza en niveles bloques del sistema de archivos activo. Esto podría no ser deseable.</block>
  <block id="eeba990304f236b36a9fec2434c77470" category="paragraph">La<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> el valor se debe establecer en un período de tiempo que permita que los datos que pueden necesitarse durante una restauración estén disponibles en el nivel de rendimiento. Por ejemplo, la mayoría de los escenarios de restauración de una base de datos de producción crucial incluyen un punto de restauración en algún momento en los pocos días anteriores. Ajuste A<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> el valor de 3 garantizaría que cualquier restauración del archivo da como resultado un archivo que proporciona un rendimiento máximo inmediatamente. Todos los bloques de los archivos activos se encuentran presentes en un almacenamiento rápido sin necesidad de recuperarlos del nivel de capacidad.</block>
  <block id="baf531ed01ad56f5614e1a68e8a2e7aa" category="section-title">Políticas: Snapshots replicadas</block>
  <block id="27e5121a4c75181022e7be2b738339d0" category="paragraph">Un snapshot que se replica con SnapMirror o SnapVault solo se usa para la recuperación deberá utilizar FabricPool<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> política. Con esta política, los metadatos se replican, pero todos los bloques de datos se envían inmediatamente al nivel de capacidad, lo que genera un rendimiento máximo. La mayoría de los procesos de recuperación implican una I/O secuencial, que es inherentemente eficiente. El tiempo de recuperación del almacén de objetos se debe evaluar, pero en una arquitectura bien diseñada, no es necesario que este proceso de recuperación sea significativamente más lento que la recuperación de datos locales.</block>
  <block id="639e481de0ffe002bd83251b26a2540a" category="paragraph">Si también se van a usar los datos replicados para la clonación, el<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la política es más apropiada, con un<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> valor que abarca los datos que se espera que se utilicen regularmente en un entorno de clonación. Por ejemplo, el conjunto de trabajo activo de una base de datos puede incluir datos leídos o escritos en los tres días anteriores, pero también podría incluir otros 6 meses de datos históricos. Si es así, entonces el<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> En el destino de SnapMirror, el conjunto de trabajo está disponible en el nivel de rendimiento.</block>
  <block id="ace0bd0c1be3a9e17d9736d93e7a1da2" category="doc">Calidad de servicio IOPS</block>
  <block id="786ee59e0cdaa09335e12fea3a168653" category="paragraph">En concreto, la creciente adopción del almacenamiento all-flash ha permitido consolidar las cargas de trabajo. Las cabinas de almacenamiento que se basan en medios giratorios tendían a admitir solo una cantidad limitada de cargas de trabajo con un gran volumen de I/O debido a las funcionalidades de IOPS limitadas de la tecnología de unidades rotacionales más antigua. Una o dos bases de datos altamente activas saturarían las unidades subyacentes mucho antes de que las controladoras de almacenamiento alcanzaran sus límites. Esto ha cambiado. La funcionalidad de rendimiento de un número relativamente pequeño de unidades SSD puede saturar incluso las controladoras de almacenamiento más potentes. Esto significa que pueden aprovecharse todas las funcionalidades de las controladoras sin miedo al colapso repentino del rendimiento cuando se disparan los picos de latencia de los medios giratorios.</block>
  <block id="270d79669200ef485add1ecc1833cc94" category="paragraph">Como ejemplo de referencia, un sencillo sistema AFF A800 de alta disponibilidad de dos nodos es capaz de dar servicio a hasta un millón de IOPS aleatorias antes de que la latencia aumente por encima del milisegundo. Sería de esperar que muy pocas cargas de trabajo individuales alcancen estos niveles. El uso completo de esta cabina para el sistema A800 de AFF implicará alojar múltiples cargas de trabajo y hacerlo de forma segura y, al mismo tiempo, garantizar la previsibilidad, requiere controles de calidad de servicio.</block>
  <block id="4dca0c3547523a2e5bd1b8d0e2ff8de5" category="paragraph">Existen dos tipos de calidad de servicio en ONTAP: IOPS y ancho de banda. Los controles de calidad de servicio se pueden aplicar a SVM, volúmenes, LUN y archivos.</block>
  <block id="3ea539ed2021ba46a3658039e8af419f" category="paragraph">Obviamente, un control de calidad de servicio de IOPS se basa en el número total de IOPS de un recurso determinado, pero hay una serie de aspectos de la calidad de servicio de IOPS que quizá no sean intuitivos. Al principio, algunos clientes se quedaron desconcertados por el aparente aumento de la latencia cuando se alcanza un umbral de IOPS. El aumento de la latencia es el resultado natural de la limitación de IOPS. Lógicamente, funciona de forma similar a un sistema de tokens. Por ejemplo, si un volumen determinado que contiene archivos de datos tiene un límite de 10K IOPS, cada I/O que llegue primero deberá recibir un token para continuar con el procesamiento. Mientras no se hayan consumido más de 10K tokens en un segundo determinado, no hay retrasos. Si las operaciones de I/O deben esperar para recibir el token, esta espera aparece como latencia adicional. Cuanto más fuerte sea una carga de trabajo que supere el límite de calidad de servicio, más tiempo debe esperar cada I/O en la cola para su procesamiento, lo cual parece que el usuario tiene una mayor latencia.</block>
  <block id="34a96885dd7f4501920b13026e7f2cab" category="admonition">Tenga cuidado al aplicar controles QoS a los datos de transacción/redo log de la base de datos. Si bien las demandas de rendimiento del redo log suelen ser mucho más bajas que las de los archivos de datos, la actividad de redo log es rápida. El E/S se produce en pulsos breves y un límite de QoS que parece adecuado para los niveles medios de E/S de redo puede ser demasiado bajo para los requisitos reales. El resultado puede ser limitaciones de rendimiento graves ya que QoS se conecta con cada ráfaga de redo log. En general, el redo y el registro de archivos no deben estar limitados por QoS.</block>
  <block id="c79dc76371299e08f4b4ebd609314ca4" category="section-title">Calidad del ancho de banda</block>
  <block id="b9d5c520039715de9b997c5a69f4aeaa" category="paragraph">No todos los tamaños de I/O son iguales. Por ejemplo, una base de datos puede estar realizando un gran número de lecturas de bloque pequeño, lo que haría que se alcance el umbral de IOPS. pero las bases de datos también pueden estar realizando una operación de exploración de tabla completa que consistiría en un número muy pequeño de lecturas de bloque grandes, lo que consume una gran cantidad de ancho de banda pero relativamente pocas IOPS.</block>
  <block id="4930ae83bb8dd5e539dc9f7e73c6d74c" category="paragraph">Del mismo modo, un entorno VMware podría generar un gran número de IOPS aleatorias durante el arranque, pero realizaría menos I/O, pero más grandes, durante un backup externo.</block>
  <block id="eabb5a523a77d4521c12622ee9388aa6" category="paragraph">A veces, para gestionar el rendimiento de forma efectiva se requieren límites de IOPS o de calidad de servicio del ancho de banda o incluso ambos.</block>
  <block id="13dac55a5f26cefab26368ea5a67e29f" category="section-title">Calidad de servicio mínima/garantizada</block>
  <block id="68559688130772c84bb39b2a9ca2c2af" category="paragraph">Muchos clientes buscan una solución que incluya una calidad de servicio garantizada, una solución que se pueda conseguir más de lo que parece y que potencialmente supone un derroche. Por ejemplo, colocar 10 bases de datos con una garantía de 10K IOPS requiere configurar un sistema para un escenario en el que las 10 bases de datos se ejecuten simultáneamente a 10K 000 IOPS, para un total de 100K 000.</block>
  <block id="c0938f706c890ea85c86388391ffad22" category="paragraph">El mejor uso para los controles mínimos de calidad de servicio es proteger las cargas de trabajo cruciales. Por ejemplo, piense en una controladora ONTAP con un número máximo de IOPS de 500K KB posible y una combinación de cargas de trabajo de producción y desarrollo. Debe aplicar políticas de calidad de servicio máximas a las cargas de trabajo de desarrollo para evitar que una base de datos determinada monopolice la controladora. A continuación, aplicaría políticas mínimas de calidad de servicio a las cargas de trabajo de producción para asegurarse de que siempre tengan las IOPS necesarias disponibles cuando las necesite.</block>
  <block id="acdda1c20fb3985ce840929f7525c803" category="section-title">Calidad de servicio adaptativa</block>
  <block id="dd5bc58ed6ab031b170a409470d9a763" category="paragraph">La calidad de servicio adaptativa se refiere a la función ONTAP, donde el límite de calidad de servicio se basa en la capacidad del objeto de almacenamiento. Rara vez se utiliza con bases de datos porque normalmente no hay ningún vínculo entre el tamaño de una base de datos y sus requisitos de rendimiento. Las bases de datos de gran tamaño pueden ser casi inertes, mientras que las bases de datos más pequeñas pueden ser las más intensivas en IOPS.</block>
  <block id="eb595833577352045f92d14ac4315ad2" category="paragraph">La calidad de servicio adaptativa puede resultar muy útil con los almacenes de datos de virtualización porque los requisitos de IOPS de dichos conjuntos de datos tienden a correlacionarse con el tamaño total de la base de datos. Es probable que los almacenes de datos más recientes que contienen 1TB TB de archivos VMDK requieran la mitad de rendimiento que un almacén de datos de 2TB GB. La calidad de servicio adaptativa le permite aumentar automáticamente los límites de calidad de servicio a medida que el almacén de datos se llena con datos.</block>
  <block id="23f3d415bb4fe6f99165df604b24da0e" category="paragraph">La organización en niveles de un conjunto de datos con FabricPool provoca una dependencia entre la cabina de almacenamiento principal y el nivel de almacén de objetos. Hay muchas opciones de almacenamiento de objetos que ofrecen distintos niveles de disponibilidad. Es importante comprender el impacto de una posible pérdida de conectividad entre la cabina de almacenamiento primaria y el nivel de almacenamiento de objetos.</block>
  <block id="7e856c11a853d276fd5d6274bf60fafd" category="paragraph">Si una I/O emitida a ONTAP requiere datos del nivel de capacidad y ONTAP no puede alcanzar el nivel de capacidad para recuperar los bloques, se agotará el tiempo de espera de las I/O finalmente. El efecto de este tiempo de espera depende del protocolo utilizado. En un entorno NFS, ONTAP responde con una respuesta EJUKEBOX o EDELAY, dependiendo del protocolo. Algunos sistemas operativos anteriores pueden interpretarlo como un error, pero los sistemas operativos actuales y los niveles de parches actuales del cliente Oracle Direct NFS lo tratan como un error recuperable y siguen esperando a que se complete la E/S.</block>
  <block id="207d9fe0f57910936bfa043248f3afca" category="paragraph">Un tiempo de espera menor se aplica a los entornos SAN. Si se requiere un bloque en el entorno de almacén de objetos y permanece inaccesible durante dos minutos, se devuelve un error de lectura al host. El volumen ONTAP y los LUN permanecen en línea, pero el SO del host puede marcar el sistema de archivos como está en estado de error.</block>
  <block id="c9251835da8df507ca4f6ce02d4216be" category="paragraph">Problemas de conectividad del almacenamiento de objetos<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> la política es menos problemática, ya que únicamente los datos de backup están organizados en niveles. Los problemas de comunicación ralentizarían la recuperación de datos, pero de otro modo no afectarían a los datos que se están utilizando activamente. La<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> y..<block ref="a181a603769c1f98ad927e7367c7aa51" prefix=" " category="inline-code"></block> Las políticas permiten la clasificación por niveles de los datos inactivos de la LUN activa, lo que significa que un error durante la recuperación de datos del almacén de objetos puede afectar a la disponibilidad de la base de datos. Una implementación de SAN con estas políticas solo debe utilizarse con almacenamiento de objetos de clase empresarial y conexiones de red diseñadas para obtener una alta disponibilidad. NetApp StorageGRID es la opción superior.</block>
  <block id="0f8062f9220efe4f38e7236fe8885379" category="paragraph">La mayoría de las bases de datos relacionales funcionan en modo de archivado de registros de transacciones para ofrecer una recuperación puntual. Los cambios en las bases de datos se confirman registrando los cambios en los registros de transacciones y el registro de transacciones se conserva sin sobrescribirse. El resultado, puede ser un requisito para conservar un enorme volumen de registros de transacciones archivados. Existen ejemplos similares con muchos otros flujos de trabajo de aplicaciones que generan datos que deben conservarse, pero es muy poco probable que se acceda jamás.</block>
  <block id="229384bbfb1db19c4897d87ba4b9bc2d" category="paragraph">FabricPool resuelve estos problemas al ofrecer una única solución con organización en niveles integrada. Los archivos se almacenan y siguen siendo accesibles en su ubicación habitual, pero prácticamente no ocupan espacio en la matriz primaria.</block>
  <block id="f60aec7aaed8420e09f17a8cfd1d7d37" category="paragraph">Utilice un<block ref="e5e88684921dd21f3f86c28343a3082f" prefix=" " category="inline-code"></block> la política de unos días provoca una retención de bloques en los archivos creados recientemente (que son los archivos con mayor probabilidad de que sean necesarios a corto plazo) en el nivel de rendimiento. Los bloques de datos de los archivos antiguos se mueven al nivel de capacidad.</block>
  <block id="485e24df9e0ebeecf416daa6e5441bba" category="paragraph">La<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> aplica la clasificación por niveles de avisos cuando se alcanza el umbral de enfriamiento independientemente de si los registros se han suprimido o siguen existiendo en el sistema de archivos primario. También se simplifica la gestión, almacenar todos los registros potencialmente necesarios en una sola ubicación del sistema de archivos activo. No hay razón para buscar a través de instantáneas para localizar un archivo que necesita ser restaurado.</block>
  <block id="bbe0132696bc482e0ba7a1f293d80083" category="paragraph">Algunas aplicaciones, como Microsoft SQL Server, truncan los archivos de registro de transacciones durante las operaciones de backup de modo que los registros ya no estén en el sistema de archivos activo. Se puede ahorrar capacidad mediante el uso del<block ref="8805d416ce540c5f2df34af5b18d742b" prefix=" " category="inline-code"></block> la política de organización en niveles, solo el<block ref="9df22f196a33acd0b372fe502de51211" prefix=" " category="inline-code"></block> la política no es útil para los datos de registro porque rara vez deben enfriarse los datos de registro en el sistema de archivos activo.</block>
  <block id="0694b4972669f201ca85f9427a230208" category="doc">MetroCluster está disponible en 3 configuraciones diferentes</block>
  <block id="948676ffa8073153cbe404795950ad85" category="list-text">Pares DE ALTA DISPONIBILIDAD con conectividad IP</block>
  <block id="ef012b81fd45a95681a584a59f8df77e" category="list-text">Pares DE ALTA DISPONIBILIDAD con conectividad FC</block>
  <block id="6ffec869ba36dff4e093b5ed8bac798a" category="list-text">Controladora única con conectividad FC</block>
  <block id="6fa7041982bed9488213a7bd2ecccfdf" category="paragraph">[NOTA]El término 'conectividad' hace referencia a la conexión de cluster utilizada para la replicación entre sitios. No hace referencia a los protocolos de host. Todos los protocolos del lado del host se admiten como de costumbre en una configuración de MetroCluster, independientemente del tipo de conexión utilizada para la comunicación entre clústeres.</block>
  <block id="4767099b22895a8101a1cba45d8cf6e9" category="section-title">IP de MetroCluster</block>
  <block id="adc397d87c1a7827f2df9fdd362d5ff7" category="paragraph">La configuración IP de MetroCluster para pares de alta disponibilidad utiliza dos o cuatro nodos por sitio. Esta opción de configuración aumenta la complejidad y los costes relacionados con la opción de dos nodos, pero ofrece una ventaja importante: La redundancia dentro del sitio. Un simple fallo de una controladora no requiere acceso a los datos a través de la WAN. El acceso a los datos sigue siendo local a través de la controladora local alternativa.</block>
  <block id="c15560f2ae5432223c591c5f5d9db5c1" category="paragraph">La mayoría de los clientes eligen la conectividad IP porque los requisitos de infraestructura son más simples. En el pasado, la conectividad entre sitios de alta velocidad solía ser más fácil de aprovisionar mediante switches FC y de fibra oscura; sin embargo, hoy en día los circuitos IP de alta velocidad y baja latencia son más fáciles de obtener.</block>
  <block id="b28c5a429800ea9669a191a402a72b49" category="paragraph">La arquitectura además es más sencilla ya que las únicas conexiones entre sitios son para las controladoras. En MetroCluster conectados a FC SAN, una controladora escribe directamente en las unidades del sitio opuesto y, por lo tanto, requiere conexiones SAN, switches y puentes adicionales. En cambio, una controladora con una configuración IP escribe en las unidades opuestas a través de la controladora.</block>
  <block id="457b0075e8f0333975a8e2aaeaceb149" category="inline-link">Arquitectura y diseño de la solución MetroCluster IP</block>
  <block id="82aa44c8aa5ebe78f1496c8fc80cb954" category="paragraph">Para obtener información adicional, consulte la documentación oficial de ONTAP y.<block ref="03a3c76178d2d43147a2756857a0985e" category="inline-link-rx"></block>.</block>
  <block id="68cf128ce140240c63e9a47e2a82a333" category="paragraph"><block ref="68cf128ce140240c63e9a47e2a82a333" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d2d438a72f6c558744351265fa49a62" category="section-title">MetroCluster con conexión SAN FC de par de ALTA DISPONIBILIDAD</block>
  <block id="3e9133ff590581b29a911d9631ab1737" category="paragraph">La configuración MetroCluster FC de par de alta disponibilidad utiliza dos o cuatro nodos por sitio. Esta opción de configuración aumenta la complejidad y los costes relacionados con la opción de dos nodos, pero ofrece una ventaja importante: La redundancia dentro del sitio. Un simple fallo de una controladora no requiere acceso a los datos a través de la WAN. El acceso a los datos sigue siendo local a través de la controladora local alternativa.</block>
  <block id="7ea740801794ba8a2ce3f87db010c319" category="paragraph"><block ref="7ea740801794ba8a2ce3f87db010c319" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bc2926f030255369db3e4435de5c774" category="paragraph">Algunas infraestructuras multisitio no están diseñadas para operaciones activo-activo, sino que se utilizan más como sitio principal y sitio de recuperación de desastres. En esta situación, generalmente es preferible una opción MetroCluster de una pareja de alta disponibilidad por las siguientes razones:</block>
  <block id="5f49f48dd22b405a813e2ef7cc02e9f8" category="list-text">Aunque un clúster MetroCluster de dos nodos es un sistema de alta disponibilidad, el fallo inesperado de una controladora o de tareas de mantenimiento planificadas requiere que los servicios de datos deban estar online en el sitio opuesto. Si la conectividad de red entre los sitios no puede soportar el ancho de banda requerido, el rendimiento se ve afectado. La única opción sería también conmutar por error los diversos sistemas operativos host y los servicios asociados a la ubicación alternativa. El clúster MetroCluster de la pareja de alta disponibilidad elimina este problema porque la pérdida de una controladora hace que la conmutación al respaldo sea sencilla dentro del mismo sitio.</block>
  <block id="0ce798a4f2e77d6aa1a6e0d718fa8e98" category="list-text">Algunas topologías de red no están diseñadas para el acceso entre sitios, sino que utilizan subredes diferentes o SAN FC aisladas. En estos casos, el clúster MetroCluster de dos nodos ya no funciona como un sistema de alta disponibilidad porque la controladora alternativa no puede proporcionar datos a los servidores del sitio opuesto. La opción MetroCluster de par de alta disponibilidad es necesaria para ofrecer una redundancia completa.</block>
  <block id="098fa44ef37572e0f8ea717199ac72e6" category="list-text">Si se considera una infraestructura de dos sitios como una única infraestructura de alta disponibilidad, la configuración de MetroCluster de dos nodos es adecuada. Sin embargo, si el sistema debe funcionar durante un largo período de tiempo tras el fallo del sitio, se prefiere un par de alta disponibilidad porque sigue proporcionando alta disponibilidad dentro de un único sitio.</block>
  <block id="ea8bb3e5a357ca97851352f6944342c9" category="section-title">MetroCluster FC de dos nodos conectado a SAN</block>
  <block id="b759079fef92c80eca80e7349bf84363" category="paragraph">La configuración de MetroCluster de dos nodos solo utiliza un nodo por sitio. Este diseño es más sencillo que la opción de pareja de alta disponibilidad porque hay menos componentes que configurar y mantener. También ha reducido las demandas de infraestructura en términos de cableado y conmutación FC. Por último, reduce los costes.</block>
  <block id="5bfcbf762ac959212294cdf71bbec2b5" category="paragraph"><block ref="5bfcbf762ac959212294cdf71bbec2b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bcf549481eb36a62594e938bca6a10bb" category="paragraph">El impacto obvio de este diseño es que el fallo de una controladora en un único sitio significa que los datos están disponibles en el sitio opuesto. Esta restricción no es necesariamente un problema. Muchas empresas tienen operaciones de centros de datos multisitio con redes extendidas de alta velocidad y baja latencia que funcionan básicamente como una única infraestructura. En estos casos, la versión de dos nodos de MetroCluster es la configuración preferida. Varios proveedores de servicios utilizan actualmente sistemas de dos nodos a escala de petabytes.</block>
  <block id="78558542e724655ba80fc4879399f103" category="section-title">Funcionalidades de resiliencia de MetroCluster</block>
  <block id="5427d2eb91f25a425f13544e56fb12c4" category="paragraph">No hay puntos únicos de error en una solución de MetroCluster:</block>
  <block id="6a988bf07e73bcbf69f62ce9724dd0f3" category="list-text">Cada controladora tiene dos rutas independientes a las bandejas de unidades en el sitio local.</block>
  <block id="2c98a75e02c6e103b43724f02e99e393" category="list-text">Cada controladora tiene dos rutas independientes a las bandejas de unidades en el sitio remoto.</block>
  <block id="e18f703538cd1f5af3b9185eed57b49b" category="list-text">Cada controladora tiene dos rutas independientes a las controladoras del sitio opuesto.</block>
  <block id="800ec0ea85a62c2fb192ac2f79ee1d02" category="list-text">En la configuración de par de alta disponibilidad, cada controladora tiene dos rutas desde su compañero local.</block>
  <block id="a3d7a569ad6ea771a0ad9b995619251b" category="paragraph">En resumen, puede eliminarse cualquier componente de la configuración sin poner en riesgo la capacidad de MetroCluster para suministrar datos. La única diferencia en términos de flexibilidad entre las dos opciones es que la versión del par de alta disponibilidad sigue siendo un sistema de almacenamiento de alta disponibilidad global tras un fallo del sitio.</block>
  <block id="9b4c3976d453e66a3dd22e2793fc3a8e" category="doc">Gestión del espacio</block>
  <block id="e89d3732a2fbc592923c30e54522dcdb" category="paragraph">El thin provisioning se presenta de muchas formas y forma parte de muchas de las funciones que ofrece ONTAP para un entorno de aplicaciones empresariales. Además, thin provisioning está estrechamente relacionado con las tecnologías de eficiencia por el mismo motivo: Las funciones de eficiencia permiten almacenar más datos lógicos de lo que existen técnicamente en el sistema de almacenamiento.</block>
  <block id="537642ed3bfef7f2bb3e580b3b266bd3" category="paragraph">Casi cualquier uso de las copias Snapshot implica thin provisioning. Por ejemplo, una base de datos de 10TB TB típica en almacenamiento de NetApp incluye unos 30 días de copias Snapshot. Este arreglo da como resultado aproximadamente 10TB TB de datos visibles en el sistema de archivos activo y 300TB TB dedicados a las copias snapshot. El total de 310TB TB de almacenamiento suele residir en aproximadamente 12TB a 15TB GB de espacio. La base de datos activa consume 10TB GB y los 300TB TB restantes solo requieren de 2TB a 5TB GB de espacio, ya que solo se almacenan los cambios realizados en los datos originales.</block>
  <block id="a19609016ad1cb6b7bae7cac796a26a4" category="paragraph">La clonación es también un ejemplo de aprovisionamiento ligero. Un importante cliente de NetApp creó 40 clones de una base de datos de 80TB para que los utilizara el equipo de desarrollo. Si los 40 desarrolladores que utilizan estos clones sobrescribieran cada bloque en cada archivo de datos, se necesitarían más de 3,2PB GB de almacenamiento. En la práctica, la rotación es baja y el requisito de espacio colectivo se acerca a 40TB, ya que solo se almacenan cambios en las unidades.</block>
  <block id="2433af6347e4871be5af0f2af0f6bd6e" category="paragraph">Se debe tener cierta precaución con el thin provisioning de un entorno de aplicaciones porque las tasas de cambios de los datos pueden aumentar de forma inesperada. Por ejemplo, el consumo de espacio debido a las instantáneas puede aumentar rápidamente si se reindexan las tablas de la base de datos o si se aplican parches a gran escala a los huéspedes de VMware. Una copia de seguridad fuera de lugar puede escribir una gran cantidad de datos en muy poco tiempo. Por último, puede ser difícil recuperar algunas aplicaciones si un sistema de archivos se queda sin espacio libre inesperadamente.</block>
  <block id="5cf4dc4d1ce52ff655ea7f1157a72e2e" category="paragraph">Afortunadamente, estos riesgos se pueden abordar con una cuidadosa configuración de<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> y..<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block> normativas. Como sus nombres implican, estas opciones permiten al usuario crear políticas que desactiven automáticamente el espacio consumido por las copias Snapshot o aumentar un volumen para alojar datos adicionales. Hay muchas opciones disponibles y las necesidades varían según el cliente.</block>
  <block id="6a28738961e6f6e4b57e4dd70c446600" category="inline-link-macro">documentación de gestión de almacenamiento lógico</block>
  <block id="01570cb5a3aec2324ab56e318e1de04d" category="paragraph">Consulte <block ref="e69bd75bdb49183ee90588843edb33f4" category="inline-link-macro-rx"></block> para obtener un análisis completo de estas funciones.</block>
  <block id="8cf44a7a390ab582c5010ba430143d4b" category="section-title">Thin provisioning de LUN</block>
  <block id="ba0bdf51bc57bacdd6f3f0bd26b7674c" category="paragraph">La eficiencia del thin provisioning de las LUN activas en un entorno de sistema de archivos se puede perder con el tiempo a medida que se eliminan los datos. A menos que los datos eliminados se sobrescriban con ceros o que el espacio se libere con la recuperación de espacio TRIM/UNMAP, los datos «borrados» ocupan cada vez más espacio en blanco sin asignar del sistema de archivos. Además, el thin provisioning de LUN activos es de uso limitado en muchos entornos de bases de datos, ya que los archivos de datos se inicializan en su tamaño completo en el momento de la creación.</block>
  <block id="e10d46632bc86306cf4c22633ee930ab" category="paragraph">Una planificación cuidadosa de la configuración de LVM puede mejorar la eficiencia y minimizar la necesidad de aprovisionar el almacenamiento y redimensionar las LUN. Cuando se utiliza un LVM como Veritas VxVM u Oracle ASM, los LUN subyacentes se dividen en extensiones que solo se utilizan cuando es necesario. Por ejemplo, si un conjunto de datos empieza con un tamaño de 2TB GB, pero podría crecer hasta 10TB TB con el tiempo, este conjunto de datos podría colocarse en 10TB LUN con thin provisioning organizados en un grupo de discos de LVM. Ocuparía solo 2TB GB de espacio en el momento de la creación y solo reclamaría espacio adicional a medida que se asignan extensiones para acomodar el crecimiento de los datos. Este proceso es seguro siempre y cuando se supervise el espacio.</block>
  <block id="66a41fd6fc38c454973e91d92cf0e291" category="section-title">Reservas fraccionarias</block>
  <block id="e8a206fe65814e0ea465e32487544751" category="paragraph">La reserva fraccionaria es el comportamiento de una LUN en un volumen con respecto a la eficiencia del espacio. Cuando la opción<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> se establece en 100 %, todos los datos del volumen pueden experimentar una rotación del 100 % con cualquier patrón de datos sin agotar el espacio en el volumen.</block>
  <block id="a3cd28aef7d0becd57b60187fdc4a24e" category="paragraph">Por ejemplo, piense en una base de datos en un único LUN de 250GB GB en un volumen de 1TB GB. La creación de una instantánea provocaría de inmediato la reserva de 250GB GB de espacio adicional en el volumen para garantizar que el volumen no se quede sin espacio por ningún motivo. El uso de reservas fraccionarias suele ser un desperdicio debido a que es extremadamente poco probable que cada byte del volumen de base de datos deba sobrescribirse. No hay razón para reservar espacio para un evento que nunca ocurre. Sin embargo, si un cliente no puede supervisar el consumo de espacio en un sistema de almacenamiento y debe tener la seguridad de que nunca se agota el espacio, se necesitarían reservas fraccionarias del 100% para utilizar copias Snapshot.</block>
  <block id="e30fbe8981929fb070a820a213381bab" category="section-title">Compresión y deduplicación</block>
  <block id="1b6e4e9a2be031edc6f3da1f559ef884" category="paragraph">La compresión y la deduplicación son ambas formas de thin provisioning. Por ejemplo, una huella de datos de 50TB MB puede comprimirse hasta 30TB MB, lo que supone un ahorro de 20TB MB. Para que la compresión proporcione beneficios, algunos de esos 20TB MB deben utilizarse para otros datos o el sistema de almacenamiento debe adquirirse con menos de 50TB TB. El resultado es almacenar más datos de los que están disponibles técnicamente en el sistema de almacenamiento. Desde el punto de vista de los datos, hay 50TB GB de datos, a pesar de que ocupa solo 30TB GB en las unidades.</block>
  <block id="dbca4bb791f36eac2c11c32f73f2b4ec" category="paragraph">Siempre existe la posibilidad de que cambie la capacidad de compresión de un conjunto de datos, lo que provocaría un aumento del consumo de espacio real. Este aumento del consumo significa que la compresión debe gestionarse como sucede con otras formas de thin provisioning en términos de supervisión y uso<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> y..<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block>.</block>
  <block id="ad241666a88b5414e8c2fe6d1cc1edb0" category="paragraph">La compresión y la deduplicación se tratan de forma más detallada en el enlace de sección:efficiency.html</block>
  <block id="8ecfcadfebb472a089481e8554ebed87" category="section-title">Compresión y reservas fraccionarias</block>
  <block id="4f8fcc146d2e8e712dcd8c56b1684fcc" category="paragraph">La compresión es una forma de thin provisioning. Las reservas fraccionarias afectan al uso de la compresión, con una nota importante; se reserva espacio con antelación para la creación de la instantánea. Normalmente, la reserva fraccionaria sólo es importante si existe una instantánea. Si no hay ninguna instantánea, la reserva fraccionaria no es importante. Este no es el caso con la compresión. Si se crea una LUN en un volumen con compresión, ONTAP conserva el espacio para acomodar una copia de Snapshot. Este comportamiento puede ser confuso durante la configuración, pero es esperado.</block>
  <block id="e26f8048b4bf60dad827c5a425271361" category="paragraph">Como ejemplo, piense en un volumen de 10GB GB con una LUN de 5GB TB que se ha comprimido en 2,5GB sin copias Snapshot. Considere estos dos escenarios:</block>
  <block id="ade18971a2dab7e37335e95d81da0ef1" category="list-text">La reserva fraccionaria = 100 da como resultado el uso de 7,5GB</block>
  <block id="1d07b8e7c92488a55301ea201328cf35" category="list-text">La reserva fraccionaria = 0 da como resultado el uso de 2,5GB</block>
  <block id="aa410d0e46ec94b6efcf344f0d870c1a" category="paragraph">El primer escenario incluye 2,5GB GB de consumo de espacio para los datos actuales y 5GB GB de espacio para representar una rotación del 100% de la fuente antes del uso de la tecnología Snapshot. El segundo escenario no reserva espacio extra.</block>
  <block id="e79414ad391b126cc9bd53af1624c8de" category="paragraph">Aunque esta situación pueda parecer confusa, es poco probable que se encuentre en la práctica. La compresión implica thin provisioning y thin provisioning de un entorno de LUN requiere reservas fraccionarias. Siempre es posible que los datos comprimidos se sobrescriban en algo que no se pueda comprimir, lo que significa que un volumen debe estar aplicado mediante thin provisioning para que la compresión produzca ahorro.</block>
  <block id="499a10b92cb9ca6b3412d4bf5a91a2b0" category="paragraph">*NetApp recomienda* las siguientes configuraciones de reserva:</block>
  <block id="7f26e875cee50c1b3baf71a014043794" category="list-text">Configurado<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> a 0 cuando se implementa la supervisión de la capacidad básica junto con<block ref="f9e1f2ea1a2becbaf82dd54e55a12e6b" prefix=" " category="inline-code"></block> y..<block ref="24d554277b3513bb6cef3f0a336725a9" prefix=" " category="inline-code"></block>.</block>
  <block id="675996bd34ec0d8c134215f5be73fb3a" category="list-text">Configurado<block ref="c1acac5c4332e37ec1f281fcbaf0765a" prefix=" " category="inline-code"></block> a 100 si no hay capacidad de monitoreo o si es imposible agotar el espacio bajo cualquier circunstancia.</block>
  <block id="8ee38535add58992c14b23a6f7cf8d27" category="doc">Tipos de LIF</block>
  <block id="50d034374ef68094a0f6c8e8d06a77af" category="inline-link-macro">Documentación de gestión de red de ONTAP</block>
  <block id="fc25025f3f0a2afd42465a55f35c02d0" category="paragraph">En esta sección se ofrece una descripción general de los principios clave del diseño de LIF. Para obtener documentación más completa, consulte <block ref="a3e6361e1a52d384f542a2f2d8bc9bb1" category="inline-link-macro-rx"></block>. Al igual que otros aspectos de la arquitectura de bases de datos, las mejores opciones para las máquinas virtuales de almacenamiento (SVM, conocidas como Vserver en la CLI) y el diseño de la interfaz lógica (LIF) dependen en gran medida de los requisitos de escalado y las necesidades empresariales.</block>
  <block id="be0801f7fb241be642bec73b799d45cb" category="paragraph">Tenga en cuenta los siguientes temas principales al crear una estrategia de LIF:</block>
  <block id="362c2978dddcf6988ce266d3d60f5beb" category="list-text">*Rendimiento.* ¿Es suficiente el ancho de banda de la red?</block>
  <block id="cfc88efb72b2c7ea83a4a3d68b760d55" category="list-text">*Resiliencia.* ¿Hay algún punto de falla en el diseño?</block>
  <block id="af02972fd4dc1e949d800731d9518812" category="list-text">*Capacidad de gestión.* ¿Se puede escalar la red de forma no disruptiva?</block>
  <block id="fdcbadc80d2dd31527cc91cf81fb725d" category="paragraph">Estos temas se aplican a la solución completa, desde el host, los switches y el sistema de almacenamiento.</block>
  <block id="f45fe079103703d0b315ff2e339728fd" category="inline-link-macro">Documentación de ONTAP sobre tipos de LIF</block>
  <block id="cc4583278db25277db9ddcd781cbf992" category="paragraph">Hay varios tipos de LIF. <block ref="9d27879d9d2bd4f0f081ffed63159522" category="inline-link-macro-rx"></block> Puede proporcionar información más completa sobre este tema, pero desde una perspectiva funcional, los LIF se pueden dividir en los siguientes grupos:</block>
  <block id="f34a52d788c5a4cf56d7ae8ccb85f8c2" category="list-text">*LIF de administración de clúster y nodos.* LIF utilizadas para administrar el clúster de almacenamiento.</block>
  <block id="73ac4e00a9ff3caf31e6df13a6df2f78" category="list-text">*LIF de administración de SVM.* Interfaces que permiten el acceso a una SVM a través de la API REST o ONTAPI (también conocida como ZAPI) para funciones como la creación de instantáneas o el redimensionamiento de volúmenes. Productos como SnapManager para Oracle (SMO) deben tener acceso a una LIF de gestión de SVM.</block>
  <block id="b7010e46f4769f638197aa230f448ba0" category="list-text">*LIF de datos.* Interfaces para FC, iSCSI, NVMe/FC, NVMe/TCP, NFS, o datos SMB/CIFS.</block>
  <block id="1eb4f53fa8ee8f0954514a1b9858bf6b" category="admonition">También puede utilizarse una LIF de datos que se utiliza para el tráfico NFS al cambiar la política de firewall de<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block> para<block ref="d724f231a9a7b89757c4394d6622bc47" prefix=" " category="inline-code"></block> O cualquier otra política que permita HTTP, HTTPS o SSH. Este cambio puede simplificar la configuración de red ya que evita la configuración de cada host para obtener acceso a tanto a la LIF de datos de NFS como a una LIF de gestión separada. No se puede configurar una interfaz para iSCSI y para el tráfico de gestión, a pesar de que ambos usen un protocolo IP. En los entornos iSCSI, se requiere una LIF de gestión separada.</block>
  <block id="85d465743ad38be108b50648ab283d78" category="section-title">Diseño de LIF SAN</block>
  <block id="8800a54085e1b2987d83537423221cf9" category="paragraph">El diseño de LIF en un entorno SAN es relativamente sencillo por una de las razones: La multivía. Todas las implementaciones de SAN modernas permiten a un cliente acceder a los datos a través de múltiples rutas de red independientes y seleccionar la mejor ruta o las mejores rutas para acceder. Como resultado, el rendimiento con respecto al diseño de las LIF es más sencillo de abordar porque los clientes SAN equilibran automáticamente la carga de I/O en las mejores rutas disponibles.</block>
  <block id="e33c923a4d6280bf6f2b2a982ff74ee3" category="paragraph">Si una ruta deja de estar disponible, el cliente selecciona automáticamente una ruta diferente. La simplicidad resultante del diseño hace que los LIF SAN sean generalmente más gestionables. Esto no significa que un entorno SAN siempre se gestione con mayor facilidad, ya que existen otros muchos aspectos del almacenamiento SAN que son mucho más complicados que NFS. Simplemente significa que el diseño de LIF SAN es más sencillo.</block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">Rendimiento</block>
  <block id="141614e246b14131ec01a449d61ed657" category="paragraph">El aspecto más importante con respecto al rendimiento de LIF en un entorno SAN es el ancho de banda. Por ejemplo, un clúster ONTAP AFF de dos nodos con dos puertos FC de 16GB Gb por nodo permite hasta 32GB Gbps de ancho de banda hacia/desde cada nodo.</block>
  <block id="02bc0523497de72834c4c7990e32d155" category="section-title">Resiliencia</block>
  <block id="01b1d8276ca14813ff4804089a9ac082" category="paragraph">Los LIF DE SAN no conmutan al nodo de respaldo en un sistema de almacenamiento AFF. Si falla un LIF de SAN debido a la recuperación tras fallos de la controladora, el software multivía del cliente detecta la pérdida de una ruta y redirige las I/O a otro LIF. Con los sistemas de almacenamiento de ASA, los LIF conmutarán por error tras un breve retraso, pero esto no interrumpe las I/O porque ya hay rutas activas en la otra controladora. El proceso de conmutación por error tiene lugar para restaurar el acceso de host en todos los puertos definidos.</block>
  <block id="b7c94ef25c0629a65f8a1f6ce7014d95" category="section-title">Gran capacidad de administración</block>
  <block id="1325935a6fa0e88cfec45038005f18e3" category="paragraph">La migración de LIF es una tarea mucho más común en un entorno NFS porque la migración de LIF suele asociarse con la reubicación de volúmenes en el clúster. No es necesario migrar un LIF en un entorno SAN cuando se reubican volúmenes en el par de alta disponibilidad. Esto se debe a que, una vez finalizado el movimiento de volúmenes, ONTAP envía una notificación a la SAN sobre un cambio en las rutas y los clientes SAN vuelven a optimizarse automáticamente. La migración de LIF con SAN está asociada principalmente a los grandes cambios de hardware físico. Por ejemplo, si es necesaria una actualización sin interrupciones de las controladoras, se migra un LIF SAN al nuevo hardware. Si se encuentra que un puerto FC está defectuoso, puede migrarse un LIF a un puerto no utilizado.</block>
  <block id="dbb887b1373e51dab774976c5a556964" category="section-title">Recomendaciones de diseño</block>
  <block id="076872b2444637e6142c3c6f0f157423" category="paragraph">NetApp hace las siguientes recomendaciones:</block>
  <block id="d8d6bca7c981c13479781da85883cfef" category="list-text">No cree más rutas de las necesarias. Un número excesivo de rutas complica la gestión general y puede provocar problemas en la conmutación al nodo de respaldo de rutas en algunos hosts. Además, algunos hosts tienen limitaciones inesperadas de la ruta para configuraciones como el arranque SAN.</block>
  <block id="bd662d86fcca370cddf188ff5378fb1b" category="list-text">Muy pocas configuraciones deberían requerir más de cuatro rutas a una LUN. El valor de tener más de dos nodos de rutas de publicidad para los LUN es limitado porque no se puede acceder al agregado que aloja una LUN si se produce un error en el nodo propietario de la LUN y su partner de alta disponibilidad. La creación de rutas en nodos que no sean el par de alta disponibilidad primario no es útil en esta situación.</block>
  <block id="8873f044ab7c082f16372e4b8bdc6e03" category="list-text">Aunque puede gestionar el número de rutas visibles de LUN si selecciona qué puertos se incluyen en las zonas FC, suele ser más fácil incluir todos los puntos de destino potenciales en la zona FC y controlar la visibilidad de la LUN a nivel de ONTAP.</block>
  <block id="0ebc6267761306c4daefb9871a470e4b" category="list-text">En ONTAP 8,3 y versiones posteriores, la función de asignación selectiva de LUN (SLM) es la opción predeterminada. Con SLM, cualquier nuevo LUN se anuncia automáticamente desde el nodo propietario del agregado subyacente y el partner de alta disponibilidad del nodo. Esta disposición evita la necesidad de crear conjuntos de puertos o configurar la división en zonas para limitar la accesibilidad del puerto. Cada LUN está disponible en el número mínimo de nodos necesarios, tanto para un rendimiento óptimo como para una resiliencia.
*En el caso de que una LUN deba migrarse fuera de los dos controladores, los nodos adicionales se pueden agregar con el<block ref="02d0bbdc14988c85bbd7994723f4dd7f" prefix=" " category="inline-code"></block> Comando para que las LUN se anuncien en los nodos nuevos. Al hacerlo, se crean rutas de SAN adicionales a las LUN para la migración de la LUN. Sin embargo, el host debe realizar una operación de detección para utilizar las rutas nuevas.</block>
  <block id="cc4b24f288afae5889c6061466dda472" category="list-text">No se preocupe demasiado por el tráfico indirecto. Es mejor evitar el tráfico indirecto en un entorno con un gran volumen de I/O para el que cada microsegundo de latencia es crucial, pero el efecto de rendimiento visible es insignificante para las cargas de trabajo típicas.</block>
  <block id="f54fccb82abaa995eb9f86264f431505" category="section-title">Diseño de LIF NFS</block>
  <block id="e68dee93f11ae71aebd7a1e4c2abfc5a" category="paragraph">A diferencia de los protocolos SAN, NFS tiene una capacidad limitada de definir varias rutas para los datos. Las extensiones paralelas de NFS (pNFS) instaladas en NFSv4 solucionan esta limitación, pero, como las velocidades de ethernet han alcanzado los 100GB GbE y más allá, rara vez hay valor en añadir rutas adicionales.</block>
  <block id="391dc675ec3d853200129b799ed5923e" category="section-title">Rendimiento y resiliencia</block>
  <block id="a0bd34f908e3947aa4aba15382354836" category="paragraph">Aunque medir el rendimiento de LIF de SAN se trata, principalmente, de calcular el ancho de banda total de todas las rutas principales, determinar el rendimiento de LIF NFS requiere observar con más detenimiento la configuración de red exacta. Por ejemplo, se pueden configurar dos puertos 10Gb GbE como puertos físicos sin configurar o como grupo de interfaces del protocolo de control de agregación de enlaces (LACP). Si se configuran como un grupo de interfaces, hay varias políticas de equilibrio de carga disponibles que funcionan de forma diferente en función de si el tráfico se conmuta o se enruta. Por último, Oracle Direct NFS (dNFS) ofrece configuraciones de equilibrio de carga que no existen en ningún cliente NFS del sistema operativo en este momento.</block>
  <block id="e500ca27c6b92454c989d80e0445c359" category="paragraph">A diferencia de los protocolos SAN, los sistemas de archivos NFS requieren resiliencia en la capa de protocolo. Por ejemplo, un LUN siempre está configurado con multivía habilitado, lo que significa que hay varios canales redundantes disponibles para el sistema de almacenamiento, cada uno de los cuales utiliza el protocolo FC. Un sistema de archivos NFS, por otro lado, depende de la disponibilidad de un único canal TCP/IP que solo se puede proteger en la capa física. Esta disposición es el motivo por el cual existen opciones como la conmutación por error de puerto y la agregación de puertos LACP.</block>
  <block id="35926e2ada969ad80fd3b16c0cd7d35a" category="paragraph">En un entorno NFS, se proporciona rendimiento y flexibilidad en la capa de protocolo de red. Como resultado, ambos temas están entrelazados y deben discutirse juntos.</block>
  <block id="84f4a5dfaa9613a469cd783c353a186c" category="section-title">Enlace las LIF a grupos de puertos</block>
  <block id="44bfb87c11d83c1b91c3589f2081e7ca" category="paragraph">Para enlazar una LIF a un grupo de puertos, asocie la dirección IP de LIF con un grupo de puertos físicos. El principal método para añadir puertos físicos juntos es LACP. La funcionalidad de tolerancia a fallos de LACP es bastante sencilla; cada puerto de un grupo de LACP se supervisa y se elimina del grupo de puertos en caso de que se produzca un funcionamiento incorrecto. No obstante, existen muchos conceptos erróneos sobre cómo funciona LACP con respecto al rendimiento:</block>
  <block id="19a43026949fb6ef1017a54cf7c94f9b" category="list-text">LACP no requiere que la configuración del switch coincida con el extremo. Por ejemplo, ONTAP puede configurarse con balanceo de carga basado en IP, mientras que un switch puede utilizar balanceo de carga basado en MAC.</block>
  <block id="86501252b34395de5303a65f5e9943e3" category="list-text">Cada punto final que utiliza una conexión LACP puede elegir de forma independiente el puerto de transmisión de paquetes, pero no puede elegir el puerto utilizado para la recepción. Esto significa que el tráfico de ONTAP a un destino en particular está vinculado a un puerto en particular, y el tráfico de retorno podría llegar a una interfaz diferente. Sin embargo, esto no causa problemas.</block>
  <block id="298ca40b99dd3540dcd82ba5537f3f8d" category="list-text">LACP no distribuye el tráfico de manera uniforme en todo momento. En un entorno de gran tamaño con muchos clientes NFS, el resultado suele utilizarse incluso en todos los puertos de una agregación de LACP. Sin embargo, cualquier sistema de archivos NFS en el entorno está limitado al ancho de banda de un solo puerto, no a toda la agregación.</block>
  <block id="d071b5ccd1569aace97a0b4d6c0a71ac" category="list-text">Si bien las políticas LACP de robin-robin están disponibles en ONTAP, estas políticas no abordan la conexión desde un switch a un host. Por ejemplo, una configuración con un tronco LACP de cuatro puertos en un host y un tronco LACP de cuatro puertos en ONTAP solo puede leer un sistema de archivos utilizando un único puerto. Aunque ONTAP puede transmitir datos a través de los cuatro puertos, actualmente no hay tecnologías de switches disponibles que se envíen del switch al host a través de los cuatro puertos. Solo se utiliza uno.</block>
  <block id="6e9e98dfaea1ca7860606f1fc05e414a" category="paragraph">El enfoque más común en entornos de mayor tamaño que consisten en muchos hosts de base de datos es crear un agregado LACP de un número adecuado de interfaces 10Gb (o más rápidas) mediante el equilibrio de carga de IP. Este enfoque permite a ONTAP ofrecer un uso uniforme de todos los puertos, siempre y cuando existan suficientes clientes. El equilibrio de carga se desglosa cuando hay menos clientes en la configuración porque la conexión troncal LACP no redistribuye la carga de forma dinámica.</block>
  <block id="7815da600ab459d2b05c5792f2271c1a" category="paragraph">Cuando se establece una conexión, el tráfico en una dirección determinada se coloca en un solo puerto. Por ejemplo, una base de datos que realiza una exploración de tabla completa en un sistema de archivos NFS conectado a través de un tronco LACP de cuatro puertos lee los datos aunque solo una tarjeta de interfaz de red (NIC). Si sólo hay tres servidores de base de datos en un entorno de este tipo, es posible que los tres estén leyendo desde el mismo puerto, mientras que los otros tres puertos estén inactivos.</block>
  <block id="153f704ea16440133d51b1877af2a657" category="section-title">Enlazar LIF a puertos físicos</block>
  <block id="70e655aa3c03f840747c5272142b3527" category="paragraph">La vinculación de una LIF a un puerto físico provoca un control más granular sobre la configuración de red, ya que una dirección IP determinada en un sistema ONTAP solo está asociada con un puerto de red a la vez. A continuación, la resiliencia se lleva a cabo mediante la configuración de grupos de conmutación al respaldo y las políticas de conmutación por error.</block>
  <block id="218f00463f5281b8ead536582c69ac3a" category="section-title">Políticas de conmutación por error y grupos de conmutación por error</block>
  <block id="0a53c26a1bc4036c84fc3b4b63542744" category="inline-link-macro">Documentación de gestión de redes de ONTAP para políticas y grupos de conmutación por error</block>
  <block id="f29ae31443947c9782482ee9683dbc0e" category="paragraph">El comportamiento de las LIF durante la interrupción de la red está controlado por las políticas de conmutación por error y los grupos de recuperación tras fallos. Las opciones de configuración han cambiado con las distintas versiones de ONTAP. Consulte la <block ref="96c8cd47b667604fb9991ace7d2eff29" category="inline-link-macro-rx"></block> Para obtener detalles específicos de la versión de ONTAP que se va a poner en marcha.</block>
  <block id="0f2f345dd1247ae428cee703c1bf1c84" category="paragraph">ONTAP 8,3 y superiores permiten la gestión de recuperación tras fallos de LIF en función de dominios de retransmisión. Por lo tanto, un administrador puede definir todos los puertos que tienen acceso a una subred determinada y permitir que ONTAP seleccione una LIF de conmutación al nodo de respaldo adecuada. Algunos clientes pueden utilizar este enfoque, pero tiene limitaciones en un entorno de red de almacenamiento de alta velocidad debido a la falta de previsibilidad. Por ejemplo, un entorno puede incluir ambos puertos 1GB para acceso rutinario al sistema de archivos y puertos 10Gb para las operaciones de I/O del archivo de datos Si ambos tipos de puertos existen en el mismo dominio de retransmisión, la conmutación por error de LIF puede provocar que se muevan las operaciones de I/O del archivo de datos de un puerto 10Gb a un puerto 1GB.</block>
  <block id="ced0729d57c08312b2b12382f2147d26" category="paragraph">En resumen, tenga en cuenta las siguientes prácticas:</block>
  <block id="57cb6a7ba8acb7faa31cc5219bae83b3" category="list-text">Configure un grupo de failover como definido por el usuario.</block>
  <block id="b444855eccae552d7fb79bf3d31a4f7b" category="list-text">Rellenar el grupo de recuperación tras fallos con puertos en el controlador asociado de recuperación tras fallos de almacenamiento (SFO) de modo que los LIF sigan a los agregados durante una conmutación al nodo de respaldo de almacenamiento. Esto evita la creación de tráfico indirecto.</block>
  <block id="86c48b21d166ed8e440a07e1d4a0b15d" category="list-text">Utilice puertos de conmutación por error con las características de rendimiento correspondientes a la LIF original. Por ejemplo, un LIF en un único puerto físico 10Gb debería incluir un grupo de conmutación por error con un único puerto 10Gb. Un LIF LACP de cuatro puertos debe conmutar por error a otro LIF LACP de cuatro puertos. Estos puertos serían un subconjunto de los puertos definidos en el dominio de retransmisión.</block>
  <block id="3e839a73f7dc1262508f23a89628ca2d" category="list-text">Establezca la política de recuperación tras fallos únicamente en SFO-partner. Al hacerlo, se asegura de que el LIF siga al agregado durante la recuperación tras fallos.</block>
  <block id="85e82ce4c9842f978fa774c4fe96b14c" category="section-title">Reversión automática</block>
  <block id="3dc8610f78478640e47688101cecbfad" category="paragraph">Ajuste la<block ref="9f1b7141f09f19c4e33409646aef43cf" prefix=" " category="inline-code"></block> parámetro como desee. La mayoría de los clientes prefieren establecer este parámetro en<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> Para que la LIF vuelva a su puerto de inicio. Sin embargo, en algunos casos, los clientes han establecido esto en 'false' para que se pueda investigar una conmutación por error inesperada antes de devolver una LIF a su puerto de origen.</block>
  <block id="edf6d4c299bc2890ba63c7eb3ef8b4d2" category="section-title">Proporción de LIF a volumen</block>
  <block id="9c75becef8c432a0152a40c7c037a04c" category="paragraph">Un concepto erróneo común es que debe haber una relación de 1:1 GbE entre los volúmenes y los LIF de NFS. Aunque esta configuración es necesaria para mover un volumen a cualquier punto de un clúster mientras no se crea tráfico de interconexión adicional, no es categóricamente un requisito. Hay que tener en cuenta el tráfico entre clústeres, pero la mera presencia del tráfico entre clústeres no crea problemas. Muchas de las pruebas de rendimiento publicadas creadas para ONTAP incluyen I/O predominantemente indirectas</block>
  <block id="2b4ebcd522b07b80d3fd76b301c506e8" category="paragraph">Por ejemplo, un proyecto de base de datos que contiene una cantidad relativamente pequeña de bases de datos críticas para el rendimiento que solo requerían un total de 40 volúmenes podría justificar un volumen de 1:1 GB para la estrategia LIF, una disposición que requeriría 40 direcciones IP. Posteriormente, cualquier volumen se podría mover a cualquier parte del clúster junto con la LIF asociada; el tráfico siempre sería directo, minimizando todas las fuentes de latencia incluso a niveles de microsegundos.</block>
  <block id="38bad4911bcdf1117d37eb1195566f8c" category="paragraph">Como ejemplo por contador, un entorno alojado de gran tamaño se podría gestionar más fácilmente con una relación de 1:1:1 entre clientes y las LIF. Con el tiempo, es posible que se deba migrar un volumen a un nodo diferente, lo cual provocaría cierto tráfico indirecto. Sin embargo, el efecto de rendimiento debe ser indetectable a menos que los puertos de red en el conmutador de interconexión estén saturados. Si hay algún problema, se puede establecer un nuevo LIF en nodos adicionales y el host puede actualizarse en la siguiente ventana de mantenimiento para eliminar el tráfico indirecto de la configuración.</block>
  <block id="d75b0d8f723c3e97eaa4ca39630c7420" category="doc">MetroCluster y varios agregados</block>
  <block id="df5855269b493a27a5565dfd9f2584f0" category="list-text">En condiciones normales, las escrituras entrantes en una controladora determinada se reflejan de forma síncrona en su compañero. En un entorno NetApp MetroCluster, las escrituras también se reflejan en una controladora remota. No se reconoce en la aplicación host hasta que se almacena una escritura en medios no volátiles en todas las ubicaciones.</block>
  <block id="05b60db315aa45e1524b7a6ffa242fa8" category="list-text">El medio que almacena los datos de escritura se denomina memoria no volátil o NVMEM. También se conoce a veces como memoria de acceso aleatorio no volátil (NVRAM), y se puede considerar como una caché de escritura aunque funciona como un diario. En un funcionamiento normal, los datos de NVMEM no se leen; solo se utilizan para proteger los datos en caso de un fallo de software o hardware. Cuando se escriben datos en las unidades, los datos se transfieren desde la RAM del sistema, no desde NVMEM.</block>
  <block id="e6dd8b559da6e046f2043043a55faafc" category="list-text">Durante una operación de toma de control, un nodo de una pareja de alta disponibilidad toma el control de las operaciones de su compañero. Una conmutación de sitios es básicamente la misma, pero se aplica a las configuraciones de MetroCluster en las que un nodo remoto toma las funciones de un nodo local.</block>
  <block id="33c0c466972aae7427262e3075a2ed07" category="paragraph">Durante las operaciones de mantenimiento rutinarias, una operación de toma de control o de conmutación de sitios debería ser transparente, excepto en una breve pausa potencial de las operaciones cuando cambian las rutas de red. Sin embargo, las redes pueden ser complicadas y es fácil cometer errores, por lo que NetApp recomienda encarecidamente probar exhaustivamente las operaciones de toma de control y conmutación antes de poner un sistema de almacenamiento en producción. Hacerlo es la única forma de asegurarse de que todas las rutas de red están configuradas correctamente. En un entorno SAN, compruebe cuidadosamente la salida del comando<block ref="41dc2c94e82e1c56ba876085acf5a974" prefix=" " category="inline-code"></block> para asegurarse de que todas las rutas primarias y secundarias esperadas estén disponibles.</block>
  <block id="d33ea1ad1493de23aafd480e95fea159" category="paragraph">Se debe tener cuidado al emitir una toma de control forzada o cambio. Al forzar un cambio en la configuración de almacenamiento con estas opciones, se ignorará el estado de la controladora propietaria de las unidades y el nodo alternativo tomará el control de las unidades de manera forzada. El forzado incorrecto de una toma de control puede provocar la pérdida de datos o la corrupción. Esto se debe a que una toma de control o una conmutación por error forzada pueden descartar el contenido de NVMEM. Una vez completada la toma de control o la conmutación por error, la pérdida de esos datos implica que los datos almacenados en las unidades pueden revertir a un estado ligeramente más antiguo desde el punto de vista de la base de datos.</block>
  <block id="c226371d96b605ccff84ad23db0069b8" category="paragraph">En raras ocasiones se debería necesitar una toma de control forzada con un par de alta disponibilidad normal. En prácticamente todas las situaciones de fallo, un nodo se apaga e informa al partner para que se produzca una conmutación automática al respaldo. Hay algunos casos periféricos, como un fallo gradual en el que se pierde la interconexión entre nodos y después se pierde una controladora, en el que se requiere una toma de control forzada. En esta situación, el mirroring entre nodos se pierde antes del fallo de la controladora, lo que significa que la controladora superviviente ya no tendría una copia de las escrituras en curso. Entonces, se debe forzar la toma de control, lo que significa que potencialmente se pueden perder los datos.</block>
  <block id="418f81f529a577cb711b44adece1376f" category="paragraph">La misma lógica se aplica a un switchover de MetroCluster. En condiciones normales, una conmutación es prácticamente transparente. Sin embargo, un desastre puede resultar en una pérdida de conectividad entre el sitio sobreviviente y el sitio del desastre. Desde el punto de vista del sitio sobreviviente, el problema podría ser nada más que una interrupción en la conectividad entre sitios, y el sitio original podría aún estar procesando datos. Si un nodo no puede comprobar el estado de la controladora principal, solo es posible realizar una conmutación de sitios forzada.</block>
  <block id="ae0c16d397348d8f8fd4e56b08b06c7c" category="paragraph">*NetApp recomienda* tomar las siguientes precauciones:</block>
  <block id="79fd18cb18befbe5c2113757478be193" category="list-text">Tenga mucho cuidado de no forzar accidentalmente una toma de control o una conmutación de sitios. Normalmente, no se debe forzar, y forzar el cambio puede provocar la pérdida de datos.</block>
  <block id="26cece11254903c5ba8bfdd8d54ae779" category="list-text">Si se requiere una toma de control forzada o una conmutación por error, asegúrese de que las aplicaciones estén cerradas, todos los sistemas de archivos estén desmontados y los grupos de volúmenes del gestor de volúmenes lógicos (LVM) se varyoffs. Los grupos de discos de ASM deben estar desmontados.</block>
  <block id="0b6986eb1285d28a9987ea13adbca358" category="list-text">En caso de una conmutación de MetroCluster forzada, elimine el nodo fallido de todos los recursos de almacenamiento que sobrevivan. Para obtener más información, consulte la Guía de gestión de MetroCluster y recuperación ante desastres para la versión relevante de ONTAP.</block>
  <block id="71303adf87737046acd4381c72151278" category="paragraph">MetroCluster es una tecnología de replicación síncrona que cambia al modo asíncrono en caso de interrupción de la conectividad. Esta es la solicitud más común de los clientes, porque la replicación síncrona garantizada implica que la interrupción de la conectividad del sitio provoca una parada completa de las operaciones de I/O de la base de datos, lo que impide que la base de datos funcione.</block>
  <block id="cb791a44ee361703eb7594a7932f57de" category="paragraph">Con MetroCluster, los agregados se resincronizan rápidamente después de restaurar la conectividad. A diferencia de otras tecnologías de almacenamiento, MetroCluster nunca debería requerir un nuevo mirroring completo tras un fallo del sitio. Sólo se deben enviar los cambios delta.</block>
  <block id="c1536091d7c1ca33c9dc4dfa8c0852a2" category="paragraph">En conjuntos de datos que abarcan agregados, existe el pequeño riesgo de que se requieran pasos adicionales de recuperación de datos en un escenario de desastre continuo. Específicamente, si (a) se interrumpe la conectividad entre sitios, (b) se restaura la conectividad, (c) los agregados alcanzan un estado en el que algunos están sincronizados y otros no, y luego (d) se pierde el sitio principal, el resultado es un sitio superviviente en el que los agregados no están sincronizados entre sí. Si esto sucede, algunas partes del conjunto de datos se sincronizan entre sí y no es posible activar aplicaciones, bases de datos o almacenes de datos sin recuperación. Si un conjunto de datos abarca agregados, NetApp recomienda aprovechar los backups basados en instantáneas con una de las muchas herramientas disponibles para verificar la capacidad de recuperación rápida en este escenario inusual.</block>
  <block id="a42c87064c284490a38efac4bf0b7f7f" category="paragraph">RAID 4, RAID 5, RAID 6, RAID DP y RAID-TEC usan la paridad para garantizar que el fallo de una unidad no provoque la pérdida de datos. Estas opciones de RAID ofrecen un aprovechamiento del almacenamiento mucho mejor en comparación con mirroring, pero la mayoría de las implementaciones de RAID tienen un inconveniente que afecta a las operaciones de escritura. La finalización de una operación de escritura en otras implementaciones de RAID puede requerir varias lecturas de unidad para volver a generar los datos de paridad, un proceso comúnmente denominado penalización de RAID.</block>
  <block id="3cfcf9a3299db75df9aa0e024ebef965" category="paragraph">Sin embargo, ONTAP no implica este proceso de penalización por RAID. Esto se debe a la integración de NetApp WAFL (Write Anywhere File Layout) con la capa RAID. Las operaciones de escritura se fusionan en la RAM y se preparan como una franja RAID completa, incluida la generación de paridad. ONTAP no necesita realizar una lectura para completar una escritura, lo que significa que ONTAP y WAFL evitan la penalización de RAID. El rendimiento de las operaciones cruciales para la latencia, como el registro de reconstrucción, no se ve afectado, y las escrituras de archivos de datos aleatorios no suponen ningún tipo de penalización de RAID por la necesidad de regenerar la paridad.</block>
  <block id="5ff9a871332f0f82f38d880b68a9874b" category="paragraph">En cuanto a la fiabilidad estadística, incluso RAID DP ofrece una mejor protección que el mirroring RAID. El problema principal es la demanda que se realiza en las unidades durante una recompilación de RAID. Con un conjunto RAID reflejado, el riesgo de que se pierdan datos tras el fallo en una unidad durante la reconstrucción a su compañero en el conjunto RAID es mucho mayor que el riesgo de un fallo de triple unidad en un conjunto RAID DP.</block>
  <block id="12c3fe87fd5a746ce8a7cbe25dc1c25b" category="paragraph">Antes de la era de las unidades flash, se utilizaba la segmentación para ayudar a superar las limitaciones de rendimiento de las unidades giratorias. Por ejemplo, si un sistema operativo necesita realizar una operación de lectura de 1MB KB, para leer que 1MB TB de datos de una sola unidad se requeriría buscar y leer muchos cabezales de unidad ya que 1MB se transfiere lentamente. Si esos 1MB TB de datos se segmentaron en 8 LUN, el sistema operativo podría emitir ocho operaciones de lectura de 128K KB en paralelo y reducir el tiempo necesario para realizar la transferencia de 1MB GB.</block>
  <block id="e337352c3d57672fd08af8ba709b544f" category="paragraph">La segmentación con unidades giratorias era más difícil porque se tenía que conocer el patrón de I/O con anterioridad. Si la segmentación no se ajustó correctamente para los patrones de I/O reales, las configuraciones seccionadas podrían dañar el rendimiento. Con las bases de datos de Oracle y, especialmente con las configuraciones all-flash, la segmentación es mucho más fácil de configurar y se ha demostrado que mejora drásticamente el rendimiento.</block>
  <block id="7025652291dc6872022b0f79a2b2be21" category="paragraph">Los gestores de volúmenes lógicos como Oracle ASM segmentan por defecto, pero el LVM del sistema operativo nativo no lo hacen. Algunos de ellos unen varias LUN como un dispositivo concatenado, lo que da como resultado archivos de datos que existen en un único dispositivo LUN. Esto provoca puntos calientes. Otras implementaciones de LVM toman por defecto extensiones distribuidas. Esto es similar a la segmentación, pero es más grueso. Las LUN del grupo de volúmenes se dividen en partes grandes, denominadas extensiones y normalmente se miden en muchos megabytes, y los volúmenes lógicos se distribuyen por esas extensiones. El resultado es que las operaciones de I/O aleatorias en un archivo se deben distribuir bien entre las LUN, pero las operaciones de I/O secuenciales no son tan eficientes como podrían.</block>
  <block id="0c2f3b2ec9d90baa0a0a0b6fb673a113" category="paragraph">La I/O de aplicaciones con rendimiento intensivo casi siempre es una (a) en unidades del tamaño de bloque básico o (b) un megabyte.</block>
  <block id="804d5b1f06570b4d242be0c2f0c3392c" category="paragraph">El principal objetivo de una configuración seccionada es garantizar que la I/O de archivo único se pueda realizar como una unidad única y que las I/O de varios bloques, que deben tener un tamaño de 1MB TB, se puedan paralelizar de manera uniforme entre todas las LUN del volumen seccionado. Esto significa que el tamaño de franja no debe ser menor que el tamaño del bloque de la base de datos y el tamaño de franja multiplicado por el número de LUN debe ser 1MB.</block>
  <block id="0598f393baefd05d48b48076cc7df606" category="paragraph">En la siguiente figura, se muestran tres opciones posibles para el ajuste del tamaño de la franja y el ancho. Se selecciona el número de LUN para satisfacer los requisitos de rendimiento tal como se han descrito anteriormente, pero en todos los casos los datos totales de una sola franja es 1MB.</block>
  <block id="9ca503fae9ccd4d6d8e67806b23adfa0" category="paragraph"><block ref="9ca503fae9ccd4d6d8e67806b23adfa0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0353522b39b87d54d40d3f09ec668851" category="doc">Configuración de ONTAP</block>
  <block id="8e52de0d4b03d5fe87dc88da09616c7f" category="inline-link-macro">aquí.</block>
  <block id="337c62c6b6eb7319bae58701105e889c" category="doc">Organización en niveles</block>
  <block id="3493794b3ccb587f71a663f51f4484ef" category="summary">Bases de datos PostgreSQL en ONTAP</block>
  <block id="2d3298c651b356a82db5d664ce68e65e" category="doc">Protección de datos nativa</block>
  <block id="31c6611c8e0bd237a3ee51db1728a440" category="paragraph">Uno de los principales aspectos del diseño del almacenamiento es permitir la protección para volúmenes PostgreSQL. Los clientes pueden proteger sus bases de datos PostgreSQL mediante el método de volcado o mediante copias de seguridad del sistema de archivos. Esta sección explica los diferentes enfoques para realizar una copia de seguridad de bases de datos individuales o de todo el cluster.</block>
  <block id="9f3265914462c64fd02bc50ab4c9ebe9" category="paragraph">Existen tres enfoques para respaldar los datos de PostgreSQL:</block>
  <block id="6b592c7950245a5a9f54d9424e851e97" category="list-text">Volcado de SQL Server</block>
  <block id="c8b1fc69d12d1da6589e384671c8e82c" category="list-text">Backup de nivel de sistema de archivos</block>
  <block id="3c25062a0babfa1495dd604698707610" category="list-text">Archivado continuo</block>
  <block id="58c132e2be12705408a7456c6183b617" category="paragraph">La idea detrás del método de volcado de SQL Server es generar un archivo con comandos de SQL Server que, cuando se devuelve al servidor, pueda volver a crear la base de datos como estaba en el momento del volcado. PostgreSQL proporciona los programas de utilidad<block ref="5a5149b2817f30cbb3805307f9cadae4" prefix=" " category="inline-code"></block> y..<block ref="0ead269b3d000482b5a44a1ef4e8cd54" prefix=" " category="inline-code"></block> para crear backup individual y a nivel de clúster. Estos volcados son lógicos y no contienen suficiente información para ser utilizada por WAL Replay.</block>
  <block id="1d05b80fc6f199681263e063190e8325" category="paragraph">Una estrategia de backup alternativa consiste en utilizar copias de seguridad a nivel de sistema de archivos, en las que los administradores copian directamente los archivos que PostgreSQL utiliza para almacenar los datos en la base de datos. Este método se realiza en modo offline: La base de datos o el cluster deben cerrarse. Otra alternativa es usar<block ref="35679fc424d9eec0c30f38459fd9b322" prefix=" " category="inline-code"></block> Para ejecutar la copia de seguridad de transmisión en caliente de la base de datos PostgreSQL.</block>
  <block id="10907e7ac5ab6e5235a23898a2331b31" category="doc">Bases de datos PostgreSQL en ONTAP</block>
  <block id="841a21e58e7c22a71c07b89a4362d2b6" category="admonition">Esta documentación sobre ONTAP y la base de datos PostgreSQL reemplaza a la base de datos _TR-4770: PostgreSQL sobre las mejores prácticas de ONTAP._</block>
  <block id="9147e5e61a7b9260dec09f3a6eb3e5be" category="doc">Snapshot</block>
  <block id="0b9d99167191c5d9ad23ca07bc6a9b38" category="paragraph">Las copias de seguridad basadas en instantáneas con PostgreSQL requieren la configuración de instantáneas para archivos de datos, archivos WAL y archivos WAL archivados para proporcionar una recuperación completa o puntual.</block>
  <block id="8c6a53edc4449a4cc3983d47ecffa851" category="paragraph">Para las bases de datos PostgreSQL, el tiempo promedio de backup con snapshots es de unos pocos segundos a unos pocos minutos. Esta velocidad de backup es entre 60 y 100 veces más rápida que<block ref="35679fc424d9eec0c30f38459fd9b322" prefix=" " category="inline-code"></block> y otros enfoques de backup basados en sistemas de archivos.</block>
  <block id="c798632224ae09152f66f60e0edc757e" category="paragraph">Las copias Snapshot en el almacenamiento de NetApp pueden ser coherentes con los fallos y con las aplicaciones. Se crea una copia Snapshot coherente con los fallos en el almacenamiento sin desactivar la base de datos, mientras que se crea una copia Snapshot coherente con la aplicación mientras la base de datos está en modo de backup. NetApp también garantiza que las copias Snapshot posteriores sean backups permanentes para ahorrar en almacenamiento y mejorar la eficiencia de la red.</block>
  <block id="d0e369216eeac8de66e915909364970a" category="paragraph">Como las copias Snapshot son rápidas y no afectan al rendimiento del sistema, puede programar varias copias Snapshot diariamente en lugar de crear un único backup diario, como ocurre con otra tecnología de backup en streaming. Cuando es necesaria una operación de restauración y recuperación, el tiempo de inactividad del sistema se reduce gracias a dos funciones clave:</block>
  <block id="316eb8adba4d16a34c92eaf9db381b9e" category="list-text">La tecnología de recuperación de datos de NetApp SnapRestore significa que la operación de restauración se ejecuta en segundos.</block>
  <block id="c128c475c12703e37685edd6db8144bc" category="list-text">Los objetivos de punto de recuperación agresivos (RPO) significan que es necesario aplicar menos registros de base de datos y que también se acelera la nueva recuperación.</block>
  <block id="9b9f26085ff7149d4dbb916b1db0f121" category="paragraph">Para realizar el backup de PostgreSQL, debe asegurarse de que los volúmenes de datos estén protegidos simultáneamente con WAL (grupo de consistencia) y los registros archivados. Mientras utiliza la tecnología Snapshot para copiar archivos WAL, asegúrese de ejecutar<block ref="a3b8c8ee15ba60bfb2b999195d2b4e7d" prefix=" " category="inline-code"></block> Para vaciar todas las entradas de WAL que se deben archivar. Si vacíe las entradas DE WAL durante la restauración, solo tendrá que detener la base de datos, desmontar o eliminar el directorio de datos existente, y realizar una operación de SnapRestore en el almacenamiento. Una vez finalizada la restauración, puede montar el sistema y devolverlo a su estado actual. Para la recuperación point-in-time, también puede restaurar WAL y archive logs; luego PostgreSQL decide el punto más consistente y lo recupera automáticamente.</block>
  <block id="8e8d6187572eace409fee5bf2dbb7cf9" category="paragraph">Los grupos de coherencia son una función en ONTAP y se recomienda cuando hay varios volúmenes montados en una sola instancia o en una base de datos con varios espacios de tabla. Una snapshot de grupo de coherencia garantiza que todos los volúmenes estén agrupados y protegidos. Un grupo de consistencia puede gestionarse de manera eficiente desde ONTAP System Manager, e incluso puede clonarlo para crear una copia de instancia de una base de datos con fines de prueba o desarrollo.</block>
  <block id="55ca4b30c6f7c3ef975a6d1e1fb222a2" category="inline-link-macro">Información general de los grupos de consistencia NetApp</block>
  <block id="69dd5879aee425e37fdd5796a8e06a56" category="paragraph">Para obtener más información sobre los grupos de consistencia, consulte <block ref="112c5744a39904facdbc5fab385d9fe1" category="inline-link-macro-rx"></block>.</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="doc">Protección de datos</block>
  <block id="16a49d0bc0249ef3dd42949589a0ed4e" category="doc">Espacios de tabla</block>
  <block id="d6d544de56c329d9f68bb176c6245e7c" category="paragraph">Al inicializar el cluster de la base de datos, se crean automáticamente dos tablespaces.</block>
  <block id="6df924905e21856e4e8b8f936767cdd6" category="paragraph">La<block ref="bd676cbef0d168a62a062c8709af1824" prefix=" " category="inline-code"></block> el tablespace se utiliza para catálogos de sistemas compartidos. La<block ref="3224684b8e7208962a73daeb0bb24110" prefix=" " category="inline-code"></block> tablespace es el tablespace por defecto de las bases de datos template1 y template0. Si la partición o el volumen en el que se inicializó el cluster se queda sin espacio y no se puede ampliar, se puede crear un tablespace en una partición diferente y utilizarlo hasta que se pueda volver a configurar el sistema.</block>
  <block id="364c9d7b9593277eee9477befaf9f66b" category="paragraph">Un índice muy utilizado se puede colocar en un disco rápido y de alta disponibilidad, como un dispositivo de estado sólido. Además, se puede almacenar una tabla que almacene datos archivados que no se utilizan con poca frecuencia o que no son críticos para el rendimiento en un sistema de disco menos costoso y más lento como las unidades SAS o SATA.</block>
  <block id="9bfe8d8e1117bd1d4b8597220e3f166e" category="paragraph">Los tablespaces forman parte del cluster de base de datos y no se pueden tratar como una recopilación autónoma de archivos de datos. Dependen de los metadatos contenidos en el directorio de datos principal y, por lo tanto, no se pueden asociar a otro clúster de base de datos ni realizar copias de seguridad individuales. Del mismo modo, si pierde un tablespace (mediante la supresión de archivos, fallos de disco, etc.), el cluster de base de datos puede volverse ilegible o no se puede iniciar. Colocar un tablespace en un sistema de archivos temporal como un disco RAM pone en riesgo la fiabilidad de todo el cluster.</block>
  <block id="7d9573b1ed3543ec6ea42c81830dc27c" category="paragraph">Una vez creado, se puede utilizar un tablespace desde cualquier base de datos si el usuario solicitante tiene suficientes privilegios. PostgreSQL utiliza enlaces simbólicos para simplificar la implementación de tablespaces. PostgreSQL añade una fila al<block ref="4a926dc6e7549c49a13755513af41e67" prefix=" " category="inline-code"></block> Tabla (una tabla en todo el clúster) y asigna un nuevo identificador de objeto (OID) a esa fila. Por último, el servidor utiliza el OID para crear un enlace simbólico entre el cluster y el directorio dado. El directorio<block ref="8e3da386e945c59fb1e1cd1d7a47697c" prefix=" " category="inline-code"></block> contiene enlaces simbólicos que apuntan a cada uno de los tablespaces no incorporados definidos en el cluster.</block>
  <block id="249fd7d68098688fab42436eed51be7d" category="doc">Configuración de la base de datos</block>
  <block id="8daf26b2c72dd18a89fa89a6b1aa988d" category="paragraph">Existen varias configuraciones de ajuste PostgreSQL que pueden mejorar el rendimiento.</block>
  <block id="abb3dae412afe5c801e9ab90de71675b" category="paragraph">Los parámetros más utilizados son los siguientes:</block>
  <block id="bfdf741f4acb3dfee6e87075b535610e" category="list-text"><block ref="39d79378db03fed7c5ba62efba38e327" prefix="" category="inline-code"></block>: El número máximo de conexiones de base de datos que se deben tener al mismo tiempo. Use este parámetro para restringir el intercambio en disco y eliminar el rendimiento. En función de los requisitos de la aplicación, también puede ajustar este parámetro para la configuración del pool de conexiones.</block>
  <block id="9625e1a6f5d1f695fd1c72401afaa07e" category="list-text"><block ref="904d399f43708a8a5b6d10c1ee3f8356" prefix="" category="inline-code"></block>: El método más simple para mejorar el rendimiento de su servidor de base de datos. El valor por defecto es bajo para la mayoría del hardware moderno. Se establece durante la implementación en aproximadamente el 25% de la RAM disponible en el sistema. Esta configuración de parámetro varía según cómo funciona con instancias de base de datos concretas; es posible que tenga que aumentar y disminuir los valores por prueba y error. Sin embargo, es probable que si lo establece alto, el rendimiento se vea afectado.</block>
  <block id="d1960c56572383fc401fec3f0b767cf9" category="list-text"><block ref="5edeed59821790d8bec6d32da26bca4c" prefix="" category="inline-code"></block>: Este valor indica al optimizador de PostgreSQL cuánta memoria PostgreSQL tiene disponible para almacenar datos en caché y ayuda a determinar si se debe usar un índice. Un valor mayor aumenta la probabilidad de usar un índice. Este parámetro se debe definir en la cantidad de memoria asignada a.<block ref="e15ed0f69e5c2475450b97691d6a2cee" prefix=" " category="inline-code"></block> Más la cantidad de caché del sistema operativo disponible. A menudo, este valor supera el 50% de la memoria total del sistema.</block>
  <block id="508df54f84fc7abb00f3a92937ca3506" category="list-text"><block ref="1edef4d43b06d4deb28010505df5724d" prefix="" category="inline-code"></block>: Este parámetro controla la cantidad de memoria que se utilizará en las operaciones de ordenación y las tablas hash. Si realiza una clasificación intensiva en su aplicación, es posible que necesite aumentar la cantidad de memoria, pero tenga cuidado. No es un parámetro de todo el sistema, sino uno por operación. Si una consulta compleja tiene varias operaciones de ordenación en ella, utiliza varias unidades de memoria work_mem, y varios back-ends podrían estar haciendo esto simultáneamente. Esta consulta a menudo puede hacer que el servidor de base de datos cambie si el valor es demasiado grande. Esta opción se llamaba anteriormente sort_mem en versiones anteriores de PostgreSQL.</block>
  <block id="59d9770060aecba84c7e8ed849b5653d" category="list-text"><block ref="65768448b4f275b95af20a317c7355a9" prefix="" category="inline-code"></block>: Este parámetro determina si todas sus páginas WAL deben sincronizarse con el disco mediante el uso de fsync() antes de que se confirme una transacción. Desactivarlo puede mejorar el rendimiento de escritura y activarlo aumenta la protección frente al riesgo de daño cuando el sistema se bloquea.</block>
  <block id="625a65dd6cef83bac66319bde3894899" category="list-text"><block ref="ff5a06a39dd6824f30a778a51cf7ea69" prefix="" category="inline-code"></block>: El proceso de punto de control vacía los datos confirmados en el disco. Esto implica una gran cantidad de operaciones de lectura/escritura en disco. El valor se establece en segundos y los valores más bajos disminuyen el tiempo de recuperación de fallos y el aumento de los valores puede reducir la carga en los recursos del sistema reduciendo las llamadas de punto de control. En función de la criticidad de la aplicación, el uso y la disponibilidad de la base de datos, defina el valor de checkpoint_timeout.</block>
  <block id="309b1036c45e7ad490448925dc4f9597" category="list-text"><block ref="6a5c0586429891e84e05d6ab15088405" prefix="" category="inline-code"></block> y..<block ref="9080796d32078fea7d191100eab64f92" prefix=" " category="inline-code"></block>: Estas opciones se utilizan juntas para ayudar a mejorar el rendimiento mediante la escritura de múltiples transacciones que se comprometen a la vez. Si hay varios objetos COMMIT_SIDBINGS activos en el momento en que la transacción se está confirmando, el servidor espera a COMMIT_DELAY microsegundos para intentar confirmar varias transacciones a la vez.</block>
  <block id="8d5137ce002c6328c2b5f4f328662e1d" category="list-text"><block ref="fa4ca2cd95c20a44171f964fb8f5fdb9" prefix="" category="inline-code"></block>: Configure el número óptimo de trabajadores para los procesos. Max_parallel_workers corresponde al Núm. De CPU disponibles. Dependiendo del diseño de la aplicación, las consultas pueden requerir un número menor de trabajadores para las operaciones en paralelo. Es mejor mantener el valor de ambos parámetros igual, pero ajustar el valor después de la prueba.</block>
  <block id="c8736e7ca19e9096796c624f3030dae5" category="list-text"><block ref="8dda85a5feb6de66d8f5f9a4cbdb0754" prefix="" category="inline-code"></block>: Este valor controla la forma en que PostgreSQL visualiza las lecturas de disco no secuenciales. Un valor más alto significa que PostgreSQL es más probable que use una exploración secuencial en lugar de una exploración de índice, lo que indica que su servidor tiene discos rápidos Modificar esta configuración después de evaluar otras opciones como optimización basada en planes, aspirar, indexar para alterar consultas o esquemas.</block>
  <block id="17edf3863f12b7d9480b3336a9fca773" category="list-text"><block ref="709989c844c22473cb8406550423d39a" prefix="" category="inline-code"></block>: Este parámetro establece el número de operaciones de E/S de disco simultáneas que PostgreSQL intenta ejecutar simultáneamente. Al aumentar este valor, aumenta el número de operaciones de I/O que cualquier sesión de PostgreSQL individual intenta iniciar en paralelo. El rango permitido es de 1 a 1.000, o cero para deshabilitar la emisión de solicitudes de E/S asíncronas. Actualmente, esta configuración sólo afecta a las exploraciones de pila de bitmap. Las unidades de estado sólido (SSD) y otro almacenamiento basado en memoria (NVMe) pueden procesar muchas solicitudes concurrentes, con lo que el mejor valor puede ser entre cientos.</block>
  <block id="82b38edb10ad73f9645c5d65e73a659b" category="paragraph">Consulte la documentación de PostgreSQL para obtener una lista completa de los parámetros de configuración de PostgreSQL.</block>
  <block id="402fbc243dbef50cd5c8e57ccbdd92f5" category="section-title">BRINDIS</block>
  <block id="0d2b62abb26bd0b4109f5bc967250933" category="paragraph">TOAST es la sigla en inglés de la Técnica de Almacenamiento de Atributos Sobredimensionados. PostgreSQL utiliza un tamaño de página fijo (comúnmente 8KB) y no permite que las tuplas se abarquen varias páginas. Por lo tanto, no es posible almacenar valores de campo grandes directamente. Cuando intenta almacenar una fila que excede este tamaño, TOAST divide los datos de las columnas grandes en “pedazos” más pequeños y los almacena en una tabla de TOSTADAS.</block>
  <block id="3f11f21bdc22c3c955c3f0fca39e9bc0" category="paragraph">Los grandes valores de atributos tostados se extraen (si se selecciona) solo en el momento en que se envía el conjunto de resultados al cliente. La tabla en sí es mucho más pequeña y puede caber más filas en la caché de buffers compartida de lo que podría sin ningún almacenamiento fuera de línea (TOSTADO).</block>
  <block id="9a311ef6dad816cb7a15c0ab41920ad8" category="section-title">VACÍO</block>
  <block id="385e23b8ebe64dfd0005f6846cc8e85e" category="paragraph">En el funcionamiento normal de PostgreSQL, las tuplas que se eliminan o quedan obsoletas por una actualización no se eliminan físicamente de su tabla; permanecen presentes hasta que se ejecuta EL VACÍO. Por lo tanto, debe ejecutar EL VACÍO periódicamente, especialmente en tablas actualizadas con frecuencia. A continuación, se debe reclamar el espacio que ocupa para que las nuevas filas lo reutilicen, a fin de evitar la interrupción del espacio en disco. Sin embargo, no devuelve el espacio al sistema operativo.</block>
  <block id="db81319c35b48ed94867775a9a1ce1d7" category="paragraph">El espacio libre dentro de una página no está fragmentado. EL VACÍO reescribe todo el bloque, empaquetando eficientemente las filas restantes y dejando un único bloque contiguo de espacio libre en una página.</block>
  <block id="8a5c17164c9920590fc057ee01f2fcb3" category="paragraph">Por el contrario, EL VACÍO COMPLETO compacta activamente las tablas escribiendo una versión completamente nueva del archivo de tabla sin espacio muerto. Esta acción minimiza el tamaño de la tabla, pero puede tardar mucho tiempo. También requiere espacio adicional en disco para la nueva copia de la tabla hasta que finalice la operación. El objetivo del VACÍO DE rutina es evitar la actividad COMPLETA DEL VACÍO. Este proceso no solo mantiene las tablas en su tamaño mínimo, sino que también mantiene el uso constante del espacio en disco.</block>
  <block id="61bcd96a2c1f8026527cbf2019d6e9a4" category="doc">Inicialización</block>
  <block id="f4f9dac58f7c47e819293af5f2dd1177" category="paragraph">Cree un nuevo cluster de base de datos mediante<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> programa. An<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> script crea los archivos de datos, las tablas del sistema y las bases de datos de plantilla (template0 y template1) que definen el cluster.</block>
  <block id="b668460552732302350bbb840d57931c" category="paragraph">La base de datos de plantillas representa una base de datos de stock. Contiene definiciones para tablas del sistema, vistas estándar, funciones y tipos de dato.<block ref="3865cf98fe802a965570b4a10a1d894b" prefix=" " category="inline-code"></block> actúa como argumento para el<block ref="abc91e782cd3950bfa31202aff74ca69" prefix=" " category="inline-code"></block> script que especifica la ubicación del cluster de base de datos.</block>
  <block id="8fcd14822a5b94d212898fe3e006526e" category="paragraph">Todos los objetos de base de datos en PostgreSQL son administrados internamente por los OIDs respectivos. Las tablas y los índices también se gestionan mediante OID individuales. Las relaciones entre los objetos de base de datos y sus respectivos OID se almacenan en las tablas de catálogo del sistema adecuadas, según el tipo de objeto. Por ejemplo, los OIDs de las bases de datos y las tablas de pila se almacenan en<block ref="d0fcebb608269edbd5d67486884ebed7" prefix=" " category="inline-code"></block> y `pg_class, respectivamente. Puede determinar los OID emitiendo consultas en el cliente PostgreSQL.</block>
  <block id="d0e97e34fe92edd2facd0f7377b6340b" category="paragraph">Cada base de datos tiene sus propias tablas individuales y archivos de índice que están restringidos a 1GB. Cada tabla tiene dos archivos asociados, sufijos respectivamente con<block ref="7b9b00c45b01f7b7c6d3a3c8ba2e9275" prefix=" " category="inline-code"></block> y..<block ref="a1d869a79e2f43693a6a416fcbdc2724" prefix=" " category="inline-code"></block>. Se les conoce como el mapa de espacio libre y el mapa de visibilidad. Estos archivos almacenan la información sobre la capacidad de espacio libre y tienen visibilidad en cada página del archivo de tabla. Los índices solo tienen mapas de espacio libre individuales y no tienen mapas de visibilidad.</block>
  <block id="048a7ed79caf84bb5c725efc5f474911" category="paragraph">La<block ref="c28f4f32219f5ff99fb4b116980b8549" prefix=" " category="inline-code"></block> el directorio contiene los logs de escritura anticipada. Los registros de escritura anticipada se utilizan para mejorar el rendimiento y la fiabilidad de las bases de datos. Cada vez que actualiza una fila en una tabla, PostgreSQL escribe primero el cambio en el registro de escritura anticipada y, más tarde, escribe las modificaciones en las páginas de datos reales en un disco. La<block ref="f7223cfaa9416056a91e259e326ac5cf" prefix=" " category="inline-code"></block> el directorio normalmente contiene varios archivos, pero initdb crea solo el primero. Se añaden archivos adicionales según sea necesario. Cada archivo xlog tiene 16MB cm de longitud.</block>
  <block id="789a6c7dd865d16eb1df122bcc5c9a3a" category="admonition">*NetApp recomienda* usar NFSv4,1 si se requieren capacidades de NFSv4. Existen algunas mejoras funcionales en el protocolo NFSv4 en NFSv4,1 que mejoran la resiliencia en ciertos casos perimetrales.</block>
  <block id="8e86e0aee135afb67c6a1d3d6e0f3306" category="inline-link-macro">Los tamaños de transferencia de NFS</block>
  <block id="d84b41126744795c4ee82f7b256e7234" category="inline-link-macro">FC SAN</block>
  <block id="2c8c2171fc87c96e58fb40d8714f85cf" category="doc">Arquitectura PostgreSQL</block>
  <block id="ee62b4420d426c21a46d892ac084872a" category="paragraph">PostgreSQL es un RDBMS basado en la arquitectura de cliente y servidor. Una instancia PostgreSQL se conoce como un cluster de base de datos, que es una colección de bases de datos en lugar de una colección de servidores.</block>
  <block id="89c30c326e106773af32af40255b92a8" category="inline-image-macro">Error: No se ha encontrado el gráfico</block>
  <block id="54c2dd41fd1ad3efa25e80bee0bae549" category="paragraph">Hay tres elementos principales en una base de datos PostgreSQL: El postmaster, el front-end (cliente) y el back-end El cliente envía solicitudes al postmaster con información como el protocolo IP y a qué base de datos conectarse. El posmaster autentica la conexión y la pasa al proceso back-end para continuar la comunicación. El proceso back-end ejecuta la consulta y envía los resultados directamente al front-end (cliente).</block>
  <block id="9f96e07bbaf7c0237047d6d0f95301a8" category="paragraph">Una instancia PostgreSQL se basa en un modelo multiproceso en lugar de un modelo multithread. Genera múltiples procesos para diferentes trabajos, y cada proceso tiene su propia funcionalidad. Los procesos principales incluyen el proceso del cliente, el proceso del escritor de WAL, el proceso del escritor en segundo plano y el proceso del puntero de control:</block>
  <block id="6aebf901bd4be26a765c56e4133b3798" category="list-text">Cuando un proceso de cliente (primer plano) envía solicitudes de lectura o escritura a la instancia de PostgreSQL, no lee ni escribe datos directamente en el disco. Primero almacena los datos en buffers compartidos y buffers de registro de escritura anticipada (WAL).</block>
  <block id="458239ee6c634dc5fef96f9dfab275f0" category="list-text">Un proceso de escritor WAL manipula el contenido de los buffers compartidos y los buffers WAL para escribir en los logs WAL. Los registros WAL son normalmente registros de transacciones de PostgreSQL y se escriben secuencialmente. Por lo tanto, para mejorar el tiempo de respuesta de la base de datos, PostgreSQL primero escribe en los registros de transacciones y reconoce al cliente.</block>
  <block id="9ec2999256fe568cd596b42e7da2cc39" category="list-text">Para poner la base de datos en un estado coherente, el proceso de escritor en segundo plano comprueba periódicamente el buffer compartido para ver si hay páginas sucias. A continuación, vacía los datos en los archivos de datos que se almacenan en volúmenes o LUN de NetApp.</block>
  <block id="5c852dd8ba7215c01dfde8e98f6c46c6" category="list-text">El proceso de puntero de control también se ejecuta periódicamente (con menos frecuencia que el proceso en segundo plano) e impide cualquier modificación en los buffers. Indica al proceso de escritor WAL que escriba y vacíe el registro de punto de control al final de los registros WAL que están almacenados en el disco NetApp. También indica al proceso de escritura en segundo plano que escriba y vacíe todas las páginas sucias en el disco.</block>
  <block id="0a7b1215fd0b9621d4d7300f88b2906c" category="doc">Software para la protección de datos</block>
  <block id="e265011e47d11db43ee112fd2fdc9d5b" category="paragraph">El complemento de NetApp SnapCenter para base de datos de PostgreSQL, combinado con las tecnologías de Snapshot y FlexClone de NetApp, le ofrece ventajas como:</block>
  <block id="4dcdaba06a92b8fecfdc823643a71723" category="list-text">Backup y restauración rápidos.</block>
  <block id="aee746a577a1baebdc33197fb5f3a279" category="list-text">Clones con gestión eficiente del espacio.</block>
  <block id="b96bb0cd2ebc0389b6670602ac80d983" category="list-text">La capacidad de crear un sistema de recuperación ante desastres rápido y eficaz.</block>
  <block id="9e060ad00fced94f2616dd71fbc49f76" category="paragraph">Puede que prefiera elegir los partners de backup premium de NetApp, como Veeam Software y Commvault, bajo las siguientes circunstancias:</block>
  <block id="0ee17b3b55ea2b0af3d90985bc347775" category="list-text">Gestionar cargas de trabajo en un entorno heterogéneo</block>
  <block id="88fbde7bbe0274fbe9e7ce01c563d03c" category="list-text">Almacenar backups en el cloud o en cinta para su retención a largo plazo</block>
  <block id="445e3e0cce7f959696dde65b3be27843" category="list-text">Soporte para una amplia gama de versiones y tipos de SO</block>
  <block id="21c5d67cc22beaf7d7c9c84c8deaabbe" category="paragraph">El plugin de SnapCenter para PostgreSQL es un plugin de soporte comunitario y la configuración y documentación está disponible en la tienda de automatización de NetApp. Con SnapCenter, el usuario puede realizar backups de la base de datos, clonar y restaurar los datos remotamente.</block>
  <block id="7d334ca369e4a752ec91b1503183f0ed" category="summary">Soluciones para SAP HANA y AnyDB</block>
  <block id="1ac73696f4529e3901b0d4e5430365cb" category="doc">SAP HANA y SAP con AnyDB</block>
  <block id="2c1b27a986b5e37a810d61f72b23ee4b" category="paragraph">Las mejores prácticas para configurar, gestionar y automatizar soluciones SAP se pueden encontrar en la página de soluciones SAP de NetApp.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link-macro">aquí</block>
  <block id="ee1e67308b27672a8f54eace4c615a98" category="paragraph">Haga clic en <block ref="c95e4a3e1de9e00fefc4bf8a7ce42893" category="inline-link-macro-rx"></block> para más.</block>
  <block id="beb3ca55ed0a53a38a2b97540b05d6e4" category="summary">Microsoft SQL Server en ONTAP</block>
  <block id="7636ae91f443b605f05bed59d7d57a02" category="doc">Recuperación ante desastres de Microsoft SQL Server</block>
  <block id="5f3bfe8f92842bdc2f9455d4102f2531" category="list-text">Si se usa CIFS, la SVM de destino debe ser miembro del mismo dominio de Active Directory al que pertenece la SVM de origen para que las listas de control de acceso (ACL) almacenadas en archivos NAS no se interrumpan durante la recuperación de un desastre.</block>
  <block id="e0fd410ebdc68e7ca628bbca66b63ff4" category="list-text">No es necesario usar nombres de volúmenes de destino iguales a los nombres de los volúmenes de origen, pero puede simplificar la gestión del proceso de montaje de los volúmenes de destino en el destino. Si se utiliza CIFS, debe hacer que el espacio de nombres NAS de destino sea idéntico en rutas y la estructura de directorios para el espacio de nombres de origen.</block>
  <block id="18c6a681ea46e1ed394e092461bb53ef" category="list-text">Distribuya los volúmenes que contienen datos de SQL Server en diferentes nodos del clúster para permitir que todos los nodos del clúster compartan la actividad de replicación de SnapMirror. Esta distribución optimiza el uso de los recursos de los nodos.</block>
  <block id="0a01e6837f5c691536f0b6cbdd0232ec" category="inline-link-macro">TR-4015: Guía de configuración de SnapMirror y prácticas recomendadas para ONTAP 9</block>
  <block id="1cca1a3fad8c6dd7e2dadbd2aa08bf07" category="paragraph">Para obtener más información acerca de SnapMirror, consulte <block ref="64b916f792bad525a069a243c092b62e" category="inline-link-macro-rx"></block>.</block>
  <block id="77641f4a3e4406855e878235cbd89b87" category="doc">Configuración de CPU</block>
  <block id="a51adad5719779145ac252822e328611" category="section-title">Hyperthreading</block>
  <block id="fe520b79816bad6a21fbebcb205c7ca9" category="paragraph">Hyperthreading es la implementación de multithreading simultáneo (SMT) patentada por Intel, que mejora la paralelización de los cálculos (multitarea) realizados en microprocesadores x86.</block>
  <block id="673c216e20d1cf8827f347c01dace664" category="paragraph">La advertencia aquí es que cada versión de SQL Server tiene sus propias limitaciones en cuanto a la potencia informática que puede utilizar. Para obtener más información, consulte Compute Capacity Limits by Edition of SQL Server.</block>
  <block id="d06fce44fdcf20791141e7585205a477" category="section-title">Las entradas del registro indican el número de núcleos que se utilizan tras el inicio de SQL Server.</block>
  <block id="cf0e2551e639758cc3c4d82df655eccd" category="inline-link-macro">SQL Server 2022: Su plataforma de datos moderna</block>
  <block id="809c9e1f6ce0bc82bf42fae361c6f43e" category="paragraph">Por lo tanto, para utilizar todas las CPU, debe utilizar la licencia de núcleo por procesador. Para obtener información detallada sobre las licencias de SQL Server, consulte <block ref="457abfaf1083b1cbfc49f2783069c6cd" category="inline-link-macro-rx"></block>.</block>
  <block id="cb8d56a3511d402b7355db8502a54c5a" category="section-title">Afinidad de CPU</block>
  <block id="74f896768ee487acfd4c42370c202bed" category="paragraph">SQL Server admite la afinidad del procesador mediante dos opciones:</block>
  <block id="cb315fb2b62c836ba51357d46f2e8c3f" category="list-text">Máscara de afinidad de CPU</block>
  <block id="cb00a2408ea648cf85edfd7dbb23fbe0" category="list-text">Máscara de I/O de afinidad</block>
  <block id="28a51b601de21080b76fe2d8b2ec8101" category="paragraph">La opción de máscara de E/S de afinidad enlaza E/S de disco de SQL Server a un subconjunto de CPU. En entornos OLTP de SQL Server, esta extensión puede mejorar el rendimiento de los subprocesos de SQL Server que emiten operaciones de E/S.</block>
  <block id="49e103832576f4486179df8868372d17" category="section-title">Grado máximo de paralelismo (MAXDOP)</block>
  <block id="a99f7ebb3b0f5b0ecea93ed586b2a17d" category="section-title">Máximo de Threads de Trabajador</block>
  <block id="aff27140f50a549b1331add8d5025f7e" category="paragraph">La opción Máximo de Threads de Trabajador ayuda a optimizar el rendimiento cuando un gran número de clientes están conectados a SQL Server.</block>
  <block id="aefc7f2ee96effbbbe49e6ece6d2f72a" category="paragraph">Normalmente, se crea un thread de sistema operativo independiente para cada solicitud de consulta. Si se realizan cientos de conexiones simultáneas a SQL Server, un subproceso por solicitud de consulta consume grandes cantidades de recursos del sistema. La opción Máximo de Threads de Trabajador ayuda a mejorar el rendimiento al permitir que SQL Server cree un pool de threads de trabajador para dar servicio a un número mayor de solicitudes de consulta.</block>
  <block id="decd79137325e1efbc7b994f946ea24f" category="paragraph">El valor por defecto es 0, que permite a SQL Server configurar automáticamente el número de threads de trabajador al iniciar. Esto funciona para la mayoría de los sistemas. Max worker threads es una opción avanzada y no se debe modificar sin la ayuda de un administrador de base de datos experimentado (DBA).</block>
  <block id="030a270970f70c1bd91d3689b6f95f3f" category="inline-link-macro">Configure la opción de configuración del servidor de threads de trabajo máx</block>
  <block id="2a0c648df721b9bc2643d59c4a3a310a" category="paragraph">¿Cuándo debe configurar SQL Server para que utilice más threads de trabajo? Si la longitud media de la cola de trabajo de cada programador es superior a 1, puede que se beneficie de agregar más threads al sistema, pero sólo si la carga no está vinculada a la CPU o si experimenta otras esperas pesadas. Si cualquiera de estos ocurre, agregar más hilos no ayuda porque terminan esperando otros cuellos de botella del sistema. Para obtener más información sobre el máximo de threads de trabajo, consulte <block ref="77c391df5f9f06cdf367c2a7314ce351" category="inline-link-macro-rx"></block>.</block>
  <block id="29d04e616d2293c4c7538dd6226feac5" category="section-title">Configuración de un máximo de threads de trabajador mediante SQL Server Management Studio.</block>
  <block id="5962130d833e0408cf58a87e342bc1f9" category="doc">Archivos tempdb de Microsoft SQL Server</block>
  <block id="ca75041d415f4dafabb49b7f06b634ed" category="paragraph">La contención de página se puede producir en las páginas de mapa de asignación de lobal (GAM), mapa de asignación global compartida (SGAM) o espacio libre de página (PFS) cuando SQL Server debe escribir en páginas especiales del sistema para asignar nuevos objetos. Los pestillos protegen (bloquean) estas páginas en la memoria. En una instancia de SQL Server ocupada, puede tardar mucho tiempo en obtener un bloqueo en una página del sistema en tempdb. Esto da como resultado tiempos de ejecución de consultas más lentos y se conoce como contención de bloqueo interno. Consulte las siguientes prácticas recomendadas para crear archivos de datos tempdb:</block>
  <block id="44dbc82801d84781083ed9e23b63be00" category="list-text">Para &lt; or = a 8 núcleos: Archivos de datos tempdb = número de núcleos</block>
  <block id="6203fcdbdad10bb603fd00edd2f0fcf5" category="list-text">Para &gt; 8 núcleos: 8 archivos de datos tempdb</block>
  <block id="b9f341e4fb0e6b384aa7ec0b5c33f964" category="paragraph">El siguiente script de ejemplo modifica tempdb creando ocho archivos tempdb y moviendo tempdb al punto de montaje<block ref="ae6fbe62f3ddc46fa9a9885244d23675" prefix=" " category="inline-code"></block> Para SQL Server 2012 y posterior.</block>
  <block id="0424163d6b24f29436021dfd7072863b" category="paragraph">A partir de SQL Server 2016, el número de núcleos de CPU visibles para el sistema operativo se detecta automáticamente durante la instalación y, en función de ese número, SQL Server calcula y configura el número de archivos tempdb necesarios para un rendimiento óptimo.</block>
  <block id="3b5b2ca12603a36517ce602ffe47361c" category="list-text">NetApp SnapCenter como software de backup, que incluye:</block>
  <block id="36a92a010308100e1efc10d9eb98c369" category="list-text">Plugin de SnapCenter para Microsoft Windows</block>
  <block id="ec51578d7d8f930329548bf3d00d7038" category="list-text">Plugin de SnapCenter para SQL Server</block>
  <block id="a6d698a68f555339f6e91957f636ad69" category="list-text">Arquitectura y administración de Microsoft SQL Server</block>
  <block id="697ea025ecb303d4f40d1bf3a8b4bde0" category="inline-link-macro">Herramienta de matriz de interoperabilidad de NetApp (IMT)</block>
  <block id="fbd4c4f9516af91c6c3cb5fa35fb5720" category="doc">Consideraciones sobre almacenamiento de Microsoft SQL Server</block>
  <block id="8136e237a15b0f72e5d7a60392225d17" category="paragraph">Para optimizar ambas tecnologías, es vital comprender el patrón y las características de E/S de SQL Server. Gracias a una buena distribución de almacenamiento para una base de datos de SQL Server, el rendimiento de SQL Server y la gestión de la infraestructura de SQL Server. Una buena distribución de almacenamiento también permite que la puesta en marcha inicial tenga éxito y que el entorno crezca sin problemas con el tiempo a medida que crece el negocio.</block>
  <block id="3da07c62fca4dd242f7ffcfcf72998be" category="section-title">Diseño de almacenamiento de datos</block>
  <block id="9e45010900186b3cbbe04f954a6f3562" category="paragraph">Para las bases de datos de SQL Server que no utilizan SnapCenter para realizar backups, Microsoft recomienda colocar los archivos de datos y de registro en unidades independientes. Para las aplicaciones que actualizan y solicitan datos simultáneamente, el archivo de registro tiene un gran consumo de escrituras y el archivo de datos (en función de la aplicación) tiene un gran volumen de lecturas y escrituras. Para la recuperación de datos, el archivo de registro no es necesario. Por lo tanto, las solicitudes de datos pueden satisfacerse desde el archivo de datos ubicado en su propia unidad.</block>
  <block id="df018ea4abdb71f91802ea1d4fb0fb37" category="inline-link-macro">Coloque los archivos de datos y de registro en unidades separadas</block>
  <block id="f2f25c68d67c561be1926b4b06e676b0" category="paragraph">Cuando se crea una nueva base de datos, Microsoft recomienda especificar unidades independientes para los datos y los registros. Para mover archivos después de crear la base de datos, ésta debe desconectarse. Para obtener más recomendaciones de Microsoft, consulte <block ref="04fab8828edf0d2e95eff3c4f124b372" category="inline-link-macro-rx"></block>.</block>
  <block id="d5350d8759b1ec84607e47908809058e" category="section-title">Agregados</block>
  <block id="77f1d6b9cbcaf3663f6bdd19a821e773" category="list-text">Un agregado de gran tamaño permite hacer un uso más eficiente del espacio en disco.</block>
  <block id="63d9962fabe500361986d05317bd65a5" category="paragraph">Para alta disponibilidad (HA), colocar la réplica síncrona secundaria de SQL Server Always On Availability Group en una máquina virtual de almacenamiento (SVM) independiente del agregado. Para fines de recuperación ante desastres, coloque la réplica asíncrona en un agregado que forma parte de un clúster de almacenamiento separado en el sitio de recuperación ante desastres, con el contenido replicado mediante la tecnología SnapMirror de NetApp. NetApp recomienda tener al menos un 10% de espacio libre disponible en un agregado para un rendimiento del almacenamiento óptimo.</block>
  <block id="c6f01c78bfe0a0a495cb5d3ed77824a9" category="section-title">Volúmenes</block>
  <block id="17fce39141e6fa457c789ce2c3239b0c" category="section-title">Consideraciones sobre el diseño del volumen</block>
  <block id="d1c9fdbcdbb8521971decf35c6d1c0c8" category="paragraph">Antes de crear un diseño de volumen de base de datos, es importante comprender cómo los patrones de I/O de SQL Server y las características varían en función de la carga de trabajo y de los requisitos de backup y recuperación. Consulte las siguientes recomendaciones de NetApp para volúmenes flexibles:</block>
  <block id="674343739e297abb52c536a453ebaad0" category="list-text">Utilice puntos de montaje NTFS en lugar de letras de unidad para superar la limitación de 26 unidades en Windows. Cuando se usan puntos de montaje de volumen, se recomienda generalmente asignar a la etiqueta de volumen el mismo nombre que el punto de montaje.</block>
  <block id="d5fe4f7f1c47df1ec78c926d21498f73" category="list-text">Cuando sea necesario, configure una política de tamaño automático de volúmenes para ayudar a evitar condiciones de falta de espacio. 17 Guía de mejores prácticas para Microsoft SQL Server con ONTAP © 2022 NetApp, Inc. Todos los derechos reservados.</block>
  <block id="3a9320cf27fb328f77ec6153273784d5" category="list-text">Si instala SQL Server en un recurso compartido de SMB, asegúrese de que Unicode esté habilitado en los volúmenes SMB/CIFS para crear carpetas.</block>
  <block id="4176288dbc134524f79476ba4e57e3aa" category="list-text">Tempdb es una base de datos del sistema utilizada por SQL Server como espacio de trabajo temporal, especialmente para operaciones DBCC CHECKDB intensivas en E/S. Por lo tanto, coloque esta base de datos en un volumen dedicado con un conjunto de discos separado. En entornos grandes en los que el número de volúmenes es un reto, puede consolidar tempdb en menos volúmenes y almacenarlo en el mismo volumen que otras bases de datos del sistema tras una planificación cuidadosa. La protección de datos para tempdb no es una prioridad alta porque esta base de datos se vuelve a crear cada vez que se reinicia SQL Server.</block>
  <block id="57eda1aa66778bf3c77caa0294652ba8" category="list-text">Coloque los archivos de datos de usuario (.mdf) en volúmenes independientes debido a que son cargas de trabajo de lectura/escritura aleatorias. Es común crear backups de registros de transacciones con más frecuencia que los backups de bases de datos. Por este motivo, coloque los archivos de registro de transacciones (.ldf) en un volumen o VMDK separados de los archivos de datos para poder crear programaciones de backup independientes para cada uno. Esta separación también aísla la E/S de escritura secuencial de los archivos de registro de la E/S de lectura/escritura aleatoria de los archivos de datos y mejora significativamente el rendimiento de SQL Server.</block>
  <block id="b703a2ceaabee81dd9dfcfb3a4b738ee" category="list-text">Asegúrese de que los archivos de la base de datos del usuario y el directorio de registro para almacenar backup de registros se encuentren en volúmenes independientes para evitar que la política de retención sobrescriba las snapshots cuando estas se usen con la tecnología SnapVault.</block>
  <block id="152bb9192ea87919eda3b4f97fd4e1bf" category="list-text">Asegúrese de que las bases de datos de SQL Server residen en LUN independientes de los LUN que tienen archivos que no son de base de datos, como los archivos relacionados con búsqueda de texto completo.</block>
  <block id="e2faf723544ceb1ea01ba41cef2d633a" category="list-text">La colocación de archivos secundarios de base de datos (como parte de un grupo de archivos) en volúmenes distintos mejora el rendimiento de la base de datos de SQL Server. Esta separación solo es válida si el archivo .mdf de la base de datos no comparte su LUN con ningún otro archivo .mdf.</block>
  <block id="ae72f885471636cbfd0dbe902ddf24e1" category="list-text">Si crea LUN con DiskManager u otras herramientas, asegúrese de que el tamaño de unidad de asignación esté establecido en 64K para las particiones al formatear las LUN.</block>
  <block id="ac4782a9243acaaff52164f9e47417d5" category="inline-link-macro">Microsoft Windows e MPIO nativo bajo las prácticas recomendadas de ONTAP para SAN moderna</block>
  <block id="934e206705ddafc720e4a8f25a4acded" category="list-text">Consulte <block ref="95506eaa4fca841adc20747ae4650d10" category="inline-link-macro-rx"></block> Para aplicar la compatibilidad con accesos múltiples en Windows a dispositivos iSCSI en las propiedades MPIO.</block>
  <block id="31a8d85b6a44cffc2c7dfc6387696f31" category="section-title">Directorio de registro</block>
  <block id="29766ed5967263787fface0a4ad3396f" category="paragraph">Los tamaños del directorio de registro de host se calculan de la siguiente manera:
Tamaño del directorio de registro de host = ( (tamaño máximo de LDF de base de datos x tasa de cambio de registro diario %) x (retención de instantánea) ÷ (1: Porcentaje de espacio de sobrecarga de LUN)
La fórmula de ajuste de tamaño del directorio de registro del host asume una sobrecarga del 10% de las LUN</block>
  <block id="31333b887781902e13c263570523ddc1" category="paragraph">Coloque el directorio de registro en un volumen o LUN dedicados. La cantidad de datos en el directorio de registro del host depende del tamaño de los backups y de la cantidad de días que se retienen los backups. SnapCenter solo permite un directorio de registro de host por cada host SQL Server. Puede configurar los directorios de registro de host en SnapCenter --&gt; Host --&gt; Configurar el plugin.</block>
  <block id="e815059019027c04aa969a50787d5b34" category="paragraph">*NetApp recomienda* lo siguiente para un directorio de registro de host:</block>
  <block id="07ae4edb1ccfbfe1f5da6006c95ee4a9" category="list-text">Asegúrese de que el directorio de registro de host no esté compartido por ningún otro tipo de datos que pueda dañar los datos de la instantánea de backup.</block>
  <block id="991bd1f492a593453f65c2a23c1f1612" category="list-text">No coloque bases de datos de usuario ni bases de datos del sistema en un LUN que aloje puntos de montaje.</block>
  <block id="bdfdf6f1492d7a7beac0bce2c4109f95" category="list-text">Cree el directorio de registro de host en el volumen FlexVol dedicado al cual SnapCenter copia los registros de transacciones.</block>
  <block id="7b01578e73f5081fecdcc6dedf28aa3c" category="list-text">Utilice los asistentes de SnapCenter para migrar bases de datos al almacenamiento NetApp de modo que las bases de datos se almacenen en ubicaciones válidas, lo que permite realizar correctamente las operaciones de backup y restauración de SnapCenter. Tenga en cuenta que el proceso de migración es disruptivo y puede provocar que las bases de datos se desconecten mientras se realiza la migración.</block>
  <block id="b2d0e2f60ee139155b728ef6933efe7c" category="list-text">Deben establecerse las siguientes condiciones para las instancias de clúster de conmutación por error (FCI) de SQL Server:</block>
  <block id="863fda0972208e1e15d0c4a16d6915af" category="list-text">Si va a utilizar una instancia de clúster de conmutación al nodo de respaldo, el LUN del directorio de registro de host debe ser un recurso de disco de clúster en el mismo grupo de clústeres que la instancia de SQL Server que se va a realizar el backup de SnapCenter.</block>
  <block id="ddb1104e1e71caabad3e7639c7675af8" category="list-text">Si utiliza una instancia de clúster de conmutación al nodo de respaldo, las bases de datos de usuario deben colocarse en LUN compartidos que sean recursos de clúster de discos físicos asignados al grupo de clústeres asociado con la instancia de SQL Server.</block>
  <block id="bca5f9a18696e080113088282fe481de" category="doc">Configuración de memoria de Microsoft SQL Server</block>
  <block id="02578ec0e8ce2fbef37ca792fd20c289" category="section-title">Memoria máxima del servidor</block>
  <block id="81dbc262a15fc545920141998ddd1c17" category="paragraph">La opción max server memory define la cantidad máxima de memoria que puede utilizar la instancia de SQL Server.</block>
  <block id="c9fa383209ffc05f20049101298fec96" category="paragraph">Se utiliza generalmente si se ejecutan varias aplicaciones en el mismo servidor donde se ejecuta SQL Server y desea garantizar que estas aplicaciones tengan suficiente memoria para funcionar correctamente.</block>
  <block id="1ceeb5f5f18aefbc39e34d0d3c7b7e1c" category="paragraph">Algunas aplicaciones solo utilizan la memoria disponible cuando se inician y no solicitan más, incluso si es necesario. Aquí es donde entra en juego la configuración de memoria máxima del servidor.</block>
  <block id="6e345f11e9b2856a7ac40d6cf283606b" category="paragraph">En un clúster de SQL Server con varias instancias de SQL Server, cada instancia podría competir por los recursos. Establecer un límite de memoria para cada instancia de SQL Server puede ayudar a garantizar el mejor rendimiento para cada instancia.</block>
  <block id="318b34a3511a1be6d179a73303da2077" category="admonition">*NetApp recomienda* dejar al menos 4GB a 6GB de RAM para el sistema operativo para evitar problemas de rendimiento.</block>
  <block id="cd151dbdf946ad6bd27e1d55ea1cd029" category="section-title">Ajuste de la memoria mínima y máxima del servidor mediante SQL Server Management Studio.</block>
  <block id="2e0d4de7d927936246f5537ba48015d2" category="paragraph">El uso de SQL Server Management Studio para ajustar la memoria mínima o máxima del servidor requiere un reinicio del servicio de SQL Server. Puede ajustar la memoria del servidor mediante Transact SQL (T-SQL) usando este código:</block>
  <block id="998c5e632fa0f987c20c182fc9322f67" category="section-title">Acceso a memoria no uniforme</block>
  <block id="d92030bf70ac1cf1da30ce4c9ab2bbf6" category="paragraph">El acceso no uniforme a la memoria (NUMA) es un método de optimización de acceso a la memoria que ayuda a aumentar la velocidad del procesador sin aumentar la carga en el bus del procesador.</block>
  <block id="6ef102e61df24a50b0119558432f5623" category="paragraph">Si NUMA está configurado en el servidor donde está instalado SQL Server, no se requiere ninguna configuración adicional porque SQL Server tiene en cuenta NUMA y funciona bien en el hardware NUMA.</block>
  <block id="b3b5cd113ed637ebe6cb28eab322307a" category="section-title">Index CREATE MEMORIA</block>
  <block id="8e7c0153e4b7aa851a5a62683c378d1c" category="paragraph">La opción INDEX CREATE MEMORY es otra opción avanzada que normalmente no debe cambiar.</block>
  <block id="631c6718cc62ad33b6e3b3b48d754569" category="paragraph">Controla la cantidad máxima de RAM asignada inicialmente para crear índices. El valor por defecto de esta opción es 0, lo que significa que SQL Server la gestiona automáticamente. Sin embargo, si tiene dificultades para crear índices, considere aumentar el valor de esta opción.</block>
  <block id="8c91aa3f5264c57bd2d2e66bd70f2ad1" category="section-title">Memoria mínima por consulta</block>
  <block id="d2a88da9a0fcc96168f8f051909d5599" category="section-title">Extensiones del pool de buffers</block>
  <block id="11a3fdcfeb0715eaf26e855034f6ab9a" category="paragraph">La extensión del pool de buffers proporciona una integración perfecta de una extensión NVRAM con el pool de buffers del motor de base de datos para mejorar significativamente el rendimiento de E/S.</block>
  <block id="c722da593d2f37b2c1ffc91a10c03dad" category="paragraph">La extensión del pool de buffers no está disponible en todas las ediciones de SQL Server. Solo está disponible con las ediciones SQL Server Standard, Business Intelligence y Enterprise de 64 bits.</block>
  <block id="df07548a7c164cbe93b68c4cbebbdcf8" category="paragraph">La función de extensión del pool de buffers amplía la caché del pool de buffers con almacenamiento no volátil (normalmente SSD). La extensión permite al pool de buffers acomodar un conjunto de trabajo de base de datos más grande, lo que obliga a la paginación de E/S entre la RAM y los SSD y descarga de forma efectiva pequeñas E/S aleatorias de discos mecánicos a SSD. Debido a la menor latencia y al mejor rendimiento de I/O aleatorio de los SSD, la extensión del pool de búfer mejora significativamente el rendimiento de I/O.</block>
  <block id="54af95ef673718e2f8bf1cc873d8b3ce" category="paragraph">La función de extensión de pool de buffers ofrece las siguientes ventajas:</block>
  <block id="2c250b49dc6705e6d219cf2bf8d50bc5" category="list-text">Aumento del rendimiento de I/O aleatoria</block>
  <block id="93dce890e8c62b3a651edb9098201e58" category="list-text">Latencia de I/O reducida</block>
  <block id="d7e49f79c1b78c9ead1e9541d2160307" category="list-text">Aumento del rendimiento de las transacciones</block>
  <block id="6643befb3c9dc2fbb68fe1107fe24842" category="list-text">Rendimiento de lectura mejorado con un pool de búfer híbrido más grande</block>
  <block id="6609220b8670ffd627a3663b3beef46b" category="list-text">Una arquitectura de caché que puede aprovechar la memoria de bajo costo, existente y futura</block>
  <block id="471bda18bb94c589b421edccb0e402fe" category="paragraph">*NetApp recomienda* configurar las extensiones del grupo de buffers para:</block>
  <block id="12810c53d2afa05bd2a75aa3c0c55592" category="list-text">Asegúrese de que se presenta un LUN respaldado por SSD (como NetApp AFF) al host de SQL Server para que pueda utilizarse como disco de destino de extensión de pool de buffers.</block>
  <block id="824cfa1576a82f89ee0af13fb9f086dc" category="list-text">El archivo de extensión debe ser del mismo tamaño o mayor que el pool de buffers.</block>
  <block id="c7e0d87e723625072015431887edf349" category="paragraph">El siguiente ejemplo muestra un comando T-SQL para configurar una extensión de pool de buffers de 32GB.</block>
  <block id="181341700086c5e2f2259774b2aaa59c" category="inline-link-macro">Implantación de Compresión de Página</block>
  <block id="46c6aaf21d639d23d4f297a1f6922d9a" category="paragraph">La compresión de filas cambia el formato de almacenamiento de datos. Por ejemplo, cambia los enteros y decimales al formato de longitud variable en lugar de su formato nativo de longitud fija. También cambia las cadenas de caracteres de longitud fija al formato de longitud variable eliminando espacios en blanco. La compresión de páginas implementa la compresión de filas y otras dos estrategias de compresión (compresión de prefijo y compresión de diccionario). Puede encontrar más detalles sobre la compresión de páginas en <block ref="88eab602b149fe360da37498ad5cdeae" category="inline-link-macro-rx"></block>.</block>
  <block id="0d629ff07f9214182fa91977089ff029" category="paragraph">Actualmente, la compresión de datos es compatible en las ediciones Enterprise, Developer y Evaluation de SQL Server 2008 y versiones posteriores. Aunque la propia base de datos puede realizar la compresión, esto rara vez se observa en un entorno de SQL Server.</block>
  <block id="c6757fbc56df4ba20f0ef165aeb214d0" category="paragraph">Aquí están las recomendaciones para administrar el espacio para los archivos de datos de SQL Server</block>
  <block id="46344e63db1ea2128cc47543b10a0f96" category="list-text">Use thin provisioning en los entornos SQL Server para mejorar el aprovechamiento del espacio y reducir los requisitos generales de almacenamiento cuando se utilice la funcionalidad de garantía de espacio.</block>
  <block id="924e1b131d6b3a2846efd1a81de8eac1" category="list-text">Use el crecimiento automático para las configuraciones de puesta en marcha más comunes porque el administrador de almacenamiento solo necesita supervisar el uso de espacio en el agregado.</block>
  <block id="13a233d96ce19e7530391105360d749b" category="list-text">Aconseje que no habilite la deduplicación en cualquier volumen que contenga archivos de datos de SQL Server, a menos que se sepa que el volumen contenga varias copias de los mismos datos, como la restauración de la base de datos desde backups en un único volumen.</block>
  <block id="752d71c042ef775879f6db705ccf6b31" category="section-title">Recuperación de espacio</block>
  <block id="89f8656e4e33094d6011ef9aaa8fa8de" category="paragraph">La recuperación de espacio se puede iniciar periódicamente para recuperar el espacio no utilizado en una LUN. Con SnapCenter, puede utilizar el siguiente comando de PowerShell para iniciar la recuperación de espacio.</block>
  <block id="aa864feb1e600aa376e91ac119da387b" category="paragraph">Si necesita ejecutar la recuperación de espacio, este proceso debe ejecutarse en períodos de baja actividad porque inicialmente consume ciclos en el host.</block>
  <block id="5c014f8939a89da0166a347a0237cf4f" category="section-title">SnapCenter</block>
  <block id="1567bc0803275089d7cbc1ffc468158c" category="inline-link-macro">TR-4714: Guía de mejores prácticas para SQL Server con NetApp SnapCenter</block>
  <block id="17f58c1b5cb5feb5dcaf49ca87298c00" category="paragraph">Para obtener más detalles sobre el plugin de SQL Server para SnapCenter, consulte <block ref="c94de7812b9bc9ed76b3c4005974958d" category="inline-link-macro-rx"></block>.</block>
  <block id="91a7baba41dc4b5f958101b261cf179b" category="section-title">Protección de la base de datos mediante instantáneas de T-SQL</block>
  <block id="02e19b2989ebddca9ad3778807bdc426" category="paragraph">A continuación, se muestra un flujo de trabajo de backup de ejemplo:</block>
  <block id="bd03301405e4dd8f2460ff1788765ac4" category="list-text">Realice copias Snapshot de varias bases de datos en los volúmenes de almacenamiento de forma simultánea con los nuevos comandos DEL GRUPO DE BACKUP y DEL SERVIDOR DE BACKUP.</block>
  <block id="a3b19be7df3ddff7295558d9934cd9b6" category="list-text">Realice copias de seguridad COMPLETAS o copias de seguridad COMPLETAS COPY_ONLY. Estas copias de seguridad también se registran en msdb.</block>
  <block id="e2d06152222f63515f4b83229cb5444c" category="list-text">Llevar a cabo una recuperación puntual mediante backups de registro realizados con el método de streaming normal después del backup COMPLETO de la instantánea. Las copias de seguridad diferenciales de transmisión también se admiten si se desea.</block>
  <block id="a7a2496066febda8d325e0964e434481" category="inline-link-macro">Documentación de Microsoft para conocer las instantáneas de T-SQL</block>
  <block id="bf06f3f95c5b653499bb4ac53ba44c95" category="paragraph">Para obtener más información, consulte <block ref="2ba8392a398067f6d2e5f6e4167e9d00" category="inline-link-macro-rx"></block>.</block>
  <block id="450eb6d84ec721a20f17b7778b24b457" category="doc">Cargas de trabajo de Microsoft SQL Server</block>
  <block id="25343e3363b414e89943f5a4e46f51ad" category="paragraph">Antes de implementar SQL Server, debe comprender los requisitos de carga de trabajo de base de datos de las aplicaciones que admiten las instancias de SQL Server. Cada aplicación tiene requisitos distintos en cuanto a capacidad, rendimiento y disponibilidad, por lo que cada base de datos debería estar diseñada para satisfacer de forma óptima dichos requisitos. Muchas organizaciones clasifican las bases de datos en varios niveles de gestión utilizando los requisitos de las aplicaciones para definir acuerdos de nivel de servicios. Las cargas de trabajo de SQL Server se pueden describir de la siguiente manera:</block>
  <block id="c6a1c5843ff7b078079edf24beeea746" category="list-text">Las bases de datos OLTP suelen ser también las más cruciales de una organización. Estas bases de datos, por lo general, generan aplicaciones orientadas al cliente y se consideran esenciales para las operaciones principales de la compañía. Las bases de datos OLTP críticas para la misión y las aplicaciones a las que dan soporte a menudo tienen SLA que requieren altos niveles de rendimiento y son sensibles a la degradación del rendimiento y a la disponibilidad. También pueden ser candidatos para Always On Failover Clusters o Always On Availability Groups. La combinación de I/O de estos tipos de bases de datos suele caracterizarse por un 75 % a un 90 % de las lecturas aleatorias y entre un 25 % y un 10 % de las escrituras.</block>
  <block id="96d864d235bcd68e1ef22c2c49aef352" category="list-text">Las bases de datos de sistema de soporte para la toma de decisiones (DSS) también se pueden denominar almacenes de datos. Estas bases de datos son cruciales en muchas organizaciones que dependen de los análisis para sus empresas. Estas bases de datos son sensibles al uso de la CPU y a las operaciones de lectura del disco cuando se ejecutan consultas. En muchas organizaciones, las bases de datos de DSS son las más críticas durante el mes, el trimestre y el final del año Por lo general, esta carga de trabajo tiene una combinación de I/O de lectura al 100 %.</block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="cell">Situación</block>
  <block id="1b1b4c822e9c1b28b845dcc038fec08e" category="doc">Archivos y grupos de archivos de bases de datos de Microsoft SQL Server</block>
  <block id="5306de2e4bff067a10c1c9b5aafe5920" category="paragraph">En teoría, SQL Server (64 bits) admite 32.767 bases de datos por instancia y 524.272TB GB de tamaño de base de datos, aunque la instalación típica suele tener varias bases de datos. Sin embargo, el número de bases de datos que SQL Server puede manejar depende de la carga y el hardware. No es raro ver instancias de SQL Server que alojan docenas, cientos o incluso miles de pequeñas bases de datos.</block>
  <block id="9a3f42cec243006996ab4580d3ce5d56" category="paragraph">Cada base de datos consta de uno o más archivos de datos y uno o varios archivos de registro de transacciones. El log de transacciones almacena la información sobre las transacciones de la base de datos y todas las modificaciones de datos realizadas por cada sesión. Cada vez que se modifican los datos, SQL Server almacena suficiente información en el log de transacciones para deshacer (realizar rollback) o rehacer (reproducir) la acción. Un registro de transacciones de SQL Server es una parte esencial de la reputación de SQL Server en cuanto a integridad y solidez de los datos. El registro de transacciones es vital para las capacidades de atomicidad, consistencia, aislamiento y durabilidad (ACID) de SQL Server. SQL Server escribe en el registro de transacciones tan pronto como se producen cambios en la página de datos. Cada sentencia de lenguaje de manipulación de datos (DML) (por ejemplo, SELECT, INSERT, UPDATE o DELETE) es una transacción completa, y el registro de transacciones se asegura de que se realice toda la operación basada en juegos, asegurándose de la atomicidad de la transacción.</block>
  <block id="cbe6958e46fbab53cdbdb9deb2d75938" category="paragraph">Cada base de datos tiene un archivo de datos primario, que, por defecto, tiene la extensión .mdf. Además, cada base de datos puede tener archivos de base de datos secundarios. Esos archivos, por defecto, tienen extensiones .ndf.</block>
  <block id="811b578b6dfbb4a4ca16ba0c0911e3df" category="paragraph">Todos los archivos de base de datos se agrupan en grupos de archivos. Un grupo de archivos es la unidad lógica, que simplifica la administración de la base de datos. Permiten la separación entre la ubicación de objetos lógicos y los archivos físicos de la base de datos. Al crear las tablas de objetos de base de datos, especifique en qué grupo de archivos se deben colocar sin preocuparse por la configuración del archivo de datos subyacente.</block>
  <block id="c136ffb510a6a465d338ab0affc16641" category="paragraph">La separación entre la ubicación de objetos lógicos en los grupos de archivos y los archivos físicos de la base de datos le permite ajustar el diseño del archivo de la base de datos, aprovechando al máximo el subsistema de almacenamiento. Por ejemplo, los proveedores de software independientes (ISV) que ponen en marcha sus productos en diferentes clientes pueden ajustar el número de archivos de base de datos en función de la configuración I/O subyacente y la cantidad esperada de datos durante la etapa de puesta en marcha. Estos cambios son transparentes para los desarrolladores de aplicaciones, que colocan los objetos de base de datos en los grupos de archivos en lugar de en los archivos de base de datos.</block>
  <block id="3ac46c2f04dec9d215efbe44d307a020" category="admonition">*NetApp recomienda* evitar el uso del grupo de archivos primario para cualquier cosa excepto objetos del sistema. La creación de un grupo de archivos independiente o un conjunto de grupos de archivos para los objetos de usuario simplifica la administración de la base de datos y la recuperación ante desastres, especialmente en el caso de bases de datos grandes.</block>
  <block id="e3fc56c012a5d0c9f92dff9b49bcc80d" category="paragraph">Puede especificar el tamaño inicial del archivo y los parámetros de crecimiento automático en el momento de crear la base de datos o agregar nuevos archivos a una base de datos existente. SQL Server utiliza un algoritmo de relleno proporcional al elegir en qué archivo de datos debe escribir los datos. Escribe una cantidad de datos proporcionalmente al espacio libre disponible en los archivos. Cuanto mayor sea el espacio libre del archivo, más escrituras gestionará.</block>
  <block id="91d249de86b62102d6324849de2360fe" category="admonition">*NetApp recomienda* que todos los archivos en un solo grupo de archivos tengan los mismos parámetros iniciales de tamaño y crecimiento automático, con el tamaño de crecimiento definido en megabytes en lugar de porcentajes. Esto ayuda al algoritmo de relleno proporcional a equilibrar de forma uniforme las actividades de escritura en los archivos de datos.</block>
  <block id="54db492ee9e4d356cc8722d1f4126f77" category="paragraph">SQL Server siempre pone a cero el registro de transacciones y ese comportamiento no se puede cambiar. Sin embargo, puede controlar si los archivos de datos están a cero habilitando o deshabilitando la inicialización instantánea de archivos. La activación de la inicialización instantánea de archivos ayuda a acelerar el crecimiento de los archivos de datos y reduce el tiempo necesario para crear o restaurar la base de datos.</block>
  <block id="92208bd4d9c6fec3f7c1dedeca62e135" category="paragraph">Un pequeño riesgo de seguridad está asociado con la inicialización instantánea de archivos. Cuando esta opción está activada, las partes no asignadas del archivo de datos pueden contener información de los archivos del sistema operativo eliminados anteriormente. Los administradores de bases de datos pueden examinar estos datos.</block>
  <block id="2b222ad4000e6e966783fd7bc480180e" category="paragraph">Puede activar la inicialización instantánea de archivos agregando el permiso SA_MANAGE_VOLUME_NAME, también conocido como “Realizar tarea de mantenimiento de volúmenes”, a la cuenta de inicio de SQL Server. Puede hacerlo en la aplicación de gestión de políticas de seguridad local (secpol.msc), como se muestra en la siguiente figura. Abra las propiedades del permiso “Realizar tarea de mantenimiento de volúmenes” y agregue la cuenta de inicio de SQL Server a la lista de usuarios allí.</block>
  <block id="c622e0142ed854a10f98fcaa8b3487f8" category="paragraph">Para comprobar si el permiso está habilitado, puede utilizar el código del siguiente ejemplo. Este código establece dos indicadores de rastreo que obligan a SQL Server a escribir información adicional en el log de errores, crear una base de datos pequeña y leer el contenido del log.</block>
  <block id="eba8c32bde087b29aaa1fe0d3bb32ef3" category="paragraph">Cuando la inicialización instantánea de archivos no está activada, el registro de errores de SQL Server muestra que SQL Server pone a cero el archivo de datos de mdf además de poner a cero el archivo log ldf, como se muestra en el siguiente ejemplo. Cuando se activa la inicialización instantánea del archivo, sólo se muestra la puesta a cero del archivo log.</block>
  <block id="cf346325be0652c6b6e9a04b9352bda3" category="paragraph">La tarea de mantenimiento de volúmenes se simplifica en SQL Server 2016 y más tarde se proporciona como opción durante el proceso de instalación. Esta figura muestra la opción para otorgar al servicio del motor de base de datos SQL Server el privilegio para realizar la tarea de mantenimiento de volúmenes.</block>
  <block id="638b283700120d26a838f9cb56fca59d" category="paragraph">Otra opción importante de la base de datos que controla los tamaños de los archivos de la base de datos es la reducción automática. Cuando esta opción está habilitada, SQL Server reduce regularmente los archivos de la base de datos, reduce su tamaño y libera espacio al sistema operativo. Esta operación consume muchos recursos y rara vez es útil porque los archivos de la base de datos vuelven a crecer después de un tiempo cuando llegan nuevos datos al sistema. La reducción automática nunca debe estar activada en la base de datos.</block>
  <block id="3b6c913908f5844ccb31a4d3775cb34e" category="doc">Instancia compartida de Microsoft SQL Server frente a instancia dedicada</block>
  <block id="37fbf1be337695452699ab9df948aa25" category="paragraph">La solución de problemas de rendimiento puede ser complicada porque debe averiguar qué instancia es la causa raíz. Esta pregunta se compara con los costes de las licencias del sistema operativo y de las licencias de SQL Server. Si el rendimiento de las aplicaciones es primordial, se recomienda encarecidamente utilizar una instancia dedicada.</block>
  <block id="c840abede1d1bcf78e7b3e30048c08b1" category="paragraph">Microsoft concede licencias de SQL Server por núcleo a nivel de servidor y no por instancia. Por este motivo, los administradores de bases de datos se ven tentados a instalar tantas instancias de SQL Server como el servidor pueda manejar para ahorrar en costes de licencias, lo que puede ocasionar mayores problemas de rendimiento más adelante.</block>
  <block id="8a77155b45f0f2313c8ebf3d755463e5" category="admonition">*NetApp recomienda* elegir instancias dedicadas de SQL Server siempre que sea posible para obtener un rendimiento óptimo.</block>
  <block id="df7423789cebcf51de121abdae4181c3" category="summary">ONTAP y aplicaciones empresariales</block>
  <block id="eaf36c98b91893b7f79bd5184a23d377" category="doc">Solaris</block>
  <block id="fb04d97697a77a89d0c3f5c09cd9ba47" category="paragraph">Temas de configuración específicos del sistema operativo Solaris.</block>
  <block id="eefc332f1bd0a0aa81d0ce222989294f" category="section-title">Opciones de montaje NFS de Solaris</block>
  <block id="3e484486d582145f6d93ca5f8c71e228" category="paragraph">En la siguiente tabla se enumeran las opciones de montaje NFS de Solaris para una única instancia.</block>
  <block id="6622c14ce91b6b9683505626a5eebdd2" category="cell">Tipo de archivo</block>
  <block id="f18f8a29d3e2281d374f43c78cf8f0f1" category="cell">Opciones de montaje</block>
  <block id="a45543a64530673135f37ff8f9e95e69" category="cell">Directorio Raíz de ADR</block>
  <block id="93a02670f814a2df6c830194a7244ea9" category="cell"><block ref="623bbf58c0b2f552d891a1c276bcc3bc" prefix="" category="inline-code"></block></block>
  <block id="80d52d74fd5c383b43f91575d569b42c" category="cell">Archivos de control
Archivos de datos
Rehacer registros</block>
  <block id="73cf9d3814b8678439c37316096219b1" category="cell"><block ref="4c899c62e1ffeb12078476828bb54351" prefix="" category="inline-code"></block></block>
  <block id="72d33cb5c8b7ff5f7fd6a894094b0697" category="cell"><block ref="e1f651debac4f720c13ae930ff3ca14a" prefix="" category="inline-code"></block></block>
  <block id="3f490427e0bf55dc5c837e7b0d4c651c" category="cell"><block ref="b9ce73264210e6d0faa4115ce7525610" prefix="" category="inline-code"></block></block>
  <block id="b00b0ab6e8494db1a230bf3da7f42fd6" category="paragraph">Uso de<block ref="545e1db0caafaa47ef37ce893c8fb92c" prefix=" " category="inline-code"></block> se ha demostrado que mejora drásticamente el rendimiento en entornos de cliente al eliminar la latencia asociada con la adquisición y la liberación de bloqueos en el sistema de almacenamiento. Utilice esta opción con cuidado en entornos en los que se han configurado varios servidores para montar los mismos sistemas de archivos y Oracle está configurado para montar estas bases de datos. Aunque esta es una configuración muy inusual, es utilizada por un pequeño número de clientes. Si una instancia se inicia accidentalmente por segunda vez, se pueden producir daños en los datos porque Oracle no puede detectar los archivos de bloqueo en el servidor externo. Los bloqueos NFS no ofrecen protección de otro modo; al igual que en la versión 3 de NFS, solo son orientativos.</block>
  <block id="f480015b57b289b7dad1473ee5c55216" category="paragraph">Debido a que el<block ref="545e1db0caafaa47ef37ce893c8fb92c" prefix=" " category="inline-code"></block> y..<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> los parámetros se excluyen entre sí, es importante hacerlo<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> está presente en la<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> archiva así<block ref="6887bae4cda2d09a283a165c5be3f2b8" prefix=" " category="inline-code"></block> se utiliza. Sin este parámetro, se utiliza el almacenamiento en caché del búfer del sistema operativo del host y el rendimiento se puede ver afectado negativamente.</block>
  <block id="5171d5dfdc21b0941b921796638c10a9" category="paragraph">En la siguiente tabla se muestran las opciones de montaje de Solaris NFS RAC.</block>
  <block id="38e4e10abf410c92cd13e9cb4d54ae35" category="cell"><block ref="41a82b9bd64cb001f8913a34614b00d1" prefix="" category="inline-code"></block></block>
  <block id="e72cc50c204d77a1e47f0dcc8ad28a56" category="cell">Archivos de control
Archivos de datos
Rehacer registros</block>
  <block id="98ee9e91a49f27abbd9dc831afa9fae5" category="cell"><block ref="f3a0fd4a197a2eae60d2ef904e5366f1" prefix="" category="inline-code"></block></block>
  <block id="f93eecf9c582d76d4e14292dc34c79f8" category="cell">CRS/votación</block>
  <block id="42c82995de255264e2a8690c3149c16a" category="cell">Específico<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block></block>
  <block id="b71e04a676ec52e65edb52c138f2ad98" category="cell"><block ref="ac15a7c050732bc5169b6c17ce30f859" prefix="" category="inline-code"></block></block>
  <block id="273f714e976e2a709a6abe18d34e4b61" category="cell">Compartido<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block></block>
  <block id="2052aa052eee25e077178cd737b68f47" category="cell"><block ref="18f533bce293643d1004086db883dd03" prefix="" category="inline-code"></block></block>
  <block id="e9d3beba8b6a40da6f8074236ca3ddbc" category="paragraph">La diferencia principal entre las opciones de montaje de instancia única y RAC es la adición de<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> y..<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> a las opciones de montaje. Esta adición tiene el efecto de deshabilitar el almacenamiento en caché del sistema operativo del host, lo que permite que todas las instancias del clúster RAC tengan una vista coherente del estado de los datos. Aunque utilice el<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> parámetro<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> tiene el mismo efecto de deshabilitar el almacenamiento en caché de host, sigue siendo necesario utilizarlo<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> y..<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block>.</block>
  <block id="983c4ff0cb78851d95be06277152653f" category="paragraph">La razón<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> es necesario para el uso compartido<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Despliegues es para facilitar la coherencia de archivos como archivos de contraseñas de Oracle y archivos spfiles. Si cada instancia de un clúster de RAC tiene un dedicado<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, este parámetro no es necesario.</block>
  <block id="5a11994cffaa4d0a9c8594d2223e3e96" category="section-title">Opciones de montaje UFS de Solaris</block>
  <block id="130c5ffb786e38c2e6648fd53593681a" category="paragraph">NetApp recomienda usar la opción de montaje de registro para conservar la integridad de los datos en caso de bloqueo del host Solaris o interrupción de la conectividad de FC. La opción de montaje logging también conserva la facilidad de uso de los backups de Snapshot.</block>
  <block id="516f7006de2e9b1f7f871d961db4a1ca" category="section-title">ZFS de Solaris</block>
  <block id="a92c2c52c7360246c6da2b1169e0fa50" category="paragraph">Solaris ZFS debe instalarse y configurarse cuidadosamente para ofrecer un rendimiento óptimo.</block>
  <block id="c9208a3ad95d5ce3d9e2ba1839426251" category="section-title">mvector</block>
  <block id="c54b9977f43cf2f9a1aa7cb0de8fec22" category="paragraph">Solaris 11 incluyó un cambio en la forma en que procesa grandes operaciones de E/S, lo que puede dar lugar a graves problemas de rendimiento en las matrices de almacenamiento SAN. El problema se documenta en detalle en el informe de errores de NetApp 630173, que indica que Solaris 11 ZFS Performance Regression. La solución es cambiar un parámetro del sistema operativo llamado<block ref="954f82599f7db0212a28fd448e03bdf3" prefix=" " category="inline-code"></block>.</block>
  <block id="17e692fa261653b11634297d15070637" category="paragraph">Ejecute el siguiente comando como root:</block>
  <block id="bc7e9b3c34345bf9ebe88467d6714f1b" category="paragraph">Si surge algún problema inesperado de este cambio, se puede revertir fácilmente ejecutando el siguiente comando como root:</block>
  <block id="6ff9f4444ac481652f4412b5e1623846" category="section-title">Kernel</block>
  <block id="78d06f587305b9e5481c8cf660693a61" category="paragraph">El rendimiento fiable de ZFS requiere un kernel de Solaris parcheado contra problemas de alineación de LUN. La corrección se introdujo con el parche 147440-19 en Solaris 10 y con SRU 10,5 para Solaris 11. Utilice sólo Solaris 10 y versiones posteriores con ZFS.</block>
  <block id="db8880d80ab20f2f01a010e5c454f7fb" category="section-title">Configuración de LUN</block>
  <block id="3b296d65c0c37979abe39ac7f6d8e1d8" category="paragraph">Para configurar una LUN, complete los siguientes pasos:</block>
  <block id="3bdc2a5622b76404f8b0ce2fc774e69a" category="list-text">Cree una LUN del tipo<block ref="7bee0477f82303aa43de5d78f7b9cb05" prefix=" " category="inline-code"></block>.</block>
  <block id="c06f6c6685c06bb821295b3a6d5e580c" category="list-text">Instale el kit de utilidades de host (HUK) adecuado especificado por el <block ref="b5b16f3cdb0eb25a282348ba54f8c677" category="inline-link-macro-rx"></block>.</block>
  <block id="33db73c9b3936cb8eaae825d3101f60c" category="inline-link-macro">documentación más reciente</block>
  <block id="c8646086dca29c1d978ab285faa93709" category="list-text">Siga las instrucciones del HUK exactamente como se describe. Los pasos básicos se describen a continuación, pero consulte la <block ref="33574dfffc2cb6d01be0edb6738c51bb" category="inline-link-macro-rx"></block> para el procedimiento adecuado.</block>
  <block id="6c06455cad171d61eac3593147bd71d6" category="list-text">Ejecute el<block ref="3062dc928daa4d85f6e34b6dea110a00" prefix=" " category="inline-code"></block> utilidad para actualizar el<block ref="d5416d340f5bec1fcb3addb6ae7d059e" prefix=" " category="inline-code"></block> archivo. Al hacerlo, las unidades SCSI pueden detectar correctamente LUN de ONTAP.</block>
  <block id="7ec6668202fa9a677238143b0445102f" category="list-text">Siga las instrucciones proporcionadas por el<block ref="3062dc928daa4d85f6e34b6dea110a00" prefix=" " category="inline-code"></block> Utilidad para habilitar la entrada/salida multivía (MPIO).</block>
  <block id="b53abe6c0013125abea171427b351ccc" category="list-text">Reiniciar. Este paso es necesario para que cualquier cambio se reconozca en el sistema.</block>
  <block id="b88caedbe9708683eed783eb534ae5f6" category="list-text">Cree particiones en las LUN y compruebe que están correctamente alineadas. Consulte el Apéndice B: Verificación de alineación de WAFL para obtener instrucciones sobre cómo probar y confirmar la alineación directamente.</block>
  <block id="a0c1c26e783204cf713b2e1f0823aab3" category="section-title">zpools</block>
  <block id="c81b8fe4a368c32102406e65fc41a227" category="inline-link-macro">Configuración de LUN</block>
  <block id="869dc3a8daf591c7f33e5bb32a4a63c9" category="paragraph">Valor de<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> el valor por defecto es 9, que significa 2^9, o 512 bytes. Para un rendimiento óptimo, el<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> El valor debe ser 12 (2^12=4K). Este valor se define en el momento en que se crea zpool y no se puede cambiar, lo que significa que los datos en zpools con<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> los datos que no sean 12 se deben migrar copiando a un zpool recién creado.</block>
  <block id="6a00a2262e030c2656588743cb031710" category="paragraph">Después de crear un zpool, verifique el valor de<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> antes de continuar. Si el valor no es 12, las LUN no se detectaron correctamente. Destruya zpool, verifique que todos los pasos mostrados en la documentación de utilidades de host relevantes se hayan realizado correctamente y vuelva a crear zpool.</block>
  <block id="15ec722ce3f6694d12f89aeb5b621941" category="section-title">Zpools y LDOMs de Solaris</block>
  <block id="8826ef54a7d108df25ed6921b5129cb6" category="paragraph">Los LDOMs de Solaris crean un requisito adicional para asegurarse de que la alineación de E/S es correcta. Aunque un LUN se puede detectar correctamente como dispositivo 4K, un dispositivo virtual vdsk en un LDOM no hereda la configuración del dominio de E/S. El vdsk basado en esa LUN vuelve a tener de forma predeterminada un bloque de 512 bytes.</block>
  <block id="9a984f24f825e4f0bca1f36e11acbca9" category="paragraph">Se necesita un archivo de configuración adicional. En primer lugar, se deben aplicar parches a los LDOM individuales para el bug de Oracle 15824910 para activar las opciones de configuración adicionales. Este parche se ha portado a todas las versiones utilizadas actualmente de Solaris. Una vez que se aplica el parche a LDOM, está listo para la configuración de las nuevas LUN correctamente alineadas de la siguiente manera:</block>
  <block id="e0f306ab540315b015db849b1ae9099e" category="list-text">Identifique los LUN o LUN que se van a utilizar en el nuevo zpool. En este ejemplo, es el dispositivo c2d1.</block>
  <block id="f469046d419183a7be08ed5a13d2c65e" category="list-text">Recuperar la instancia vdc de los dispositivos que se van a utilizar para una agrupación ZFS:</block>
  <block id="bcaa63dcd5db76bffd8b867e8720a272" category="list-text">Editar<block ref="ebceeaa7b6ce5abf6c8de7177255fef5" prefix=" " category="inline-code"></block>:</block>
  <block id="ec960a08b4666fe258b6e005064378ab" category="paragraph">Esto significa que a la instancia de dispositivo 1 se le asigna un tamaño de bloque de 4096.</block>
  <block id="3df4cdc476a0c3a5a930597e9d8da84c" category="paragraph">Como ejemplo adicional, supongamos que las instancias de vdsk 1 a 6 deben configurarse para un tamaño de bloque de 4K KB y.<block ref="74a491ed941b00d0c9909d488eee67bf" prefix=" " category="inline-code"></block> se lee de la siguiente manera:</block>
  <block id="dfed6d8974f03c5b31f20c9c5c2bbe66" category="list-text">La final<block ref="3328fba80b08b36663ffae0684f6c578" prefix=" " category="inline-code"></block> el archivo debe contener lo siguiente:</block>
  <block id="764a2caff05993fc0d3eff5de7b225e9" category="cell">Precaución</block>
  <block id="5c442834a7707cc96719e468c87b2ff6" category="cell">El LDOM debe reiniciarse después de configurar vdc.conf y crear vdsk. Este paso no se puede evitar. El cambio de tamaño del bloque solo se aplica después de un reinicio. Continúe con la configuración de zpool y asegúrese de que el ashift está correctamente ajustado en 12 como se ha descrito anteriormente.</block>
  <block id="2138e0b461ac7e557539bb0b33bde81a" category="section-title">Registro de Intención de ZFS (ZIL)</block>
  <block id="5477cebfd480a13008afdd16bea2b3f9" category="paragraph">Por lo general, no hay razón para localizar el registro de intención ZFS (ZIL) en un dispositivo diferente. El registro puede compartir espacio con el pool principal. El uso principal de un ZIL separado es cuando se utilizan unidades físicas que carecen de las funciones de almacenamiento en caché de escritura en cabinas de almacenamiento modernas.</block>
  <block id="26a004aeb043de19f767bd7daa39cf2f" category="section-title">sesgo logarítmico</block>
  <block id="07fff183bc4c01bf9bbb21a48b389845" category="paragraph">Ajuste la<block ref="26a004aeb043de19f767bd7daa39cf2f" prefix=" " category="inline-code"></block> Parámetro en sistemas de archivos ZFS que alojan datos de Oracle.</block>
  <block id="ac01fbc5e98d6450f3b565d0617f4a55" category="paragraph">Usar este parámetro reduce los niveles generales de escritura. En los valores predeterminados, los datos escritos se confirman primero en el ZIL y, a continuación, en el pool de almacenamiento principal. Este enfoque es adecuado para una configuración que utiliza una configuración de unidad simple, que incluye un dispositivo ZIL basado en SSD y medios giratorios para el pool de almacenamiento principal. Esto se debe a que permite un commit en una sola transacción de I/O en el medio de menor latencia disponible.</block>
  <block id="c6cc0f147c42f124079d7fc1a0761886" category="paragraph">Cuando se utiliza una cabina de almacenamiento moderna que incluye su propia funcionalidad de almacenamiento en caché, este método no suele ser necesario. En raras ocasiones, es posible que sea conveniente comprometer una escritura con una sola transacción en el registro, como una carga de trabajo que consta de escrituras aleatorias altamente concentradas y sensibles a la latencia. Existen consecuencias en la amplificación de escritura, ya que los datos registrados se escriben finalmente en el pool de almacenamiento principal, lo que provoca el doble de la actividad de escritura.</block>
  <block id="92b9531657a4ce6a31c623d889a2c55d" category="section-title">E/S directa</block>
  <block id="387f4a4c250ed7a5003f3f6a19abfd1f" category="paragraph">Muchas aplicaciones, incluidos los productos de Oracle, pueden omitir la caché de buffers del host activando la E/S directa Esta estrategia no funciona como se esperaba con los sistemas de archivos ZFS. Aunque se omite la caché de buffers del host, ZFS continúa almacenando los datos en caché. Esta acción puede provocar resultados engañosos cuando se usan herramientas como fio o sio para realizar pruebas de rendimiento, ya que es difícil predecir si I/O está llegando al sistema de almacenamiento o si se está almacenando en caché localmente dentro del sistema operativo. Esta acción también hace que sea muy difícil utilizar estas pruebas sintéticas para comparar el rendimiento de ZFS con otros sistemas de archivos. Como cuestión práctica, hay poca o ninguna diferencia en el rendimiento del sistema de archivos con las cargas de trabajo de los usuarios reales.</block>
  <block id="ec79b30d56e7bae54aa7efedccc47e93" category="section-title">Varios zpools</block>
  <block id="f5aa5b31f0536ddcdb748ae360d91358" category="paragraph">Las copias de seguridad basadas en instantáneas, las restauraciones, los clones y el archivado de datos basados en ZFS se deben realizar en el nivel de zpool y, por lo general, requieren varios zpools. Un zpool es análogo a un grupo de discos LVM y debe configurarse usando las mismas reglas. Por ejemplo, es probable que una base de datos se disponga mejor con los archivos de datos en los que reside<block ref="f1fb162e58045170396a0ac29d648fa5" prefix=" " category="inline-code"></block> y los registros de archivo, los archivos de control y los registros de recuperación en los que residen<block ref="92073f03d18c8eaec3eb5e0908210e1a" prefix=" " category="inline-code"></block>. Este enfoque permite realizar un backup dinámico estándar en el que la base de datos se coloca en modo de backup dinámico, seguido de una copia Snapshot de<block ref="f1fb162e58045170396a0ac29d648fa5" prefix=" " category="inline-code"></block>. A continuación, la base de datos se elimina del modo de backup dinámico, se fuerza el archivo de registro y una copia de Snapshot de<block ref="92073f03d18c8eaec3eb5e0908210e1a" prefix=" " category="inline-code"></block> se ha creado. Una operación de restauración requiere el desmontaje de los sistemas de archivos zfs y desconectar zpool íntegramente, a continuación de una operación de restauración de SnapRestore. El zpool se puede poner en línea de nuevo y la base de datos se recupera.</block>
  <block id="f1110589be196c2310808482067fce1b" category="section-title">filesystemio_options</block>
  <block id="c271ff9f255f2d215054d508448781a3" category="paragraph">Parámetro de Oracle<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Funciona de forma diferente con ZFS. Si<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block> o.<block ref="6887bae4cda2d09a283a165c5be3f2b8" prefix=" " category="inline-code"></block> Se utiliza, las operaciones de escritura son síncronas y omiten la caché de buffers del sistema operativo, pero ZFS almacena en búfer las lecturas. Esta acción causa dificultades en el análisis de rendimiento porque a veces la caché ZFS intercepta y suministra servicio a las E/S, lo que hace que la latencia de almacenamiento y el total de E/S sean menores de lo que podría parecer.</block>
  <block id="b1fd823d262032e04291313f72be9452" category="doc">HP-UX</block>
  <block id="8ec258cd0b6ab050fc478a415a20f2e9" category="section-title">Opciones de montaje NFS de HP-UX</block>
  <block id="7c5876d5737071c64af78562fe375386" category="paragraph">En la siguiente tabla se enumeran las opciones de montaje de HP-UX NFS para una única instancia.</block>
  <block id="9c9fb3cc18a83e4e46165b5c3d4ce8ef" category="cell">Archivos de control
Archivos de datos
Rehacer registros</block>
  <block id="55b835c747261995c0e1022d234e286d" category="cell"><block ref="fa8766c679857b7d589983df0ab5bcf4" prefix="" category="inline-code"></block></block>
  <block id="189dbd39cabd57c5d2e51714d9a5b85b" category="paragraph">En la siguiente tabla se enumeran las opciones de montaje de HP-UX NFS para RAC.</block>
  <block id="fa9da3a6a7ef8986a94c7395577c322f" category="cell"><block ref="8b080dc74532d24847a6163dcc34d93f" prefix="" category="inline-code"></block></block>
  <block id="add42ff64fa5b57e5abeab49d154a9d9" category="cell"><block ref="acdef4af05a9f0c43f72b7c600f04d62" prefix="" category="inline-code"></block></block>
  <block id="c88a7b7f83f761f7fc2979815d210140" category="cell"><block ref="d29d7b7ed8c19a99fe17fd7f3d07ea7b" prefix="" category="inline-code"></block></block>
  <block id="af8831a1b8129b099114c3237a61db88" category="paragraph">La diferencia principal entre las opciones de montaje de instancia única y RAC es la adición de<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> y..<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block> a las opciones de montaje. Esta adición tiene el efecto de deshabilitar el almacenamiento en caché del sistema operativo del host, lo que permite que todas las instancias del clúster RAC tengan una vista coherente del estado de los datos. Aunque utilice el<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> parámetro<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> tiene el mismo efecto de deshabilitar el almacenamiento en caché de host, sigue siendo necesario utilizarlo<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> y..<block ref="6698a391ee8befa0ca4646a86a1bbd66" prefix=" " category="inline-code"></block>.</block>
  <block id="b865c6aba24c3f61595471aab993d27c" category="paragraph">La razón<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> es necesario para el uso compartido<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Despliegues es para facilitar la coherencia de archivos como archivos de contraseñas de Oracle y archivos spfiles. Si cada instancia de un clúster de RAC tiene un dedicado<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, este parámetro no es necesario.</block>
  <block id="898311d838a2fa2fa41b4b52a63a7f1d" category="section-title">Opciones de montaje HP-UX VxFS</block>
  <block id="85b4a3d44370909d395ab8af28ff4927" category="paragraph">Utilice las siguientes opciones de montaje para sistemas de archivos que alojan binarios de Oracle:</block>
  <block id="6630bbc9a901be0d038b2c39e2faf65d" category="paragraph">Utilice las siguientes opciones de montaje para sistemas de archivos que contienen archivos de datos, redo logs, archive logs y archivos de control en los que la versión de HP-UX no admite E/S simultáneas:</block>
  <block id="ed37730e0f28a631768a396e7898e197" category="paragraph">Cuando se admiten E/S simultáneas (VxFS 5.0.1 y posteriores, o con ServiceGuard Storage Management Suite), utilice estas opciones de montaje para sistemas de archivos que contengan archivos de datos, redo logs, archive logs y archivos de control:</block>
  <block id="f51ddb98d92e83609db075add5fba4d8" category="admonition">El parámetro<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> Es especialmente crítico en entornos VxFS. Oracle recomienda que este parámetro permanezca sin definir en Oracle 10g R1 y posteriores a menos que se indique lo contrario específicamente. El valor por defecto con un tamaño de bloque de Oracle 8KB es 128. Si el valor de este parámetro se fuerza a 16 o menos, quite el<block ref="a6b02283cba560dcfdea44af66ec792c" prefix=" " category="inline-code"></block> Opción de montaje porque puede dañar el rendimiento de I/O secuencial. Este paso daña otros aspectos del rendimiento y solo debe tomarse si el valor de<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> debe cambiarse a partir del valor predeterminado.</block>
  <block id="5802d9527a43305e9e1c903bc6b5a721" category="paragraph">Temas de configuración específicos del sistema operativo Linux mediante AFD y ASMLib</block>
  <block id="2681013be5b0a9063a7ef0a8fe4d31da" category="section-title">Tamaños de bloque ASMLib</block>
  <block id="1943673cc25055e93f0129f2baa8f499" category="paragraph">ASMLib es una biblioteca de gestión de ASM opcional y utilidades asociadas. Su valor principal es la capacidad para estampar un LUN o un archivo basado en NFS como un recurso ASM con una etiqueta legible para el ser humano.</block>
  <block id="51713fdb873939c9c333273947776b8e" category="paragraph">Las versiones recientes de ASMLib detectan un parámetro de LUN llamado Logical Blocks per Physical Block Exponent (LBPPBE). El destino SCSI de ONTAP no notificó este valor hasta hace poco. Ahora devuelve un valor que indica que se prefiere un tamaño de bloque de 4KB KB. Esta no es una definición de tamaño de bloque, pero es una indicación para cualquier aplicación que utilice LBPPBE de que las E/S de un determinado tamaño podrían manejarse de manera más eficiente. Sin embargo, ASMLib interpreta LBPPBE como un tamaño de bloque y marca de forma persistente la cabecera ASM cuando se crea el dispositivo ASM.</block>
  <block id="65242d5b49071240043eeef598415104" category="paragraph">Este proceso puede causar problemas con actualizaciones y migraciones de varias maneras, todo ello en función de la incapacidad de mezclar dispositivos ASMLib con diferentes tamaños de bloque en el mismo grupo de discos ASM.</block>
  <block id="ea884eec0628302adc731211dc4e2cc7" category="paragraph">Por ejemplo, las matrices más antiguas generalmente reportaron un valor LBPPBE de 0 o no reportaron este valor en absoluto. ASMLib lo interpreta como un tamaño de bloque de 512 bytes. Las cabinas más recientes se interpretarán con un tamaño de bloque de 4KB KB. No es posible mezclar dispositivos de 512 bytes y 4KB en el mismo grupo de discos ASM. Al hacerlo, se bloquearía a un usuario para que no aumente el tamaño del grupo de discos de ASM utilizando LUN de dos matrices o aprovechando ASM como herramienta de migración. En otros casos, es posible que RMAN no permita la copia de archivos entre un grupo de discos de ASM con un tamaño de bloque de 512 bytes y un grupo de discos de ASM con un tamaño de bloque de 4KB KB.</block>
  <block id="f17ff15b23b87f35906ece98842a080f" category="paragraph">La solución preferida es parchear ASMLib. El identificador de error de Oracle es 13999609 y el parche está presente en oracleasm-support-2,1.8-1 y superior. Este parche permite al usuario definir el parámetro<block ref="442e2026c8afecc4611b52331b5d0d56" prefix=" " category="inline-code"></block> para<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> en la<block ref="92a59ba9a0643a344be2d72cfd504181" prefix=" " category="inline-code"></block> archivo de configuración. Al hacerlo, se bloquea ASMLib para que no utilice el parámetro LBPPBE, lo que significa que los LUN de la nueva matriz ahora se reconocen como dispositivos de bloque de 512 bytes.</block>
  <block id="f140ff6b2b71e70e551e39dacb9561ef" category="admonition">La opción no cambia el tamaño de bloque en LUN que ASMLib estampó anteriormente. Por ejemplo, si un grupo de discos ASM con bloques de 512 bytes debe migrarse a un nuevo sistema de almacenamiento que notifique un bloque de 4KB KB, la opción<block ref="442e2026c8afecc4611b52331b5d0d56" prefix=" " category="inline-code"></block> Debe establecerse antes de que las nuevas LUN se estampen con ASMLib.  Si los dispositivos ya han sido estampados por oracleasm, deben ser reformateados antes de ser reincorporados con un nuevo tamaño de bloque. En primer lugar, desconfigure el dispositivo con<block ref="41bd8c47b8e640da7bdb5c7dc995d435" prefix=" " category="inline-code"></block>, Y, a continuación, borre los primeros 1GB del dispositivo con<block ref="85c2e94baaf4d9c084e19d290907596e" prefix=" " category="inline-code"></block>. Por último, si el dispositivo se ha particionado previamente, utilice<block ref="9a287d63dabd6fbcbbe1b12344bfe922" prefix=" " category="inline-code"></block> Comando para eliminar particiones obsoletas o simplemente reiniciar el sistema operativo.</block>
  <block id="75ad83418241561186f96dfed5229aaa" category="paragraph">Si no se puede aplicar un parche a ASMLib, se puede eliminar ASMLib de la configuración. Este cambio es disruptivo y requiere el desestampado de discos de ASM y asegurarse de que el<block ref="0802edf7303a95bdecde832bbbe3a89c" prefix=" " category="inline-code"></block> el parámetro se ha definido correctamente. Sin embargo, este cambio no requiere la migración de datos.</block>
  <block id="ad9ac4c6d7ed2e11bdcf8c693658a482" category="section-title">Tamaños de bloque de unidad de filtro de ASM (AFD)</block>
  <block id="de59cd97a61c9f9964a35d2cd8b05c88" category="paragraph">AFD es una biblioteca de gestión de ASM opcional que se está convirtiendo en el reemplazo de ASMLib. Desde el punto de vista del almacenamiento, es muy similar a ASMLib, pero incluye características adicionales como la capacidad de bloquear E/S no Oracle para reducir las posibilidades de errores de usuario o aplicación que podrían dañar los datos.</block>
  <block id="36dc27685773851e52f035f82e3deba2" category="section-title">Tamaños de bloques de dispositivos</block>
  <block id="1ef92cf7e561e179d6079cc937b2778a" category="paragraph">Al igual que ASMLib, AFD también lee el parámetro LUN Bloques lógicos por Exponente de bloque físico (LBPPBE) y utiliza de forma predeterminada el tamaño del bloque físico, no el tamaño del bloque lógico.</block>
  <block id="b95ce6c503801cb15f2f9c0773c58f00" category="paragraph">Esto podría crear un problema si se agrega AFD a una configuración existente donde los dispositivos ASM ya están formateados como dispositivos de bloque de 512 bytes. El controlador AFD reconocería el LUN como un dispositivo 4K y la discrepancia entre la etiqueta ASM y el dispositivo físico impediría el acceso. Del mismo modo, las migraciones se verían afectadas porque no es posible mezclar dispositivos de 512 bytes y 4KB en el mismo grupo de discos de ASM. Al hacerlo, se bloquearía a un usuario para que no aumente el tamaño del grupo de discos de ASM utilizando LUN de dos matrices o aprovechando ASM como herramienta de migración. En otros casos, es posible que RMAN no permita la copia de archivos entre un grupo de discos de ASM con un tamaño de bloque de 512 bytes y un grupo de discos de ASM con un tamaño de bloque de 4KB KB.</block>
  <block id="7ef45d3a7c5fff234bf42bdf549b8339" category="paragraph">La solución es simple: AFD incluye un parámetro para controlar si utiliza los tamaños de bloque lógicos o físicos. Este es un parámetro global que afecta a todos los dispositivos del sistema. Para forzar a AFD a utilizar el tamaño de bloque lógico, establezca<block ref="722fc896569f3d455bb5ef8f5b8c3703" prefix=" " category="inline-code"></block> en la<block ref="dcd5fd81543c5e08e927c54e89acdd40" prefix=" " category="inline-code"></block> archivo.</block>
  <block id="47b0d7fc4c27720c4fc326722edad27c" category="section-title">Tamaños de transferencia multivía</block>
  <block id="7c329811bcc7bb2f50005da5a3aff250" category="paragraph">Los cambios recientes del kernel de linux aplican las restricciones de tamaño de I/O enviadas a dispositivos multivía y el AFD no cumple con estas restricciones. A continuación, se rechazan las I/O, lo que hace que la ruta de LUN se desconecte. El resultado es una incapacidad para instalar Oracle Grid, configurar ASM o crear una base de datos.</block>
  <block id="926e4b7a2822a39a07f61474b92e9d8c" category="paragraph">La solución es especificar manualmente la longitud máxima de transferencia del archivo multipath.conf para las LUN de ONTAP:</block>
  <block id="3d0c741146f1e8e31bc7d07128ca6e0a" category="admonition">Incluso si no existe ningún problema en la actualidad, este parámetro debe configurarse si se utiliza AFD para garantizar que una actualización de linux futura no cause problemas de forma inesperada.</block>
  <block id="d99ae60d37a12f766bc2a1f1c228fb4f" category="section-title">I/O concurrente</block>
  <block id="0f3eb508f611e203aeffa91d5753648a" category="paragraph">Lograr un rendimiento óptimo en IBM AIX requiere el uso de E/S concurrentes Sin operaciones de I/O simultáneas, es probable que las limitaciones de rendimiento se deban a que AIX realiza I/O atómicas serializadas, lo que conlleva una sobrecarga significativa.</block>
  <block id="ecdc41fc6a2adf7e41e7277e12eeb805" category="paragraph">En un principio, NetApp recomendó utilizar el<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Opción de montaje para forzar el uso de E/S concurrentes en el sistema de archivos, pero este proceso tenía inconvenientes y ya no es necesario. Desde la introducción de AIX 5,2 y Oracle 10gR1, Oracle en AIX puede abrir archivos individuales para I/O simultánea, en lugar de forzar las operaciones de I/O simultáneas en todo el sistema de archivos.</block>
  <block id="445b433b62b675f0ca0bda7acb56d41b" category="paragraph">El mejor método para habilitar E/S concurrente es establecer el<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> parámetro<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> para<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block>. Al hacerlo, Oracle puede abrir archivos específicos para utilizarlos con E/S simultáneas</block>
  <block id="6206c23a0282b18352573158f9a8f9b3" category="paragraph">Uso<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Como opción de montaje fuerza el uso de I/O concurrente, lo cual puede tener consecuencias negativas. Por ejemplo, al forzar la E/S simultánea se desactiva la lectura anticipada en los sistemas de archivos, lo que puede dañar el rendimiento de las E/S que se producen fuera del software de la base de datos Oracle, como copiar archivos y realizar copias de seguridad en cinta. Además, productos como Oracle GoldenGate y SAP BR*Tools no son compatibles con el uso del<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> Opción de montaje con determinadas versiones de Oracle.</block>
  <block id="770cb9a1e9321ca3012ecbb9ec65c422" category="list-text">No utilice la<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> opción de montaje en el nivel de sistema de archivos. En su lugar, habilite la I/O simultánea mediante el uso de<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block>.</block>
  <block id="872080b7d5ec5585776f1426fb157842" category="list-text">Utilice sólo el<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> la opción de montaje debería si no es posible configurarla<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block>.</block>
  <block id="0c5d86482201f32acb30cd2f7de3048f" category="section-title">Opciones de montaje de AIX NFS</block>
  <block id="1ce07cafb2507c98c8b96ad5f35fb66a" category="paragraph">En la siguiente tabla, se enumeran las opciones de montaje de AIX NFS para bases de datos de instancia única de Oracle.</block>
  <block id="9a8f040dae3f0f15b337fe69a85239c0" category="cell"><block ref="86d38d6e2b36f6557e583e005e23d258" prefix="" category="inline-code"></block></block>
  <block id="d45a1a2afa30c30042b28f028fe75953" category="cell"><block ref="915be14765d6133923d803e1221f1513" prefix="" category="inline-code"></block></block>
  <block id="b74f5956b4bcda2de3c82ee97e192ab6" category="paragraph">En la siguiente tabla, se enumeran las opciones de montaje de AIX NFS para RAC.</block>
  <block id="b547b55ba7f2a20602494777c5426eba" category="cell"><block ref="7e879bda961bd5b7d64d2ef4f5fb7869" prefix="" category="inline-code"></block></block>
  <block id="875abb256654bd3f6da7abcb1bd92f27" category="cell"><block ref="f93eecf9c582d76d4e14292dc34c79f8" prefix="" category="inline-code"></block></block>
  <block id="3ed8fb68917b28af138fb74ccde62e80" category="cell"><block ref="415e8eb8b9fc05cb48e633d31fd04944" prefix="" category="inline-code"></block></block>
  <block id="8102775fe4080f632332ab8d3312311a" category="paragraph">La diferencia principal entre las opciones de montaje de instancia única y RAC es la adición de<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> a las opciones de montaje. Esta adición tiene el efecto de deshabilitar el almacenamiento en caché del SO del host que permite que todas las instancias del clúster RAC tengan una vista uniforme del estado de los datos.</block>
  <block id="1e3f10dfa324520cb7261c0da5bf6ec7" category="paragraph">Aunque utilice el<block ref="4482571a249db31b3abed938e4567a15" prefix=" " category="inline-code"></block> monte la opción y la<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> parámetro<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> tiene el mismo efecto de deshabilitar el almacenamiento en caché de host, sigue siendo necesario utilizarlo<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block>.<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> es necesario para el uso compartido<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Despliegues para facilitar la coherencia de archivos como archivos de contraseñas de Oracle y.<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> archivos de parámetros. Si cada instancia de un clúster de RAC tiene un dedicado<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, entonces este parámetro no es necesario.</block>
  <block id="5365dd1a92461c9e6cf65017c4a11647" category="section-title">Opciones de montaje jfs/JFS2 de AIX</block>
  <block id="d7a578263480a2003f05c459a8961298" category="paragraph">En la siguiente tabla se enumeran las opciones de montaje jfs/JFS2 de AIX.</block>
  <block id="0aabf727ab0a83c5f5d078e8b18445e0" category="cell">Valores predeterminados</block>
  <block id="e1f651debac4f720c13ae930ff3ca14a" category="cell">ORACLE_HOME</block>
  <block id="27a7ffa293f5a4d2a5bb54354486dece" category="paragraph">Antes de utilizar AIX<block ref="b7cc91287fc99a8937a55e79376c6f54" prefix=" " category="inline-code"></block> los dispositivos de cualquier entorno, incluidas las bases de datos, comprueban el parámetro<block ref="9d51746070ef554ad4e93a16de4aed0f" prefix=" " category="inline-code"></block>. Este parámetro no es la profundidad de la cola del HBA, más bien se relaciona con la profundidad de la cola SCSI de una persona<block ref="66ad66c6ace8456eae4ca6807552e54b" prefix=" " category="inline-code"></block> puede ser demasiado bajo para un buen rendimiento. Las pruebas han demostrado que el valor óptimo es 64.</block>
  <block id="bb79f96acbff544ded541446c9c7c894" category="doc">Microsoft Windows</block>
  <block id="14ce2582c2080a7f08fe9249f6565f40" category="paragraph">Oracle admite el uso de Microsoft Windows con el cliente NFS directo. Esta funcionalidad ofrece un acceso a las ventajas de gestión de NFS, incluida la capacidad de ver archivos de distintos entornos, cambiar el tamaño de volúmenes de forma dinámica y utilizar un protocolo IP menos costoso. Consulte la documentación oficial de Oracle para obtener información sobre la instalación y configuración de una base de datos en Microsoft Windows mediante DNFS. No existen mejores prácticas especiales.</block>
  <block id="f854b764258138b512f30be71e1c7908" category="paragraph">Para una eficiencia de compresión óptima, asegúrese de que el sistema de archivos NTFS utilice una unidad de asignación de 8K o más. El uso de una unidad de asignación de 4K, que suele ser la predeterminada, afecta negativamente a la eficiencia de la compresión.</block>
  <block id="edc9f0a5a5d57797bf68e37364743831" category="doc">Linux</block>
  <block id="dfc95ed5e895617bbd0d4b1a8bfba8ca" category="paragraph">Temas de configuración específicos del sistema operativo Linux.</block>
  <block id="5ecd4a6f4aedfdd45cce80a18b1a7942" category="section-title">Tablas de ranuras</block>
  <block id="2518e65e64213437c921c39a097db167" category="section-title">Opciones de montaje de Linux NFS</block>
  <block id="29cd2e6d4fc96e749c4a0e622cad7f50" category="paragraph">En la siguiente tabla, se enumeran las opciones de montaje de NFS de Linux para una instancia única.</block>
  <block id="9fafd031075cede0e8a5a796ec45fbff" category="paragraph">La siguiente tabla enumera las opciones de montaje de NFS de Linux para RAC.</block>
  <block id="f16135915fe2ca5c3b0d660acc0325d3" category="cell"><block ref="4c927b3193f1cd00c7cfd3ac2e7ba8ea" prefix="" category="inline-code"></block></block>
  <block id="fc1ea13514277ff14dc705f62c31c0fc" category="cell"><block ref="4d0511346ac74044d79c9bc297d59b09" prefix="" category="inline-code"></block></block>
  <block id="13c64659680c0bc3603209997cc22225" category="cell">CRS/votación</block>
  <block id="672c5eef2603018159295408f761324b" category="cell"><block ref="26b20bdf0b0e7d3ddef3749a70c17932" prefix="" category="inline-code"></block></block>
  <block id="f7085c7dc406f5b44813ac43c18b80c0" category="paragraph">La diferencia principal entre las opciones de montaje de instancia única y RAC es la adición de<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> a las opciones de montaje. Esta adición tiene el efecto de deshabilitar el almacenamiento en caché del sistema operativo del host, lo que permite que todas las instancias del clúster RAC tengan una vista coherente del estado de los datos. Aunque utilice el<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> parámetro<block ref="b6a2b868e8bebfc19497b406a12a1071" prefix=" " category="inline-code"></block> tiene el mismo efecto de deshabilitar el almacenamiento en caché de host, sigue siendo necesario utilizarlo<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block>.</block>
  <block id="d2537738f34705bc9d100925252c0102" category="paragraph">La razón<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> es necesario para el uso compartido<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block> Despliegues es para facilitar la consistencia de archivos como los archivos de contraseñas de Oracle y spfiles. Si cada instancia de un clúster de RAC tiene un dedicado<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>, entonces este parámetro no es necesario.</block>
  <block id="5084019c1051a9937b5ff77568ce579b" category="paragraph">Por lo general, los archivos que no son de base de datos se deben montar con las mismas opciones utilizadas para los archivos de datos de instancia única, aunque las aplicaciones específicas pueden tener requisitos diferentes. Evite las opciones de montaje<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> y..<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> si es posible, ya que estas opciones desactivan la lectura anticipada y el almacenamiento en búfer de nivel de sistema de archivos. Esto puede causar graves problemas de rendimiento en procesos como extracción, traducción y carga.</block>
  <block id="243de27c01fea05cc58186d2e5ad1ce5" category="section-title">ACCESO y GETATTR</block>
  <block id="59dcf78e97c197a0f240067da57a248f" category="paragraph">Algunos clientes han observado que un nivel extremadamente alto de otros IOPS, como EL ACCESO y GETATTR, puede dominar sus cargas de trabajo. En casos extremos, las operaciones como las de lectura y escritura pueden ser tan bajas como el 10 % del total. Este es un comportamiento normal con cualquier base de datos que incluya el uso<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> y/o.<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> En Linux, porque estas opciones provocan que el sistema operativo Linux vuelva a cargar constantemente los metadatos de los archivos del sistema de almacenamiento. Las operaciones como EL ACCESO y GETATTR son operaciones de bajo impacto que se proporcionan desde la caché de ONTAP en un entorno de base de datos. No se deben considerar IOPS auténticos, como lecturas y escrituras, que crean una demanda real de sistemas de almacenamiento. Sin embargo, estas otras IOPS crean una cierta carga, sobre todo en entornos RAC. Para solucionar esta situación, habilite DNFS, que omite la caché de buffers del sistema operativo y evita estas operaciones de metadatos innecesarias.</block>
  <block id="041f371e212c70407e145ae9f752a8b4" category="section-title">NFS directo de Linux</block>
  <block id="dd2f3f344f14ae5daf12cb0a817a72e0" category="paragraph">Una opción de montaje adicional denominada<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block>, Es necesario cuando (a) DNFS está activado y (b) un volumen de origen se monta más de una vez en un único servidor (c) con un montaje NFS anidado. Esta configuración se ve principalmente en entornos que admiten aplicaciones SAP. Por ejemplo, un único volumen de un sistema NetApp podría tener un directorio ubicado en<block ref="9f9f4ccb1fc3afcbfe0cc3f5eac4332c" prefix=" " category="inline-code"></block> y un segundo en<block ref="ac2f9bbcd397d8f6b39e6713658051ea" prefix=" " category="inline-code"></block>. Si<block ref="9f9f4ccb1fc3afcbfe0cc3f5eac4332c" prefix=" " category="inline-code"></block> está montado en<block ref="9ad16912cc0ba54a259b1a15d233c264" prefix=" " category="inline-code"></block> y..<block ref="ac2f9bbcd397d8f6b39e6713658051ea" prefix=" " category="inline-code"></block> está montado en<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block>, El resultado son montajes NFS anidados que se originan en la misma fuente.</block>
  <block id="b06ff38483faff2d17d8de1fc966848e" category="paragraph">El sistema operativo puede detectar el hecho de que<block ref="9ad16912cc0ba54a259b1a15d233c264" prefix=" " category="inline-code"></block> y..<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block> residir en el mismo volumen, que es el mismo sistema de archivos de origen. A continuación, el sistema operativo utiliza el mismo identificador de dispositivo para acceder a los datos. Al hacerlo, se mejora el uso del almacenamiento en caché del sistema operativo y algunas otras operaciones, pero interfiere con DNFS. Si DNFS debe acceder a un archivo, como el<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block>, activado<block ref="1da707b60c3b55bd01cb7df7c171a368" prefix=" " category="inline-code"></block>, podría intentar erróneamente utilizar la ruta incorrecta a los datos. El resultado es una operación de I/O con errores. En estas configuraciones, agregue la<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block> Opción de montaje en cualquier sistema de archivos NFS que comparta un volumen FlexVol de origen con otro sistema de archivos NFS en ese host. Al hacerlo, se fuerza al sistema operativo Linux a asignar un identificador de dispositivo independiente para ese sistema de archivos.</block>
  <block id="14dd7af30f62ec838445a1e167d2aff6" category="section-title">Linux Direct NFS y Oracle RAC</block>
  <block id="c6a209e4ad702c6424efb7d63d76feca" category="paragraph">El uso de DNFS ofrece ventajas especiales de rendimiento para Oracle RAC en el sistema operativo Linux, ya que Linux no dispone de un método para forzar la entrada/salida directa, que se necesita con RAC para lograr coherencia entre los nodos. Como solución alternativa, Linux requiere el uso de<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> Opción de montaje, que hace que los datos de archivo caduquen inmediatamente desde la caché del sistema operativo. Esta opción, a su vez, fuerza al cliente NFS de Linux a volver a leer constantemente los datos de atributos, lo que daña la latencia y aumenta la carga en la controladora de almacenamiento.</block>
  <block id="3070cb366c38db327b0cf057d63792c1" category="paragraph">Al habilitar DNFS se omite el cliente NFS del host y se evita este daño. Varios clientes han informado de mejoras significativas en el rendimiento en clústeres RAC y reducciones considerables en la carga de ONTAP (especialmente con respecto a otras IOPS) al habilitar DNFS.</block>
  <block id="e97ab7f94d503bbec4b013b5b77118c6" category="section-title">Linux Direct NFS y archivo oranfstab</block>
  <block id="f63255b70940d25581e0cf5f81dd6cd6" category="paragraph">Al utilizar DNFS en Linux con la opción multipathing, se deben utilizar varias subredes. En otros sistemas operativos, se pueden establecer varios canales DNFS mediante el<block ref="54b4c4075463b2e02cd69f5cd139b5b2" prefix=" " category="inline-code"></block> y..<block ref="bbf52a1a57a4eaa83512cab68fd52b70" prefix=" " category="inline-code"></block> Opciones para configurar varios canales DNFS en una sola subred. Sin embargo, esto no funciona correctamente en Linux y puede resultar en problemas de rendimiento inesperados. Con Linux, cada NIC utilizada para el tráfico DNFS debe estar en una subred diferente.</block>
  <block id="6c5cf31ca1af553b1f4a9b99e3cb054c" category="section-title">Programador de I/O.</block>
  <block id="49bb1f5f4810e5f3d32dac84bd96005d" category="paragraph">El kernel de Linux permite un control de bajo nivel sobre la forma en que se programa la E/S para bloquear los dispositivos. Los valores por defecto en varias distribuciones de Linux varían considerablemente. Las pruebas demuestran que la fecha límite suele ofrecer los mejores resultados, pero en ocasiones NOOP ha sido ligeramente mejor. La diferencia de rendimiento es mínima, pero pruebe ambas opciones si es necesario extraer el máximo rendimiento posible de una configuración de base de datos. CFQ es el valor predeterminado en muchas configuraciones y ha demostrado tener problemas de rendimiento significativos con cargas de trabajo de bases de datos.</block>
  <block id="38f25b8840d56fc601af1024115764b2" category="paragraph">Consulte la documentación relevante del proveedor de Linux para obtener instrucciones sobre la configuración del programador de E/S.</block>
  <block id="4150162ad42bffea7bb903b4c7a4ffd9" category="section-title">Accesos múltiples</block>
  <block id="305482bf1c318f0a9a04f94987db06b2" category="paragraph">Algunos clientes se han encontrado con fallos durante la interrupción de la red porque el daemon multivía no se estaba ejecutando en su sistema. En versiones recientes de Linux, el proceso de instalación del sistema operativo y el daemon de rutas múltiples pueden dejar estos sistemas operativos vulnerables a este problema. Los paquetes están instalados correctamente, pero no están configurados para el inicio automático después de un reinicio.</block>
  <block id="6fb0bf499bef576f56e0fd6360eba0a6" category="paragraph">Por ejemplo, el valor predeterminado para el daemon multipath en RHEL5,5 puede aparecer del siguiente modo:</block>
  <block id="31026ba0b77cbe4c9d44ed6afc859ed6" category="paragraph">Esto se puede corregir con los siguientes comandos:</block>
  <block id="c759a9b7e4db09da8a25fb73d256f6b7" category="section-title">Duplicación de ASM</block>
  <block id="f2f41836b42c08199948378b4a4a6e26" category="paragraph">La duplicación de ASM puede requerir cambios en la configuración multivía de Linux para permitir que ASM reconozca un problema y cambie a un grupo de fallos alternativo. La mayoría de las configuraciones de ASM en ONTAP utilizan redundancia externa, lo que significa que la cabina externa ofrece protección de datos y ASM no refleja datos. Algunos sitios utilizan ASM con redundancia normal para proporcionar duplicación bidireccional, normalmente en diferentes sitios.</block>
  <block id="25f47751ccd5df99e3c25a8eb2a21fc5" category="inline-link-macro">Documentación de utilidades de host de NetApp</block>
  <block id="066a79b72a430b074cdc0476b67bbde3" category="paragraph">La configuración de Linux que se muestra en la <block ref="210658f6fe0d0061c73c19a9a6b263d1" category="inline-link-macro-rx"></block> Incluya parámetros multivía que generen la cola indefinida de I/O. Esto significa que una I/O en un dispositivo LUN sin rutas activas espera tanto tiempo como sea necesario para que finalice la I/O. Esto suele ser deseable ya que los hosts Linux esperan todo el tiempo necesario para que se completen los cambios de ruta SAN, para que se reinicien los switches FC o para que un sistema de almacenamiento complete una conmutación al respaldo.</block>
  <block id="184ea23c04f24d03fc0123bc6eb30de2" category="paragraph">Este comportamiento de puesta en cola ilimitada provoca un problema con el mirroring de ASM debido a que ASM debe recibir un error de I/O para que vuelva a intentar I/O en un LUN alternativo.</block>
  <block id="5616945ee545765b51d3fe1871cff4ec" category="paragraph">Defina los siguientes parámetros en Linux<block ref="9ac80d53ede05256c28cf9e043eb423c" prefix=" " category="inline-code"></block> Archivo para LUN de ASM utilizados con la duplicación de ASM:</block>
  <block id="49af3bbe0c557480960d217b217502ff" category="paragraph">Estos valores crean un timeout de 120 segundos para los dispositivos ASM. El tiempo de espera se calcula como el<block ref="e2f0125c5971e1ce714f86f145386ee3" prefix=" " category="inline-code"></block> *<block ref="9434de34302b4f40887a7277cf35a8fc" prefix=" " category="inline-code"></block> como segundos. Puede que sea necesario ajustar el valor exacto en algunas circunstancias, pero un tiempo de espera de 120 segundos debería ser suficiente para la mayoría de los usos. Concretamente, 120 segundos deberían permitir que se produzca una toma de control o una devolución de la controladora sin que se produzca un error de I/O, lo que provocaría que el grupo de errores se desconectara.</block>
  <block id="dbff1dc161f3f1d61258259b3a0b549c" category="paragraph">A inferior<block ref="9434de34302b4f40887a7277cf35a8fc" prefix=" " category="inline-code"></block> Value puede reducir el tiempo necesario para que ASM cambie a un grupo de fallos alternativo, pero esto también aumenta el riesgo de una conmutación por error no deseada durante actividades de mantenimiento como la toma de control de un controlador. El riesgo se puede mitigar mediante una supervisión cuidadosa del estado de duplicación de ASM. Si se produce una conmutación al respaldo no deseada, los duplicados pueden volver a sincronizarse rápidamente si la resincronización se realiza con relativa rapidez. Para obtener información adicional, consulte la documentación de Oracle on ASM Fast Mirror Resync para ver la versión del software de Oracle en uso.</block>
  <block id="ec0b68df6b5a0fdd6d73ac710b9684da" category="section-title">Opciones de montaje de Linux xfs, ext3 y ext4</block>
  <block id="278230e4238d02fcb49850454e7d79e0" category="admonition">*NetApp recomienda* usar las opciones de montaje predeterminadas.</block>
  <block id="02a5a4d50c5112bb31ff9c94f5b47ce9" category="paragraph">Muchos clientes de Oracle en ONTAP utilizan ethernet, el protocolo de red de NFS, iSCSI, NVMe/TCP y, especialmente, el cloud.</block>
  <block id="8a1870adbe8a237106c32d72660a9c42" category="summary">Diseño de interfaz lógica para bases de datos de Oracle</block>
  <block id="f46a94d438563c03413adfec27c6bfda" category="paragraph">Las bases de datos de Oracle necesitan acceder al almacenamiento. Las interfaces lógicas (LIF) son las tuberías de red que conecta una máquina virtual de almacenamiento (SVM) a la red y, por tanto, a la base de datos. Es necesario diseñar un LIF adecuado para garantizar que exista un ancho de banda suficiente para cada carga de trabajo de la base de datos. La conmutación por error no conlleva la pérdida de los servicios de almacenamiento.</block>
  <block id="f445528d334d486a14570735705e2223" category="summary">Configuración de red FC para bases de datos de Oracle</block>
  <block id="92cdde4ecc529b9f9379ed2bdb6aae34" category="paragraph">La configuración de SAN FC para bases de datos de Oracle consiste principalmente en seguir prácticas recomendadas diarias de SAN.</block>
  <block id="9eaca569c6f5ca3388f5613da3aa008c" category="doc">Bases de datos de Oracle en ONTAP</block>
  <block id="528b35962f1679204260ddef6800eece" category="paragraph">ONTAP está diseñado para bases de datos de Oracle. Durante décadas, ONTAP se ha optimizado para las demandas específicas de las I/O de las bases de datos relacionales y se crearon varias funciones de ONTAP específicamente para satisfacer las necesidades de las bases de datos de Oracle e incluso a petición de la misma Oracle Inc.</block>
  <block id="c9f8ef2db64ce19b15d2cc98fbd3d24c" category="admonition">Esta documentación sustituye a los informes técnicos _TR-3633 publicados anteriormente: Bases de datos Oracle en ONTAP; TR-4591: Protección de datos de Oracle: Backup, recuperación, replicación; TR-4592: Oracle en MetroCluster; y TR-4534: Migración de bases de datos de Oracle a sistemas de almacenamiento de NetApp_</block>
  <block id="b42ad0517ef7394f97178fb9e1de8d78" category="paragraph">Además de las muchas formas posibles en que ONTAP aporta valor a su entorno de bases de datos, también presenta una amplia variedad de requisitos de usuario, como el tamaño de la base de datos, los requisitos de rendimiento y las necesidades de protección de datos. Las puestas en marcha conocidas del almacenamiento de NetApp incluyen todo, desde un entorno virtualizado de aproximadamente 6.000 bases de datos que se ejecutan con VMware ESX hasta un almacén de datos de instancia única con un tamaño actualmente de 996TB TB, que sigue creciendo. Como resultado, existen pocas mejores prácticas claras para configurar una base de datos Oracle en un almacenamiento de NetApp.</block>
  <block id="7bf0493f27e81fe4c3740e773e137a48" category="paragraph">Los requisitos para operar una base de datos Oracle en el almacenamiento de NetApp se tratan de dos formas. En primer lugar, cuando existe una práctica recomendada clara, se llamará específicamente. En un nivel general, se explicarán muchas consideraciones de diseño que deben tratar los arquitectos de las soluciones de almacenamiento de Oracle basadas en sus requisitos empresariales específicos.</block>
  <block id="633d94718c25247da5772ed6f2b244c9" category="summary">Introducción a la migración del almacenamiento de Oracle</block>
  <block id="08beeb11d62fd51ef2742eae3ee3719f" category="admonition">Esta documentación sustituye al informe técnico _TR-4534: Migración de bases de datos de Oracle a sistemas de almacenamiento de NetApp_</block>
  <block id="5f2a4190824fd64be3c8cabeb7dc62ff" category="paragraph">En el caso de un nuevo proyecto de base de datos, no se trata de un problema, ya que los entornos de bases de datos y aplicaciones están construidos in situ. Sin embargo, la migración plantea desafíos especiales con respecto a la interrupción del negocio, el tiempo necesario para completar la migración, las habilidades necesarias y la minimización de riesgos.</block>
  <block id="a83f1ca5ad00b39773d9e6a26b0e70b2" category="section-title">Scripts</block>
  <block id="08293bec81c296b61f4a751175d9caa7" category="paragraph">En esta documentación se proporcionan secuencias de comandos de ejemplo. Estos scripts proporcionan métodos de ejemplo de automatización de diversos aspectos de la migración para reducir la posibilidad de errores de usuario. Las secuencias de comandos pueden reducir las demandas generales sobre el PERSONAL DE TI responsable de la migración y pueden acelerar el proceso general. Todos estos scripts se extraen de los proyectos de migración reales realizados por los servicios profesionales de NetApp y los partners de NetApp. A lo largo de esta documentación se muestran ejemplos de su uso.</block>
  <block id="c28b52826242c7cdffe5f3ae1e917f61" category="paragraph">No es posible evitar alguna interrupción durante una importación de LUN externa debido a la necesidad de cambiar la configuración de red FC. Sin embargo, la interrupción no tiene que durar mucho más del tiempo requerido para reiniciar el entorno de bases de datos y actualizar la división en zonas de FC para cambiar la conectividad de FC de host desde el LUN externo a ONTAP.</block>
  <block id="a2248459756ffc1877beb9b39c77668b" category="paragraph">Este proceso se puede resumir de la siguiente manera:</block>
  <block id="c9f77905e39abbada6c73a7a3d5f51f8" category="list-text">Desactive toda la actividad de LUN en las LUN externas.</block>
  <block id="cff6e7c6c4f8dd7e57a0286f28712c58" category="list-text">Redirija las conexiones host FC al nuevo sistema ONTAP.</block>
  <block id="9fea842823b73e1eb32307ab325f170e" category="list-text">Active el proceso de importación.</block>
  <block id="df814ea2bf92d4f18e72a648e93103a2" category="list-text">Vuelva a detectar las LUN.</block>
  <block id="030a5009bbe6fb141ca5863ab6c59464" category="list-text">Reinicie la base de datos.</block>
  <block id="f3bb22d18791c042e889671ad1963239" category="paragraph">No es necesario esperar hasta que finalice el proceso de migración. Tan pronto como comience la migración de una LUN determinada, está disponible en ONTAP y puede servir datos mientras continúa el proceso de copia de datos. Todas las lecturas se pasan a través del LUN externo y todas las escrituras se escriben sincrónicamente en ambas cabinas. La operación de copia es muy rápida y la sobrecarga que conlleva redirigir el tráfico FC es mínima, por lo que cualquier impacto sobre el rendimiento debe ser temporal y mínimo. Si existe algún problema, puede retrasar el reinicio del entorno hasta que se complete el proceso de migración y se eliminen las relaciones de importación.</block>
  <block id="b19e17ab765f91aa0bc0e7152f13779f" category="section-title">Cierre la base de datos</block>
  <block id="2869cd69e0fec20ba28a42e74afef158" category="paragraph">El primer paso para desactivar el entorno en este ejemplo es cerrar la base de datos.</block>
  <block id="e20dab0880a91f5da2ea05170177576d" category="section-title">Cierre los servicios de red</block>
  <block id="89c458e5176d6caf0690f1e61ecb0620" category="paragraph">Uno de los sistemas de archivos basados en SAN que se están migrando también incluye los servicios de Oracle ASM. Para desactivar las LUN subyacentes es necesario desmontar los sistemas de archivos, lo que, a su vez, significa detener cualquier proceso con archivos abiertos en este sistema de archivos.</block>
  <block id="49f05bf7da4eacfa4c80bb987443eb5a" category="section-title">Desmonte los sistemas de archivos</block>
  <block id="c5a09ac3ff0bb25c97951c7b7f815cd0" category="paragraph">Si todos los procesos se cierran, la operación umount se realiza correctamente. Si se deniega el permiso, debe haber un proceso con un bloqueo en el sistema de archivos. La<block ref="ace112f9725b6fa0b702e6b3970b2102" prefix=" " category="inline-code"></block> command puede ayudar a identificar estos procesos.</block>
  <block id="765e13ffc3361a9fd6c6088b2603ffbf" category="section-title">Desactivar los grupos de volúmenes</block>
  <block id="907e5f35f70dc2f5e4b67da56381bdf4" category="paragraph">Una vez que se han desmontado todos los sistemas de archivos de un grupo de volúmenes determinado, el grupo de volúmenes puede desactivarse.</block>
  <block id="ad80f935ccd133a802189e3c2f4421d7" category="section-title">Cambios de red FC</block>
  <block id="a497da6790d9ab4bb5cce3d04b0efd2e" category="paragraph">Ahora las zonas de FC se pueden actualizar para eliminar todo el acceso del host a la cabina externa y establecer acceso a ONTAP.</block>
  <block id="3ef31115a10790468ad841ec2cdf566f" category="section-title">Inicie el proceso de importación</block>
  <block id="5bc309ef1913ddc70534a0a7135ba938" category="paragraph">Para iniciar los procesos de importación de LUN, ejecute el<block ref="76ffc50817aa4cd6214aa0061339fdf6" prefix=" " category="inline-code"></block> comando.</block>
  <block id="0a10f1ad4a0b45d384c5771ec0906c4c" category="section-title">Supervise el progreso de la importación</block>
  <block id="9a3a7545f4a7407ec022c4b2271e0c34" category="paragraph">La operación de importación se puede supervisar con el<block ref="1ab15ef2c245a4434fcea3cc3149f4f4" prefix=" " category="inline-code"></block> comando. Como se muestra a continuación, la importación de todas las 20 LUN está en curso, lo que significa que ahora se puede acceder a los datos a través de ONTAP aunque la operación de copia de datos aún progresa.</block>
  <block id="d36f98c8a305e33483232e7b5cd90c49" category="inline-link-macro">Importación de LUN externa: Completado</block>
  <block id="24a74765303a8fc0e4b1e7afbb8e2205" category="paragraph">Si necesita un proceso sin conexión, retrase la detección o el reinicio de servicios hasta que el<block ref="1ab15ef2c245a4434fcea3cc3149f4f4" prefix=" " category="inline-code"></block> comando indica que toda la migración se ha realizado correctamente y se ha completado. A continuación, puede completar el proceso de migración tal y como se describe en <block ref="5b0017122426f8734e0358273adc6802" category="inline-link-macro-rx"></block>.</block>
  <block id="a9c97f84ee4958d39ed989b3da7ed0ba" category="paragraph">Si necesita una migración en línea, continúe con la detección de las LUN en su nuevo directorio raíz y obtenga los servicios.</block>
  <block id="d0369936c6fe8c292874e3bc647893b8" category="section-title">Busque cambios en el dispositivo SCSI</block>
  <block id="6d338faddede649cab4c5b498e8e4379" category="paragraph">En la mayoría de los casos, la opción más sencilla para volver a detectar nuevos LUN es reiniciar el host. Al hacerlo, se eliminan automáticamente los dispositivos obsoletos antiguos, se detectan correctamente todas las LUN nuevas y se crean dispositivos asociados como dispositivos multivía. El ejemplo aquí muestra un proceso totalmente en línea con fines de demostración.</block>
  <block id="3b493a859f19779c1f7db7d1951785ee" category="paragraph">Precaución: Antes de reiniciar un host, asegúrese de que todas las entradas en<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Que se comentan los recursos SAN migrados de referencia. Si no se realiza y hay problemas con el acceso a la LUN, es posible que el sistema operativo no arranque. Esta situación no daña los datos. Sin embargo, puede ser muy incómodo arrancar en modo de rescate o un modo similar y corregir el<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Para que el sistema operativo se pueda iniciar y permitir la solución de problemas.</block>
  <block id="9d7b16568eb7edb80492b49cb02d7663" category="paragraph">Las LUN de la versión de Linux utilizada en este ejemplo se pueden volver a analizar con el<block ref="b6f75508bf2af141e9de6f862662661e" prefix=" " category="inline-code"></block> comando. Si el comando se realiza correctamente, cada ruta de LUN debería aparecer en el resultado. El resultado puede ser difícil de interpretar, pero, si la configuración de división en zonas y igroup es correcta, deberían aparecer muchas LUN que incluyan un<block ref="971c047750d8e3b03c71d24020b3816f" prefix=" " category="inline-code"></block> cadena de proveedor.</block>
  <block id="3384aa7c090758ad18028832967b143f" category="section-title">Compruebe si hay dispositivos multivía</block>
  <block id="07a39d42e6d8cc61e0a880e43b83e2a3" category="paragraph">El proceso de detección de LUN también activa la recreación de dispositivos multivía, pero se sabe que el controlador multivía de Linux tiene problemas ocasionales. El resultado de<block ref="eeb30d005cab1d8c69785a3cd5818f55" prefix=" " category="inline-code"></block> debe comprobarse para verificar que la salida tiene el aspecto esperado. Por ejemplo, la salida a continuación muestra los dispositivos multivía asociados con a.<block ref="971c047750d8e3b03c71d24020b3816f" prefix=" " category="inline-code"></block> cadena de proveedor. Cada dispositivo tiene cuatro rutas, dos con una prioridad de 50 y dos con una prioridad de 10. Aunque la salida exacta puede variar con diferentes versiones de Linux, esta salida tiene el aspecto esperado.</block>
  <block id="efd921479c3d57448954050760c568ca" category="admonition">Consulte la documentación de utilidades de host para la versión de Linux que utiliza para verificar que el<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> los ajustes son correctos.</block>
  <block id="28751dc1e914a778d11ca0e69613690b" category="section-title">Reactivar el grupo de volúmenes LVM</block>
  <block id="a66a38e4056f28a310ef6d1fa8bbcc77" category="paragraph">Si las LUN LVM se han detectado correctamente, el<block ref="5239f542d8edbc4b528b1f362153c0c7" prefix=" " category="inline-code"></block> el comando debería tener éxito. Este es un buen ejemplo del valor de un gestor de volúmenes lógicos. Un cambio en el WWN de una LUN o incluso un número de serie no es importante, porque los metadatos del grupo de volúmenes se escriben en la propia LUN.</block>
  <block id="1d374f8de5ba1b82ab4407b8c6efbd0d" category="paragraph">El SO analizó las LUN y detectó una pequeña cantidad de datos escritos en la LUN que la identifica como un volumen físico que pertenece al<block ref="83b7788c8e4de444d6cd4c69978eaf32" prefix=" " category="inline-code"></block>. Luego construyó todos los dispositivos necesarios. Todo lo que se requiere es reactivar el grupo de volúmenes.</block>
  <block id="1f0285a57b2357507c3b77ce5130b548" category="section-title">Vuelva a montar los sistemas de archivos</block>
  <block id="a9047d68dc7e99f553b71590cff301d6" category="paragraph">Una vez que se reactiva el grupo de volúmenes, los sistemas de archivos pueden montarse con todos los datos originales intactos. Como se ha explicado anteriormente, los sistemas de archivos funcionan completamente incluso si la replicación de datos sigue activa en el grupo de back.</block>
  <block id="a787d65e2525ac6bc3a6328efe383b5c" category="section-title">Repetir escaneo para dispositivos ASM</block>
  <block id="a25bb20f07ed95a633f623678855e8dc" category="paragraph">Los dispositivos ASMLib deberían haber sido redescubiertos cuando los dispositivos SCSI se volvieron a analizar. La redetección se puede verificar en línea reiniciando ASMLib y luego escaneando los discos.</block>
  <block id="37fb12a52b4a5371c12209e89e09b04f" category="admonition">Este paso sólo es relevante para las configuraciones de ASM en las que se utiliza ASMLib.</block>
  <block id="6de48f39063d81d53fd0ff3e9938af13" category="paragraph">Precaución: Si no se utiliza ASMLib, el<block ref="9c9f766701f811ef6f170c7a3453c53f" prefix=" " category="inline-code"></block> los dispositivos deberían haberse vuelto a crear automáticamente. Sin embargo, es posible que los permisos no sean correctos. Debe definir permisos especiales en los dispositivos subyacentes para ASM en ausencia de ASMLib. Hacer esto generalmente se logra a través de entradas especiales en cualquiera de los<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> o.<block ref="ab775c875d5f89d991a670444dd32ad2" prefix=" " category="inline-code"></block> reglas, o posiblemente en ambos conjuntos de reglas. Es posible que estos archivos deban actualizarse para reflejar los cambios en el entorno en términos de WWN o números de serie para asegurarse de que los dispositivos ASM siguen teniendo los permisos correctos.</block>
  <block id="08b33d6af4ec78f99dbbc3533589aafc" category="paragraph">En este ejemplo, al reiniciar ASMLib y buscar discos se muestran las mismas 10 LUN de ASM que el entorno original.</block>
  <block id="17c4ae76000d9a79a56195071665af32" category="section-title">Reinicie los servicios de grid</block>
  <block id="e8c3dc00e15826e3b77a2d41d7fde92a" category="paragraph">Ahora que los dispositivos LVM y ASM están en línea y disponibles, los servicios de grid se pueden reiniciar.</block>
  <block id="934317e45581988a01f54761705ca58a" category="section-title">Reinicie la base de datos</block>
  <block id="41475a737e947d73c674b90e78e246a0" category="paragraph">Una vez reiniciados los servicios de grid, se puede activar la base de datos. Puede que sea necesario esperar unos minutos para que los servicios de ASM estén completamente disponibles antes de intentar iniciar la base de datos.</block>
  <block id="b171714b39ad4102aced4daceef8c678" category="paragraph">Desde el punto de vista del host, la migración se completa, pero las operaciones de I/O siguen funcionando desde la cabina externa hasta que se eliminan las relaciones de importación.</block>
  <block id="f708d001227724fa0a8a3d57aacedb1a" category="paragraph">Antes de eliminar las relaciones, debe confirmar que el proceso de migración se ha completado para todas las LUN.</block>
  <block id="85cf20229bc9008553794abdaed507f5" category="section-title">Suprimir relaciones de importación</block>
  <block id="b23ec325eb9c6278cb36e4c45c2c3499" category="paragraph">Una vez completado el proceso de migración, elimine la relación de migración. Una vez hecho esto, las operaciones de I/O se proporcionan exclusivamente desde las unidades de ONTAP.</block>
  <block id="40b98b0023a7eea7c432c29e3c44ba7d" category="section-title">Anular el registro de LUN externas</block>
  <block id="5ccc14ae93ba94bd4183439a9f80f6c8" category="paragraph">Finalmente, modifique el disco para eliminar el<block ref="96ea0e5f46787e93e2970a086b47fdb6" prefix=" " category="inline-code"></block> designación.</block>
  <block id="875bb561ba851d301052704e0ffb70f4" category="summary">Migración de Oracle mediante el envío de logs</block>
  <block id="e0f9c3b73fe5700df95f30eb98ca4034" category="doc">Envío de registros de Oracle</block>
  <block id="8e42b5809657e127c7e2d24f30bc493e" category="paragraph">El objetivo de una migración mediante el envío de registros es crear una copia de los archivos de datos originales en una nueva ubicación y, a continuación, establecer un método de envío de cambios en el nuevo entorno.</block>
  <block id="599df5f564506c95624dd78b0b75eeac" category="paragraph">Una vez establecido, el envío y la reproducción de registros se pueden automatizar para mantener la base de datos de réplicas en gran medida sincronizada con la fuente. Por ejemplo, se puede programar un trabajo cron para (a) copiar los logs más recientes en la nueva ubicación y (b) reproducirlos cada 15 minutos. De este modo, se genera una interrupción mínima en el momento de la transición, ya que no se deben volver a reproducir más de 15 minutos de registros de archivo.</block>
  <block id="41bec1b4ddc17b3367c68a025c0ddfb9" category="paragraph">El procedimiento que se muestra a continuación también es esencialmente una operación de clonado de base de datos. La lógica mostrada es similar al motor de NetApp SnapManager para Oracle (SMO) y el plugin para Oracle de NetApp SnapCenter. Algunos clientes han utilizado el procedimiento mostrado en los flujos de trabajo de WFA o en los scripts para operaciones de clonado personalizadas. Aunque este procedimiento es más manual que usar SMO o SnapCenter, todavía dispone de secuencias de comandos sencillas y las API de gestión de datos en ONTAP simplifican aún más el proceso.</block>
  <block id="f0616883a5ca70aa97676de436a7fb9e" category="section-title">Envío de registros: Sistema de archivos al sistema de archivos</block>
  <block id="8f922b64f0bc64f6bba1d555a61ee3bb" category="paragraph">Este ejemplo muestra la migración de una base de datos denominada WAFFLE de un sistema de archivos ordinario a otro sistema de archivos ordinario ubicado en un servidor diferente. También ilustra el uso de SnapMirror para realizar una copia rápida de los archivos de datos, pero esto no forma parte integral del procedimiento general.</block>
  <block id="60100e1b826a4b972fc113c391f932e7" category="section-title">Crear copia de seguridad de base de datos</block>
  <block id="80cf34e10dcfbc5e76c6b2f845f2708d" category="paragraph">El primer paso es crear una copia de seguridad de la base de datos. En concreto, este procedimiento requiere un juego de archivos de datos que se pueda utilizar para la reproducción del archive log.</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="section-title">Entorno Oracle</block>
  <block id="744a73803cdac4a5067725ca5814a2cf" category="section-title">Restauración al nuevo entorno</block>
  <block id="46228bb2ce31b0d397faad2b805e8a37" category="paragraph">La copia de seguridad se debe restaurar ahora en el nuevo entorno. Esto puede realizarse de varias maneras, incluida Oracle RMAN, restauración desde una aplicación de backup como NetBackup o una operación de copia sencilla de archivos de datos ubicados en modo de backup dinámico.</block>
  <block id="1f255556546f1fdfb53692e41f35eb6c" category="list-text">Cree un volumen nuevo para recibir los datos de las snapshots. Inicialice el mirroring a partir de<block ref="937e9fa808ccfe9a4f6b004a2a7caada" prefix=" " category="inline-code"></block> para<block ref="96f9dacb3cb1b1f6f9b4ad02992a1a0e" prefix=" " category="inline-code"></block>.</block>
  <block id="5b1944ec8c0ed933e5b2ea2e3e5fa76e" category="list-text">Una vez definido el estado mediante SnapMirror, que indica que la sincronización está completada, actualice el mirror según la snapshot que desee.</block>
  <block id="f4d90c6c29b1f76ab9c87a9996c9751e" category="list-text">La sincronización correcta se puede verificar en el<block ref="31952c255e722053d4cc3f82921e95db" prefix=" " category="inline-code"></block> en el volumen de reflejo.</block>
  <block id="0934c3fcad3065c2a479125e4a80b259" category="list-text">El espejo puede romperse.</block>
  <block id="fcf1f505b94151a36eba8e1563e7176f" category="list-text">Monte el nuevo sistema de archivos.Con los sistemas de archivos basados en bloques, los procedimientos precisos varían según el LVM en uso. Debe configurarse la división en zonas de FC o las conexiones iSCSI. Después de establecer la conectividad a las LUN, comandos como Linux<block ref="302c49bbd5bcda5463eb5130804effc1" prefix=" " category="inline-code"></block> Puede que sea necesario detectar qué grupos de volúmenes o LUN tienen que estar correctamente configurados para que ASM pueda detectar.</block>
  <block id="20c4d1d4163c2463cf15ff7df6424459" category="paragraph">En este ejemplo, se utiliza un sistema de archivos NFS simple. Este sistema de archivos se puede montar directamente.</block>
  <block id="b2dd88a1f03a5fb4c2e3c0d46f425161" category="section-title">Crear plantilla de creación de archivo de control</block>
  <block id="1c30e11140f1d0a1093bedee34eef1e4" category="paragraph">A continuación, debe crear una plantilla de archivo de control. La<block ref="3177841b2335a6640ea3054199830f1c" prefix=" " category="inline-code"></block> command crea comandos de texto para volver a crear un archivo de control. Esta función puede ser útil para restaurar una base de datos a partir de un backup bajo determinadas circunstancias, y se suele utilizar con scripts que realizan tareas como la clonación de bases de datos.</block>
  <block id="3f51d58ec72b9d36cb5e0636525130b5" category="list-text">La salida del siguiente comando se utiliza para recrear los controlfiles para la base de datos migrada.</block>
  <block id="cb395c3bf18fd427287caecc9b28058a" category="list-text">Después de crear los archivos de control, copie el archivo en el nuevo servidor.</block>
  <block id="cf5c9046a3617a19c0ccc24e4cf54a33" category="section-title">Archivo de parámetros de copia de seguridad</block>
  <block id="0d1d1a7db58f3f93ec977733f4909f5d" category="paragraph">También se necesita un archivo de parámetros en el nuevo entorno. El método más simple es crear un pfile a partir del spfile o pfile actual. En este ejemplo, la base de datos de origen está utilizando un spfile.</block>
  <block id="051a634cb1e9a53dbf139214e1d24001" category="section-title">Crear entrada oratab</block>
  <block id="2dabc26c8b55d44e25a184ba2624eed0" category="paragraph">La creación de una entrada oratab es necesaria para el correcto funcionamiento de utilidades como oraenv. Para crear una entrada de oratab, realice el siguiente paso.</block>
  <block id="87ef75141d237e3b44e8310aad8fcf19" category="section-title">Preparar la estructura de directorios</block>
  <block id="12f833c44c11e6bbd970cc126bce2bcb" category="paragraph">Si los directorios necesarios no estaban presentes, debe crearlos o el procedimiento de inicio de la base de datos falla. Para preparar la estructura de directorios, complete los siguientes requisitos mínimos.</block>
  <block id="60225c364a012796a6d886e8cf4ec486" category="section-title">Actualizaciones de archivos de parámetros</block>
  <block id="e36ee2d9a95a6b672917862d714af383" category="list-text">Para copiar el archivo de parámetros en el nuevo servidor, ejecute los siguientes comandos. La ubicación predeterminada es la<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> directorio. En este caso, el archivo pfile se puede colocar en cualquier lugar. Sólo se utiliza como paso intermedio en el proceso de migración.</block>
  <block id="d437a40a59905247cfb39cf9dc9da256" category="list-text">Edite el archivo según sea necesario. Por ejemplo, si la ubicación del archive log ha cambiado, el archivo pfile debe modificarse para reflejar la nueva ubicación. En este ejemplo, sólo se reubican los archivos de control, en parte para distribuirlos entre los sistemas de archivos de registro y de datos.</block>
  <block id="55cc35656c3d28c1b3267c246b397521" category="list-text">Una vez finalizadas las ediciones, cree un archivo spfile basado en este archivo pfile.</block>
  <block id="a833a03e6af0b969524dcccb8f296f1c" category="section-title">Vuelva a crear los archivos de control</block>
  <block id="74a636ee3a009f08cd5623dc8066dd09" category="paragraph">En un paso anterior, la salida de<block ref="3177841b2335a6640ea3054199830f1c" prefix=" " category="inline-code"></block> se ha copiado en el nuevo servidor. La parte específica de la salida necesaria es la<block ref="0ca1fba455d799b9a1cc2440b9ba7043" prefix=" " category="inline-code"></block> comando. Esta información se puede encontrar en el archivo bajo la sección marcada<block ref="9fb76d62be749cec8bdd06f46c77bf5b" prefix=" " category="inline-code"></block>. Comienza con la línea<block ref="13ac20c4a96b2ecfd703e831ad722907" prefix=" " category="inline-code"></block> y debe incluir la palabra<block ref="c3c62948f78a7ccaabb9ef2eea80a895" prefix=" " category="inline-code"></block>. Termina con el carácter de punto y coma (; ).</block>
  <block id="bf4b2a006646a8e77166a2a596425074" category="list-text">En este procedimiento de ejemplo, el archivo se lee de la siguiente manera.</block>
  <block id="a9a27c002ec883341220e267712250a7" category="list-text">Edite este script como desee para reflejar la nueva ubicación de los distintos archivos. Por ejemplo, algunos archivos de datos conocidos por admitir una gran I/O podrían redirigirse a un sistema de archivos en un nivel de almacenamiento de alto rendimiento. En otros casos, los cambios podrían ser únicamente por motivos de administrador, como el aislamiento de los archivos de datos de una PDB determinada en volúmenes dedicados.</block>
  <block id="2540fb1670d4f9ee8a704a7eb8d748fe" category="list-text">En este ejemplo, la<block ref="b86df74c6982de8dec7509d039294d7a" prefix=" " category="inline-code"></block> stanza se deja sin cambios, pero los redo logs se mueven a una nueva ubicación en<block ref="96bb85ed0fe822778c4e5a821e991ad8" prefix=" " category="inline-code"></block> en lugar de compartir espacio con archive logs<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block>.</block>
  <block id="8d47ad079859f2976fdc7ebf742f768d" category="paragraph">Si alguno de los archivos está mal ubicado o los parámetros están mal configurados, se generan errores que indican lo que debe corregirse. La base de datos está montada, pero aún no está abierta y no se puede abrir porque los archivos de datos en uso siguen marcados como en modo de copia de seguridad en caliente. Los archive logs deben aplicarse primero para que la base de datos sea coherente.</block>
  <block id="6b7c2d588ac708b58f7ac889090608f6" category="section-title">Replicación de registro inicial</block>
  <block id="2db2d3d6001a06d1a027904fa66bc78c" category="paragraph">Se necesita al menos una operación de respuesta de log para que los archivos de datos sean consistentes. Hay muchas opciones disponibles para reproducir logs. En algunos casos, la ubicación original del archive log en el servidor original se puede compartir a través de NFS, y la respuesta del log se puede realizar directamente. En otros casos, los archive logs deben copiarse.</block>
  <block id="5c394e6951584d114c6706d0768e30d7" category="paragraph">Por ejemplo, un simple<block ref="8a444a43bdf534c0c6338bb7809659b3" prefix=" " category="inline-code"></block> la operación puede copiar todos los registros actuales del servidor de origen al servidor de migración:</block>
  <block id="5fdb3158ed28dd3aa90b94556476b781" category="section-title">Reproducción de log inicial</block>
  <block id="c2f93ef52583f81f0eba05a39483e2d8" category="paragraph">Una vez que los archivos están en la ubicación del archive log, se pueden reproducir emitiendo el comando<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block> seguido de la respuesta<block ref="e1f2d5134ed2543d38a0de9751cf75d9" prefix=" " category="inline-code"></block> para reproducir automáticamente todos los logs disponibles.</block>
  <block id="f30a45a22256018185c5d235292e4d5e" category="paragraph">La respuesta final del archive log informa de un error, pero esto es normal. El registro lo indica<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> estaba buscando un archivo de registro en particular y no lo encontró. La razón es, lo más probable, que el archivo log no existe aún.</block>
  <block id="80bea8a60412cace54760b223b2d799e" category="paragraph">Si la base de datos de origen se puede cerrar antes de copiar archive logs, este paso debe realizarse una sola vez. Los archive logs se copian y se reproducen y, a continuación, el proceso puede continuar directamente con el proceso de transposición que replica los redo logs críticos.</block>
  <block id="1e334141582a9dcb581c9b34ef2df071" category="section-title">Replicación y repetición de log incremental</block>
  <block id="5fd2b0bf662c2b1ebdc677ea888536ce" category="paragraph">En la mayoría de los casos, la migración no se realiza de forma inmediata. Pueden pasar días o incluso semanas antes de que se complete el proceso de migración, lo que significa que los registros deben enviarse continuamente a la base de datos de réplica y reproducirse. Por lo tanto, al llegar la transición, es necesario transferir y reproducir unos datos mínimos.</block>
  <block id="0c56d82ec6857bcef5475899b9f7b5cc" category="paragraph">Al hacerlo se puede ejecutar un script de muchas maneras, pero uno de los métodos más populares es usar rsync, una utilidad común de replicación de archivos. La forma más segura de utilizar esta utilidad es configurarla como daemon. Por ejemplo, la<block ref="b31375af035ed8a698a803a491084f61" prefix=" " category="inline-code"></block> el siguiente archivo muestra cómo crear un recurso llamado<block ref="260e23541ff372b9bc53b4bd3c0c38ba" prefix=" " category="inline-code"></block> Al que se accede con las credenciales de usuario de Oracle y se asigna a.<block ref="488a4921a81e36fca411e6f13cefbbf2" prefix=" " category="inline-code"></block>. Lo que es más importante, el recurso se establece en solo lectura, lo que permite que los datos de producción se lean, pero no se alteren.</block>
  <block id="eabf1b424989b2c7113ba3a538079afa" category="paragraph">El siguiente comando sincroniza el destino del archive log del nuevo servidor con el recurso rsync<block ref="260e23541ff372b9bc53b4bd3c0c38ba" prefix=" " category="inline-code"></block> en el servidor original. La<block ref="e358efa489f58062f10dd7316b65649e" prefix=" " category="inline-code"></block> argumento en<block ref="293e33723231f0504effabb52b054a31" prefix=" " category="inline-code"></block> hace que la lista de archivos se compare en función de la marca de tiempo, y solo se copian los archivos nuevos. Este proceso proporciona una actualización incremental del nuevo servidor. Este comando también se puede programar en cron para que se ejecute de forma regular.</block>
  <block id="c775c44069da13c8f7ee5c5116e76e36" category="inline-link-macro">Reproducir Logs en Base de Datos</block>
  <block id="c3bf9b2ef3e3ae2ae6a02f7f77cfcbc6" category="paragraph">Una vez recibidos los registros, deben reproducirse. Ejemplos anteriores muestran el uso de sqlplus para ejecutar manualmente<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block>, un proceso que se puede automatizar fácilmente. El ejemplo que se muestra aquí utiliza el script descrito en <block ref="3e57a2099043fa40c58f1e0d4eed995d" category="inline-link-macro-rx"></block>. Los scripts aceptan un argumento que especifica la base de datos que necesita una operación de reproducción. Esto permite utilizar el mismo script en un esfuerzo de migración de varias bases de datos.</block>
  <block id="4ea2a6c39b10b3e3076f976f58a861d1" category="section-title">Transición</block>
  <block id="5de3f1ba0bbef459baa93f04f63b9ea1" category="paragraph">Cuando esté listo para realizar la transición al nuevo entorno, debe realizar una sincronización final que incluya tanto archive logs como redo logs. Si la ubicación de redo log original no se conoce todavía, se puede identificar de la siguiente manera:</block>
  <block id="677f005cc0f8be0f891df5af72fb5688" category="list-text">Cierre la base de datos de origen.</block>
  <block id="41b182875e12de118d17b3432cca93fa" category="list-text">Realice una sincronización final de los archive logs en el nuevo servidor con el método deseado.</block>
  <block id="37d6d9420cef8230249e7691315f0e13" category="list-text">Los redo logs de origen se deben copiar en el nuevo servidor. En este ejemplo, los redo logs se reubicaron en un nuevo directorio en<block ref="96bb85ed0fe822778c4e5a821e991ad8" prefix=" " category="inline-code"></block>.</block>
  <block id="d0a5f1380bd67b0d0fd3bc72f22d88f2" category="list-text">En esta etapa, el nuevo entorno de base de datos contiene todos los archivos necesarios para llevarlo al mismo estado que el origen. Los registros de archivos se deben reproducir por última vez.</block>
  <block id="c2721157205b2d2e96c656c45ca72992" category="list-text">Una vez finalizado, los redo logs se deben volver a reproducir. Si el mensaje<block ref="975df7a5099101ffbe47981cd1d37c2c" prefix=" " category="inline-code"></block> se devuelve, el proceso se realiza correctamente y las bases de datos se sincronizan y se pueden abrir.</block>
  <block id="6acab27c5f334c66f06f3f74bc62d6d8" category="section-title">Envío de registros: ASM al sistema de archivos</block>
  <block id="a67ffcc8b155bb909a6f8c5d5ba2f334" category="paragraph">Este ejemplo muestra el uso de Oracle RMAN para migrar una base de datos. Es muy similar al ejemplo anterior del envío de registros del sistema de archivos al sistema de archivos, pero los archivos de ASM no son visibles para el host. La única opción para migrar datos ubicados en dispositivos ASM es mediante la reubicación del LUN de ASM o mediante Oracle RMAN para realizar las operaciones de copia.</block>
  <block id="1c51600a778919f7f3abb5b25175220a" category="paragraph">Aunque RMAN es un requisito para copiar archivos de Oracle ASM, el uso de RMAN no se limita a ASM. RMAN se puede utilizar para migrar de cualquier tipo de almacenamiento a cualquier otro tipo.</block>
  <block id="2cb6a5bfc4a76f651d496cddc685e078" category="paragraph">Este ejemplo muestra la reubicación de una base de datos llamada PANCAKE del almacenamiento de ASM a un sistema de archivos normal ubicado en un servidor diferente en las rutas de acceso<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> y..<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block>.</block>
  <block id="d1d789c37f1c96d0a5de07798c14fcc5" category="paragraph">El primer paso es crear una copia de seguridad de la base de datos que se migrará a un servidor alternativo. Dado que el origen utiliza Oracle ASM, se debe utilizar RMAN. Se puede realizar una copia de seguridad simple de RMAN del siguiente modo. Este método crea una copia de seguridad etiquetada que RMAN puede identificar fácilmente más adelante en el procedimiento.</block>
  <block id="ed927706d8abc2bbf3a5a8bc55e1e562" category="paragraph">El primer comando define el tipo de destino para la copia de seguridad y la ubicación que se utilizará. El segundo inicia la copia de seguridad de los archivos de datos solamente.</block>
  <block id="db85d05166dd65559ae5f426b51198e6" category="section-title">Copia de seguridad del archivo de control</block>
  <block id="a0b95d36955723a82dde7bbe40b6ccb9" category="paragraph">Se necesita un archivo de control de copia de seguridad más adelante en el procedimiento del<block ref="08de2bfcc2d52d5bc4f3f2dcb97558ad" prefix=" " category="inline-code"></block> funcionamiento.</block>
  <block id="76ff543de72e62217293a1d0ceade0aa" category="paragraph">También se necesita un archivo de parámetros en el nuevo entorno. El método más simple es crear un pfile a partir del spfile o pfile actual. En este ejemplo, la base de datos de origen utiliza un spfile.</block>
  <block id="d28f3a5b77909b45c50e6c711bef8b60" category="section-title">Script de cambio de nombre de archivo de ASM</block>
  <block id="c242730c760d895368557f78141ff8b1" category="paragraph">Varias ubicaciones de archivos definidas actualmente en los controlfiles cambian cuando se mueve la base de datos. El siguiente archivo de comandos crea un archivo de comandos de RMAN para facilitar el proceso. Este ejemplo muestra una base de datos con un número muy pequeño de archivos de datos, pero normalmente las bases de datos contienen cientos o incluso miles de archivos de datos.</block>
  <block id="359b84bcf7447a77b212e844aeaa9d89" category="inline-link-macro">Conversión de ASM a Nombre de Sistema de Archivos</block>
  <block id="374a1a0facd7c604ac09ed0dca6efb3e" category="paragraph">Este script se puede encontrar en <block ref="288325982fd7bee6cf9eb66ad33f6f7a" category="inline-link-macro-rx"></block> y hace dos cosas.</block>
  <block id="42787fdca1cf792241ce03151ec7dbd3" category="paragraph">En primer lugar, crea un parámetro para redefinir las ubicaciones de redo log llamadas<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block>. Es esencialmente una lista de campos alternos. El primer campo es la ubicación de un redo log actual y el segundo campo es la ubicación del nuevo servidor. El patrón se repite entonces.</block>
  <block id="cf444fd96c87609516f0ad8212f41b01" category="paragraph">La segunda función consiste en proporcionar una plantilla para el cambio de nombre del archivo de datos. El archivo de comandos pasa por los archivos de datos, extrae la información del nombre y el número de archivo y lo formatea como un archivo de comandos de RMAN. A continuación, hace lo mismo con los archivos temporales. El resultado es un script de rman simple que se puede editar como se desee para asegurarse de que los archivos se restauran en la ubicación deseada.</block>
  <block id="50614366822786a4f2ee3a5065543634" category="paragraph">Captura la salida de esta pantalla. La<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block> el parámetro se coloca en el archivo pfile como se describe a continuación. El archivo de datos RENAME y el archivo de comandos DUPLICATE de RMAN se deben editar en consecuencia para colocar los archivos de datos en las ubicaciones deseadas. En este ejemplo, se colocan todos<block ref="36c3572e381980ee1f1343988ae4a955" prefix=" " category="inline-code"></block>.</block>
  <block id="e60cd818b9f7ae02a73d8b3a6ea0a809" category="paragraph">Los scripts están casi listos para ejecutarse, pero primero debe estar la estructura de directorios en su lugar. Si los directorios necesarios no están ya presentes, se deben crear o el procedimiento de inicio de la base de datos falla. El ejemplo siguiente refleja los requisitos mínimos.</block>
  <block id="2f2eed2ed14ba876a017aa9ea9515724" category="paragraph">El siguiente comando es necesario para que utilidades como oraenv funcionen correctamente.</block>
  <block id="f34a9f7c077457a54f8838b55b9fc025" category="section-title">Actualizaciones de parámetros</block>
  <block id="fd5c3a935e7374f8b1577e73e85ef375" category="paragraph">El archivo pfile guardado se debe actualizar para reflejar cualquier cambio de ruta en el nuevo servidor. El script de duplicación de RMAN modifica los cambios de la ruta de acceso del archivo de datos y casi todas las bases de datos requieren cambios en el<block ref="d98137bd230dac4372cf20a2e7839463" prefix=" " category="inline-code"></block> y..<block ref="2d205df7ae2efff1576140524b40b93c" prefix=" " category="inline-code"></block> parámetros. Es posible que también haya ubicaciones de archivos de auditoría que deban modificarse y parámetros como<block ref="40f8833ae28ec69bcc89eb0eba090fe4" prefix=" " category="inline-code"></block> Puede que no sea relevante fuera de ASM. Un DBA con experiencia debe revisar cuidadosamente los cambios propuestos antes de continuar.</block>
  <block id="b581dd429e9b4c24127b8940ca8e4346" category="paragraph">En este ejemplo, los cambios clave son las ubicaciones del archivo de control, el destino del archivo de registro y la adición del<block ref="0f2d7ef9b967c2d9fb1ad5aa5e9eb688" prefix=" " category="inline-code"></block> parámetro.</block>
  <block id="bbba1f65801697ba3abd94d90c83ba71" category="paragraph">Después de confirmar los nuevos parámetros, los parámetros deben ponerse en vigor. Existen varias opciones, pero la mayoría de los clientes crean un spfile basado en el archivo pfile de texto.</block>
  <block id="3a17a12678d74dabb1032aaf373166d8" category="section-title">Inicio nomount</block>
  <block id="a9dc570a0b3161e69edc31f3545cbf22" category="paragraph">El último paso antes de replicar la base de datos es abrir los procesos de la base de datos pero no montar los archivos. En este paso, los problemas con el spfile pueden hacerse evidentes. Si la<block ref="357eedab214bb515c5622e275bc19cdb" prefix=" " category="inline-code"></block> el comando falla debido a un error de parámetro, es fácil de cerrar, corregir la plantilla pfile, recargarla como spfile e intentarlo de nuevo.</block>
  <block id="0257eff4bf9bf0cb483f2544fd42f109" category="section-title">Duplique la base de datos</block>
  <block id="4632b675c558eda129fe6da4fbbae2b2" category="paragraph">La restauración de la copia de seguridad de RMAN anterior en la nueva ubicación consume más tiempo que otros pasos de este proceso. La base de datos se debe duplicar sin cambiar el identificador de base de datos (DBID) ni restablecer los logs. Esto evita que se apliquen los logs, lo que es un paso necesario para sincronizar completamente las copias.</block>
  <block id="06206ea0cdea741420d9f7619503db89" category="paragraph">Conéctese a la base de datos con RMAN como aux y emita el comando DUPLICATE DATABASE mediante el script creado en un paso anterior.</block>
  <block id="5ae45dfed3c4aff7fe4fd6a7e3606cb0" category="paragraph">Ahora debe enviar los cambios de la base de datos de origen a una nueva ubicación. Si lo hace, puede que sea necesario realizar una combinación de pasos. El método más sencillo sería tener RMAN en la base de datos de origen escribir archive logs en una conexión de red compartida. Si una ubicación compartida no está disponible, un método alternativo es utilizar RMAN para escribir en un sistema de archivos local y, a continuación, utilizar rcp o rsync para copiar los archivos.</block>
  <block id="e355807335e5f05930a748afe1c3b23d" category="paragraph">En este ejemplo, la<block ref="45987b06d5eae35fc3e3487749a9ba27" prefix=" " category="inline-code"></block> Directory es un recurso compartido NFS que está disponible tanto para la base de datos original como para la migrada.</block>
  <block id="49fffa356bcd041918ce24ef714f3f72" category="paragraph">Una cuestión importante aquí es la<block ref="6761e3b36547cd115b3966fcbc7192b2" prefix=" " category="inline-code"></block> cláusula. El formato de disco del backup es<block ref="9ae0f22d9fa2eac270499e74092af364" prefix=" " category="inline-code"></block>, Lo que significa que debe utilizar el formato de número de hilo, número de secuencia e identificador de activación para la base de datos. Aunque las letras son diferentes, esto coincide con<block ref="03e92f2c3a8cae5315f0e42bf6acf436" prefix=" " category="inline-code"></block> en el pfile. Este parámetro también especifica archive logs en el formato de Núm. De thread, Núm. De secuencia e ID de activación. El resultado final es que los backups de los archivos de registro del origen utilizan una convención de nomenclatura que espera la base de datos. Al hacerlo, se realizan operaciones como<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> mucho más sencillo porque sqlplus anticipa correctamente los nombres de los archive logs que se van a reproducir.</block>
  <block id="76d77393c7ffc6b0a0edd47ad09afe4d" category="paragraph">Una vez que los archivos están en la ubicación del archive log, se pueden reproducir emitiendo el comando<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block> seguido de la respuesta<block ref="e1f2d5134ed2543d38a0de9751cf75d9" prefix=" " category="inline-code"></block> para reproducir automáticamente todos los logs disponibles. El archivo de parámetros está dirigiendo los archive logs al<block ref="e421a42fc6f604fcc78707336ed222b9" prefix=" " category="inline-code"></block>, Pero esto no coincide con la ubicación en la que se utilizó RMAN para guardar registros. La ubicación se puede redirigir temporalmente de la siguiente manera antes de recuperar la base de datos.</block>
  <block id="0a96a4559ad3ab8c616a12a207e8daca" category="paragraph">La respuesta final del archive log informa de un error, pero esto es normal. El error indica que sqlplus estaba buscando un archivo log en particular y no lo encontró. La razón es más probable que el archivo log no exista aún.</block>
  <block id="e2a234d3299b9e66f0756db00c9ee8c7" category="paragraph">En la mayoría de los casos, la migración no se realiza de forma inmediata. Pueden pasar días o incluso semanas antes de que se complete el proceso de migración, lo que significa que los registros deben enviarse continuamente a la base de datos de réplica y reproducirse. Al hacerlo, se garantiza que se deban transferir y reproducir unos datos mínimos al llegar la transición.</block>
  <block id="247e1695519da78866726a4dcb2c5252" category="paragraph">Este proceso se puede programar fácilmente. Por ejemplo, el siguiente comando se puede programar en la base de datos original para asegurarse de que la ubicación utilizada para el envío de registros se actualiza continuamente.</block>
  <block id="3ce19ecb7c874f75b9a46e29abe2012e" category="inline-link-macro">Logs de Reproducción en Base de Datos en Espera</block>
  <block id="469d3082a0f3ad08223ba8fe69bf9311" category="paragraph">Una vez recibidos los registros, deben reproducirse. Ejemplos anteriores mostraron el uso de sqlplus para ejecutar manualmente<block ref="5fea768eb2d353716ca623ae58ce382c" prefix=" " category="inline-code"></block>, que se puede automatizar fácilmente. El ejemplo que se muestra aquí utiliza el script descrito en <block ref="7c7730292e0135c86626e1771f7f02ec" category="inline-link-macro-rx"></block>. El script acepta un argumento que especifica la base de datos que necesita una operación de reproducción. Este proceso permite utilizar el mismo script en un esfuerzo de migración de varias bases de datos.</block>
  <block id="15d3442f7626bb62f4b255c7ed5c5098" category="paragraph">Cuando esté listo para pasar al nuevo entorno, debe realizar una sincronización final. Cuando se trabaja con sistemas de archivos normales, es fácil asegurarse de que la base de datos migrada esté sincronizada al 100% con la original, ya que los redo logs originales se copian y se vuelven a reproducir. No hay una buena forma de hacerlo con ASM. Sólo los archive logs se pueden volver a copiar fácilmente. Para asegurarse de que no se pierden datos, el cierre final de la base de datos original debe realizarse con cuidado.</block>
  <block id="f9952f2469fbec5fc9dca180322ff9ee" category="list-text">En primer lugar, la base de datos debe estar en modo inactivo, asegurándose de que no se realicen cambios. Esta desactivación puede incluir la desactivación de las operaciones programadas, el cierre de listeners y/o el cierre de aplicaciones.</block>
  <block id="58fd1c52efcde7151ac264a8f67b14ff" category="list-text">Después de realizar este paso, la mayoría de los DBA crean una tabla ficticia que sirve como marcador del cierre.</block>
  <block id="442da9ab2cced82a6cbdd112be285bcf" category="list-text">Forzar un archivo log para asegurarse de que la creación de la tabla ficticia se registra en los archive logs. Para ello, ejecute los siguientes comandos:</block>
  <block id="83fce8a41250d6af49205f9659468351" category="list-text">Para copiar el último de los archive logs, ejecute los siguientes comandos. La base de datos debe estar disponible pero no abierta.</block>
  <block id="1b0e887c1394d4617c2a5243da19e44e" category="list-text">Para copiar los archive logs, ejecute los siguientes comandos:</block>
  <block id="86a7e05acb17098c514dd570b9220302" category="list-text">Por último, vuelva a reproducir los archive logs restantes en el nuevo servidor.</block>
  <block id="a430882deb5403e7b4b8061dec17cc80" category="list-text">En esta fase, replique todos los datos. La base de datos está lista para convertirse de una base de datos en espera a una base de datos operativa activa y, a continuación, abrirse.</block>
  <block id="077c7bcbf9a94bb62aecadc85045886e" category="list-text">Confirme la presencia de la tabla ficticia y, a continuación, suéltela.</block>
  <block id="6130a27b8ec8ccf18e06bb3389b0fbbd" category="section-title">Migración de redo log no disruptiva</block>
  <block id="26c294f993888218237d5f9306bfcfc4" category="paragraph">Hay veces en las que una base de datos está correctamente organizada en general con la excepción de los redo logs. Esto puede ocurrir por muchos motivos, el más común de los cuales está relacionado con las copias Snapshot. Productos como SnapManager para Oracle, SnapCenter y el marco de gestión de almacenamiento Snap Creator de NetApp permiten la recuperación casi instantánea de una base de datos, pero únicamente si revierte el estado de los volúmenes de archivos de datos. Si los redo logs comparten espacio con los archivos de datos, la reversión no se puede realizar de forma segura porque podría provocar la destrucción de los redo logs, lo que probablemente significa pérdida de datos. Por lo tanto, los redo logs deben reubicarse.</block>
  <block id="2c56f5081b94b926c93c40f4c935a44a" category="paragraph">Este procedimiento es sencillo y puede realizarse sin interrupciones.</block>
  <block id="2986f9fe7ed4aab5aaa64c2ee9fe4841" category="section-title">Configuración actual de redo log</block>
  <block id="dd786d22c88a5f1fe0c10cfec58c1b44" category="list-text">Identifique el Núm. De grupos de redo logs y sus respectivos Núm.s de grupo.</block>
  <block id="3cd0f7a32a4f5ee026702f8125f3dda7" category="list-text">Introduzca el tamaño de los redo logs.</block>
  <block id="7c2f6ada37d59f2be0bc1a3ead80f77c" category="section-title">Crear nuevos logs</block>
  <block id="106b215e5d87fb1256e47932f2ebf9cf" category="list-text">Para cada redo log, cree un nuevo grupo con un tamaño y un Núm. De miembros coincidentes.</block>
  <block id="0851b65f20b98420968e488fc3c0085e" category="list-text">Verifique la nueva configuración.</block>
  <block id="cbccec9e0905e0b7f5cd630a3fa12f64" category="section-title">Borre los registros antiguos</block>
  <block id="00f63618719701ddae7fc2ff1d406ec2" category="list-text">Borre los registros antiguos (grupos 1, 2 y 3).</block>
  <block id="f00c8361a8acc818247282bb6420a8c1" category="list-text">Si encuentra un error que le impide borrar un log activo, fuerce un cambio al siguiente log para liberar el bloqueo y forzar un punto de control global. Vea el siguiente ejemplo de este proceso. Se ha denegado el intento de borrar el grupo de archivos de registro 2, que se encontraba en la ubicación anterior, porque todavía había datos activos en este archivo de registro.</block>
  <block id="5d49a93437a42d2926c8be7eb3c7a56f" category="list-text">Un archivo log seguido de un punto de control permite borrar el archivo log.</block>
  <block id="e3898c187d7edf64fc8e4d4e409fd244" category="list-text">A continuación, elimine los registros del sistema de archivos. Debe realizar este proceso con extremo cuidado.</block>
  <block id="dacc2a633e9981c9f91e43ac6b59e889" category="paragraph">La migración de datos de Oracle puede producirse en uno de tres niveles: La base de datos, el host o la cabina de almacenamiento.</block>
  <block id="5153193d50d4c628312db2d5bc0132ed" category="paragraph">Las diferencias residen en qué componente de la solución general es responsable del movimiento de datos: La base de datos, el sistema operativo del host o el sistema de almacenamiento.</block>
  <block id="cc3e73ae592a355b9beb405232d08fe2" category="paragraph">La siguiente figura muestra un ejemplo de los niveles de migración y el flujo de datos. En el caso de la migración a nivel de base de datos, los datos se mueven desde el sistema de almacenamiento original a través de las capas de base de datos y host al nuevo entorno. La migración al nivel de host es similar, pero los datos no pasan a través de la capa de aplicaciones y, en su lugar, se escriben en la nueva ubicación mediante procesos de host. Por último, con la migración a nivel del almacenamiento, una cabina como un sistema NetApp FAS es responsable del movimiento de datos.</block>
  <block id="204415652114bfb773b51cd76c8c692e" category="paragraph"><block ref="204415652114bfb773b51cd76c8c692e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b059e0e23ffaa8fbd97f681942ce0018" category="paragraph">Una migración a nivel de base de datos generalmente hace referencia al uso del envío de logs de Oracle a través de una base de datos en espera para completar una migración en la capa de Oracle. Las migraciones a nivel de host se realizan utilizando la capacidad nativa de la configuración del sistema operativo host. Esta configuración incluye operaciones de copia de archivos mediante comandos como cp, tar y Oracle Recovery Manager (RMAN) o mediante un gestor de volúmenes lógicos (LVM) para reubicar los bytes subyacentes de un sistema de archivos. Oracle Automatic Storage Management (ASM) se clasifica como una capacidad de nivel de host porque se ejecuta por debajo del nivel de la aplicación de base de datos. ASM sustituye al administrador de volúmenes lógicos habitual en un host. Por último, los datos pueden migrarse a nivel de cabina de almacenamiento, lo cual significa que se encuentra debajo del nivel del sistema operativo.</block>
  <block id="228d9e0418aa12bae73676a5743558db" category="section-title">Consideraciones DE PLANIFICACIÓN</block>
  <block id="ce7eea640cd6ee20e55cbe868f4026e9" category="paragraph">La mejor opción para la migración depende de una combinación de factores, como la escala del entorno que se va a migrar, la necesidad de evitar el tiempo de inactividad y el esfuerzo general requerido para realizar la migración. Obviamente, las bases de datos grandes requieren más tiempo y esfuerzo para la migración, pero la complejidad de estas migraciones es mínima. Las bases de datos pequeñas se pueden migrar rápidamente, pero, si hay miles que migrar, la escala del esfuerzo puede crear complicaciones. Por último, cuanto mayor sea la base de datos, más probabilidades hay de que sea crítica para el negocio, lo cual da lugar a la necesidad de minimizar los tiempos de inactividad a la vez que se conserva una ruta de back-out.</block>
  <block id="d4b9b19593598d98059aae44d6a7bbe1" category="paragraph">Aquí se tratan algunas de las consideraciones para planificar una estrategia de migración.</block>
  <block id="931c6f2c99380fbd899e3eaa31e97d98" category="section-title">Tamaño de datos</block>
  <block id="64e4d570abeebacf6bdcb19dfb73fcae" category="paragraph">Los tamaños de las bases de datos que se migrarán afectan obviamente a la planificación de la migración, aunque el tamaño no afecta necesariamente al tiempo de transición. Cuando es necesario migrar una gran cantidad de datos, la principal cuestión es el ancho de banda. Las operaciones de copia suelen realizarse con I/O secuenciales eficientes Según estimaciones conservadoras, asuma el aprovechamiento del 50% del ancho de banda de red disponible para operaciones de copia. Por ejemplo, un puerto FC de 8GB Gb puede transferir aproximadamente 800Mbps Gb en teoría. Suponiendo una utilización del 50%, se puede copiar una base de datos a una velocidad de aproximadamente 400Mbps KB. Por lo tanto, una base de datos de 10TB TB se puede copiar en unas siete horas a esta velocidad.</block>
  <block id="84a80a048e7abc027dd6bdce55fda9d2" category="inline-link-macro">Movimiento de archivos de datos en línea</block>
  <block id="1c169b76761527b28040655a783e50a2" category="section-title">Recuento de bases de datos</block>
  <block id="da3770c5d6d1215e9f2524b9d7b7c3c5" category="paragraph">En muchos casos, el problema de mover una gran cantidad de datos no es el tamaño de los datos, sino la complejidad de la configuración que soporta la base de datos. No basta con saber que deben migrarse 50TB TB de bases de datos. Podría ser una única base de datos de misión crítica de 50TB TB, una colección de 4, 000 bases de datos heredadas o una combinación de datos de producción y no de producción. En algunos casos, gran parte de los datos se componen de clones de una base de datos de origen. Estos clones no tienen que migrarse de ninguna manera, ya que pueden volver a crearse fácilmente, especialmente cuando la nueva arquitectura está diseñada para aprovechar los volúmenes FlexClone de NetApp.</block>
  <block id="a1739e745a7544d2432b2b990a715817" category="paragraph">Para la planificación de la migración, hay que entender cuántas bases de datos están incluidas y cómo deben priorizarse. A medida que aumenta el número de bases de datos, la opción de migración preferida tiende a ser más baja y más baja en la pila. Por ejemplo, la copia de una única base de datos se puede realizar fácilmente con RMAN y una interrupción breve. Es la replicación a nivel de host.</block>
  <block id="284723d6a05b50ace5e5b96c761d03ac" category="paragraph">Si hay bases de datos 50, es posible que sea más fácil evitar configurar una nueva estructura del sistema de archivos para recibir una copia de RMAN y, en su lugar, mover los datos. Este proceso puede realizarse aprovechando la migración de LVM basada en host para reubicar datos de las LUN antiguas a nuevas LUN. De este modo, se traslada la responsabilidad del equipo del administrador de la base de datos (DBA) al equipo del sistema operativo y, como resultado, los datos se migran de forma transparente con respecto a la base de datos. La configuración del sistema de archivos no cambia.</block>
  <block id="8e734da04d394519001f47f723341e9d" category="paragraph">Por último, si es necesario migrar 500 bases de datos en 200 servidores, pueden utilizarse opciones basadas en almacenamiento como la funcionalidad Importación de LUN externas (FLI) de ONTAP para realizar una migración directa de las LUN.</block>
  <block id="39f43935349622951e0f392c83b6e736" category="section-title">Vuelva a crear los requisitos de la arquitectura</block>
  <block id="50f1558a3f9d47464b5d57f9d9d0f9d1" category="paragraph">Normalmente, el diseño de un archivo de base de datos debe modificarse para aprovechar las funciones de la nueva cabina de almacenamiento; sin embargo, esto no siempre es así. Por ejemplo, las funciones de las cabinas all-flash EF-Series se dirigen principalmente al rendimiento SAN y la fiabilidad de SAN. En la mayoría de los casos, las bases de datos pueden migrarse a una cabina EF-Series sin tener en cuenta ninguna necesidad de distribución de los datos. Los únicos requisitos son el alto nivel de IOPS, la baja latencia y la sólida fiabilidad. Aunque existen prácticas recomendadas en relación con factores como la configuración de RAID o los pools de discos dinámicos, los proyectos EF-Series rara vez requieren cambios significativos en la arquitectura general de almacenamiento para aprovechar estas funciones.</block>
  <block id="0e2c78f7e9948e19ccb1bf2e1b7f0faf" category="paragraph">Por el contrario, la migración a ONTAP generalmente requiere tener en cuenta el diseño de la base de datos para asegurarse de que la configuración final aporta el máximo valor. Por sí mismo, ONTAP ofrece muchas funciones para un entorno de base de datos, incluso sin ningún esfuerzo de arquitectura específico. Y lo que es más importante, ofrece la capacidad de migrar sin interrupciones a un nuevo hardware cuando el hardware actual llega al final de su vida útil. En términos generales, una migración a ONTAP es la última migración que se debería realizar. Se actualiza el hardware subsiguiente in situ y los datos se migran a los nuevos medios de forma no disruptiva.</block>
  <block id="ad93bd21d59f2286385dc519fd7e39fb" category="paragraph">Con un poco de planificación, aún hay más beneficios disponibles. Las consideraciones más importantes rodean el uso de instantáneas. Las copias Snapshot son la base para realizar backups, restauraciones de datos y operaciones de clonado casi instantáneas. Como ejemplo del potencial de las copias Snapshot, el uso más grande conocido es con una única base de datos de 996TB TB que se ejecuta en unas 250 LUN en 6 controladoras. Puede realizarse backup de esta base de datos en 2 minutos, restaurarse en 2 minutos y clonarse en 15 minutos. Entre otras ventajas, se incluyen la capacidad de mover datos por el clúster en respuesta a los cambios en la carga de trabajo y la aplicación de controles de calidad de servicio para proporcionar un buen rendimiento constante en un entorno multibase de datos.</block>
  <block id="6b48ce64da84423ce167ffb72f5f9a8b" category="inline-link-macro">Descripción general de los procedimientos de migración de Oracle</block>
  <block id="1311d3b592e4da5950e91965dac1d593" category="paragraph">Tecnologías como los controles de calidad de servicio, la reubicación de datos, las snapshots y el clonado funcionan en prácticamente cualquier configuración. Sin embargo, generalmente se requiere algo de pensamiento para maximizar los beneficios. En algunos casos, la distribución del almacenamiento de la base de datos puede requerir cambios en el diseño para maximizar la inversión en la nueva cabina de almacenamiento. Estos cambios de diseño pueden afectar a la estrategia de migración, ya que las migraciones basadas en host o basadas en almacenamiento replican la distribución de datos original. Podrían ser necesarios pasos adicionales para completar la migración y ofrecer una distribución de datos optimizada para ONTAP. Los procedimientos que se muestran en la <block ref="d4d5600aaaced44e203002ec1910822d" category="inline-link-macro-rx"></block> y más tarde, mostrar algunos de los métodos no solo para migrar una base de datos, sino para migrarla al diseño final óptimo con el mínimo esfuerzo.</block>
  <block id="1fd9b0a8321228b5b8ad4be85e71cf64" category="section-title">Tiempo de transición</block>
  <block id="95b9194d9f06f6f70febc87c071f3050" category="paragraph">Se debe determinar la interrupción máxima permitida del servicio durante la transición. Es un error común asumir que todo el proceso de migración provoca interrupciones. Muchas tareas pueden completarse antes de que comience cualquier interrupción del servicio y muchas opciones permiten completar la migración sin interrupciones ni interrupciones del servicio. Incluso cuando resulte imposible evitar las interrupciones, debe definir la interrupción del servicio máxima permitida, puesto que la duración del tiempo de transición varía de un procedimiento a otro.</block>
  <block id="9cfeaf56d2fc41c2695a69adf260c3f8" category="section-title">Ruta de retroceso</block>
  <block id="f493e16f7e2caba820eba88a1c5f82d8" category="paragraph">Ninguna migración está completamente exenta de riesgos. Incluso si la tecnología funciona perfectamente, siempre existe la posibilidad de error del usuario. El riesgo asociado a una ruta de migración elegida debe tenerse en cuenta junto con las consecuencias de una migración fallida. Por ejemplo, la capacidad transparente de migración de almacenamiento en línea de Oracle ASM es una de sus funciones clave, y este método es una de las más fiables conocidas. Sin embargo, los datos se copian de forma irreversible con este método. En el caso muy poco probable de que se produzca un problema con ASM, no hay una ruta de salida fácil. La única opción es restaurar el entorno original o utilizar ASM para revertir la migración de nuevo a las LUN originales. El riesgo puede minimizarse, pero no eliminarse, realizando un backup del tipo snapshot en el sistema de almacenamiento original, asumiendo que el sistema sea capaz de realizar dicha operación.</block>
  <block id="1886f1ab01daa4511ce537d1af675427" category="section-title">Ensayo</block>
  <block id="dd5dac65febd7071311b1ae3be1eca90" category="paragraph">Algunos procedimientos de migración deben verificarse por completo antes de la ejecución. La necesidad de migración y ensayo del proceso de transición es una solicitud común con bases de datos críticas para la misión para la que la migración debe tener éxito y se debe minimizar el tiempo de inactividad. Además, las pruebas de aceptación del usuario se incluyen con frecuencia como parte del trabajo posterior a la migración y el sistema en general solo puede volver a la producción una vez que se hayan completado estas pruebas.</block>
  <block id="7d06b32cdd06d27f7c62fb110d831e60" category="paragraph">Si hay una necesidad de ensayo, varias capacidades de ONTAP pueden hacer el proceso mucho más fácil. En particular, las copias Snapshot pueden restablecer un entorno de prueba y crear rápidamente varias copias con gestión eficiente del espacio de un entorno de base de datos.</block>
  <block id="440a667261bd94f099ef4dde5caf024f" category="summary">Migrando archivos de datos de Oracle individuales</block>
  <block id="727bb4db430517995ca651c4f57b0c9f" category="doc">Movimiento del archivo de datos</block>
  <block id="fade70b277397e039e100bf0faa98d8e" category="paragraph">Los archivos de datos de Oracle individuales se pueden mover con un solo comando.</block>
  <block id="50c3d56e93d52f122bab9de1f2b35780" category="paragraph">Por ejemplo, el siguiente comando mueve el archivo de datos IOPST.dbf del sistema de archivos<block ref="87941c54be03c9785752ea54ac9a2dd4" prefix=" " category="inline-code"></block> al sistema de archivos<block ref="eff8b2f7c4da1cf002bdea257a43fd10" prefix=" " category="inline-code"></block>.</block>
  <block id="53784088a62519d581c3dac4640c41b5" category="paragraph">Mover un archivo de datos con este método puede ser lento, pero normalmente no debería producir suficientes E/S que interfiera con las cargas de trabajo diarias de la base de datos. Por el contrario, la migración a través del reequilibrio de ASM puede ejecutarse mucho más rápido, pero a costa de ralentizar la base de datos general mientras se mueven los datos.</block>
  <block id="f92065612dfd409585ca08d95cc7a4dc" category="paragraph">El tiempo necesario para mover archivos de datos se puede medir fácilmente creando un archivo de datos de prueba y moviéndolo después. El tiempo transcurrido para la operación se registra en los datos de v$session:</block>
  <block id="78fb69ccdf01155db62828d0bc182b84" category="paragraph">En este ejemplo, el archivo que se movió era el archivo de datos 8, que tenía un tamaño de 21GB GB y requería unos 6 minutos para migrar. El tiempo necesario depende obviamente de las funcionalidades del sistema de almacenamiento, la red de almacenamiento y la actividad general de las bases de datos que se produzca en el momento de la migración.</block>
  <block id="593b763e01de37a327966ee1abb3f8a2" category="summary">Migración de Oracle mediante la pila de almacenamiento del host</block>
  <block id="3dc2d5f8d7209bb75e8d67aed68bc5ed" category="paragraph">Al igual que sucede con la migración a nivel de base de datos, la migración en la capa de host proporciona un enfoque independiente del proveedor de almacenamiento.</block>
  <block id="1686ceaaa0d8fb4f9a8adb5e717b029c" category="paragraph">En otras palabras, en algún momento “solo copiar los archivos” es la mejor opción.</block>
  <block id="d5732a4ab4c633ceb871cebdbf9ae34f" category="paragraph">Aunque este enfoque de baja tecnología puede parecer demasiado básico, ofrece beneficios significativos porque no se requiere ningún software especial y los datos originales permanecen intactos de forma segura durante el proceso. La principal limitación es el hecho de que una migración de datos de copia de archivos es un proceso disruptivo, ya que la base de datos debe cerrarse antes de que comience la operación de copia. No hay una buena manera de sincronizar los cambios dentro de un archivo, por lo que los archivos deben estar completamente desactivados antes de que comience la copia.</block>
  <block id="706e7514bb30a289d7ce786a1a5c2ca0" category="paragraph">Si el cierre necesario para una operación de copia no es deseable, la siguiente mejor opción basada en host es utilizar un gestor de volúmenes lógicos (LVM). Existen muchas opciones de LVM, incluido Oracle ASM, todas con capacidades similares, pero también con algunas limitaciones que deben tenerse en cuenta. En la mayoría de los casos, la migración se puede realizar sin tiempos de inactividad ni interrupciones.</block>
  <block id="f58e97ac8406ca3e8f0bb7a019a81985" category="section-title">Copiando sistema de archivos al sistema de archivos</block>
  <block id="a08ab728e75c63a41ce7571cb781cda2" category="paragraph">La utilidad de una operación de copia simple no debe subestimarse. Esta operación requiere un tiempo de inactividad durante el proceso de copia, pero es un proceso muy fiable y no requiere experiencia especial en sistemas operativos, bases de datos o sistemas de almacenamiento. Además, es muy seguro porque no afecta a los datos originales. Normalmente, un administrador de sistemas cambia los sistemas de archivos de origen para montarse como de solo lectura y luego reinicia un servidor para garantizar que nada pueda dañar los datos actuales. El proceso de copia se puede programar para asegurarse de que se ejecuta lo más rápido posible sin riesgo de error por parte del usuario. Dado que el tipo de I/O es una transferencia secuencial simple de datos, es altamente eficiente del ancho de banda.</block>
  <block id="ba0bd93801872993ce832352dd03b56a" category="paragraph">El siguiente ejemplo muestra una opción para una migración segura y rápida.</block>
  <block id="d8cb8bcd239bbe7a2a488c1d68dbe420" category="paragraph">El entorno que se va a migrar es el siguiente:</block>
  <block id="3ffbdefc66ad1d1e707c1d6820afbdc0" category="list-text">Sistemas de archivos actuales</block>
  <block id="bdc9e98c6b17bb14a7bce916054413ba" category="list-text">Sistemas de archivos nuevos</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="section-title">Descripción general</block>
  <block id="e76912cd513cc8cbcabc2735b524e814" category="paragraph">El DBA puede migrar la base de datos simplemente cerrando la base de datos y copiando los archivos, pero el proceso se ejecuta fácilmente en la secuencia de comandos si se deben migrar muchas bases de datos o si se minimiza el tiempo de inactividad es crítico. El uso de scripts también reduce la posibilidad de errores de los usuarios.</block>
  <block id="d21aae9692f3b1d4e53fd73131414b93" category="paragraph">Los scripts de ejemplo que se muestran automatizan las siguientes operaciones:</block>
  <block id="66909ae9d06bad444f5a059b8ee2cd41" category="list-text">Cerrando la base de datos</block>
  <block id="ae737f3f8c04ccbefa99b2bbf87dccc2" category="list-text">Convertir los sistemas de archivos existentes a un estado de sólo lectura</block>
  <block id="1dd90b7b28cbd03687df6538c66ff494" category="list-text">Copia de todos los datos de los sistemas de archivos de origen a los de destino, lo que conserva todos los permisos de archivos</block>
  <block id="741341be7809d7f5765b2352e6ab0aab" category="list-text">Desmontaje de los sistemas de archivos antiguos y nuevos</block>
  <block id="7465bc030ca3fe236bcf3ecdf8aaebe4" category="list-text">Volver a montar los nuevos sistemas de archivos en las mismas rutas que los sistemas de archivos anteriores</block>
  <block id="8c4271e6faf2cea4cfc8e5b7108d8ee9" category="section-title">Procedimiento</block>
  <block id="b273f8d4284bd1f58cfbafe8065af9fa" category="list-text">Cierre la base de datos.</block>
  <block id="67eadd4b70772835f318e6d3027e4308" category="inline-link-macro">Convertir sistema de archivos a Sólo lectura</block>
  <block id="474aae6515223cc3ba71074c9d5abcae" category="list-text">Convierta los sistemas de archivos a sólo lectura. Esto se puede hacer más rápidamente usando un script, como se muestra en <block ref="2d6e37849c641071fe1cf71ac348d28c" category="inline-link-macro-rx"></block>.</block>
  <block id="4879ec77723fce4974f8ae2a7f87121a" category="list-text">Confirme que los sistemas de archivos ahora son de sólo lectura.</block>
  <block id="c91e7f5dba3c873d0978f4892bf8b3f2" category="list-text">Sincronice el contenido del sistema de archivos con<block ref="89a4551b0f29c1a652648b1cb8747021" prefix=" " category="inline-code"></block> comando.</block>
  <block id="91e702884985853b8a7091ed5f2beceb" category="inline-link-macro">Reemplazar sistema de archivos</block>
  <block id="ea27cab9fe7b891870e0ce59aa34e853" category="list-text">Desmonte los sistemas de archivos antiguos y reubique los datos copiados. Esto se puede hacer más rápidamente usando un script, como se muestra en <block ref="fa3b775593af4f3de8972aced258710d" category="inline-link-macro-rx"></block>.</block>
  <block id="5fe2431acb45422c46eadf66a93851af" category="list-text">Confirme que los nuevos sistemas de archivos están en posición.</block>
  <block id="2d53403ab873059f92ad884eb271e8dc" category="list-text">Inicie la base de datos.</block>
  <block id="40351c33ab81b8b374a20fd292057481" category="section-title">Transición totalmente automatizada</block>
  <block id="3f70361470a11fb351c83257cd7aa63e" category="paragraph">Este script de ejemplo acepta argumentos del SID de la base de datos seguidos de pares de sistemas de archivos delimitados comúnmente. Para el ejemplo mostrado anteriormente, el comando se emite del siguiente modo:</block>
  <block id="5cddd7b314b7ae819e2cfcac85021426" category="paragraph">Cuando se ejecuta, el script de ejemplo intenta realizar la siguiente secuencia. Termina si encuentra un error en cualquier paso:</block>
  <block id="43d4fce7952ee09c0c8df60a17f5ea56" category="list-text">Convierta los sistemas de archivos actuales al estado de sólo lectura.</block>
  <block id="9d53d62d1e6dc69460f47c83e6c1919d" category="list-text">Utilice cada par delimitado por comas de argumentos del sistema de archivos y sincronice el primer sistema de archivos con el segundo.</block>
  <block id="39ff0e6dfa9915344ec96f9e78a27267" category="list-text">Desmonte los sistemas de archivos anteriores.</block>
  <block id="e220fa2a2806386a64e9860f27372e43" category="list-text">Actualice el<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> el archivo es el siguiente:</block>
  <block id="232c2c4ddd45fc028ae13b58251c5f7e" category="list-text">Cree un backup en<block ref="9eb56e72a6bb8350a1453c2762d14178" prefix=" " category="inline-code"></block>.</block>
  <block id="d5082ae73767550813688202df21bc4d" category="list-text">Comente las entradas anteriores de los sistemas de archivos anteriores y nuevos.</block>
  <block id="b8793b424d1738f1e00e545379867b0d" category="list-text">Cree una nueva entrada para el nuevo sistema de archivos que utilice el antiguo punto de montaje.</block>
  <block id="29478980f354caa483bc0cfb827c7251" category="list-text">Monte los sistemas de archivos.</block>
  <block id="a0ec0d8bede7d9d58172084de7d5ce53" category="paragraph">El siguiente texto proporciona un ejemplo de ejecución para este script:</block>
  <block id="350265a378d2cb1183cd51d56f0e5843" category="section-title">Migración de Oracle ASM spfile y passwd</block>
  <block id="f37bc722651f2fd86ba4da87f947c4db" category="paragraph">Una dificultad para completar la migración que implica ASM es el spfile específico de ASM y el archivo de contraseñas. Por defecto, estos archivos de metadatos críticos se crean en el primer grupo de discos de ASM definido. Si se debe evacuar y eliminar un grupo de discos de ASM concreto, se debe reubicar el archivo spfile y de contraseñas que rigen dicha instancia de ASM.</block>
  <block id="88e2a97e52f9854b59ce63e74c4b0cac" category="paragraph">Otro caso de uso en el que es posible que sea necesario reubicar estos archivos es durante un despliegue de software de gestión de base de datos como SnapManager para Oracle o el complemento de Oracle de SnapCenter. Una de las características de estos productos es restaurar rápidamente una base de datos mediante la reversión del estado de las LUN de ASM que alojan los archivos de datos. Para hacerlo, es necesario desconectar el grupo de discos de ASM antes de realizar una restauración. Esto no es un problema siempre que los archivos de datos de una base de datos determinada estén aislados en un grupo de discos de ASM dedicado.</block>
  <block id="24de04443b6bdae76336fcab04ae946c" category="paragraph">Cuando ese grupo de discos también contiene el archivo spfile/passwd de ASM, la única forma en que el grupo de discos se puede poner fuera de línea es cerrar toda la instancia de ASM. Este es un proceso disruptivo, lo que significa que el archivo spfile/passwd tendría que ser reubicado.</block>
  <block id="a6221bf4332cc966c69066295a843480" category="list-text">SID de base de datos = TOAST</block>
  <block id="0af0da2831407b8130e7f2fabdfab87d" category="list-text">Archivos de datos actuales en<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block></block>
  <block id="24aa2824a0b52b46b301afdb3af9336f" category="list-text">Archivos log y archivos de control actuales en<block ref="ad6062251d172504e3b3bed3a8256a5a" prefix=" " category="inline-code"></block></block>
  <block id="bb6de9ea84381f7d01fdd038f104e4ae" category="list-text">Se han establecido nuevos grupos de discos de ASM como<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block> y..<block ref="5e20ccf28224fc0cc564f9825c208dbd" prefix=" " category="inline-code"></block></block>
  <block id="8b14bd9d310bf8b211c19645576201e3" category="section-title">Ubicaciones de archivos spfile/passwd de ASM</block>
  <block id="7c7d8dd5d09a73f06678562b66dcdc68" category="paragraph">La reubicación de estos archivos puede realizarse de forma no disruptiva. Sin embargo, por motivos de seguridad, NetApp recomienda cerrar el entorno de la base de datos para que pueda estar seguro de que los archivos se han reubicado y que la configuración se ha actualizado correctamente. Este procedimiento se debe repetir si hay varias instancias de ASM presentes en un servidor.</block>
  <block id="3666b74ddcf77306328ac5d6db94fecd" category="section-title">Identificar instancias de ASM</block>
  <block id="9d19a85576af8e1b3dbd78e343a2b022" category="paragraph">Identifique las instancias de ASM en función de los datos registrados en la<block ref="9da4474b569071bcb2ece1d0bdfe7560" prefix=" " category="inline-code"></block> archivo. Las instancias de ASM se indican con un símbolo +.</block>
  <block id="3fe2dd8cf6f82ac15544fd96f9b59b28" category="paragraph">Hay una instancia de ASM denominada +ASM en este servidor.</block>
  <block id="35a557b0490d5a93931025eaaf712cac" category="section-title">Asegúrese de que todas las bases de datos están cerradas</block>
  <block id="e6b0819ae1eca7d408a097efc2fbf2cf" category="paragraph">El único proceso smon visible debe ser smon para la instancia de ASM en uso. La presencia de otro proceso smon indica que una base de datos todavía está en ejecución.</block>
  <block id="97639c779a60f010af01997e2363f4eb" category="paragraph">El único proceso smon es la propia instancia de ASM. Esto significa que no se ejecuta ninguna otra base de datos y es seguro continuar sin riesgo de interrumpir las operaciones de la base de datos.</block>
  <block id="a8d157790e55d19378ddbbdfeb675ef8" category="section-title">Localizar archivos</block>
  <block id="12d8c982eb4072e31ac4bfe375193160" category="paragraph">Identifique la ubicación actual del archivo spfile y de contraseña de ASM mediante<block ref="e258dbf5114b4df07f0d9e72deb386f2" prefix=" " category="inline-code"></block> y..<block ref="bb41cdf6c9bb75ee17856f938070f23d" prefix=" " category="inline-code"></block> comandos.</block>
  <block id="bebe64e9d0d4ae3d44b4dfb3583e0109" category="paragraph">Los archivos se encuentran en la base del<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> grupo de discos.</block>
  <block id="558f28628ba8ab4cb8420949524832d3" category="section-title">Copiar archivos</block>
  <block id="c0c2c850cb11c5bb52abbd55a9578e54" category="paragraph">Copie los archivos en el nuevo grupo de discos de ASM con<block ref="c0baea639672c84505e661b9e369c68a" prefix=" " category="inline-code"></block> y..<block ref="c7adee97d05083a7b65e4b6953045177" prefix=" " category="inline-code"></block> comandos. Si el nuevo grupo de discos se ha creado recientemente y está vacío actualmente, es posible que tenga que montarlo primero.</block>
  <block id="3ed2faf3e1299edd7d92d6c4064f1579" category="paragraph">Los archivos se han copiado ahora de<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> para<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block>.</block>
  <block id="1dba5fc559232a8dae45d9f88ed36030" category="section-title">Actualizar instancia de ASM</block>
  <block id="1fe2cc6cf436a4bcc6bdc41f947a416a" category="paragraph">La instancia de ASM debe actualizarse para reflejar el cambio de ubicación. La<block ref="c8b1affa9ec15d0c0e79347905e75d3e" prefix=" " category="inline-code"></block> y..<block ref="73fb08020d8535b4123a8968c596038c" prefix=" " category="inline-code"></block> Los comandos actualizan los metadatos de ASM necesarios para iniciar el grupo de discos de ASM.</block>
  <block id="626759f91a0458b0c068cce8a05a6468" category="section-title">Active ASM con archivos actualizados</block>
  <block id="69f08287c6faa04381e5a05f4087abe1" category="paragraph">En este punto, la instancia de ASM sigue utilizando las ubicaciones anteriores de estos archivos. La instancia se debe reiniciar para forzar una nueva lectura de los archivos desde sus nuevas ubicaciones y liberar bloqueos en los archivos anteriores.</block>
  <block id="5505cf0c514193b89221f1cef3004c58" category="section-title">Elimine los archivos de contraseña y spfile antiguos</block>
  <block id="8f2d3ac58be7a91f51d7ce9ffa04e397" category="paragraph">Si el procedimiento se ha realizado correctamente, los archivos anteriores ya no se bloquean y ahora se pueden eliminar.</block>
  <block id="cfca2b2eb0d694e70904ec82f5d1c34e" category="section-title">Copia de Oracle ASM en ASM</block>
  <block id="12632d520b8d9518b5622ac00dc764a8" category="paragraph">Oracle ASM es esencialmente un gestor de volúmenes combinado ligero y un sistema de archivos. Dado que el sistema de archivos no se puede ver fácilmente, se debe utilizar RMAN para realizar operaciones de copia. A pesar de que un proceso de migración basado en copias es seguro y sencillo, el resultado es cierto tipo de interrupciones. La interrupción puede minimizarse, pero no eliminarse por completo.</block>
  <block id="152106ebb2aaa94cc87657d353331189" category="paragraph">Si desea una migración no disruptiva de una base de datos basada en ASM, la mejor opción es aprovechar la capacidad de ASM para reequilibrar las extensiones de ASM a nuevos LUN y borrar los LUN antiguos. Hacerlo resulta generalmente seguro y no disruptivo para las operaciones, pero no ofrece ningún camino de retroceso. Si se encuentran problemas funcionales o de rendimiento, la única opción es volver a migrar los datos al origen.</block>
  <block id="81fe23a1ac3b2bb348e579b2c5b0f5d5" category="paragraph">Este riesgo puede evitarse copiando la base de datos a la nueva ubicación en lugar de mover los datos, de modo que los datos originales queden intactos. La base de datos se puede probar completamente en su nueva ubicación antes de comenzar a funcionar, y la base de datos original está disponible como opción de reserva si se encuentran problemas.</block>
  <block id="3028182db088e823770b3d02aa0eac9e" category="paragraph">Este procedimiento es una de las muchas opciones que implica RMAN. Está diseñado para permitir un proceso de dos pasos en el que se crea la copia de seguridad inicial y, a continuación, se sincroniza a través de la reproducción de log. Este proceso es deseable minimizar los tiempos de inactividad, ya que permite que la base de datos permanezca operativa y sirviendo datos durante la copia básica inicial.</block>
  <block id="634f50a6c6f112c46150a301d749dbcb" category="section-title">Copiar base de datos</block>
  <block id="5f0bd85dd65afab1472713e8e034fff7" category="paragraph">Oracle RMAN crea una copia de nivel 0 (completa) de la base de datos de origen ubicada actualmente en el grupo de discos de ASM<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> a la nueva ubicación en<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block>.</block>
  <block id="b51dc519efad4b151a05682b68f4b182" category="section-title">Forzar el cambio de archive log</block>
  <block id="10793485747151dfa2eaddb0854c84b2" category="paragraph">Debe forzar un cambio de archive log para asegurarse de que los archive logs contienen todos los datos necesarios para que la copia sea totalmente coherente. Sin este comando, es posible que los datos clave sigan presentes en los redo logs.</block>
  <block id="c55a88a6b8fdc5972d4e2a4924f93dbf" category="section-title">Cierre la base de datos de origen</block>
  <block id="9ec82bff06c706f42a8170befdd6cf39" category="paragraph">La interrupción comienza en este paso porque la base de datos se cierra y se coloca en un modo de solo lectura de acceso limitado. Para cerrar la base de datos de origen, ejecute los siguientes comandos:</block>
  <block id="6ecf02e1343e82cf0cd95d7303346ff1" category="section-title">Backup de CONTROLFILE</block>
  <block id="e7bc82f6d1381df55ace121dc02368e6" category="paragraph">Debe realizar una copia de seguridad del archivo de control en caso de que deba anular la migración y volver a la ubicación de almacenamiento original. Una copia del archivo de control de copia de seguridad no es 100% necesaria, pero hace que el proceso de restablecer las ubicaciones de los archivos de base de datos a la ubicación original sea más fácil.</block>
  <block id="4e7a51f2c1ee60c69cd719d415f5e87a" category="paragraph">El spfile actual contiene referencias a los archivos de control en sus ubicaciones actuales dentro del antiguo grupo de discos de ASM. Debe editarse, lo cual se hace fácilmente editando una versión pfile intermedia.</block>
  <block id="253e30479f86461bc79f2fca58ee4cb1" category="section-title">Actualizar archivo pfile</block>
  <block id="35db8a54b9c7581f0f77b059233cc61b" category="paragraph">Actualice los parámetros que hagan referencia a los grupos de discos de ASM antiguos para reflejar los nuevos nombres de grupos de discos de ASM. A continuación, guarde el archivo pfile actualizado. Compruebe que la<block ref="5fa1d01559c04dcdb3ba05775712b1ab" prefix=" " category="inline-code"></block> los parámetros están presentes.</block>
  <block id="bb607fbd46f48c3a4080ecda83288b69" category="paragraph">En el ejemplo siguiente, las referencias a.<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> eso fue cambiado a.<block ref="cb2eb5386826561ac7895f1c878e4252" prefix=" " category="inline-code"></block> se resaltan en amarillo. Dos parámetros clave son el<block ref="5fa1d01559c04dcdb3ba05775712b1ab" prefix=" " category="inline-code"></block> parámetros que crean cualquier archivo nuevo en la ubicación correcta.</block>
  <block id="5275e85db4d606621d8f074e44b95748" category="section-title">Actualice el archivo init.ora</block>
  <block id="17a2b5d1af48f7f8d1511d5372896f7a" category="paragraph">La mayoría de las bases de datos basadas en ASM utilizan un<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> archivo ubicado en la<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> Directorio, que es un punto a spfile en el grupo de discos de ASM. Este archivo se debe redirigir a una ubicación en el nuevo grupo de discos de ASM.</block>
  <block id="6ad274256421918b584abff3b9446b09" category="paragraph">Cambie este archivo de la siguiente manera:</block>
  <block id="b6638505615764c377e2cf2585993fd0" category="section-title">Recreación del archivo de parámetros</block>
  <block id="52b21c2e6103a3b8d888a4185e21a787" category="paragraph">El archivo spfile ya está listo para ser rellenado por los datos del archivo pfile editado.</block>
  <block id="37f4738eddd35e77d15af55a40e1ab1c" category="section-title">Inicie la base de datos para empezar a utilizar el nuevo spfile</block>
  <block id="79f8a930424fe3b21dc30a72791171d4" category="paragraph">Inicie la base de datos para asegurarse de que ahora utiliza el spfile recién creado y de que cualquier otro cambio en los parámetros del sistema se registra correctamente.</block>
  <block id="231ef0ea12d142611eeea2fdfad67114" category="section-title">Restaure el archivo de control</block>
  <block id="33cdbbeabc7f2c647f20b3f8b924307f" category="paragraph">RMAN también puede restaurar el archivo de control de copia de seguridad creado por RMAN directamente en la ubicación especificada en el nuevo spfile.</block>
  <block id="ce656b7f351ebdc7c599aff6a99e0f2a" category="paragraph">Monte la base de datos y verifique el uso del nuevo archivo de control.</block>
  <block id="fda1e79fe400519496075b7e2871092a" category="section-title">Reproducción de registro</block>
  <block id="daaec4441f16b5bac11476d4582a296c" category="paragraph">La base de datos utiliza actualmente los archivos de datos en la ubicación antigua. Antes de poder utilizar la copia, deben sincronizarse. Ha transcurrido tiempo durante el proceso de copia inicial y los cambios se han registrado principalmente en los archive logs. Estos cambios se replican de la siguiente manera:</block>
  <block id="fca6726270a94f51cab3142509d32919" category="list-text">Realice una copia de seguridad incremental de RMAN, que contiene los archive logs.</block>
  <block id="8b8a5667b011b5f37163ff4da1004343" category="list-text">Vuelva a reproducir el log.</block>
  <block id="a9a62e70841c4d06dd16306a85700d36" category="section-title">Activación</block>
  <block id="8fecb0145484a35b1d9d5926c945ca30" category="paragraph">El archivo de control que se restauró sigue haciendo referencia a los archivos de datos en la ubicación original y también contiene la información de ruta de acceso para los archivos de datos copiados.</block>
  <block id="f590db5fdc10f6942f7cd173c0bb578b" category="list-text">Para cambiar los archivos de datos activos, ejecute el<block ref="7705ebb59373d0b1dfc71d86ef726f93" prefix=" " category="inline-code"></block> comando.</block>
  <block id="2c5c2b5174eafe321358329636e80f5e" category="paragraph">Los archivos de datos activos son ahora los archivos de datos copiados, pero es posible que haya cambios en los redo logs finales.</block>
  <block id="fe83c5826bec1aa20e26802fa94a4a0f" category="list-text">Para reproducir todos los logs restantes, ejecute el<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> comando. Si el mensaje<block ref="cef3519da39a73834e89a18ca91951f1" prefix=" " category="inline-code"></block> aparece, el proceso se ha realizado correctamente.</block>
  <block id="15434ad90ad32205a804fe96f265b91d" category="paragraph">Este proceso solo cambió la ubicación de los archivos de datos normales. Se debe cambiar el nombre de los archivos de datos temporales, pero no es necesario copiarlos porque solo son temporales. La base de datos está inactiva, por lo que no hay datos activos en los archivos de datos temporales.</block>
  <block id="2a7c5560f8e4ad220c853666c46eb051" category="list-text">Para reubicar los archivos de datos temporales, primero identifique su ubicación.</block>
  <block id="10b2632cf9c3bf6568b36f6a37e627c2" category="list-text">Reubicar los archivos de datos temporales mediante un comando de RMAN que define el nuevo nombre para cada archivo de datos. Con Oracle Managed Files (OMF), el nombre completo no es necesario; el grupo de discos de ASM es suficiente. Cuando se abre la base de datos, OMF se enlaza a la ubicación adecuada en el grupo de discos de ASM. Para reubicar archivos, ejecute los siguientes comandos:</block>
  <block id="2c592b1e2841899b280deafe27eeefbf" category="section-title">Migración de redo log</block>
  <block id="3f53598059c3bf11ff505ad9dc0d6776" category="paragraph">El proceso de migración está casi completo, pero los redo logs siguen estando en el grupo de discos de ASM original. Los redo logs no se pueden reubicar directamente. En su lugar, se crea un nuevo juego de redo logs y se agrega a la configuración, seguido de un borrado de los antiguos logs.</block>
  <block id="d54f1c98a924385411a8488657b21dad" category="list-text">Para cada redo log, cree un nuevo grupo con una configuración coincidente. Si no utiliza OMF, debe especificar la ruta completa. Este es también un ejemplo que utiliza<block ref="c9655c773db3ebd5871fbe76c0e38a52" prefix=" " category="inline-code"></block> parámetros. Como se mostró anteriormente, este parámetro se estableció en +NEWLOGS. Esta configuración permite utilizar los siguientes comandos para crear nuevos logs en línea sin necesidad de especificar una ubicación de archivo o incluso un grupo de discos de ASM específico.</block>
  <block id="3e0c7c8ee841e9919343fe45e3e04f2d" category="list-text">Abra la base de datos.</block>
  <block id="7e4b38db083a404d0d628bdb1ad83311" category="list-text">Borre los registros antiguos.</block>
  <block id="37e48dd687a01e58ed329feebebf3198" category="list-text">Si encuentra un error que le impide borrar un log activo, fuerce un cambio al siguiente log para liberar el bloqueo y forzar un punto de control global. A continuación se muestra un ejemplo. Se ha denegado el intento de borrar el grupo de archivos de registro 3, que se encontraba en la ubicación anterior, porque todavía había datos activos en este archivo de registro. Un archivo de registro después de un punto de control le permite suprimir el archivo de registro.</block>
  <block id="79d08abfbe5fd73dc85c55cd20ad4974" category="list-text">Revise el entorno para asegurarse de que todos los parámetros basados en la ubicación estén actualizados.</block>
  <block id="799f5ce04f1d9cad4455676b2fd908d9" category="list-text">El siguiente script muestra cómo simplificar este proceso:</block>
  <block id="9867dfc0eee2725f24f86d8114c356a0" category="list-text">Si los grupos de discos de ASM se evacuaron por completo, ahora se pueden desmontar con<block ref="ae709dc3414219bf2c9c8abc9ff6c67a" prefix=" " category="inline-code"></block>. Sin embargo, en muchos casos, los archivos que pertenecen a otras bases de datos o al archivo spfile/passwd de ASM pueden estar presentes.</block>
  <block id="49f8dc5754bd205ea0da17521cb89a1f" category="section-title">Oracle ASM a la copia del sistema de archivos</block>
  <block id="0f5b1767a58e43cb548226e94441dc07" category="paragraph">El procedimiento de copia del sistema de archivos de Oracle ASM a es muy similar al procedimiento de copia de ASM a ASM, con ventajas y restricciones similares. La diferencia principal es la sintaxis de los distintos comandos y parámetros de configuración cuando se utiliza un sistema de archivos visible en lugar de un grupo de discos de ASM.</block>
  <block id="b533404c568b600f9fceddeac9253964" category="paragraph">Oracle RMAN se utiliza para crear una copia de nivel 0 (completa) de la base de datos de origen ubicada actualmente en el grupo de discos de ASM<block ref="c097579d8cb34b312d396304e0b8f487" prefix=" " category="inline-code"></block> a la nueva ubicación en<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block>.</block>
  <block id="f78b0ab71e2863c28dbe331056451135" category="paragraph">Es necesario forzar el cambio de archive log para asegurarse de que los archive logs contienen todos los datos necesarios para que la copia sea totalmente coherente. Sin este comando, es posible que los datos clave sigan presentes en los redo logs. Para forzar un cambio de archive log, ejecute el siguiente comando:</block>
  <block id="c37c761fc28428b9ead4533aba9ee148" category="paragraph">La interrupción comienza en este paso porque la base de datos se cierra y se coloca en un modo de solo lectura de acceso limitado. Para cerrar la base de datos de origen, ejecute los siguientes comandos:</block>
  <block id="3abd8870d8a333edcaec6a1082520c67" category="paragraph">Realice una copia de seguridad de controlfiles en caso de que deba cancelar la migración y volver a la ubicación de almacenamiento original. Una copia del archivo de control de copia de seguridad no es 100% necesaria, pero hace que el proceso de restablecer las ubicaciones de los archivos de base de datos a la ubicación original sea más fácil.</block>
  <block id="38825215f02e25ca63ff64387b01c1c2" category="paragraph">Todos los parámetros que hagan referencia a grupos de discos de ASM antiguos deben actualizarse y, en algunos casos, suprimirse cuando ya no sean relevantes. Actualícelos para reflejar las nuevas rutas del sistema de archivos y guardar el archivo pfile actualizado. Asegúrese de que se muestra la ruta de destino completa. Para actualizar estos parámetros, ejecute los siguientes comandos:</block>
  <block id="9d0dce3e570fa0ec18269ca508809401" category="section-title">Desactive el archivo init.ora original</block>
  <block id="03dda6526778417460fd0bbb7716b373" category="paragraph">Este archivo se encuentra en la<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> Directory AND se encuentra normalmente en un archivo pfile que sirve como puntero al spfile en el grupo de discos de ASM. Para asegurarse de que el spfile original ya no se utiliza, cámbiele el nombre. Sin embargo, no lo elimine porque este archivo es necesario si se debe cancelar la migración.</block>
  <block id="6087f741090627369fd114fbc794abc4" category="paragraph">Este es el último paso en la reubicación de spfile. El spfile original ya no se utiliza y la base de datos se inicia actualmente (pero no se monta) mediante el archivo intermedio. El contenido de este archivo se puede escribir en la nueva ubicación spfile de la siguiente manera:</block>
  <block id="3f62847435205b7b2af1bd5aaf1d3277" category="paragraph">Debe iniciar la base de datos para liberar los bloqueos en el archivo intermedio e iniciar la base de datos utilizando sólo el nuevo archivo spfile. El inicio de la base de datos también demuestra que la nueva ubicación spfile es correcta y que sus datos son válidos.</block>
  <block id="ea164abfd83078cd71a2f3ba5d237900" category="paragraph">Se creó un archivo de control de copia de seguridad en la ruta<block ref="7a1a1280501cff0194d8ce6e351f2a2c" prefix=" " category="inline-code"></block> anteriormente en el procedimiento. El nuevo spfile define las ubicaciones del archivo de control como <block ref="b4d54c88ccade13a82dcaf8f7c07cac5" prefix="/" category="inline-code"></block> y..<block ref="cd300fb0386526438b368e7a6d1b8ace" prefix=" " category="inline-code"></block>. Sin embargo, esos archivos aún no existen.</block>
  <block id="f7ed72e578ca8d23dd45bfa2c0a61ed8" category="list-text">Este comando restaura los datos del archivo de control a las rutas definidas en spfile.</block>
  <block id="c947c89cb4c7a595782d0be73bbe8cfa" category="list-text">Emita el comando mount para que los archivos de control se detecten correctamente y contengan datos válidos.</block>
  <block id="da4ae71a31a1286600968f8a340fddb2" category="paragraph">Para validar el<block ref="d98137bd230dac4372cf20a2e7839463" prefix=" " category="inline-code"></block> parámetro, ejecute el siguiente comando:</block>
  <block id="c25a81770c591c46d6909aae84bf5814" category="paragraph">La base de datos está utilizando actualmente los archivos de datos en la ubicación antigua. Para poder utilizar la copia, es necesario sincronizar los archivos de datos. El tiempo transcurrido durante el proceso de copia inicial y los cambios se registraron principalmente en los registros de archivos. Estos cambios se replican en los dos pasos siguientes.</block>
  <block id="95ea23a5654037c0ab2a5418478d9da2" category="list-text">Vuelva a reproducir los registros.</block>
  <block id="e726fdb8508ef59abc6d8ef533186382" category="list-text">Para cambiar los archivos de datos activos, ejecute el<block ref="7705ebb59373d0b1dfc71d86ef726f93" prefix=" " category="inline-code"></block> comando:</block>
  <block id="7fdba4cfea0e0d298cda23e7f46e40c4" category="list-text">Aunque los archivos de datos deben ser totalmente coherentes, se necesita un paso final para reproducir los cambios restantes registrados en los redo logs en línea. Utilice la<block ref="81168dbef15af03d02c51a7447378e76" prefix=" " category="inline-code"></block> comando para reproducir estos cambios y hacer que la copia sea 100% idéntica a la original. Sin embargo, la copia aún no está abierta.</block>
  <block id="8eb94d53286760da56ca9c892a49cd8b" category="section-title">Reubicar archivos de datos temporales</block>
  <block id="a1e7f15bee0eaa976661307aa884fd99" category="list-text">Identifique la ubicación de los archivos de datos temporales que aún se están utilizando en el grupo de discos original.</block>
  <block id="89b79c94ceba42d5bc646c1b4b1acd24" category="list-text">Para reubicar los archivos de datos, ejecute los siguientes comandos. Si hay muchos archivos temporales, utilice un editor de texto para crear el comando RMAN y, a continuación, córtelo y péguelo.</block>
  <block id="81aa65cb154a5f125bbf3ede064d4b3f" category="paragraph">El proceso de migración está casi completo, pero los redo logs siguen estando en el grupo de discos de ASM original. Los redo logs no se pueden reubicar directamente. En su lugar, se crea un nuevo juego de redo logs y se agrega a la configuración, luego se borran los logs antiguos.</block>
  <block id="6e46687c6cc5deabe53fa42932683c4d" category="list-text">Para cada redo log, cree un nuevo grupo utilizando el mismo tamaño que el grupo de redo logs actual mediante la nueva ubicación del sistema de archivos.</block>
  <block id="22fd48a866ce4d04edb57c15b2fad5da" category="list-text">Elimine los grupos de archivos de registro antiguos que aún se encuentran en el almacenamiento anterior.</block>
  <block id="94158400e59555bf69ecd550887bd9f6" category="list-text">Si se detecta un error que bloquea el borrado de un log activo, fuerce un cambio al siguiente log para liberar el bloqueo y forzar un punto de control global. A continuación se muestra un ejemplo. Se ha denegado el intento de borrar el grupo de archivos de registro 3, que se encontraba en la ubicación anterior, porque todavía había datos activos en este archivo de registro. Un archivo log seguido de un punto de control permite la supresión de archivos log.</block>
  <block id="326770a786c5933416b6a167c854e7b8" category="list-text">El siguiente script muestra cómo facilitar este proceso.</block>
  <block id="ffdcdc8ee9653232a906773fa11358fd" category="list-text">Si los grupos de discos de ASM se evacuaron por completo, ahora se pueden desmontar con<block ref="ae709dc3414219bf2c9c8abc9ff6c67a" prefix=" " category="inline-code"></block>. En muchos casos, los archivos que pertenecen a otras bases de datos o al archivo spfile/passwd de ASM pueden seguir presentes.</block>
  <block id="3d8b8f4734039817e35d5fb6993c8d08" category="section-title">Procedimiento de limpieza del archivo de datos</block>
  <block id="637607e2203ac522fc9dbc88deb6c36f" category="inline-link-macro">Limpieza de Migración de ASM</block>
  <block id="18325b8b206963bc1ae6cca25406f942" category="paragraph">El proceso de migración puede dar lugar a archivos de datos con sintaxis larga o críptica, según cómo se haya utilizado Oracle RMAN. En el ejemplo que se muestra aquí, la copia de seguridad se realizó con el formato de archivo de<block ref="1da91ad80bcfeb818066022a42cde773" prefix=" " category="inline-code"></block>.<block ref="432459869b7d0085e120ec9454032267" prefix=" " category="inline-code"></block> Indica que RMAN debe crear un nombre único por defecto para cada archivo de datos. El resultado es similar al que se muestra en el siguiente texto. Los nombres tradicionales de los archivos de datos están incrustados en los nombres. Esto se puede limpiar utilizando el enfoque con guión que se muestra en la <block ref="bf0c2c579af181f7d1e4d0267c1385fe" category="inline-link-macro-rx"></block>.</block>
  <block id="5e8488a95f83d2789417a1f3298f2f31" category="section-title">Reequilibrio de Oracle ASM</block>
  <block id="2768938325db3a71a6713959a0f309d9" category="paragraph">Como se ha explicado anteriormente, un grupo de discos de Oracle ASM se puede migrar de forma transparente a un nuevo sistema de almacenamiento mediante el proceso de reequilibrio. En resumen, el proceso de reequilibrio requiere la adición de LUN de igual tamaño al grupo existente de LUN seguido de una operación de eliminación del LUN anterior. Oracle ASM reubica automáticamente los datos subyacentes en un nuevo almacenamiento en un diseño óptimo y, al finalizar, libera las LUN antiguas.</block>
  <block id="24a638b29b3c55f26c731aa4b9943a52" category="paragraph">El proceso de migración utiliza I/O secuencial eficiente y no suele provocar interrupciones en el rendimiento, pero la tasa de migración puede acelerarse cuando es necesario.</block>
  <block id="25d06b03dd002ad791b19500c58e9f72" category="section-title">Identifique los datos que se van a migrar</block>
  <block id="3709d4034873467e8e6ae138da54a443" category="section-title">Cree nuevas LUN</block>
  <block id="32176bd565539329eafb96db9447e517" category="paragraph">Cree nuevas LUN del mismo tamaño y establezca la pertenencia de usuarios y grupos como sea necesario. Las LUN deben aparecer como<block ref="bea4821516973214973a70aea8337c38" prefix=" " category="inline-code"></block> discos.</block>
  <block id="6e59535a7b8dd239c67b8d015618f5e1" category="section-title">Agregar NUEVAS LUN</block>
  <block id="71f7e1ff1a6e075f8364d083f145b655" category="paragraph">Aunque las operaciones de agregar y soltar se pueden realizar de forma conjunta, generalmente es más sencillo añadir nuevas LUN en dos pasos. En primer lugar, agregue las nuevas LUN al grupo de discos. Este paso hace que la mitad de las extensiones se migren de las LUN de ASM actuales a las nuevas LUN.</block>
  <block id="7989dfdf722e8bee00001dac817e4833" category="paragraph">La potencia de reequilibrio indica la velocidad a la que se transfieren los datos. Cuanto mayor sea el número, mayor será el paralelismo de la transferencia de datos. La migración se realiza con eficientes operaciones de I/O secuenciales que es poco probable que provoquen problemas de rendimiento. Sin embargo, si lo desea, la potencia de reequilibrio de una migración continua se puede ajustar con el<block ref="e20ea7dfbbe351f6a5275d7adc71efbd" prefix=" " category="inline-code"></block> comando. Las migraciones típicas utilizan un valor de 5.</block>
  <block id="2b69f08c262a142b3fb0868f4d31ab4f" category="section-title">Supervise el funcionamiento</block>
  <block id="a5097a0967c777285f74d63bf0cc26a1" category="paragraph">Una operación de reequilibrio puede supervisarse y gestionarse de varias maneras. Utilizamos el siguiente comando para este ejemplo.</block>
  <block id="5d68829c11bdb5ae7a50b847bb126d44" category="paragraph">Una vez finalizada la migración, no se informan las operaciones de reequilibrio.</block>
  <block id="957310262614cddc1992368d2d0b14b3" category="section-title">Borre las LUN antiguas</block>
  <block id="260c16583c8eb689202ed5b4a44708b1" category="paragraph">La migración se ha completado a mitad de camino. Podría ser deseable realizar algunas pruebas de rendimiento básicas para asegurarse de que el entorno está en buen estado. Después de la confirmación, se pueden reubicar los datos restantes eliminando las LUN antiguas. Tenga en cuenta que esto no provoca una versión inmediata de las LUN. La operación de borrado indica a Oracle ASM que reubique primero las extensiones y, a continuación, libere el LUN.</block>
  <block id="90423249814011b02ba06afd9fb2d617" category="paragraph">La operación de reequilibrio se puede supervisar y gestionar de varias maneras. Utilizamos el siguiente comando para este ejemplo:</block>
  <block id="1544b3a52519b3856f1f7d1e704cb56f" category="section-title">Quite las LUN antiguas</block>
  <block id="983d704730b30910fc03d3ed444278f0" category="paragraph">Antes de quitar las LUN antiguas del grupo de discos, debe realizar una comprobación final del estado del encabezado. Después de liberar una LUN desde ASM, ya no aparece un nombre y el estado de la cabecera aparece como<block ref="e2ffc99cf675f5f0f1a3456438551a9a" prefix=" " category="inline-code"></block>. Esto indica que estas LUN se pueden eliminar de forma segura del sistema.</block>
  <block id="22a67c375eff91d37f2363ea69b0c41f" category="section-title">Migración de LVM</block>
  <block id="d52f83c78118c243801797ba9b795b72" category="paragraph">El procedimiento que se presenta aquí muestra los principios de una migración basada en LVM de un grupo de volúmenes llamado<block ref="ec2db4422261eae02091227fb9e53c88" prefix=" " category="inline-code"></block>. Los ejemplos se extraen del LVM de Linux, pero los principios se aplican por igual a AIX, HP-UX y VxVM. Los comandos precisos pueden variar.</block>
  <block id="64a375907ede7a86c9e8a1b4b142f22e" category="list-text">Identifique las LUN actualmente en el<block ref="ec2db4422261eae02091227fb9e53c88" prefix=" " category="inline-code"></block> grupo de volúmenes.</block>
  <block id="0ae75856dd12545cdd98b8cad5c12ad8" category="list-text">Cree nuevas LUN del mismo tamaño físico o ligeramente mayor y definiéndolas como volúmenes físicos.</block>
  <block id="2426fa707e9d362c711977b79acd65bb" category="list-text">Añada los volúmenes nuevos al grupo de volúmenes.</block>
  <block id="02443ebd7f86c3a688a1e3466d3f106a" category="list-text">Emita el<block ref="8167c9a6bd495f7ed235364201039099" prefix=" " category="inline-code"></block> Comando para reubicar las extensiones de cada LUN actual en la nueva LUN. La<block ref="1b464374742cfda0167b82bc6f9462f1" prefix=" " category="inline-code"></block> argument supervisa el progreso de la operación.</block>
  <block id="ce4a174d56245f6ba5b8808527919921" category="list-text">Cuando finalice este proceso, borre las LUN antiguas del grupo de volúmenes mediante el<block ref="3a4d1e7b0af1cf3d80e419c09d238535" prefix=" " category="inline-code"></block> comando. Si es correcto, la LUN ahora se puede quitar de forma segura del sistema.</block>
  <block id="599a80136f745b38f35077e1c7eb020e" category="summary">Procedimientos de migración de Oracle</block>
  <block id="329ffa7a9038afa62748f87628b749d5" category="paragraph">Hay muchos procedimientos disponibles para la base de datos de migración de Oracle. El correcto depende de las necesidades de su empresa.</block>
  <block id="48a2d08de8943e7ca4718c02e6b791b6" category="paragraph">En muchos casos, los administradores de sistemas y los administradores de bases de datos cuentan con sus propios métodos preferidos para reubicar datos de volúmenes físicos, realizar mirroring y desduplicación o utilizar Oracle RMAN para copiar datos.</block>
  <block id="79d01f6e7efcfef7db530c0b3c5ea516" category="paragraph">Estos procedimientos se proporcionan principalmente como orientación para el PERSONAL DE TI menos familiarizado con algunas de las opciones disponibles. Además, los procedimientos muestran las tareas, los requisitos de tiempo y las demandas de habilidades para cada método de migración. De este modo, otras partes como NetApp y los servicios profesionales de partners o el equipo de gestión de TI pueden apreciar de forma más completa los requisitos de cada procedimiento.</block>
  <block id="5604c71a7d9ae37df511cc85052c1894" category="paragraph">No existe una práctica recomendada única para crear una estrategia de migración. La creación de un plan requiere primero comprender las opciones de disponibilidad y luego seleccionar el método que mejor se adapte a las necesidades del negocio. La siguiente figura ilustra las consideraciones básicas y las conclusiones típicas de los clientes, pero no es universalmente aplicable a todas las situaciones.</block>
  <block id="fa2e72668f7d48694bef3ba5474e3967" category="paragraph">Por ejemplo, un paso plantea el problema del tamaño total de la base de datos. El siguiente paso depende de si la base de datos es mayor o menor que 1TB. Los pasos recomendados son simplemente eso: Recomendaciones basadas en las prácticas típicas del cliente. La mayoría de los clientes no utilizarían DataGuard para copiar una base de datos pequeña, pero algunos podrían. La mayoría de los clientes no intentarían copiar una base de datos de 50TB GB debido al tiempo necesario, pero algunos pueden tener una ventana de mantenimiento lo suficientemente grande como para permitir dicha operación.</block>
  <block id="82f59f5f005a6ea06f0466a4ffc18b6c" category="paragraph">Puede encontrar un diagrama de flujo de los tipos de consideraciones sobre qué ruta de migración es la mejor <block ref="d197151b12289ca0258c12e9b0e8fb1c" category="inline-link-macro-rx"></block>.</block>
  <block id="e38af1623479eee6cfe1782df43819d3" category="paragraph">Oracle 12cR1 y las versiones superiores incluyen la capacidad de mover un archivo de datos mientras la base de datos permanece en línea. Además, funciona entre diferentes tipos de sistemas de archivos. Por ejemplo, un archivo de datos se puede reubicar de un sistema de archivos xfs a ASM. Este método no se utiliza generalmente a escala debido al número de operaciones de movimiento de archivos de datos individuales que serían necesarias, pero es una opción que vale la pena considerar con bases de datos más pequeñas con menos archivos de datos.</block>
  <block id="5972a038819f045814401b2baea9ee09" category="paragraph">Además, simplemente mover un archivo de datos es una buena opción para migrar partes de bases de datos existentes. Por ejemplo, los archivos de datos menos activos podrían reubicarse en un almacenamiento más rentable, como un volumen FabricPool que pueda almacenar bloques inactivos en el almacén de objetos.</block>
  <block id="fcdd0d9eae6df775f1bdc52f950a0160" category="section-title">Migración a nivel de base de datos</block>
  <block id="2b619622b2b8505c335acc8be3a2c3fd" category="paragraph">La migración a nivel de base de datos implica permitir que la base de datos vuelva a ubicar los datos. Específicamente, esto significa el envío de registros. Tecnologías como RMAN y ASM son productos de Oracle, pero, para la migración, funcionan en el nivel de host en el que copian archivos y gestionan volúmenes.</block>
  <block id="1048000638cc5357b8b2b36ab55cbc5a" category="section-title">Trasvase de registros</block>
  <block id="36f7294e33f88b462199b92362434684" category="paragraph">La base para la migración a nivel de base de datos es el archive log de Oracle, que contiene un log de los cambios realizados en la base de datos. La mayoría de las veces, un registro de archivo forma parte de una estrategia de backup y recuperación. El proceso de recuperación comienza con la restauración de una base de datos y luego la reproducción de uno o más registros de archivos para que la base de datos alcance el estado deseado. Esta misma tecnología básica se puede usar para realizar una migración con poca o ninguna interrupción de las operaciones. Y lo que es más importante, esta tecnología permite la migración sin modificar la base de datos original, lo que mantiene un camino de back-out.</block>
  <block id="d43de5ded302797939b76670bc488b51" category="paragraph">El proceso de migración comienza con la restauración de un backup de base de datos a un servidor secundario. Puede hacerlo de varias formas, pero la mayoría de los clientes utilizan su aplicación de backup normal para restaurar los archivos de datos. Después de restaurar los archivos de datos, los usuarios establecen un método para el envío de registros. El objetivo es crear una fuente constante de los archive logs generados por la base de datos primaria y reproducirlos en la base de datos restaurada para mantenerlos cerca del mismo estado. Cuando llega el tiempo de transposición, la base de datos de origen se cierra por completo y los archive logs finales, y en algunos casos los redo logs, se copian y se vuelven a reproducir. Es fundamental que los redo logs también se tengan en cuenta porque pueden contener algunas de las transacciones finales confirmadas.</block>
  <block id="f6fc42763ddbd981d5803ee6676dc7c3" category="paragraph">Después de transferir y reproducir estos registros, ambas bases de datos son coherentes entre sí. En este momento, la mayoría de los clientes realizan algunas pruebas básicas. Si se produce algún error durante el proceso de migración, la reproducción de log debe informar de los errores y fallar. Aún es aconsejable realizar algunas pruebas rápidas basadas en consultas conocidas o actividades controladas por aplicaciones para verificar que la configuración es óptima. También es una práctica común crear una tabla de prueba final antes de cerrar la base de datos original para verificar si está presente en la base de datos migrada. Este paso garantiza que no se hayan producido errores durante la sincronización del registro final.</block>
  <block id="d8e9d23b4beb4db3da15d77542782747" category="paragraph">Una simple migración de envío de registros se puede configurar fuera de banda con respecto a la base de datos original, lo que la hace particularmente útil para las bases de datos de misión crítica. No se requieren cambios de configuración para la base de datos de origen, y la restauración y configuración inicial del entorno de migración no afectan a las operaciones de producción. Después de configurar el envío de registros, coloca algunas demandas de E/S en los servidores de producción. Sin embargo, el envío de registros consiste en lecturas secuenciales simples de los archive logs, lo que es poco probable que afecte al rendimiento de la base de datos de producción.</block>
  <block id="2c31403002a9f424c6ef56460c6b3715" category="paragraph">El envío de registros ha demostrado ser particularmente útil para proyectos de migración de larga distancia y alta tasa de cambio. En un ejemplo, una sola base de datos de 220TB TB se migró a una nueva ubicación aproximadamente a 500 kilómetros de distancia. La tasa de cambio fue extremadamente alta y las restricciones de seguridad impidieron el uso de una conexión de red. El envío de registros se realizó mediante cinta y mensajería. Se restauró inicialmente una copia de la base de datos de origen mediante los procedimientos descritos a continuación. A continuación, los registros se enviaron semanalmente por mensajería hasta el momento de la transición, cuando se entregó el conjunto final de cintas y se aplicaron los registros a la base de datos de réplica.</block>
  <block id="b8efa655c4deb7af8a24fc241f8b53ff" category="section-title">Oracle DataGuard</block>
  <block id="d3165c4060fc6d19c0a6364e7c4580ee" category="paragraph">En algunos casos, se garantiza un entorno DataGuard completo. No es correcto utilizar el término DataGuard para hacer referencia a cualquier envío de log o configuración de base de datos en espera. Oracle DataGuard es un marco completo para gestionar la replicación de bases de datos, pero no es una tecnología de replicación. La principal ventaja de un entorno DataGuard completo en un esfuerzo de migración es el switchover transparente de una base de datos a otra. DATAGUARD también permite un switchover transparente a la base de datos original si se detecta un problema, como un problema de rendimiento o conectividad de red con el nuevo entorno. Un entorno DataGuard completamente configurado requiere la configuración no sólo de la capa de base de datos, sino también de las aplicaciones, de modo que las aplicaciones puedan detectar un cambio en la ubicación de la base de datos primaria. En general, no es necesario utilizar DataGuard para completar una migración, pero algunos clientes tienen una amplia experiencia en DataGuard interna y ya dependen de ella para el trabajo de migración.</block>
  <block id="f17c0a1ce359c1a6665412f89234bf41" category="section-title">Vuelva a diseñar la arquitectura</block>
  <block id="ece8d784e248d63091fc0d248cdeebc3" category="paragraph">Como hemos visto anteriormente, aprovechar las funciones avanzadas de las cabinas de almacenamiento en ocasiones requiere cambiar el diseño de la base de datos. Además, un cambio en el protocolo de almacenamiento, como migrar de ASM a un sistema de archivos NFS, altera necesariamente la distribución del sistema de archivos.</block>
  <block id="71843fb61639ed5fe216bfebc85af16f" category="paragraph">Una de las principales ventajas de los métodos de envío de registros, incluido DataGuard, es que el destino de replicación no tiene que coincidir con el origen. No hay problemas con el uso de un enfoque de envío de logs para migrar de ASM a un sistema de archivos normal o viceversa. El diseño preciso de los archivos de datos se puede cambiar en el destino para optimizar el uso de la tecnología de base de datos conectable (PDB) o para establecer controles de QoS de forma selectiva en ciertos archivos. En otras palabras, un proceso de migración basado en el envío de registros le permite optimizar el diseño de almacenamiento de la base de datos de forma fácil y segura.</block>
  <block id="f00ec1b23f539163f4c748a85e49e2dd" category="section-title">Recursos del servidor</block>
  <block id="76c5d43a72d856a95b0eed94694ae696" category="paragraph">La necesidad de un segundo servidor es una limitación para la migración a nivel de base de datos. Hay dos maneras de usar este segundo servidor:</block>
  <block id="6cb133f8b5045ef30c17e96ab281749e" category="list-text">Puede utilizar el segundo servidor como nuevo directorio raíz permanente para la base de datos.</block>
  <block id="f5133929790fe62dbc76a73db4c88544" category="list-text">Puede utilizar el segundo servidor como servidor temporal. Una vez completada y probada la migración de datos a la nueva cabina de almacenamiento, los sistemas de archivos LUN o NFS se desconectan del servidor provisional y se vuelven a conectar al servidor original.</block>
  <block id="48a00ba9881b62c610201cd833ee9c88" category="paragraph">La primera opción es la más fácil, pero su uso podría no ser factible en entornos muy grandes que requieran servidores muy potentes. La segunda opción requiere trabajo adicional para volver a ubicar los sistemas de archivos en la ubicación original. Esta operación puede ser sencilla en la que NFS se utiliza como protocolo de almacenamiento, ya que los sistemas de archivos se pueden desmontar del servidor de almacenamiento provisional y volver a montarse en el servidor original.</block>
  <block id="c223252c2d577984b75caddbd1dff9dc" category="paragraph">Los sistemas de archivos basados en bloques requieren trabajo adicional para actualizar la división en zonas de FC o los iniciadores de iSCSI. Con la mayoría de los administradores de volúmenes lógicos (incluido ASM), los LUN se detectan automáticamente y se conectan después de que estén disponibles en el servidor original. Sin embargo, algunas implementaciones de sistemas de archivos y LVM pueden requerir más trabajo para exportar e importar los datos. El procedimiento preciso puede variar, pero generalmente es fácil establecer un procedimiento simple y repetible para completar la migración y volver a alojar los datos en el servidor original.</block>
  <block id="2d22ab8be3661ce5dfd8c9910d1cc003" category="paragraph">Aunque es posible configurar el envío de logs y replicar una base de datos en un entorno de servidor único, la nueva instancia debe tener un SID de proceso diferente para reproducir los logs. Es posible traer temporalmente la base de datos bajo un juego diferente de IDs de proceso con un SID diferente y cambiarla más tarde. Sin embargo, esta operación puede resultar en una gran cantidad de actividades de gestión complicadas y pone en riesgo al entorno de bases de datos de que se produzcan errores por parte del usuario.</block>
  <block id="2660e825d3a58f68aeec49e1c749f477" category="section-title">Migración de nivel de host</block>
  <block id="fae5bb68519bf78c1b3711566283f4ef" category="paragraph">Migrar datos a nivel de host significa utilizar el sistema operativo del host y las utilidades asociadas para completar la migración. Este proceso incluye cualquier utilidad que copie datos, incluidos Oracle RMAN y Oracle ASM.</block>
  <block id="01070e0746a412afd171ccf162d3a170" category="section-title">Copiado de datos</block>
  <block id="180e717e34d5e4bd2991c47960d00f51" category="paragraph">No se debe subestimar el valor de una operación de copia simple. Las infraestructuras de red modernas pueden transferir datos a velocidades medidas en gigabytes por segundo y las operaciones de copia de archivos se basan en una eficiente E/S de lectura y escritura secuencial Una operación de copia de host no puede evitar más interrupciones cuando se compara con el envío de registros, pero una migración supone algo más que movimiento de datos. Por lo general, incluye cambios en las redes, el tiempo de reinicio de la base de datos y las pruebas posteriores a la migración.</block>
  <block id="750e04d167938f35054d1c30fd06af58" category="paragraph">El tiempo real necesario para copiar los datos puede no ser significativo. Además, una operación de copia conserva una ruta de back-out garantizada, ya que los datos originales permanecen sin tocar. Si se produce algún problema durante el proceso de migración, se pueden volver a activar los sistemas de archivos originales con los datos originales.</block>
  <block id="5a3572c65171e06d99a4e055f9d35d32" category="section-title">Cambio de la plataforma</block>
  <block id="d123cc133e4de7ab3a4b1a5af3bf37a7" category="paragraph">El cambio de plataforma hace referencia a un cambio en el tipo de CPU. Cuando una base de datos se migra desde una plataforma tradicional Solaris, AIX o HP-UX a x86 Linux, los datos se deben volver a formatear debido a los cambios en la arquitectura de la CPU. Las CPU SPARC, IA64 y POWER se conocen como procesadores big endian, mientras que las arquitecturas x86 y x86_64 se conocen como little endian. Como resultado, algunos datos de los archivos de datos de Oracle se ordenan de forma diferente dependiendo del procesador en uso.</block>
  <block id="6a03806f9c4b1f0048478bab7863fd2c" category="paragraph">Tradicionalmente, los clientes utilizaban DataPump para replicar datos entre plataformas. DataPump es una utilidad que crea un tipo especial de exportación de datos lógicos que se puede importar más rápidamente en la base de datos destino. Debido a que crea una copia lógica de los datos, DataPump deja atrás las dependencias de endianness del procesador. Algunos clientes siguen utilizando DataPump para la transformación de plataformas, pero se ha puesto a disposición una opción más rápida con los tablespaces transportables multiplataforma de Oracle 11g:. Este avance permite que un tablespace se convierta a un formato endian diferente. Se trata de una transformación física que ofrece un mejor rendimiento que una exportación de DataPump, que debe convertir bytes físicos en datos lógicos y luego volver a convertir a bytes físicos.</block>
  <block id="713bf8ff4ea4c4ece861f3345e15e3ea" category="paragraph">No se trata completamente de la NetApp documentación de DataPump y los espacios de tablas transportables. No obstante, NetApp cuenta con algunas recomendaciones basadas en nuestra experiencia al ayudar a los clientes durante la migración a un nuevo registro de cabina de almacenamiento con una nueva arquitectura de CPU:</block>
  <block id="86b0ebca28354c7f55b4cc2fe79bee0e" category="list-text">Si se utiliza DataPump, el tiempo necesario para completar la migración se debe medir en un entorno de prueba. A veces, los clientes se sorprenden por el momento necesario para completar la migración. Este tiempo de inactividad adicional inesperado puede provocar una interrupción.</block>
  <block id="8a592f25a72fd6f3718b1b01869ade30" category="list-text">Muchos clientes creen erróneamente que los tablespaces transportables entre plataformas no requieren conversión de datos. Cuando se utiliza una CPU con un endian diferente, un RMAN<block ref="31168275dcaac634489082b54c4c66d0" prefix=" " category="inline-code"></block> la operación debe realizarse en los archivos de datos de antemano. No se trata de una operación instantánea. En algunos casos, el proceso de conversión se puede acelerar al tener varios subprocesos que funcionan en diferentes archivos de datos, pero el proceso de conversión no se puede evitar.</block>
  <block id="db7b3f86f4c9a2a6a76adac81614c03b" category="section-title">Migración controlada por el gestor de volúmenes lógicos</block>
  <block id="86586aa50b0df80a7c68bcd3e86c8606" category="paragraph">Los LVM funcionan tomando un grupo de uno o más LUN y dividiéndolos en unidades pequeñas que normalmente se conocen como extensiones. El pool de extensiones se utiliza entonces como origen para crear volúmenes lógicos que están esencialmente virtualizados. Esta capa de virtualización proporciona valor de varias formas:</block>
  <block id="68d083c44669b8b20f0421b0389c6ded" category="list-text">Los volúmenes lógicos pueden utilizar extensiones extraídas de varios LUN. Cuando se crea un sistema de archivos en un volumen lógico, puede utilizar todas las funcionalidades de rendimiento de todas las LUN. También promueve la carga uniforme de todas las LUN en el grupo de volúmenes, lo que ofrece un rendimiento más previsible.</block>
  <block id="10d1e748082641ce33e82f457cabcbe7" category="list-text">Los volúmenes lógicos se pueden cambiar de tamaño agregando y, en algunos casos, eliminando extensiones. Cambiar el tamaño de un sistema de archivos en un volumen lógico suele ser no disruptivo.</block>
  <block id="5efed6e7bf2fda8321882aff35768721" category="list-text">Los volúmenes lógicos pueden migrarse de forma no disruptiva moviendo las extensiones subyacentes.</block>
  <block id="96371ba57b3d2f331cc9bd7b5e34708b" category="paragraph">La migración mediante un LVM funciona de dos maneras: Mover una extensión o duplicar/desactivar una extensión. La migración de LVM utiliza I/O secuencial de grandes bloques y solo rara vez crea preocupación sobre el rendimiento. Si esto se convierte en un problema, normalmente existen opciones para reducir la tasa de I/O. Hacerlo, aumenta el tiempo necesario para completar la migración pero reduce la carga de I/O en el host y los sistemas de almacenamiento.</block>
  <block id="28084a93e6570f55c3923991e269816e" category="section-title">Retrovisor y retrovisor</block>
  <block id="f5b05967100f74bb14ae26d5021ef4e3" category="paragraph">Algunos administradores de volúmenes, como AIX LVM, permiten al usuario especificar el número de copias para cada extensión y controlar qué dispositivos alojan cada copia. La migración se lleva a cabo tomando un volumen lógico existente, reflejando las extensiones subyacentes a los nuevos volúmenes, esperando a que se sincronicen las copias y borrando la antigua. Si se desea una ruta de retroceso, se puede crear una instantánea de los datos originales antes del punto en el que se descarta la copia de duplicación. También puede apagar el servidor brevemente para enmascarar las LUN originales antes de eliminar forzosamente las copias de duplicación contenidas. De este modo se conserva una copia recuperable de los datos en su ubicación original.</block>
  <block id="7151373ff69a9fafa4a579b40282beeb" category="section-title">Migración de extensiones</block>
  <block id="682ba6adb168511d03877bdbf940a0b7" category="paragraph">Casi todos los gestores de volúmenes permiten migrar extensiones y, a veces, existen varias opciones. Por ejemplo, algunos administradores de volúmenes permiten que un administrador reubique las extensiones individuales de un volumen lógico específico, de almacenamiento antiguo a nuevo. Los gestores de volúmenes, como Linux LVM2, ofrecen el<block ref="8167c9a6bd495f7ed235364201039099" prefix=" " category="inline-code"></block> Comando, que reubica todas las extensiones del dispositivo LUN especificado en una LUN nueva. Después de evacuar la LUN antigua, puede quitarse.</block>
  <block id="8c232bd157fb78062260d11e1ec3fc2c" category="admonition">El principal riesgo para las operaciones es la eliminación de LUN antiguas y no utilizadas de la configuración. Debe tenerse mucho cuidado al cambiar la división en zonas de FC y eliminar los dispositivos LUN obsoletos.</block>
  <block id="41175a8b2053bedbf868e340edf92f55" category="section-title">Gestión Automática de Almacenamiento de Oracle</block>
  <block id="dce3f0c1b1c85aaee6448197054602d1" category="paragraph">Oracle ASM es un gestor de volúmenes lógicos y un sistema de archivos combinados. En un nivel superior, Oracle ASM toma una colección de LUN, los divide en pequeñas unidades de asignación y los presenta como un único volumen conocido como grupo de discos ASM. ASM también incluye la capacidad de reflejar el grupo de discos mediante la definición del nivel de redundancia. Un volumen puede estar no reflejado (redundancia externa), reflejado (redundancia normal) o reflejado en tres direcciones (alta redundancia). Se debe tener cuidado al configurar el nivel de redundancia porque no se puede cambiar después de la creación.</block>
  <block id="d0ac5c14a6207835f733f4366345089d" category="paragraph">ASM también proporciona la funcionalidad del sistema de archivos. Aunque el sistema de archivos no está visible directamente desde el host, la base de datos Oracle puede crear, mover y suprimir archivos y directorios en un grupo de discos ASM. Además, la estructura puede ser navegada usando la utilidad asmcmd.</block>
  <block id="e72c9da30cbec4daedddc9b6e6fdf03b" category="paragraph">Al igual que con otras implementaciones de LVM, Oracle ASM optimiza el rendimiento de E/S mediante la segmentación y el equilibrio de carga de E/S de cada archivo en todas las LUN disponibles. En segundo lugar, las extensiones subyacentes se pueden reubicar para permitir tanto el cambio de tamaño del grupo de discos de ASM como la migración. Oracle ASM automatiza el proceso mediante la operación de reequilibrio. Se agregan nuevos LUN a un grupo de discos ASM y se eliminan LUN antiguas, lo que activa la reubicación de extensiones y la posterior caída de la LUN evacuada del grupo de discos. Este proceso es uno de los métodos de migración más probados, y la fiabilidad de ASM a la hora de proporcionar una migración transparente es posiblemente su característica más importante.</block>
  <block id="d4ad443888b51ec4e13912c45da68f76" category="admonition">Como el nivel de mirroring de Oracle ASM es fijo, no se puede utilizar con el método de migración mirror y demirror.</block>
  <block id="048429277e643e20907317612c1f3318" category="section-title">Migración de nivel de almacenamiento</block>
  <block id="623bb7ffbb3730716ea39b5086d26f18" category="paragraph">La migración al nivel de almacenamiento significa realizar la migración por debajo tanto del nivel de aplicación como del sistema operativo. Anteriormente, esto suponía el uso de dispositivos especializados que copiaban LUN a nivel de red, pero estas funcionalidades ahora se encuentran de forma nativa en ONTAP.</block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="section-title">SnapMirror</block>
  <block id="963ce762febea70d619f1fd5c114d85c" category="paragraph">La migración de bases de datos desde sistemas NetApp se realiza casi universalmente con el software de replicación de datos SnapMirror de NetApp. El proceso implica configurar una relación de mirroring para los volúmenes que se migrarán, lo que permite que se sincronicen y luego esperar la ventana de transposición. Cuando llega, la base de datos de origen se cierra, se realiza una actualización de duplicación final y se interrumpe la duplicación. A continuación, los volúmenes de réplica están listos para su uso, ya sea montando un directorio de sistema de archivos NFS contenido o detectando los LUN contenidos e iniciando la base de datos.</block>
  <block id="1871452e5ea7e53152b5c874a12a890b" category="paragraph">La reubicación de volúmenes dentro de un único clúster de ONTAP no se considera una migración, sino una rutina<block ref="0fc2ecb8aa71bddc595fbc39f593496a" prefix=" " category="inline-code"></block> funcionamiento. SnapMirror se utiliza como motor de replicación de datos en el clúster. Este proceso está totalmente automatizado. No hay otros pasos de migración que se deben realizar cuando atributos del volumen, como la asignación de LUN o los permisos de exportación de NFS, se mueven con el propio volumen. La reubicación no provoca interrupciones en las operaciones del host. En algunos casos, el acceso a la red debe actualizarse para garantizar que se accede a los datos recién reubicados de la forma más eficiente posible, pero estas tareas también no producen interrupciones.</block>
  <block id="19fee3ea4b7f4472b5c1853122e8f47b" category="section-title">Importación de LUN externa (FLI)</block>
  <block id="a73cf458eed5aeff5c15aa5d70298cce" category="paragraph">FLI es una función que permite que un sistema Data ONTAP que ejecuta 8,3 o superior migre un LUN existente desde otra cabina de almacenamiento. El procedimiento es simple: El sistema ONTAP se divide en zonas en la cabina de almacenamiento existente como si fuera cualquier otro host SAN. A continuación, Data ONTAP toma el control de las LUN heredadas deseadas y migra los datos subyacentes. Además, el proceso de importación utiliza la configuración de eficiencia del volumen nuevo a medida que se migran los datos, lo que significa que los datos se pueden comprimir y deduplicar online durante el proceso de migración.</block>
  <block id="0ee4b09881406835f151f103412a2f1e" category="paragraph">La primera implementación de FLI en Data ONTAP 8,3 solo permitía la migración sin conexión. Esta transferencia fue extremadamente rápida, pero seguía significando que los datos de la LUN no estaban disponibles hasta que se completó la migración. La migración en línea se introdujo en Data ONTAP 8,3.1. Este tipo de migración minimiza las interrupciones al permitir que ONTAP sirva datos de LUN durante el proceso de transferencia. Se produce una breve interrupción mientras se vuelve a dividir en zonas el host para usar los LUN a través de ONTAP. No obstante, tan pronto como se realicen estos cambios, los datos volverán a estar accesibles y seguirán siendo accesibles durante todo el proceso de migración.</block>
  <block id="19d95ee75467fc2f9a06d150cc99d944" category="paragraph">La I/O de lectura se proxy mediante ONTAP hasta que se completa la operación de copia, mientras que la I/O de escritura se escribe de forma síncrona en el LUN externo y en el LUN de ONTAP. Las dos copias LUN se mantienen sincronizadas de esta manera hasta que el administrador ejecuta una transposición completa que libera la LUN externa y ya no replica las escrituras.</block>
  <block id="5caad387757ca99ada41709ce30a31a5" category="paragraph">FLI está diseñado para funcionar con FC, pero si se desea cambiar a iSCSI, el LUN migrado puede volver a asignarse fácilmente como LUN iSCSI una vez finalizada la migración.</block>
  <block id="7fa6cfc683e0f5f9e3a79f6be14e23f4" category="paragraph">Entre las características de FLI se encuentra la detección y ajuste automático de alineación. En este contexto, el término alineación hace referencia a una partición en un dispositivo LUN. Para un rendimiento óptimo es necesario alinear las E/S con bloques de 4K KB. Si una partición se coloca en un desplazamiento que no es múltiplo de 4K, el rendimiento se ve afectado.</block>
  <block id="7b4ef266729f1ddfbc724cad17af4efc" category="paragraph">Hay un segundo aspecto de la alineación que no se puede corregir ajustando un desplazamiento de partición: El tamaño del bloque del sistema de archivos. Por ejemplo, un sistema de archivos ZFS generalmente toma por defecto un tamaño de bloque interno de 512 bytes. Otros clientes que usan AIX han creado ocasionalmente sistemas de archivos JFS2 con un tamaño de bloque de 512 o 1, 024 bytes. Aunque es posible que el sistema de archivos esté alineado con un límite de 4K KB, los archivos creados dentro de ese sistema de archivos no lo están y el rendimiento se resienta.</block>
  <block id="1d6b28ed67b1d554df806b0b5a020711" category="paragraph">FLI no debe utilizarse en estas circunstancias. Aunque se puede acceder a los datos tras la migración, el resultado son sistemas de archivos con serias limitaciones de rendimiento. Como principio general, cualquier sistema de archivos que admita una carga de trabajo de sobrescritura aleatoria en ONTAP debería utilizar un tamaño de bloque de 4K KB. Esto es aplicable principalmente a cargas de trabajo como los archivos de datos de bases de datos e implementaciones de VDI. El tamaño de bloque se puede identificar mediante los comandos del sistema operativo del host relevantes.</block>
  <block id="4941562ef813562e0d6aaef673158b99" category="paragraph">Por ejemplo, en AIX, el tamaño de bloque se puede ver con<block ref="10c9a985c983a826424b496a708263ec" prefix=" " category="inline-code"></block>. Con Linux,<block ref="ba5265473f00b27178098cc38d3aef24" prefix=" " category="inline-code"></block> y..<block ref="1f8a87190704df357c64a49aee936874" prefix=" " category="inline-code"></block> se puede utilizar para<block ref="310201b6353c5f38bc039e0e51b079d3" prefix=" " category="inline-code"></block> y..<block ref="5382133ffbecb9bce9d47f2e44327b16" prefix=" " category="inline-code"></block>, respectivamente. Con<block ref="8cbc6ba7c8bba133ce2bc44780d88742" prefix=" " category="inline-code"></block>, el comando es<block ref="1615297782a0dff59b20451e2ca97ea7" prefix=" " category="inline-code"></block>.</block>
  <block id="033a4cb04b5225e2b7cf966f2ce16598" category="paragraph">El parámetro que controla el tamaño del bloque es<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> y, por lo general, el valor predeterminado es 9, lo que significa 2^9, o 512 bytes. Para un rendimiento óptimo, el<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> El valor debe ser 12 (2^12=4K). Este valor se define en el momento en que se crea zpool y no se puede cambiar, lo que significa que los datos zpools con un<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block> los datos que no sean 12 se deben migrar copiando a un zpool recién creado.</block>
  <block id="8bd9661d8c8eb9924c62b8242191af4e" category="paragraph">Oracle ASM no tiene un tamaño de bloque fundamental. El único requisito es que la partición en la que se crea el disco de ASM esté alineada correctamente.</block>
  <block id="ea7f7e1e8119ee64585b6173afe720e8" category="section-title">Herramienta de transición de 7-Mode</block>
  <block id="75df51cc2f43b8dde951695f97b838c0" category="paragraph">La herramienta de transición de 7-Mode (7MTT) es una utilidad de automatización que se usa para migrar configuraciones de 7- Mode de gran tamaño a ONTAP. La mayoría de los clientes de bases de datos encuentran otros métodos más sencillos, en parte, debido a que suelen migrar la base de datos de sus entornos por base de datos en lugar de reubicar todo el espacio físico de almacenamiento. Además, normalmente las bases de datos solo forman parte de un entorno de almacenamiento de mayor tamaño. Por tanto, las bases de datos suelen migrarse de forma individual y entonces el entorno restante puede moverse con el 7MTT.</block>
  <block id="85fd7dcbc2206c27059ae7f88712154d" category="paragraph">Hay un número pequeño pero significativo de clientes que disponen de sistemas de almacenamiento dedicados a entornos de bases de datos complicados. Estos entornos pueden contener numerosos volúmenes, copias Snapshot y numerosos detalles de configuración, como permisos de exportación, grupos de iniciadores de LUN, permisos de usuario y configuración de protocolo ligero de acceso a directorios. En tales casos, las capacidades de automatización de 7MTT pueden simplificar una migración.</block>
  <block id="2c87fbdecbf0dfe299f9f89958d61085" category="paragraph">7MTT puede funcionar en uno de dos modos:</block>
  <block id="dc818e71a5519d1b99c7e996cf21fd74" category="list-text">*Transición basada en copia (CBT).* 7MTT Con CBT se configuran los volúmenes de SnapMirror a partir de un sistema 7-Mode existente en el nuevo entorno. Una vez que los datos están sincronizados, 7MTT orquesta el proceso de transición.</block>
  <block id="453bbc96e365e25cc2d091dced3565a6" category="list-text">*Transición sin copia (CFT).* 7MTT con CFT se basa en la conversión in situ de las bandejas de discos 7-Mode existentes. No se copian datos y las bandejas de discos existentes pueden volver a utilizarse. La configuración existente de la protección de datos y la eficiencia del almacenamiento se conserva.</block>
  <block id="16262236c3981cb3310b9320b5a67fd0" category="paragraph">La principal diferencia entre estas dos opciones es que la transición sin copias es un método muy importante, en el que todas las bandejas de discos conectadas al par de alta disponibilidad 7- Mode original deben reubicarse en el nuevo entorno. No existe una opción para mover un subconjunto de bandejas. El enfoque basado en copia permite mover los volúmenes seleccionados. También hay potencialmente un periodo de transición más largo con una transición sin copias debido al vínculo necesario para volver a conectar las bandejas de discos y convertir los metadatos. Según la experiencia práctica, NetApp recomienda permitir 1 hora para reubicar y reconectar las bandejas de discos, y entre 15 minutos y 2 horas para la conversión de metadatos.</block>
  <block id="f1033948d9d2d14612d27f1808720f12" category="inline-link">TR-4380: Migración de SAN mediante la importación de LUN externos</block>
  <block id="58fc59a248fefa86003ac1867e5bd279" category="paragraph">Los procedimientos para migrar recursos SAN con FLI se documentan en NetApp<block ref="5abd855dd5d8332b78fa966ac34c0f22" category="inline-link-rx"></block>.</block>
  <block id="795bbfbd054829fad905065087ba2d5a" category="paragraph">Desde un punto de vista de base de datos y host, no se requieren pasos especiales. Después de actualizar las zonas de FC y de que los LUN estén disponibles en ONTAP, LVM debería poder leer los metadatos de LVM de los LUN. Además, los grupos de volúmenes están listos para usarse sin más pasos de configuración. En raras ocasiones, los entornos pueden incluir archivos de configuración que se codificaron de forma fija con referencias a la cabina de almacenamiento anterior. Por ejemplo, un sistema Linux que incluyó<block ref="dd5ff67ba72768d33f75e645aa2b8e56" prefix=" " category="inline-code"></block> Las reglas que hacen referencia a un WWN de un dispositivo determinado se deben actualizar para reflejar los cambios introducidos por FLI.</block>
  <block id="9e7ddc2ddefcd6f202fb11a82a80bc7e" category="admonition">Consulte la Matriz de compatibilidad de NetApp para obtener información sobre las configuraciones admitidas. Si su entorno no está incluido, póngase en contacto con su representante de NetApp para obtener ayuda.</block>
  <block id="0f5b3758229b3e28c8605b6c42398115" category="paragraph">Este ejemplo muestra la migración de LUN de ASM y LVM alojadas en un servidor Linux. FLI es compatible con otros sistemas operativos y, aunque los comandos del lado del host pueden ser diferentes, los principios son los mismos y los procedimientos de ONTAP son idénticos.</block>
  <block id="f1036cd97e461d07351c9df32fc5948d" category="section-title">Identifique las LUN de LVM</block>
  <block id="88f7413f9621a816ee3d370703168647" category="paragraph">El primer paso de preparación es identificar las LUN que se van a migrar. En el ejemplo que se muestra aquí, hay dos sistemas de archivos basados en SAN montados en<block ref="572f241ef88fdb17d16eba97133d861f" prefix=" " category="inline-code"></block> y..<block ref="d14bc7787c7396144583e99a7df52f67" prefix=" " category="inline-code"></block>.</block>
  <block id="ecad615a52fda392a9b7c1075d2cb2c5" category="paragraph">El nombre del grupo de volúmenes se puede extraer del nombre del dispositivo, que utiliza el formato (nombre del grupo de volúmenes)-(nombre del volumen lógico). En este caso, se denomina al grupo de volúmenes<block ref="bb97320b8c517da828eae4ec543113db" prefix=" " category="inline-code"></block>.</block>
  <block id="b08986bb1757d5ae8de06d523c71803d" category="paragraph">La<block ref="f1e2c495108b111c930735e3a0f9a04e" prefix=" " category="inline-code"></block> El comando se puede utilizar de la siguiente manera para identificar las LUN que admiten este grupo de volúmenes. En este caso, hay 10 LUN que componen el<block ref="bb97320b8c517da828eae4ec543113db" prefix=" " category="inline-code"></block> grupo de volúmenes.</block>
  <block id="8b47fac6803dfff2e8d2cdad6f297cfa" category="section-title">Identificar LUN de ASM</block>
  <block id="a23d0124954ecdbfe9d0f3aceb9e17a2" category="paragraph">Las LUN de ASM también se deben migrar. Para obtener el número de rutas de LUN y LUN desde sqlplus como usuario sysasm, ejecute el siguiente comando:</block>
  <block id="918841992da84786f00de7c4c7d83dbf" category="paragraph">El entorno actual contiene 20 LUN que se van a migrar. Actualice la SAN actual para que ONTAP pueda acceder a los LUN actuales. Los datos aún no se han migrado, pero ONTAP debe leer la información de configuración de las LUN actuales para crear el nuevo directorio raíz de los datos.</block>
  <block id="5816768a5d83977f34ffa5025c14f430" category="paragraph">Como mínimo, se debe configurar al menos un puerto HBA en el sistema AFF/FAS como puerto iniciador. Además, deben actualizarse las zonas de FC para que ONTAP pueda acceder a los LUN en la cabina de almacenamiento externa. Algunas cabinas de almacenamiento tienen configurado el enmascaramiento de LUN, lo que limita los nombres WWN que pueden acceder a una LUN determinada. En tales casos, el enmascaramiento de LUN también debe actualizarse para conceder acceso a los WWN de ONTAP.</block>
  <block id="030a992b1340f67584d67ef6230e9adf" category="paragraph">Cuando se completa este paso, ONTAP debe poder ver la cabina de almacenamiento externa con el<block ref="d90ba20b63acab53952d68665c50ec47" prefix=" " category="inline-code"></block> comando. El campo clave que devuelve es el prefijo que se utiliza para identificar la LUN externa en el sistema. En el siguiente ejemplo, las LUN de la cabina externa<block ref="25103eba8d70e82b5bd837be0d2f63c4" prefix=" " category="inline-code"></block> Aparece en ONTAP con el prefijo de<block ref="6b35470d99880c4630ed3ca7b4c842e7" prefix=" " category="inline-code"></block>.</block>
  <block id="c1a0f5174323df40a8b659eb65ac5155" category="section-title">Identifique la cabina externa</block>
  <block id="6c1b8919e2e706972b3ec48cb7f014ba" category="section-title">Identificar LUN externas</block>
  <block id="63841e312d3a8531331e35bd826268d1" category="paragraph">Las LUN se pueden enumerar pasando el<block ref="907702f5103a7823393b8dd296a75c26" prefix=" " category="inline-code"></block> para la<block ref="242f4ce1948273386f8bb487bdd3732f" prefix=" " category="inline-code"></block> comando. Se hace referencia a los datos devueltos varias veces durante el procedimiento de migración.</block>
  <block id="e5e94f7e2098883f0d621e064b1104f4" category="section-title">Registre LUN de cabina externa como candidatos para importar</block>
  <block id="c968ec41c1c0c449b0263962966d8293" category="paragraph">Las LUN externas inicialmente se clasifican como cualquier tipo de LUN específico. Antes de poder importar los datos, las LUN deben etiquetarse como externas y, por lo tanto, candidatas para el proceso de importación. Este paso se completa pasando el número de serie al<block ref="93c633f7fa188f1b27df574c0e5e929a" prefix=" " category="inline-code"></block> command, tal y como se muestra en el siguiente ejemplo. Tenga en cuenta que este proceso solo etiqueta la LUN como externa en ONTAP. No se escriben datos en la propia LUN externa.</block>
  <block id="33380a523841f23815f2f83c9de1a628" category="section-title">Crear volúmenes para alojar LUN migradas</block>
  <block id="2c2ba8ca6bdd77da1da981b91a3fae4a" category="paragraph">Se necesita un volumen para alojar los LUN migrados. La configuración exacta de volúmenes depende del plan general para aprovechar las funciones de ONTAP. En este ejemplo, las LUN de ASM se colocan en un volumen y las LUN de LVM se colocan en un segundo volumen. Esto le permite gestionar las LUN como grupos independientes para fines como organización en niveles, creación de snapshots o configuración de controles de calidad de servicio.</block>
  <block id="8bc7d64e68e4be8f4908effd57293a2a" category="paragraph">Ajuste la<block ref="fb983ebeedc63d8723c0d4aa558a4c02" prefix=" " category="inline-code"></block>. El proceso de migración puede incluir un alto volumen de cambios de datos. Por lo tanto, es posible que se produzca un gran aumento en el consumo de espacio si las instantáneas se crean por accidente porque se capturan datos no deseados en las copias Snapshot.</block>
  <block id="8c0675d07e44f55f1f5aa6d45abe0cdb" category="section-title">Crear LUN de ONTAP</block>
  <block id="0b799020dac78a5e12a3d1a6400fd0c8" category="paragraph">Después de crear los volúmenes, es necesario crear las nuevas LUN. Normalmente, la creación de una LUN requiere que el usuario especifique dicha información como el tamaño de LUN, pero en este caso el argumento de disco externo se pasa al comando. Como resultado, ONTAP replica los datos de configuración de LUN actuales del número de serie especificado. También utiliza la geometría de la LUN y los datos de la tabla de particiones para ajustar la alineación de la LUN y establecer un rendimiento óptimo.</block>
  <block id="5272a1dc3854f1eddc353c8073234e03" category="paragraph">En este paso, se deben hacer referencias cruzadas de los números de serie a la cabina externa para asegurarse de que la LUN externa correcta coincida con la nueva LUN correcta.</block>
  <block id="f6ee70ec9fce7bd34fa5a33d8969fb5e" category="section-title">Crear relaciones de importación</block>
  <block id="94700a911b95416221efe4064acbc2ba" category="paragraph">Las LUN ahora se han creado, pero no se configuran como destino de replicación. Antes de poder realizar este paso, las LUN deben colocarse primero sin conexión. Este paso adicional está diseñado para proteger los datos de los errores de los usuarios. Si ONTAP permitiera realizar una migración a una LUN online, supondría el riesgo de que un error tipográfico pudiera provocar la sobrescritura de los datos activos. El paso adicional de obligar al usuario a desconectar primero una LUN ayuda a verificar que se utiliza la LUN de destino correcta como destino de migración.</block>
  <block id="85255e52054af9c6ffd3c4e79c723a34" category="paragraph">Después de que las LUN estén sin conexión, puede establecer la relación de importación pasando el número de serie de la LUN externa al<block ref="04c2f87857699971f5aedd525e65690a" prefix=" " category="inline-code"></block> comando.</block>
  <block id="8e3c921431d2b7f66fa0cc85f3ae5c9d" category="paragraph">Una vez establecidas todas las relaciones de importación, las LUN pueden volver a colocarse en línea.</block>
  <block id="ea382cbfdb353cee0cf25eaae9bba150" category="section-title">Cree el iGroup</block>
  <block id="152c4728a5fb152525a639439b9d7cb9" category="inline-link-macro">Conversión de protocolos</block>
  <block id="298a1c3c736859f2cfa3cb8eb1f3fdcc" category="paragraph">En este ejemplo, se crea un igroup que contiene dos WWN que corresponden a los dos puertos disponibles en el HBA del host.</block>
  <block id="4f6f03762bfcdc7174cdd30240ce45b3" category="section-title">Asignar nuevas LUN al host</block>
  <block id="c22fee2d07a149be91ae1ae2ada1cb57" category="paragraph">Después de la creación del igroup, las LUN se asignan al igroup definido. Estos LUN solo están disponibles para los WWN incluidos en este igroup. NetApp asume que en esta etapa del proceso de migración no se ha zonificado el host en ONTAP. Esto es importante porque si se divide en zonas el host simultáneamente en la cabina externa y el nuevo sistema ONTAP, existe el riesgo de que LUN con el mismo número de serie se puedan detectar en cada cabina. Esta situación podría provocar fallos de funcionamiento de varias rutas o daños en los datos.</block>
  <block id="ecca392290c36269e0489c0b1cf36f50" category="summary">Scripts de ejemplo para automatizar las operaciones de migración de Oracle</block>
  <block id="fc53c036602508ed6c2afc18e2fbdf51" category="doc">Scripts de ejemplo</block>
  <block id="6f78af00b87bcad5d08c95c7b6066ad0" category="paragraph">Los scripts presentados se proporcionan como ejemplos de cómo realizar scripts de varias tareas del sistema operativo y de la base de datos. Se suministran tal cual. Si se necesita soporte para un procedimiento concreto, póngase en contacto con NetApp o con un distribuidor de NetApp.</block>
  <block id="3146889e40b3ca2b78c56a19178bff84" category="section-title">Cierre de la base de datos</block>
  <block id="5b98b9877c0c74dc3a3daf46cf943d3f" category="paragraph">El siguiente script Perl toma un argumento único del SID de Oracle y cierra una base de datos. Se puede ejecutar como usuario oracle o como raíz.</block>
  <block id="7df41a3619af59182fb5df6d1920d11a" category="section-title">Inicio de la base de datos</block>
  <block id="57249fb9cdac8ddc9ea8843636c4e088" category="section-title">Convertir el sistema de archivos a sólo lectura</block>
  <block id="f2977a22ba44544ca8921e2d75bce435" category="paragraph">El siguiente script toma un argumento del sistema de archivos e intenta desmontarlo y volver a montarlo como de solo lectura. Esto resulta útil durante los procesos de migración en los que un sistema de ficheros debe estar disponible para replicar los datos y, sin embargo, debe protegerse frente a daños accidentales.</block>
  <block id="4eac395595a8d266839db0b88fae31e4" category="section-title">Sustituya el sistema de archivos</block>
  <block id="988d7030a130298e1641007b5b0aae20" category="paragraph">El siguiente ejemplo de script se utiliza para reemplazar un sistema de archivos por otro. Debido a que edita el archivo `/etc/fstab `, debe ejecutarse como root. Acepta un único argumento delimitado por comas de los sistemas de archivos antiguos y nuevos.</block>
  <block id="149c75d086adf78a50a16bcb5e349158" category="list-text">Para sustituir el sistema de archivos, ejecute el siguiente script:</block>
  <block id="67a4c588434c781febb12c165c3e860a" category="paragraph">Como ejemplo del uso de este script, supongamos que los datos de<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> se ha migrado a.<block ref="27df80f143a5812bda1553d09c712efc" prefix=" " category="inline-code"></block> y..<block ref="0e62afc91abe157ef67895cca0a7f912" prefix=" " category="inline-code"></block> se ha migrado a.<block ref="1c988fc7a325635f00f9b55992128a08" prefix=" " category="inline-code"></block>. Uno de los métodos más simples para realizar esta tarea es mediante una simple operación de copia de archivos para reubicar el nuevo dispositivo en el punto de montaje original.</block>
  <block id="4a3d90c30a5e921650fe8ad0decf4827" category="list-text">Suponga que los sistemas de archivos antiguos y nuevos están presentes en la<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> el archivo es el siguiente:</block>
  <block id="4588a4e3d2f8d0f7c036f59c1be2163f" category="list-text">Cuando se ejecuta, este script desmonta el sistema de archivos actual y lo reemplaza por el nuevo:</block>
  <block id="2d808cb44231d0a80164567e7220fc44" category="list-text">El script también actualiza el<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> archivar según corresponda. En el ejemplo que se muestra aquí, incluye los siguientes cambios:</block>
  <block id="840967a448e36b9efeaacf7673f825aa" category="section-title">Migración de bases de datos automatizada</block>
  <block id="1107dd36fe8ba0c18ea8abc8734986e2" category="paragraph">Este ejemplo muestra el uso de scripts de apagado, inicio y reemplazo del sistema de archivos para automatizar completamente una migración.</block>
  <block id="36881541e7d9c7bced65fcac337ac327" category="section-title">Mostrar ubicaciones de archivos</block>
  <block id="1e9a1acc40d4943a73e6865cdebaf560" category="paragraph">Este script recopila una serie de parámetros críticos de la base de datos e imprime en un formato fácil de leer. Este script puede ser útil al revisar diseños de datos. Además, el script se puede modificar para otros usos.</block>
  <block id="6172b49b7fdf806b59af0aeef8de71e3" category="section-title">Limpieza de migración de ASM</block>
  <block id="dd8d75d6766af495b5442e67eb27d387" category="section-title">Conversión de ASM al nombre del sistema de archivos</block>
  <block id="abc3fc91423668bb4bd49e6e837fa3e4" category="section-title">Reproduzca los logs en la base de datos</block>
  <block id="cc7b9a518bb2532f61662a9893248133" category="paragraph">Este archivo de comandos acepta un argumento único de un SID de Oracle para una base de datos que está en modo de montaje e intenta reproducir todos los archive logs disponibles actualmente.</block>
  <block id="2a5bd3a209a1ed33b81c5306780227ce" category="section-title">Logs de Reproducción en Base de Datos en Espera</block>
  <block id="ea7bebed0b4151a9b28acbde55fc0eb3" category="paragraph">Este script es idéntico al anterior, excepto que está diseñado para una base de datos en espera.</block>
  <block id="2adcfd589637337984e39e94dd14ae33" category="paragraph">El cambio del protocolo utilizado para acceder a una LUN es un requisito habitual.</block>
  <block id="38fe6838f11a6023172d11d806adbfcf" category="paragraph">En algunos casos, forma parte de una estrategia global para migrar datos al cloud. TCP/IP es el protocolo de la nube y el cambio de FC a iSCSI permite facilitar la migración a diversos entornos de cloud. En otros casos, iSCSI puede ser conveniente aprovechar los costes reducidos de una SAN IP. En ocasiones, una migración podría utilizar un protocolo diferente como medida temporal. Por ejemplo, si una cabina externa y LUN basadas en ONTAP no pueden coexistir en los mismos HBA, puede utilizar LUN de iSCSI el tiempo suficiente para copiar datos de la cabina anterior. Entonces, puede volver a convertir a FC después de eliminar las LUN antiguas del sistema.</block>
  <block id="832c81bd0db3ad98a3804ff5ce996a58" category="paragraph">El siguiente procedimiento muestra la conversión de FC a iSCSI, pero los principios generales se aplican a una conversión de iSCSI a FC inversa.</block>
  <block id="e21180783b17ea695cf9275fce8a0bc7" category="section-title">Instale el iniciador de iSCSI</block>
  <block id="0e1ddcc32a3ef636c9ca084a3d7706f5" category="paragraph">La mayoría de los sistemas operativos incluyen un iniciador iSCSI de software de forma predeterminada, pero si no se incluye uno, se puede instalar fácilmente.</block>
  <block id="289fe013df899f5f74fb362d4efcdd5d" category="section-title">Identificar el nombre del iniciador de iSCSI</block>
  <block id="8242e97b190184a6c7b8ec96c5662886" category="paragraph">Se genera un nombre de iniciador iSCSI único durante el proceso de instalación. En Linux, se encuentra en el<block ref="22565a44e8f73044eb2029acbb069639" prefix=" " category="inline-code"></block> archivo. Este nombre se utiliza para identificar el host en la SAN IP.</block>
  <block id="721a96eb0b922b337fa815839839b328" category="section-title">Cree un nuevo iGroup</block>
  <block id="cda1311d977b7b77ad3aebe4a813b3bd" category="paragraph">Un igroup forma parte de la arquitectura de enmascaramiento LUN de ONTAP. No es posible acceder a un LUN recién creado a menos que se conceda acceso en primer lugar a un host. Para lograr este paso, debe crear un igroup que enumere los nombres de iniciadores iSCSI o WWN de FC que requieren acceso.</block>
  <block id="6548788f050643897f7354b6df4488db" category="paragraph">En este ejemplo, se crea un igroup que contiene el iniciador iSCSI del host Linux.</block>
  <block id="da8490d81c1ef6b559b09c2ab94631d2" category="section-title">Apague el entorno</block>
  <block id="0bf211160ad57fedca3499176f213b11" category="paragraph">Antes de cambiar el protocolo de LUN, las LUN deben estar completamente desactivadas. Cualquier base de datos en uno de los LUN que se van a convertir debe cerrarse, los sistemas de archivos deben desmontarse y los grupos de volúmenes deben desactivarse. Donde se utiliza ASM, asegúrese de que el grupo de discos de ASM está desmontado y cierre todos los servicios de grid.</block>
  <block id="2ba1c509ee5f5e31f05b24aed2d23054" category="section-title">Desasigne las LUN de la red FC</block>
  <block id="2f9e42c479a76dd54d7946c181049dd4" category="paragraph">Una vez que las LUN estén completamente en modo inactivo, quite las asignaciones del iGroup FC original.</block>
  <block id="5f889f52ef85be290c3e5c0211bbb8fa" category="section-title">Vuelva a asignar los LUN a la red IP</block>
  <block id="4ac84701530b31d8d33d9aa742715d25" category="paragraph">Otorgue acceso a cada LUN al nuevo grupo de iniciadores basado en iSCSI.</block>
  <block id="3d59eaa280c8b75d8e997eac2cf5b3e6" category="section-title">Detectar destinos iSCSI</block>
  <block id="981b782c3eacf8b87d8231b887873f03" category="paragraph">Existen dos fases para la detección iSCSI. El primero es detectar los destinos, que no es lo mismo que detectar una LUN. La<block ref="f88921f58beaaae5bcb9dffac54bf5ad" prefix=" " category="inline-code"></block> el comando que se muestra a continuación sondea el grupo de portales especificado por el<block ref="24e12535882a30ad33a21d76d76bd0ff" prefix=" " category="inline-code"></block> Y almacena una lista de todas las direcciones IP y puertos que ofrecen servicios iSCSI. En este caso, hay cuatro direcciones IP que tienen servicios iSCSI en el puerto predeterminado 3260.</block>
  <block id="0ab5dd035c7f92f4dce1026744c01604" category="admonition">Este comando puede tardar varios minutos en completarse si no se puede acceder a alguna de las direcciones IP de destino.</block>
  <block id="1dba8f39914c5f44e3cb635e7ac7563e" category="section-title">Descubra LUN de iSCSI</block>
  <block id="68307bef4b9dc4071d875a0c2aadd321" category="paragraph">Después de detectar los destinos iSCSI, reinicie el servicio iSCSI para detectar los LUN iSCSI disponibles y crear dispositivos asociados, como dispositivos multivía o ASMLib.</block>
  <block id="25d811252f87ae85dda97f2ab9dd1f3a" category="section-title">Reinicie el entorno</block>
  <block id="8a9aae851d31dae8baf96171f114955e" category="paragraph">Reinicie el entorno reactivando los grupos de volúmenes, volviendo a montar sistemas de archivos, reiniciando los servicios de RAC, etc. Como medida de precaución, NetApp recomienda reiniciar el servidor una vez que se haya completado el proceso de conversión para asegurarse de que todos los archivos de configuración sean correctos y de que se eliminen todos los dispositivos obsoletos.</block>
  <block id="00f4c8378b0bf837cee4b0aed8886f31" category="paragraph">Precaución: Antes de reiniciar un host, asegúrese de que todas las entradas en<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Que se comentan los recursos SAN migrados de referencia. Si este paso no se realiza y hay problemas con el acceso a la LUN, el resultado puede ser un sistema operativo que no se inicia. Este problema no daña los datos. Sin embargo, puede ser muy incómodo arrancar en modo de rescate o un modo similar y correcto<block ref="816a3ef77b62ade41c3f936c958aa555" prefix=" " category="inline-code"></block> Para que el sistema operativo se pueda iniciar para permitir que se inicien los esfuerzos de solución de problemas.</block>
  <block id="08e3cfb3c3dfa08d34bcbbfe07fe5f28" category="paragraph">La gestión segura y eficaz de varias bases de datos Oracle requiere una estrategia de QoS eficaz. La razón es el aumento constante en las funcionalidades de rendimiento de un sistema de almacenamiento moderno.</block>
  <block id="3408fe4b6e4b2ed9366356f08e3b9ab0" category="summary">Eficiencia del almacenamiento y bases de datos de Oracle</block>
  <block id="151654fbc652cca26707bd7a060073d3" category="doc">Funciones de eficiencia de ONTAP y bases de datos de Oracle</block>
  <block id="4564218d346b0ef8263512ebe659337d" category="paragraph">Las funciones de gestión eficiente del espacio de ONTAP se optimizan para las bases de datos de Oracle. En casi todos los casos, el mejor método es dejar los valores predeterminados con todas las funciones de eficiencia activadas.</block>
  <block id="794c6d3bb54da92d9a4a4022bc5c4e94" category="summary">Bases de datos RAID y Oracle</block>
  <block id="e959fe6bb794f67f31a0d4e6bc5d5bf4" category="paragraph">RAID se refiere al uso de redundancia para proteger los datos contra la pérdida de una unidad.</block>
  <block id="b60b0e7c75501fe2f322675f2e6da6d7" category="paragraph">De vez en cuando se plantean preguntas sobre los niveles de RAID en la configuración del almacenamiento NetApp utilizado para las bases de datos de Oracle y otras aplicaciones empresariales. Muchas de las mejores prácticas de Oracle heredadas sobre la configuración de la cabina de almacenamiento contienen advertencias sobre el uso de mirroring de RAID y/o la prevención de ciertos tipos de RAID. Aunque plantean puntos válidos, estas fuentes no se aplican a RAID 4 y a las tecnologías de NetApp RAID DP y RAID-TEC utilizadas en ONTAP.</block>
  <block id="6de6bcceac7c1a53ecb774d42b8d5c9a" category="summary">Thin Provisioning de Oracle y ONTAP</block>
  <block id="26c71bfc140fc9f2d56f83f7aedffd53" category="paragraph">El thin provisioning para una base de datos de Oracle requiere una planificación cuidadosa porque el resultado es configurar más espacio en un sistema de almacenamiento del que necesariamente está disponible físicamente. Vale mucho la pena el esfuerzo porque, cuando se hace correctamente, el resultado es un ahorro significativo de costes y mejoras en la capacidad de gestión.</block>
  <block id="c9a6446e7a1a2aa2d3d06c76b3dd02ae" category="summary">Aprovisionamiento de SVM para bases de datos de Oracle</block>
  <block id="eaa6380760494a867d1be23523aaba3e" category="doc">Oracle Database y Storage Virtual Machines</block>
  <block id="ffa2dec61afa63c15c9906328e62e2e8" category="paragraph">La gestión del almacenamiento de bases de datos de Oracle se centraliza en una máquina virtual de almacenamiento (SVM).</block>
  <block id="ba0fd7b6bfa61ad7f7ad5326a0934d01" category="summary">Se requiere comprender las funciones de toma de control y conmutación de sitios de almacenamiento para garantizar que estas operaciones no interrumpan las operaciones de la base de datos de Oracle. Además, los argumentos utilizados por las operaciones de toma de control y conmutación de sitios pueden afectar a la integridad de los datos si se usan incorrectamente.</block>
  <block id="999548558d2844d78a3b5f9186c231a4" category="summary">Bases de datos y la capacidad de almacenamiento y el espacio libre de ONTAP</block>
  <block id="360612d74cdd78953036946ec943f795" category="paragraph">Gestionar una base de datos u otra aplicación empresarial con almacenamiento empresarial predecible, gestionable y de alto rendimiento requiere cierto espacio libre en las unidades para la gestión de datos y metadatos. La cantidad de espacio libre necesario depende del tipo de unidad utilizada y los procesos empresariales.</block>
  <block id="d3cc759510a3aba837fc8efeb2e24b91" category="doc">db_file_multibloque_read_count</block>
  <block id="32faf0a922da10425f2be9f86a5f5e18" category="paragraph">La<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> El parámetro controla el Núm. Máximo de bloques de bases de datos Oracle que Oracle lee como una sola operación durante la E/S secuencial</block>
  <block id="36cb03af3dc688208e0e94fda31ca7a4" category="paragraph">Sin embargo, este parámetro no afecta a la cantidad de bloques que Oracle lee durante cualquier operación de lectura ni afecta a las operaciones de lectura aleatorias Solo se ve afectado el tamaño de bloque de I/O secuencial.</block>
  <block id="2565c992b3732464484104f4c846d9b4" category="paragraph">Oracle recomienda que el usuario deje este parámetro sin definir. Al hacerlo, el software de la base de datos puede definir automáticamente el valor óptimo. Por lo general, este parámetro se establece en un valor que proporciona un tamaño de I/O de 1MB. Por ejemplo, una lectura de 1MB de bloques de 8KB requeriría la lectura de 128 bloques y el valor predeterminado de este parámetro sería, por lo tanto, de 128.</block>
  <block id="0fd26e725a6c1a81508e013094776e2c" category="paragraph">La mayoría de los problemas de rendimiento de la base de datos observados por NetApp en los sitios de los clientes implican una configuración incorrecta para este parámetro. Hay motivos válidos para cambiar este valor con las versiones 8 y 9 de Oracle. Como resultado, el parámetro puede estar presente sin saberlo en<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> Archivos porque la base de datos se actualizó in situ a Oracle 10 y versiones posteriores. Una configuración heredada de 8 o 16, en comparación con el valor predeterminado de 128, daña significativamente el rendimiento de I/O secuencial.</block>
  <block id="3f594bb922365c7a9f095f44822fa22e" category="admonition">*NetApp recomienda* configurar el<block ref="d3cc759510a3aba837fc8efeb2e24b91" prefix=" " category="inline-code"></block> el parámetro no debe estar presente en el<block ref="b6bd7c570605affc5b50bbd3e436f0c0" prefix=" " category="inline-code"></block> archivo. NetApp nunca se ha encontrado con una situación en la que cambiar este parámetro mejoró el rendimiento, pero hay muchos casos en los que causó daños claros en el rendimiento de I/O secuencial.</block>
  <block id="0eec903bb9d87349e379892ca99ef9ec" category="paragraph">Oracle RAC es un producto de clusterware con varios tipos de procesos internos de latido que controlan el estado del cluster.</block>
  <block id="7c13d022c9fda6e792c4349a043a6c74" category="inline-link-macro">recuento de errores</block>
  <block id="bab4ae46619fcbbb84e3375ef205e61c" category="admonition">La información de la <block ref="9cd17d807316d35ef47b12cbecab4ec8" category="inline-link-macro-rx"></block> La sección incluye información crítica para entornos Oracle RAC que utilizan almacenamiento en red y, en muchos casos, la configuración predeterminada de Oracle RAC deberá cambiarse para garantizar que el cluster RAC sobrevive los cambios de ruta de red y las operaciones de failover/switchover de almacenamiento.</block>
  <block id="0494651671c3dc7f1ccdf99a4368a2cf" category="section-title">tiempo de espera del disco</block>
  <block id="1973cfff3b7c6d828ede9d420b8481b5" category="paragraph">El parámetro de RAC relacionado con el almacenamiento primario es<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>. Este parámetro controla el umbral en el que debe completarse la E/S del archivo de quorum. Si la<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> Se supera el parámetro y el nodo RAC se expulsa del clúster. El valor predeterminado de este parámetro es 200. Este valor debería ser suficiente para los procedimientos estándar de toma de control y devolución del almacenamiento.</block>
  <block id="4aa33fc988e36b9531d36da80d35ec2f" category="paragraph">NetApp recomienda probar exhaustivamente las configuraciones de RAC antes de colocarlas en producción, ya que existen muchos factores que afectan a una toma de control o al retorno primario. Además del tiempo necesario para que se complete la conmutación por error del almacenamiento, también se requiere más tiempo para que se propaguen los cambios del protocolo de control de agregación de enlaces (LACP). Además, el software multivía SAN debe detectar un tiempo de espera de I/O y volver a intentarlo en una ruta alternativa. Si una base de datos está extremadamente activa, se debe poner en cola una gran cantidad de E/S y volver a intentarlo antes de procesar la E/S del disco de quorum.</block>
  <block id="655a10764a0781d26dca3bfb939457b7" category="paragraph">Si no se puede realizar una toma de control o una devolución del almacenamiento real, el efecto se puede simular mediante pruebas de extracción de cables en el servidor de bases de datos.</block>
  <block id="b2a9e8dd67b2d9a7333cb2c2495c2aa5" category="list-text">Dejando el<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> parámetro con el valor predeterminado de 200.</block>
  <block id="971a52f4b805c654dd133cf142457c53" category="list-text">Pruebe siempre a fondo una configuración de RAC.</block>
  <block id="cd7a91511dbfbe5c79de12fa7d394dc0" category="paragraph">La<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> Normalmente, el parámetro sólo afecta al latido de red entre los nodos de RAC. El valor predeterminado es 30 segundos. Si los binarios de grid se encuentran en una cabina de almacenamiento o si la unidad de arranque del sistema operativo no es local, este parámetro puede volverse importante. Esto incluye hosts con unidades de arranque ubicadas en una SAN FC, sistemas operativos arrancados NFS y unidades de arranque ubicadas en almacenes de datos de virtualización, como un archivo VMDK.</block>
  <block id="9c1fd24d7d8e04847dadb944a6643121" category="paragraph">Si el acceso a una unidad de arranque se interrumpe por una toma de control o una restauración del almacenamiento, es posible que la ubicación binaria del grid o todo el sistema operativo se bloquee temporalmente. El tiempo necesario para que ONTAP complete la operación de almacenamiento y que el sistema operativo cambie de rutas y reanude las I/O puede superar el<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> umbral. Como resultado, un nodo se expulsa inmediatamente después de restaurar la conectividad con el LUN de arranque o los binarios de grid. En la mayoría de los casos, la expulsión y el reinicio posterior se producen sin mensajes de registro que indiquen el motivo del reinicio. No todas las configuraciones se ven afectadas, por lo que debe realizar pruebas de cualquier host basado en almacenes de datos, arranque en NFS o arranque en SAN en un entorno RAC para que RAC se mantenga estable si se interrumpe la comunicación con la unidad de arranque.</block>
  <block id="2b875dbca82565f3d7e2fa51633bc2c9" category="paragraph">En el caso de unidades de arranque no locales o de un sistema de archivos no local<block ref="ff4a008470319a22d9cf3d14af485977" prefix=" " category="inline-code"></block> binarios, el<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> será necesario cambiar para que coincida<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>. Si se cambia este parámetro, realice otras pruebas para identificar también cualquier efecto sobre el comportamiento de RAC, como el tiempo de conmutación por error del nodo.</block>
  <block id="08d7a86ed9292993deaa28bee18d5ce5" category="list-text">Abandone el<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> parámetro con el valor por defecto de 30 a menos que se aplique una de las siguientes condiciones:</block>
  <block id="5b46e861366ffd98cd94c26abf2bf550" category="list-text"><block ref="ff4a008470319a22d9cf3d14af485977" prefix="" category="inline-code"></block> Los binarios se encuentran en una unidad conectada a la red, como las unidades basadas en almacén de datos, NFS, iSCSI y FC.</block>
  <block id="7ace6d79e63cb29c86093526fbddf845" category="list-text">El sistema operativo se inicia mediante SAN.</block>
  <block id="985511d6258bbf659d35bd76e0b0cea1" category="list-text">En tales casos, evalúe el efecto de las interrupciones de la red que afectan el acceso al sistema operativo o.<block ref="9599929f8663b5e2093f7bc5cb20b0c2" prefix=" " category="inline-code"></block> sistemas de ficheros: En algunos casos, estas interrupciones provocan que los daemons de Oracle RAC se atasquen, lo que puede provocar un<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block>-basado en tiempo de espera y desalojo. El tiempo de espera predeterminado es 27 segundos, que es el valor de<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> menos<block ref="c9333b0a26b9f9e9fd808e6238d613b0" prefix=" " category="inline-code"></block>. En tales casos, aumentar<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> a 200 para coincidir<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block>.</block>
  <block id="a3f7c31b8d967e0ac9f9dd30fc81c061" category="paragraph">Parámetro de inicialización de Oracle<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> Controla el uso de la E/S asíncrona y directa</block>
  <block id="d1fa3441fd96418a75a509ac2907d644" category="paragraph">Contrariamente a la creencia común, las E/S asincrónicas y directas no son mutuamente excluyentes. NetApp ha observado que este parámetro suele estar mal configurado en los entornos del cliente, y esta mala configuración es el responsable directo de muchos problemas de rendimiento.</block>
  <block id="0775b72ddf51e2a16e466ee2df8f75ab" category="paragraph">La E/S asíncrona significa que las operaciones de I/O de Oracle se pueden paralelizar. Antes de la disponibilidad de E/S asíncrona en varios sistemas operativos, los usuarios configuraron numerosos procesos de escritura de base de datos y cambiaron la configuración del proceso del servidor. Con la E/S asíncrona, el propio sistema operativo realiza E/S en nombre del software de base de datos de forma paralela y altamente eficiente. Este proceso no pone los datos en riesgo y las operaciones críticas, como el redo registro de Oracle, se siguen realizando de forma síncrona.</block>
  <block id="6b72950206966c1983e559eb6886ec69" category="paragraph">La E/S directa omite la caché de buffers del SO. Las E/S en un sistema UNIX normalmente fluyen a través de la caché de buffers del sistema operativo. Esto es útil para aplicaciones que no mantienen una caché interna, pero Oracle tiene su propia caché de buffers en SGA. En casi todos los casos, es mejor habilitar la E/S directa y asignar la RAM del servidor a la SGA en lugar de confiar en la caché de buffers del SO. Oracle SGA utiliza la memoria de forma más eficaz. Además, cuando la I/O fluye por el búfer del SO, se somete a un procesamiento adicional, lo que aumenta las latencias. El aumento de las latencias es especialmente notable en operaciones pesadas de I/O de escritura cuando un requisito crucial es la baja latencia.</block>
  <block id="d8590a940a5bb30d8a845f4359f3c779" category="paragraph">Las opciones para<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> son:</block>
  <block id="0aea10c6719256027228a859db38f291" category="list-text">*Async.* Oracle envía solicitudes de E/S al sistema operativo para su procesamiento. Este proceso permite a Oracle realizar otro trabajo en lugar de esperar la finalización de E/S y, por lo tanto, aumenta la paralelización de E/S.</block>
  <block id="00cb0cc309682c42b3b936a19a042434" category="list-text">*Directio.* Oracle realiza E/S directamente contra archivos físicos en lugar de enrutar E/S a través de la caché del SO host.</block>
  <block id="f9941e1b6cc84711e95db0e757efc36a" category="list-text">*None.* Oracle utiliza E/S síncronas y en buffer En esta configuración, la elección entre los procesos de servidor compartido y dedicado y el número de dbwriters son más importantes.</block>
  <block id="f0939ff6231565c83c5c8c9ce1eddc9d" category="list-text">*Setall.* Oracle utiliza E/S tanto asíncrona como directa En casi todos los casos, el uso de<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block> es óptimo.</block>
  <block id="8647b2eaf101a9425f69e6f2e67aeb9d" category="admonition">La<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> El parámetro no tiene ningún efecto en los entornos DNFS y ASM. El uso de DNFS o ASM da como resultado el uso de E/S tanto asíncrona como directa</block>
  <block id="6dd5604aa0be2956f8b1b41c74fa648e" category="paragraph">Algunos clientes se han encontrado con problemas de E/S asíncronos en el pasado, especialmente con versiones anteriores de Red Hat Enterprise Linux 4 (RHEL4). Algunos consejos anticuados en Internet todavía sugieren evitar la IO asíncrona debido a la información obsoleta. La E/S asíncrona es estable en todos los sistemas operativos actuales. No hay motivo para desactivarlo, sin un error conocido en el sistema operativo.</block>
  <block id="1ea377466376b194b2d1bfc3ab2fa4c4" category="paragraph">Si una base de datos ha estado utilizando E/S en búfer, un cambio a E/S directa también puede justificar un cambio en el tamaño de SGA. Al desactivar las E/S en buffer, se elimina la ventaja de rendimiento que proporciona la caché del SO del host para la base de datos. Al volver a agregar RAM a SGA se soluciona este problema. El resultado neto debe ser una mejora en el rendimiento de E/S.</block>
  <block id="787b3d8b62af05ac3efd1c9ca7a8fc7e" category="paragraph">Aunque casi siempre es mejor utilizar RAM para Oracle SGA que para el almacenamiento en caché de buffers del sistema operativo, puede ser imposible determinar el mejor valor. Por ejemplo, puede ser preferible utilizar E/S en buffer con tamaños SGA muy pequeños en un servidor de bases de datos con muchas instancias de Oracle activas de forma intermitente. Esta disposición permite el uso flexible de la RAM libre restante en el SO por todas las instancias de base de datos en ejecución. Se trata de una situación muy inusual, pero se ha observado en algunos sitios de clientes.</block>
  <block id="d4157ab77eb31459bd406aa0f873e20c" category="admonition">*NetApp recomienda* ajuste<block ref="f1110589be196c2310808482067fce1b" prefix=" " category="inline-code"></block> para<block ref="aef8f91b1e026cc1bb55e8b08c491d35" prefix=" " category="inline-code"></block>, Pero tenga en cuenta que, en algunas circunstancias, la pérdida de la caché de buffers del host puede requerir un aumento en Oracle SGA.</block>
  <block id="f8b42f9efd1a05ede10b0e0c11dfa8b0" category="paragraph">ONTAP utiliza internamente un tamaño de bloque variable, lo que significa que las bases de datos Oracle se pueden configurar con el tamaño de bloque deseado. Sin embargo, los tamaños de bloque del sistema de archivos pueden afectar al rendimiento y, en algunos casos, un tamaño de bloque de redo más grande puede mejorar el rendimiento.</block>
  <block id="0944aedb4703c4a5e94fb90de9d7a22f" category="section-title">Tamaños de bloque de archivos de datos</block>
  <block id="cc4662c047050e0082701ce6f052dcb7" category="paragraph">Algunos sistemas operativos ofrecen diferentes tamaños de bloque del sistema de archivos. En el caso de los sistemas de archivos que admiten archivos de datos de Oracle, el tamaño de bloque debe ser 8KB cuando se utiliza la compresión. Cuando no se necesita compresión, se puede utilizar un tamaño de bloque de 8KB KB o 4KB KB.</block>
  <block id="e1a001cf8c7e2072c7a44ee65e8fee11" category="paragraph">Si se coloca un archivo de datos en un sistema de archivos con un bloque de 512 bytes, es posible que los archivos estén mal alineados. El LUN y el sistema de archivos podrían alinearse correctamente de acuerdo con las recomendaciones de NetApp, pero la I/O de archivo estaría mal alineada. Tal desalineación podría causar graves problemas de rendimiento.</block>
  <block id="9514c8638f798f68108498dd218ec793" category="paragraph">Los sistemas de archivos compatibles con redo logs deben utilizar un tamaño de bloque que sea múltiplo del tamaño del bloque de redo. Esto generalmente requiere que tanto el sistema de archivos redo log como el propio redo log utilicen un tamaño de bloque de 512 bytes.</block>
  <block id="cac7d87a1164763b666ca7d02109d153" category="section-title">Rehacer tamaños de bloques</block>
  <block id="fa06b9584ea36af182742c07894220f0" category="paragraph">Con tasas de redo muy elevadas, es posible que los bloques de 4KB KB rindan mejor porque las tasas de rehacer elevadas permiten realizar I/O en operaciones cada vez más eficientes. Si las tasas de redo son mayores que 50Mbps, considere la posibilidad de probar un tamaño de bloque de 4KB KB.</block>
  <block id="781000593b4913b5625dd5ed9eebe87e" category="paragraph">Se han identificado algunos problemas de los clientes con bases de datos que utilizan redo logs con un tamaño de bloque de 512 bytes en un sistema de archivos con un tamaño de bloque de 4KB KB y muchas transacciones muy pequeñas. La sobrecarga involucrada en la aplicación de varios cambios de 512 bytes a un único bloque del sistema de archivos de 4KB se tradujo en problemas de rendimiento que se resolvieron mediante el cambio del sistema de archivos para que utilizara un tamaño de bloque de 512 bytes.</block>
  <block id="a02416fde36b174cf1196213fcf1bef6" category="admonition">*NetApp recomienda* que no cambie el tamaño del bloque de redo a menos que se lo indique un servicio de atención al cliente relevante o una organización de servicios profesionales o que el cambio se base en la documentación oficial del producto.</block>
  <block id="65a6ece62f52a5e2ff74baaae821ae86" category="paragraph">La recuperación tras desastres se refiere a la restauración de servicios de datos tras un evento catastrófico, como un incendio que destruye un sistema de almacenamiento o incluso un sitio entero.</block>
  <block id="e168b3b0b2f075f39012df52c5ea3c0a" category="admonition">Esta documentación sustituye a los informes técnicos publicados anteriormente _TR-4591: Oracle Data Protection_ y _TR-4592: Oracle en MetroCluster._</block>
  <block id="a91982f09e6a0341a90dae002865ea11" category="paragraph">La recuperación tras desastres puede llevarse a cabo mediante la replicación sencilla de datos mediante SnapMirror; por supuesto, muchos clientes actualizan réplicas replicadas cada hora.</block>
  <block id="ad2c5e9521f13e89cd84fdd65ec96c7d" category="paragraph">MetroCluster se refiere a ONTAP en una configuración de hardware que incluye almacenamiento reflejado sincrónico de bajo nivel y numerosas funciones adicionales. Las soluciones integradas como MetroCluster simplifican las complicadas infraestructuras de bases de datos, aplicaciones y virtualización actuales y de escalado horizontal. Reemplaza múltiples productos y estrategias de protección de datos externa por una cabina de almacenamiento simple y central. También proporciona integración de backup, recuperación, recuperación tras siniestros y alta disponibilidad (HA) en un único sistema de almacenamiento en clúster.</block>
  <block id="a38cb04f35bd24313f90398cdc07e149" category="paragraph">El siguiente diagrama muestra un modelo de despliegue sencillo en el que se están dividiendo o conectando dispositivos de almacenamiento desde los clusters de almacenamiento primario y remoto de una base de datos Oracle.</block>
  <block id="ac38db4f14e512b48d088eedb84cd611" category="paragraph">Oracle sólo está configurado en el primario. Este modelo aborda la conmutación al nodo de respaldo de almacenamiento fluida en el caso de desastres en el almacenamiento, por lo que no se pierden datos sin que se produzcan tiempos de inactividad de las aplicaciones. Sin embargo, este modelo no ofrecería alta disponibilidad del entorno de base de datos durante un fallo del sitio. Este tipo de arquitectura resulta útil para los clientes que buscan una solución con cero pérdida de datos con alta disponibilidad de los servicios de almacenamiento, pero aceptan que una pérdida total del cluster de la base de datos requeriría trabajo manual.</block>
  <block id="4e072ef2eba1c46e59475046cd4fb880" category="paragraph">Este método también permite ahorrar dinero en costes de licencia de Oracle. La configuración previa de los nodos de la base de datos Oracle en el sitio remoto requeriría que todos los núcleos tengan una licencia bajo la mayoría de los acuerdos de licencia de Oracle. Si se acepta el retraso ocasionado por el tiempo necesario para instalar un servidor de bases de datos Oracle y montar la copia de los datos superviviente, este diseño puede resultar muy rentable.</block>
  <block id="9331b3ad2bcf259818157930e1c82ad3" category="paragraph">Por ejemplo, puede crear un clúster de Oracle RAC que aloje seis bases de datos individuales. El almacenamiento de tres de las bases de datos se alojaría principalmente en el sitio A, y el almacenamiento para las otras tres bases de datos se alojaría en el sitio B. Esta configuración garantiza el mejor rendimiento posible al minimizar el tráfico entre sitios. Además, las aplicaciones se configurarían para utilizar las instancias de base de datos locales en el sistema de almacenamiento con rutas activas. Esto minimiza el tráfico de interconexión RAC. Por último, este diseño general garantiza que todos los recursos informáticos se utilicen de la misma forma. A medida que cambian las cargas de trabajo, se puede conmutar al nodo de respaldo de forma selectiva en todos los sitios para garantizar una carga uniforme.</block>
  <block id="4278792a47efb1e599476fe07109dca4" category="inline-link-macro">Oracle RAC en MetroCluster</block>
  <block id="8eea62084ca7e541d918e823422bd82e" category="cell">Resultado</block>
  <block id="ee70ac41df7240931fee4110b599c39f" category="cell">Fallo del enlace de replicación</block>
  <block id="e79e76eca171f3e596eb56ba4bb24743" category="cell">Mediador reconoce este escenario de cerebro dividido y reanuda las E/S en el nodo que contiene la copia maestra. Cuando la conectividad entre los sitios vuelve a estar en línea, el sitio alternativo realiza una resincronización automática.</block>
  <block id="98a638ba6cee257a8f751bcf8d30e1f2" category="cell">Fallo del almacenamiento en el sitio principal</block>
  <block id="b92af6cefecfe68535bbd851b797379f" category="cell">Mediator inicia la conmutación automática por error imprevista.

Sin interrupciones de las operaciones de I/O.</block>
  <block id="ce9a584219636ca5b159a27f2dd8c445" category="cell">Fallo del almacenamiento en un sitio remoto</block>
  <block id="68a293bd16c4e2589057d43506a5afbd" category="cell">No hay interrupción de I/O. Hay una pausa momentánea debido a que la red hace que se aborte la replicación de sincronización y el maestro establece que es el propietario legítimo continuar sirviendo E/S (consenso). Por lo tanto, hay una pausa de I/O de unos segundos y, a continuación, se reanudará la actividad de I/O.

Hay una resincronización automática cuando el sitio está en línea.</block>
  <block id="64f4e3573d0b569ef7b5a08476fb9f7d" category="cell">Pérdida de mediador o enlace entre Mediator y las cabinas de almacenamiento</block>
  <block id="7e7abe23ef8e465ee1b6879b35e6bab3" category="cell">Las operaciones de I/O continúan y permanecen sincronizadas con el clúster remoto, pero la conmutación por error y la conmutación tras recuperación automatizadas no planificadas o imprevistas no son posibles si no existe Mediator.</block>
  <block id="96b352ebd03c8c5b7589a527b18f1a2d" category="cell">Pérdida de una de las controladoras de almacenamiento en el clúster de alta disponibilidad</block>
  <block id="426c4468c3cc76191842240593fcfec3" category="cell">El nodo asociado del clúster de alta disponibilidad intenta tomar el control (NDO). Si la toma de control falla, Mediator advierte que tanto el nodo del almacenamiento no funciona y lleva a cabo una conmutación automática al respaldo no planificada en el clúster remoto.</block>
  <block id="0e578c93ab393c3d449d484e9fa4b84e" category="cell">Pérdida de discos</block>
  <block id="3d5fea5d89ec844fc92c08a585050e4e" category="cell">I/O continúa en casos de fallos de disco consecutivos. Esto es parte de RAID-TEC.</block>
  <block id="bd300f92769c0ee071832cadaff91f04" category="cell">Pérdida de todo el sitio en una puesta en marcha típica</block>
  <block id="d12be40db836559c628e8024f5d6ff56" category="paragraph">Para comprender el funcionamiento de las bases de datos Oracle en un entorno MetroCluster, es necesario explicar el diseño físico de un sistema MetroCluster.</block>
  <block id="5e33c0d8a2417ce5fb6e7a211ad063bb" category="admonition">Esta documentación sustituye al informe técnico _TR-4592 publicado anteriormente: Oracle en MetroCluster._</block>
  <block id="37fa92fc2662529308c62c84eb1b38ea" category="paragraph">Comprender el funcionamiento de las bases de datos Oracle en un entorno MetroCluster alsop requiere alguna explicación de la funcionalidad lógica de un sistema MetroCluster.</block>
  <block id="2623b589ddbc1cdb6184ba32aa06e83f" category="inline-link-macro">NVFAIL</block>
  <block id="a4feacea8b05d0f24e5a4612a164a055" category="paragraph">Siguen siendo aplicables las prácticas recomendadas habituales y, si sus necesidades solo requieren protección de datos con objetivo de punto de recuperación = 0, esta se cumplirá con MetroCluster. Sin embargo, la mayoría de los clientes utilizan MetroCluster no solo para la protección de datos con objetivo de punto de recuperación = 0, sino también para mejorar el objetivo de tiempo de recuperación durante escenarios de desastre, y proporcionar una conmutación por error transparente como parte de las actividades de mantenimiento del sitio.</block>
  <block id="3ff8bcf18c694581aa25b0a347508e0f" category="section-title">Conmutación al nodo de respaldo con un SO preconfigurado</block>
  <block id="9bd9ad7f296a0e8ac3df804b3c6a392f" category="paragraph">SyncMirror ofrece una copia síncrona de los datos del sitio de recuperación de desastres, pero para que los datos estén disponibles, requiere un sistema operativo y las aplicaciones asociadas. La automatización básica puede mejorar drásticamente el tiempo de conmutación al nodo de respaldo del entorno global. Los productos de Clusterware como Oracle RAC, Veritas Cluster Server (VCS) o VMware HA se utilizan a menudo para crear un clúster en todos los sitios y, en muchos casos, el proceso de conmutación por error se puede realizar con scripts sencillos.</block>
  <block id="c5a2f3b867d990c681a218d29a55fcfa" category="paragraph">Si se pierden los nodos primarios, el clusterware (o scripts) se configura para poner las aplicaciones en línea en el sitio alternativo. Una opción es crear servidores en espera que estén preconfigurados para los recursos NFS o SAN que componen la aplicación. Si el sitio principal falla, el clusterware o la alternativa con secuencia de comandos realiza una secuencia de acciones similar a las siguientes:</block>
  <block id="442f34633164f1be348a442b2c62d29d" category="list-text">Forzar un cambio de MetroCluster</block>
  <block id="e081e79ea1b1040c51d4a452e46de76d" category="list-text">Detección de LUN FC (solo SAN)</block>
  <block id="6f3fd86521759fc98ed93853eaf8a03a" category="list-text">Montaje de sistemas de archivos</block>
  <block id="9d9ea7a9c532a3cec63305130018a45b" category="list-text">Iniciando la aplicación</block>
  <block id="b8eca7b573624230962095fcadb03ddf" category="paragraph">El requisito principal de este método es un sistema operativo en ejecución instalado en el sitio remoto. Se debe preconfigurar con binarios de aplicación, lo que también significa que las tareas como la aplicación de parches se deben realizar en la ubicación primaria y en espera. Como alternativa, los archivos binarios de la aplicación pueden duplicarse en el sitio remoto y montarse si se declara un desastre.</block>
  <block id="e60946bf73021e18706a6ac33386b376" category="paragraph">El procedimiento de activación real es simple. Los comandos como la detección de LUN sólo requieren unos pocos comandos por puerto FC. El montaje del sistema de archivos no es más que un<block ref="19822b1b15d9eefc54c07ab49f87b100" prefix=" " category="inline-code"></block> Y tanto las bases de datos como ASM se pueden iniciar y parar en la CLI con un único comando. Si los volúmenes y los sistemas de archivos no se están utilizando en el sitio de recuperación de desastres antes de la conmutación de sitios, no es necesario establecerlos<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> en los volúmenes.</block>
  <block id="486eed21f55b6fb544db5504294592e6" category="section-title">Conmutación por error con un sistema operativo virtualizado</block>
  <block id="bf65e943f86f26b49698bfdac9b95f81" category="paragraph">La conmutación por error de los entornos de base de datos puede ampliarse para incluir el propio sistema operativo. En teoría, esta recuperación tras fallos se puede realizar con las LUN de arranque, pero la mayoría de las veces se realiza con un sistema operativo virtualizado. El procedimiento es similar a los siguientes pasos:</block>
  <block id="7c37589384e83d2b43bba430c18a45aa" category="list-text">Montar los almacenes de datos que alojan las máquinas virtuales del servidor de bases de datos</block>
  <block id="3d4d04d6cdab90b7ca0deb0344f04eec" category="list-text">Inicio de las máquinas virtuales</block>
  <block id="ba2f22f63087151f0a0694be5f35fcf2" category="list-text">Iniciar las bases de datos manualmente o configurar las máquinas virtuales para iniciar automáticamente las bases de datos</block>
  <block id="810078f3b19b93e24de8638d68f727b5" category="paragraph">Por ejemplo, un clúster ESX podría abarcar sitios. En caso de desastre, los equipos virtuales pueden conectarse en línea en el sitio de recuperación ante desastres después del cambio. Mientras los almacenes de datos que alojan los servidores de bases de datos virtualizadas no estén en uso en el momento del desastre, no es necesario configurarlos<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> en los volúmenes asociados.</block>
  <block id="c702c387f07bcb4f18482e68d69a155a" category="paragraph">La base de la protección de datos de Oracle con un sistema MetroCluster es SyncMirror, una tecnología de mirroring síncrono de escalado horizontal y máximo rendimiento.</block>
  <block id="9028b52caaa7bdbfb9be779eeb1fe00e" category="summary">Oracle Extended RAC con MetroCluster</block>
  <block id="dbcedb2fd86e6012347a3c9ad111f3a8" category="doc">Oracle RAC ampliado en MetroCluster</block>
  <block id="4d4d8a609e5b2ac58e622eb1e90f9e39" category="paragraph">Muchos clientes optimizan su objetivo de tiempo de recuperación al ampliar un clúster de Oracle RAC en todos los sitios, lo que proporciona una configuración completamente activo-activo. El diseño general se complica porque debe incluir la gestión de quórum de Oracle RAC. Además, se accede a los datos desde ambos sitios, lo que significa que una conmutación por error forzada puede provocar el uso de una copia desactualizada de los datos.</block>
  <block id="89ffaa1a7d089080e9a1ce912bb8c2d3" category="paragraph">Aunque se encuentra una copia de los datos en ambos sitios, solo la controladora que actualmente posee un agregado puede servir datos. Por lo tanto, con clústeres RAC ampliados, los nodos remotos deben ejecutar operaciones de I/O a través de una conexión de sitio a sitio. El resultado es una latencia de I/O añadida, pero esta latencia no suele ser un problema. La red de interconexión de RAC también debe extenderse entre sitios, lo que significa que se necesita una red de alta velocidad y baja latencia de todos modos. Si la latencia añadida provoca un problema, el clúster se puede operar de una forma activa-pasiva. Luego, las operaciones con un gran volumen de I/O deben dirigirse a los nodos de RAC locales a la controladora propietaria de los agregados. A continuación, los nodos remotos realizan operaciones de E/S más ligeras o se utilizan únicamente como servidores de espera templados.</block>
  <block id="375c3caa97162bd0c2c07869d9c5b026" category="paragraph">Si se requiere un RAC extendido activo-activo, se debe considerar el mirroring de ASM en lugar de MetroCluster. La duplicación de ASM permite que se prefiera una réplica específica de los datos. Por lo tanto, se puede crear un clúster RAC ampliado en el que todas las lecturas se realicen localmente. La I/O de lectura nunca se cruza con los sitios, lo que ofrece la menor latencia posible. Toda la actividad de escritura debe seguir transfiriendo la conexión entre sitios, pero dicho tráfico es inevitable con cualquier solución de mirroring síncrono.</block>
  <block id="f441d5fdc388f3419fb87e071534f3ce" category="inline-link-macro">Oracle RAC con ONTAP</block>
  <block id="59d934fc4614a6275fef2828bfab30cf" category="admonition">Si las LUN de inicio, incluidos los discos de inicio virtualizados, se utilizan con Oracle RAC, el<block ref="7c13d022c9fda6e792c4349a043a6c74" prefix=" " category="inline-code"></block> es posible que sea necesario cambiar el parámetro. Para obtener más información sobre los parámetros de tiempo de espera de RAC, consulte <block ref="75080d28a1748f78cf8a666ababf51af" category="inline-link-macro-rx"></block>.</block>
  <block id="58285fb769eb7fb05ab12d9e0efb3e50" category="section-title">Configuración de dos sitios</block>
  <block id="af1184f29d838fbfec8d5b5bf5225f66" category="paragraph">Una configuración de RAC ampliada de dos sitios puede ofrecer servicios de base de datos activa-activa que pueden sobrevivir muchos escenarios de desastres de forma no disruptiva, pero no todos.</block>
  <block id="7544489c7854fcae445508015240a865" category="section-title">Archivos de quorum de RAC</block>
  <block id="8b6e46422f88dab6ea82f2dbcadfc76b" category="paragraph">La primera consideración al implementar RAC ampliado en MetroCluster debe ser la gestión del quórum. Oracle RAC tiene dos mecanismos para gestionar el quórum: Latido de disco y latido de red. El latido del disco supervisa el acceso al almacenamiento mediante los archivos de votación. Con una configuración de RAC de un único sitio, un único recurso de votación es suficiente siempre que el sistema de almacenamiento subyacente ofrezca funcionalidades de alta disponibilidad.</block>
  <block id="fafd618b82d1827eeb8197e1c38722bc" category="paragraph">En versiones anteriores de Oracle, los archivos de quorum se colocaban en dispositivos de almacenamiento físico, pero en las versiones actuales de Oracle los archivos de quorum se almacenan en grupos de discos de ASM.</block>
  <block id="aeab2391a07321ac474989b9c9047226" category="admonition">Oracle RAC es compatible con NFS. Durante el proceso de instalación de grid, se crea un juego de procesos de ASM para presentar la ubicación NFS utilizada para los archivos de grid como un grupo de discos de ASM. El proceso es prácticamente transparente para el usuario final y no requiere una gestión de ASM en curso una vez finalizada la instalación.</block>
  <block id="42aca4aae768d5ec1cb0c50d41b7b8b7" category="paragraph">El primer requisito de una configuración de dos ubicaciones es asegurarse de que cada sitio siempre pueda acceder a más de la mitad de los archivos de votación de forma que se garantice un proceso de recuperación ante desastres sin interrupciones. Esta tarea era sencilla antes de que los archivos de votación se almacenaran en grupos de discos de ASM, pero hoy en día los administradores necesitan comprender los principios básicos de la redundancia de ASM.</block>
  <block id="60a723853bb2c173648452baf2199e73" category="paragraph">Los grupos de discos de ASM tienen tres opciones de redundancia<block ref="6a21b6995a068148bbb65c8f949b3fb2" prefix=" " category="inline-code"></block>,<block ref="fea087517c26fadd409bd4b9dc642555" prefix=" " category="inline-code"></block>, y.<block ref="8d966b2253a917086c8604959e152243" prefix=" " category="inline-code"></block>. En otras palabras, se refleja en 3 direcciones y no reflejado. Una opción más reciente llamada<block ref="09d2bd168181f1e64c2b1651a80a8aa8" prefix=" " category="inline-code"></block> también está disponible, pero rara vez se utiliza. El nivel de redundancia y la ubicación de los dispositivos redundantes controlan lo que sucede en escenarios de fallo. Por ejemplo:</block>
  <block id="32cdeb2c0245b51a0b590e6054f03c21" category="list-text">Colocación de los archivos de votación en un<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> con<block ref="6a21b6995a068148bbb65c8f949b3fb2" prefix=" " category="inline-code"></block> los recursos de redundancia garantizan el desalojo de un sitio si se pierde la conectividad entre sitios.</block>
  <block id="a549b4f1fc0c2d14bc333c70bbde73dc" category="list-text">Colocación de los archivos de votación en un<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> con<block ref="fea087517c26fadd409bd4b9dc642555" prefix=" " category="inline-code"></block> La redundancia con un solo disco ASM por sitio garantiza la expulsión de nodos en ambas ubicaciones si se pierde la conectividad entre sitios porque ninguno de los sitios tendría un quórum mayoritario.</block>
  <block id="c15f1c43a368db0ab3dde90eca52582d" category="list-text">Colocación de los archivos de votación en un<block ref="d4f266c5956ee60df748738c483f3dc0" prefix=" " category="inline-code"></block> con<block ref="8d966b2253a917086c8604959e152243" prefix=" " category="inline-code"></block> la redundancia con dos discos en un sitio y un solo disco en el otro sitio permite las operaciones activo-activo cuando ambos sitios están operativos y se puede acceder mutuamente. Sin embargo, si el sitio de un solo disco está aislado de la red, ese sitio se expulsa.</block>
  <block id="478ced47a1ea1d6f0db02af749bfdaec" category="section-title">Latido de red RAC</block>
  <block id="2432333dc52d6150fb3d58051bc8b0c2" category="paragraph">El latido de red de Oracle RAC supervisa la accesibilidad de nodos en la interconexión de cluster. Para permanecer en el clúster, un nodo debe ser capaz de contactar más de la mitad de los otros nodos. En una arquitectura de dos sitios, este requisito crea las siguientes opciones para el recuento de nodos de RAC:</block>
  <block id="3e36a59c8a51ee9cc2cba0e7051ed35f" category="list-text">La colocación de un número igual de nodos por sitio provoca el expulsión en un sitio en caso de que se pierda la conectividad de red.</block>
  <block id="4955aede919912b3c62fadbc1039671b" category="list-text">La colocación de los nodos N en un sitio y los nodos N+1 en el sitio opuesto garantiza que la pérdida de conectividad entre sitios da lugar al sitio con el mayor número de nodos restantes en el quórum de red y el sitio con menos nodos expulsados.</block>
  <block id="80bd651a66488201c928634689e2e5cc" category="paragraph">Antes de Oracle 12cR2, no era posible controlar qué lado experimentaría un desalojo durante la pérdida del sitio. Cuando cada ubicación tiene el mismo número de nodos, el nodo maestro controla la expulsión, que en general es el primer nodo RAC que se inicia.</block>
  <block id="d128c05245b2e633856a5061db176b7e" category="paragraph">Oracle 12cR2 introduce la capacidad de ponderación de nodos. Esta capacidad proporciona al administrador más control sobre cómo Oracle resuelve las condiciones de cerebro dividido. Como ejemplo sencillo, el siguiente comando establece la preferencia de un nodo concreto en un RAC:</block>
  <block id="104c5747f0d9dbb47b0d09953c709a8d" category="paragraph">Después de reiniciar Oracle High-Availability Services, la configuración tiene el siguiente aspecto:</block>
  <block id="693cce334ab6658c73ea67674775156b" category="paragraph">Nodo<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> ahora se designa como servidor crítico. Si los dos nodos de RAC están aislados,<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> sobrevive, y.<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> se expulsa.</block>
  <block id="386839b09451962d03e26b7bbfabce74" category="admonition">Para obtener más información, consulte el white paper de Oracle sobre Oracle Clusterware 12c Versión 2 Technical Overview. ”</block>
  <block id="11f65689342acc8f71c8014eeb7945ee" category="paragraph">Para las versiones de Oracle RAC anteriores a 12cR2, el nodo maestro se puede identificar comprobando los logs de CRS de la siguiente manera:</block>
  <block id="c8b8cd80b31dac17fb85459c341042bd" category="paragraph">Este log indica que el nodo maestro es<block ref="c81e728d9d4c2f636f067f89cc14862c" prefix=" " category="inline-code"></block> y el nodo<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> Tiene un ID de<block ref="c4ca4238a0b923820dcc509a6f75849b" prefix=" " category="inline-code"></block>. Este hecho significa eso<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> no es el nodo maestro. La identidad del nodo maestro se puede confirmar con el comando<block ref="08e7c60bbf8289a563b25cc033d431f7" prefix=" " category="inline-code"></block>.</block>
  <block id="fdf6179b59d3f4873b042609a5f09bc4" category="paragraph">El nodo con un ID de<block ref="c81e728d9d4c2f636f067f89cc14862c" prefix=" " category="inline-code"></block> es<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block>, que es el nodo maestro. En una configuración con el mismo número de nodos en cada sitio, el sitio con<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> es el sitio que sobrevive si los dos conjuntos pierden la conectividad de red por cualquier motivo.</block>
  <block id="f2932b43ad604fa01d57212558608ed6" category="paragraph">Es posible que la entrada de log que identifica el nodo maestro pueda quedar obsoleta en el sistema. En esta situación, se pueden utilizar las marcas de tiempo de las copias de seguridad de Oracle Cluster Registry (OCR).</block>
  <block id="50cd29958db0c1dcb6505d470f553e54" category="paragraph">En este ejemplo se muestra que el nodo maestro es<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block>. También indica un cambio en el nodo maestro desde<block ref="a31853cdea7badfc68b560e70cbbeb02" prefix=" " category="inline-code"></block> para<block ref="bf38e7432ba60433c4c8967fc8da0258" prefix=" " category="inline-code"></block> En algún lugar entre las 2:05 y las 21:39 el 4 de mayo. Este método de identificación del nodo maestro sólo es seguro si también se han comprobado los registros de CRS porque es posible que el nodo maestro haya cambiado desde la copia de seguridad de OCR anterior. Si se ha producido este cambio, debería estar visible en los registros de OCR.</block>
  <block id="df044a3c3d7f7f244db7c42b347b9a90" category="paragraph">La mayoría de los clientes eligen un único grupo de discos de votación que da servicio a todo el entorno y un número igual de nodos de RAC en cada sitio. El grupo de discos se debe colocar en el sitio que contiene la base de datos. El resultado es que la pérdida de conectividad provoca el desalojo en el sitio remoto. El sitio remoto ya no tendría quórum ni tendría acceso a los archivos de la base de datos, pero el sitio local continúa funcionando como de costumbre. Cuando se restaura la conectividad, la instancia remota puede volver a conectarse.</block>
  <block id="84a24276bfdfbe485b9d961c1a57a830" category="paragraph">En caso de desastre, se requiere un cambio para poner los archivos de la base de datos y el grupo de discos de votación en línea en el sitio superviviente. Si el desastre permite que AUSO active la conmutación por error, NVFAIL no se activa porque se sabe que el clúster está sincronizado y que los recursos de almacenamiento se conectan de forma normal. AUSO es una operación muy rápida y debe completarse antes de la<block ref="0494651671c3dc7f1ccdf99a4368a2cf" prefix=" " category="inline-code"></block> el período caduca.</block>
  <block id="6244ee13e435dcc768edbc9b0b38b73e" category="paragraph">Dado que solo hay dos sitios, no es factible utilizar ningún tipo de software automatizado de tiebreaking externo, lo que significa que la conmutación por error forzada debe ser una operación manual.</block>
  <block id="568c8c12fdb7c74f65125732ee717ad3" category="section-title">Configuraciones en tres sitios</block>
  <block id="2c7696fb04f52eb5687d059415066fa7" category="paragraph">Un clúster RAC ampliado es mucho más fácil de diseñar con tres sitios. Los dos sitios que alojan cada mitad del sistema de MetroCluster también admiten cargas de trabajo de base de datos, mientras que el tercer sitio sirve como desempate tanto para la base de datos como para el sistema de MetroCluster. La configuración de Oracle tiebreaker puede ser tan sencilla como colocar un miembro del grupo de discos de ASM utilizado para votar en un sitio 3rd y también puede incluir una instancia operativa en el sitio 3rd para asegurarse de que hay un número impar de nodos en el cluster RAC.</block>
  <block id="6265611ca77e9ad52249c5fdd4780da9" category="admonition">Consulte la documentación de Oracle sobre el “grupo de fallos de quórum” para obtener información importante sobre el uso de NFS en una configuración RAC ampliada. En resumen, puede que sea necesario modificar las opciones de montaje NFS para incluir la opción soft para garantizar que la pérdida de conectividad con los recursos de quórum del sitio de 3rd que alojan no cuelgue los servidores Oracle principales ni los procesos de Oracle RAC.</block>
  <block id="d84d0eea463e72a6e15018c70a45af46" category="doc">Oracle, MetroCluster y NVFAIL</block>
  <block id="9dc6a9986107298da2a22e7c5a3efb00" category="summary">Instancia única de Oracle en MetroCluster</block>
  <block id="f8b28e31633ae72c2971ee8b815ed4af" category="paragraph">Como se indicó anteriormente, la presencia de un sistema MetroCluster no necesariamente agrega ni cambia ninguna práctica recomendada para el funcionamiento de una base de datos. La mayoría de las bases de datos que se ejecutan actualmente en los sistemas MetroCluster del cliente son de única instancia y sigue las recomendaciones de la documentación de Oracle en ONTAP.</block>
  <block id="f4872c843923dd8d8731ef66462b5a99" category="paragraph">SyncMirror ofrece una copia síncrona de los datos del sitio de recuperación de desastres, pero para que los datos estén disponibles, requiere un sistema operativo y las aplicaciones asociadas. La automatización básica puede mejorar drásticamente el tiempo de conmutación al nodo de respaldo del entorno global. Los productos de Clusterware, como Veritas Cluster Server (VCS), se utilizan a menudo para crear un clúster en todos los sitios y, en muchos casos, el proceso de conmutación por error se puede llevar a cabo con scripts sencillos.</block>
  <block id="c50820a41eb4f23d0a3acc1eeddb391b" category="paragraph">Si se pierden los nodos primarios, el clusterware (o scripts) se configura para poner las bases de datos en línea en el sitio alternativo. Una opción es crear servidores en espera que estén preconfigurados para los recursos NFS o SAN que componen la base de datos. Si el sitio principal falla, el clusterware o la alternativa con secuencia de comandos realiza una secuencia de acciones similar a las siguientes:</block>
  <block id="2a6f458321ddf666cb0c876ee39255f3" category="list-text">Montaje de sistemas de archivos y/o montaje de grupos de discos ASM</block>
  <block id="3dee93bd9bc9b8b50dcdd2066a86009f" category="list-text">Iniciando la base de datos</block>
  <block id="620515885465a26daea6cc6441403e34" category="paragraph">El requisito principal de este método es un sistema operativo en ejecución instalado en el sitio remoto. Se debe preconfigurar con binarios de Oracle, lo que también significa que las tareas como los parches de Oracle se deben realizar en la ubicación primaria y en espera. Como alternativa, los binarios de Oracle se pueden duplicar en la ubicación remota y montar si se declara un desastre.</block>
  <block id="edb5332feef69c0aa60ea10ed5d31a9f" category="list-text">Iniciar bases de datos manualmente o configurar las máquinas virtuales para iniciar automáticamente las bases de datos, por ejemplo, un clúster ESX puede abarcar varios sitios. En caso de desastre, los equipos virtuales pueden conectarse en línea en el sitio de recuperación ante desastres después del cambio. Mientras los almacenes de datos que alojan los servidores de bases de datos virtualizadas no estén en uso en el momento del desastre, no es necesario configurarlos<block ref="3b93661df04b698b1340ff2da3238d16" prefix=" " category="inline-code"></block> en los volúmenes asociados.</block>
  <block id="64bba30b717cb45555458da4fed880a1" category="paragraph">Casi todas las aplicaciones requieren replicación de datos.</block>
  <block id="25fb1fa02f326334533a22c105ad3e69" category="paragraph">En el nivel más básico, la replicación puede significar una copia en cinta almacenada fuera de las instalaciones o una replicación a nivel de aplicación en una ubicación en espera. La recuperación ante desastres hace referencia al uso de dichas copias de réplica para poner un servicio en línea en caso de pérdida catastrófica de servicio.</block>
  <block id="eab6cb3a1168ef2311865e6155b8272c" category="paragraph">ONTAP ofrece múltiples opciones de replicación para abordar varios requisitos de forma nativa en la cabina de almacenamiento, lo que cubre un espectro completo de necesidades. Estas opciones pueden incluir replicación sencilla de backups en un sitio remoto mediante una solución síncrona y totalmente automatizada que proporcione tanto recuperación ante desastres como alta disponibilidad en la misma plataforma.</block>
  <block id="32df0c1cabf839652741a56bdaac7def" category="paragraph">Las tecnologías principales de replicación de ONTAP que se aplican a las aplicaciones son las tecnologías SnapMirror y NetApp SyncMirror de NetApp. No se trata de productos complementarios, sino que están totalmente integrados en ONTAP y se activan con la simple adición de una clave de licencia. La replicación a nivel de almacenamiento tampoco es la única opción. La replicación en el nivel de la aplicación, como Oracle DataGuard, también puede integrarse en una estrategia de protección de datos basada en ONTAP.</block>
  <block id="a2259fa074bae962e46ca7fc7aa31be1" category="paragraph">La elección correcta depende de los requisitos específicos de replicación, recuperación y retención.</block>
  <block id="0d3b37ff5855bf299f3c4a154373c1e2" category="section-title">SnapMirror de ONTAP</block>
  <block id="296e89e943f5160d338484b3b705a44e" category="paragraph">SnapMirror es la solución de replicación asíncrona de NetApp, idónea para la protección de conjuntos de datos grandes, complicados y dinámicos, como bases de datos y sus aplicaciones asociadas. Sus valores clave son los siguientes:</block>
  <block id="d9f36dae2818ace926c4259271530724" category="list-text">* Capacidad de gestión. * SnapMirror es fácil de configurar y administrar porque es una parte nativa del software de almacenamiento. No son necesarios productos complementarios. Las relaciones de replicación pueden establecerse en minutos y pueden gestionarse directamente en el sistema de almacenamiento.</block>
  <block id="8f761eff026903aa0140319f597d1fb0" category="list-text">*Simplicidad.* La replicación se basa en volúmenes FlexVol, que son contenedores de LUN o archivos que se replican como un único grupo consistente.</block>
  <block id="8b737d6a9db3de6436966db508cb51d4" category="list-text">*Eficiencia.* Después de establecer la relación de replicación inicial, solo se replican los cambios. Además, se mantienen las funciones de eficiencia como la deduplicación y la compresión, lo que reduce aún más la cantidad de datos que se deben transferir a un sitio remoto.</block>
  <block id="0783dadb67ff77ed26bbfc5d80fa0cbd" category="list-text">*Flexibilidad.* Los espejos se pueden romper temporalmente para permitir la prueba de los procedimientos de recuperación de desastres, y luego el reflejo se puede restablecer fácilmente sin necesidad de una repetición completa. Solo se deben aplicar los datos modificados para volver a sincronizar los reflejos. El mirroring también se puede revertir para permitir una resincronización rápida cuando el desastre finalice y el sitio original vuelva a estar en servicio. Por último, los clones de lectura y escritura de datos replicados están disponibles para realizar pruebas y desarrollo.</block>
  <block id="8a00f09d8937e890f2cfb4d7acf72733" category="paragraph">ONTAP ofrece varias tecnologías de replicación diferentes, pero la más flexible es SnapMirror, una opción de mirroring asíncrono de volumen a volumen.</block>
  <block id="80c8fae3d0b5dd100cc984d9ba3eced7" category="paragraph">Como ya se ha mencionado anteriormente, un volumen FlexVol es la unidad básica de gestión para backups basados en Snapshot y para la recuperación basada en SnapRestore. Un volumen FlexVol también es la unidad básica para la replicación basada en SnapMirror. El primer paso es establecer el reflejo de base de referencia del volumen de origen al volumen de destino. Una vez que se inicializa esta relación de reflejo, todas las operaciones posteriores se basan únicamente en la replicación de los datos modificados.</block>
  <block id="c1020b1755f65f23643158ce6a4d22cc" category="paragraph">Desde la perspectiva de recuperación, los valores clave de SnapMirror son los siguientes:</block>
  <block id="50bde20b37cd4d57fbff2b95f2f8ec97" category="list-text">Las operaciones de SnapMirror son fáciles de entender y se pueden automatizar fácilmente.</block>
  <block id="66162be45733f65fee4abb22e989eb78" category="list-text">Para una sencilla actualización de una réplica de SnapMirror es necesario que solo se repliquen los cambios delta, lo que reduce las demandas de ancho de banda y permite realizar actualizaciones con mayor frecuencia.</block>
  <block id="a3b4fbe416387a4991ccaa8b325a68be" category="list-text">SnapMirror es altamente granular. Se basa en relaciones simples de volumen a volumen, lo que permite la creación de cientos de réplicas e intervalos de replicación gestionados de forma independiente. No es necesario que la replicación sea universal.</block>
  <block id="4e3785883ef3ccad9938d7e35e493057" category="list-text">La dirección de mirroring puede invertirse fácilmente al tiempo que se conserva la capacidad de actualizar la relación basándose únicamente en los cambios. Esto proporciona una rápida capacidad de conmutación por recuperación una vez que el sitio principal se restaura en servicio tras un desastre como un fallo del suministro eléctrico. Solo los cambios deben sincronizarse de nuevo con el origen.</block>
  <block id="8b8325381cf528eff12c1e678a3112f9" category="list-text">Los espejos pueden romperse fácilmente y volver a sincronizarse eficientemente para permitir el ensayo de los procedimientos de recuperación ante desastres.</block>
  <block id="b1f45b7d95bfc815351fb649fa94b671" category="list-text">SnapMirror funciona en el modo de replicación por bloques completo replica no solo los datos de un volumen, sino también las copias Snapshot. Esta funcionalidad proporciona tanto una copia de los datos como un conjunto completo de backups en el sitio de recuperación ante desastres.</block>
  <block id="ffafd9ae31dee51209961eb2453ac806" category="paragraph">El modo de versión flexible basado en SnapMirror permite la replicación de snapshots específicos, lo que permite distintos períodos de retención en el sitio principal y secundario.</block>
  <block id="974658d7ac018cb945e78365b0a760fb" category="section-title">SnapMirror síncrono</block>
  <block id="ffbf9d0ce29a631b6eae8b22c41ec95e" category="paragraph">SnapMirror síncrono (SM-S) es una mejora de SnapMirror que proporciona un objetivo de punto de recuperación=0 de replicación síncrona. La mayoría de los datos se utiliza en arquitecturas de almacenamiento donde solo un subconjunto de los datos totales requiere mirroring síncrono.</block>
  <block id="e8a45c4c0391895df78421904703c933" category="paragraph">SM-S puede funcionar en dos modos ligeramente diferentes, Sync y StrictSync.</block>
  <block id="15a4e16195fb9d30c5df0e11df5c2166" category="paragraph">En el modo de sincronización, los cambios se replican antes de ser aceptados. Esto garantiza un objetivo de punto de recuperación de cero, siempre y cuando la replicación esté operativa. Si el cambio no se puede replicar, SM-S puede salir del modo síncrono y permitir que las operaciones continúen. Esto permite un objetivo de punto de recuperación=0 en circunstancias normales, pero los procesos de datos no se detienen por completo si el destino de replicación no está disponible.</block>
  <block id="115455025d4664c0dd6deaaf3c1fc93c" category="paragraph">StrictSync garantiza un RPO=0. Un fallo al replicar los cambios provoca un error de I/O, que normalmente provoca el apagado de la aplicación.</block>
  <block id="1b1ea0d1ad6e5cfb06253a14fcdcfe71" category="inline-link">CONSULTE TR-4733</block>
  <block id="9ccd61d6efc86cc37743fdff385832e8" category="paragraph">Para obtener una explicación completa de SM-S, consulte<block ref="4459b84726c651a8047a6486e87e48fb" category="inline-link-rx"></block> Y la documentación oficial de ONTAP. Las funciones se añaden continuamente con las nuevas versiones de ONTAP.</block>
  <block id="6165c4352e1504dbaeef34d0cc50c187" category="section-title">Grupos de consistencia</block>
  <block id="0651e813e385dbd62a9bca9baee23c6c" category="paragraph">ONTAP permite crear snapshots de grupo de consistencia y, a partir de 9.13.1, ONTAP puede replicar grupos de volúmenes (recuerde que un volumen en la terminología de ONTAP no es una LUN, es un contenedor de gestión que consta de uno o más archivos o LUN) como grupo consistente.</block>
  <block id="455c7758003d6ebd974e8858f5ef1d7d" category="paragraph">El resultado es que puede replicar un conjunto de datos de varios volúmenes y garantizar que todos los volúmenes sean coherentes entre sí. Entre otras cosas, esto permite dividir las operaciones de recuperación ante desastres «duplicaciones e iniciar» sin la necesidad de disponer de pasos adicionales de recuperación de aplicaciones o bases de datos.</block>
  <block id="c44a2da164b7b770fce6338a987670ee" category="section-title">MetroCluster y SyncMirror</block>
  <block id="b1a1cfbf3988d8abdfdedaabc1742ae9" category="paragraph">MetroCluster también es una solución de replicación síncrona, dirigida a cargas de trabajo esenciales a gran escala. La replicación se basa en SyncMirror. En la capa más sencilla, SyncMirror crea dos conjuntos completos de datos protegidos por RAID en dos ubicaciones distintas. Pueden estar en habitaciones contiguas en un centro de datos o estar situados a varios kilómetros de distancia.</block>
  <block id="89b8adf28db7abb0febecafdca5871ad" category="paragraph">SyncMirror está totalmente integrado con ONTAP y funciona justo por encima del nivel de RAID. Por lo tanto, todas las funciones habituales de ONTAP, como las copias Snapshot, SnapRestore y FlexClone de NetApp, funcionan sin problemas. Sigue siendo ONTAP, solo incluye una capa adicional de mirroring síncrono de datos.</block>
  <block id="75c677fa68f5d15c17efbf6fd1fe1765" category="paragraph">Una colección de controladoras de ONTAP que gestionan datos de SyncMirror se denomina configuración NetApp MetroCluster. El objetivo principal de MetroCluster es proporcionar un acceso de alta disponibilidad a los datos reflejados de forma síncrona en diversos escenarios típicos y de fallo de recuperación ante desastres.</block>
  <block id="af845652f0234e1f71bc37e241ab63dc" category="paragraph">Los valores clave de la protección de datos con MetroCluster y SyncMirror son los siguientes:</block>
  <block id="9ab80c5e33e343c3415c21be433c4447" category="list-text">En las operaciones normales, SyncMirror ofrece mirroring síncrono garantizado en todas las ubicaciones. No se reconoce una operación de escritura hasta que está presente en medios no volátiles en ambos sitios.</block>
  <block id="680ccf94624c9f922ed236c8cc0c1af2" category="list-text">Si la conectividad entre los sitios falla, SyncMirror cambia automáticamente al modo asíncrono para mantener el sitio principal sirviendo datos hasta que se restaure la conectividad. Tras su restauración, permite una rápida resincronización actualizando eficientemente los cambios que se han acumulado en el sitio principal. No es necesaria la reinicialización completa.</block>
  <block id="c18ec55908c635b68abe8c6edbf6476e" category="paragraph">SnapMirror también es totalmente compatible con sistemas basados en SyncMirror. Por ejemplo, una base de datos primaria podría estar ejecutándose en un cluster MetroCluster distribuido en dos ubicaciones geográficas. Esta base de datos también puede replicar los backups en un tercer sitio como archivos a largo plazo o para la creación de clones en un entorno de DevOps.</block>
  <block id="3a8111f0b903472ec78531619bf984f6" category="paragraph">Los procedimientos de replicación para una base de datos Oracle son esencialmente los mismos que los procedimientos de copia de seguridad. El requisito principal es que las copias Snapshot que constituyen un backup recuperable se deban replicar en el sistema de almacenamiento remoto.</block>
  <block id="c62b3abab4fdbaf8f0a84e8c3559b5fd" category="paragraph">Como ya se ha explicado anteriormente en la documentación sobre protección de datos local, es posible crear un backup recuperable con el proceso de backup dinámico o aprovechando los backups optimizados en instantáneas.</block>
  <block id="3d8f8c6a5c90bcd85a22fbd17390a864" category="inline-link-macro">Distribución de datos</block>
  <block id="30394da99a39ca8264b8f7c0e6f679e0" category="paragraph">El requisito más importante es el aislamiento de los archivos de datos en uno o más volúmenes dedicados. No deben estar contaminados por ningún otro tipo de archivo. La razón es asegurarse de que la replicación de archivos de datos sea totalmente independiente de la replicación de otros tipos de datos, como archive logs. Para obtener más información sobre los diseños de archivos y para obtener detalles importantes sobre cómo garantizar que el diseño de almacenamiento es compatible con instantáneas, consulte  <block ref="5a4fdf6a1fc411e544cf6d70d47a8289" category="inline-link-macro-rx"></block>.</block>
  <block id="f3f227cc5c07a040d61c36679053a58a" category="paragraph">Suponiendo que los archivos de datos están encapsulados en volúmenes dedicados, la siguiente pregunta es cómo gestionar los redo logs, archive logs y controlfiles. El método más simple es colocar todos esos tipos de datos en un único volumen. La ventaja de esto es que los redo logs replicados, archive logs y controlfiles están perfectamente sincronizados. No hay ningún requisito para la recuperación incompleta o el uso de un archivo de control de copia de seguridad, aunque podría ser deseable también crear scripts de creación de archivos de control de copia de seguridad para otros escenarios de recuperación potenciales.</block>
  <block id="927992cbeccc8211e382c97e81514ef9" category="section-title">Distribución de dos volúmenes</block>
  <block id="fe1cf96940a710dc95fd30bbb7533b52" category="paragraph">El diseño más simple se muestra en la siguiente figura.</block>
  <block id="57f1db4bdf2ce49a98f375d8393f02bf" category="paragraph">Este es el enfoque más común. Desde el punto de vista del DBA, puede parecer inusual colocar todas las copias de los redo logs y archive logs en el mismo volumen. Sin embargo, la separación no ofrece mucha protección adicional cuando los archivos y las LUN aún se encuentran en el mismo conjunto de unidades subyacente.</block>
  <block id="bc46e4831ef5654d084e456c4c544a42" category="section-title">Distribución de tres volúmenes</block>
  <block id="f6e969769d9d166122489505d676769b" category="paragraph">En ocasiones, es necesario separar los redo logs debido a problemas de protección de datos o a la necesidad de distribuir E/S de redo log entre las controladoras. Si es así, la distribución de tres volúmenes que se muestra en la siguiente figura se utilizará para la replicación sin dejar de tener que realizar recuperaciones incompletas o depender de los archivos de control de backup.</block>
  <block id="4957c2feaa2cb72d80a0ab65228ad43f" category="paragraph">Esto permite la segmentación de los redo logs y los archivos de control en conjuntos independientes de discos y controladores en el origen. Sin embargo, los archive logs y un juego de archivos de control y redo logs se pueden replicar en un estado sincronizado con los archive logs.</block>
  <block id="39128da64bc55500b4b11391aa54a011" category="paragraph">En este modelo, el volumen Redo Log B no se replica.</block>
  <block id="c0ce858e99375deac8274c96b7e5d0ee" category="section-title">Procedimiento de recuperación ante desastres: Backups activos</block>
  <block id="6993729228512b7e23e3ff3ec9099f33" category="paragraph">Para realizar la recuperación ante desastres mediante backups activos, utilice el siguiente procedimiento básico:</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">Requisitos previos</block>
  <block id="41bde9c586a860264c425700c48bd375" category="list-text">Los binarios de Oracle se instalan en el servidor de recuperación ante desastres.</block>
  <block id="cebf7cec81152da2cadffd580d81937f" category="list-text">Las instancias de base de datos se muestran en<block ref="2c0b0433aa1c96a2be6f40d9e71bc6af" prefix=" " category="inline-code"></block>.</block>
  <block id="17f8e5eda67237f2ca94c7dcce3e4022" category="list-text">La<block ref="76a2173be6393254e72ffa4d6df1030a" prefix=" " category="inline-code"></block> y..<block ref="6b2f852f7f63f2e5d4be597bbca97bb6" prefix=" " category="inline-code"></block> o.<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> para la instancia debe estar en la<block ref="45c7302d9c2e8745b3a2bff0f992b6df" prefix=" " category="inline-code"></block> directorio. .</block>
  <block id="645a84975202e30700b572b49a5ee29d" category="section-title">Recuperación tras siniestros</block>
  <block id="25d18766964d7515e1f5acd893094f6e" category="list-text">Rompa los reflejos de los archivos de datos y del volumen de registro común.</block>
  <block id="8fc655e4752d521563db3bfa138ba62e" category="list-text">Restaure los volúmenes de archivos de datos en la snapshot de backup en caliente más reciente de los archivos de datos.</block>
  <block id="68a9c75816a16f6d4f7572fe287961bf" category="list-text">Si se utiliza SAN, activar grupos de volúmenes y/o montar sistemas de archivos.</block>
  <block id="312007510a0f0dc7878d4ed6a7a01554" category="list-text">Reproduzca los archive logs en el punto deseado.</block>
  <block id="e54b793d8bfa83bbb1bd965992c3474e" category="list-text">Reproduzca los redo logs actuales si desea una recuperación completa.</block>
  <block id="72e5734d53581f86093de5c97d8a3a24" category="paragraph">El uso de NFS simplifica el procedimiento drásticamente, ya que los sistemas de archivos NFS para los archivos de datos y los archivos de registro se pueden montar en el servidor de recuperación ante desastres en cualquier momento. Se hace lectura/escritura cuando los espejos están rotos.</block>
  <block id="de4735bc5bbfdcae3d690313c739ad67" category="section-title">Procedimiento de recuperación ante desastres: Backups optimizados para Snapshot</block>
  <block id="6b2b8ef11e5ded8a083372ba49d488d2" category="paragraph">La recuperación desde backups optimizados para snapshots es prácticamente idéntica al procedimiento de recuperación de backup en caliente con los siguientes cambios:</block>
  <block id="af1e49e7bc2b25ce36bd93df09433fb4" category="list-text">Restaure los volúmenes de archivos de datos en una copia de Snapshot creada antes de la réplica actual del volumen de registro.</block>
  <block id="5e09669c98226c5d3a748f7e0f0333ad" category="paragraph">Estas diferencias simplifican el procedimiento de recuperación general, ya que no hay ningún requisito para asegurarse de que se creó correctamente una copia Snapshot en el origen mientras la base de datos estaba en modo de backup dinámico. El procedimiento de recuperación ante desastres se basa en las marcas de tiempo de los snapshots del sitio de recuperación ante desastres. El estado de la base de datos cuando se crearon las instantáneas no es importante.</block>
  <block id="81d6beef7eaf28bbce692d4b59888f3e" category="section-title">Recuperación ante desastres con copias Snapshot de backup activas</block>
  <block id="dc711b77f0d6a9c9ccf88b424509440a" category="paragraph">Este es un ejemplo de estrategia de recuperación ante desastres basada en la replicación de snapshots de backup en caliente. También sirve como ejemplo de estrategia de backup local sencilla y escalable.</block>
  <block id="edaef18e1c956b9284405fd664c4ca4a" category="paragraph">La base de datos de ejemplo se encuentra en una arquitectura de dos volúmenes básica.<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> contiene archivos de datos y.<block ref="894db1fc1592356880976f1b92c3e6a2" prefix=" " category="inline-code"></block> se utiliza para la combinación de redo logs, archive logs y archivos de control.</block>
  <block id="fc0e7b6cd7cd15929987b1429d1c3a7e" category="paragraph">Se requieren dos programaciones, una para los backups de archivos de datos nocturnos y otra para los backups de archivos de registro. Estos se llaman medianoche y 15minutes, respectivamente.</block>
  <block id="44c0956347a70c78d2124c1041321049" category="paragraph">Estas programaciones se utilizan dentro de las políticas de snapshot<block ref="44dc83cda2d6b3ce99cc25803e824061" prefix=" " category="inline-code"></block> y..<block ref="9b055600529d69c4ae0d2a9408dc7aa3" prefix=" " category="inline-code"></block>, como se muestra a continuación:</block>
  <block id="180e86b8e3c5049779c98c2c1006bb15" category="paragraph">Por último, estas políticas de snapshots se aplican a los volúmenes.</block>
  <block id="2887f2c14c7efbc97d53ac2f914c5657" category="paragraph">Esto define la programación de backup de los volúmenes. Las instantáneas de archivos de datos se crean a medianoche y se conservan durante 60 días. El volumen de registro contiene 72 copias de Snapshot creadas a intervalos de 15 minutos, lo que suma 18 horas de cobertura.</block>
  <block id="e1e5ef0e7100311d950b4ffebe040670" category="paragraph">A continuación, asegúrese de que la base de datos esté en modo de backup dinámico cuando se cree una snapshot de archivo de datos. Esto se hace con un pequeño script que acepta algunos argumentos básicos que inician y paran el modo de copia de seguridad en el SID especificado.</block>
  <block id="683cdd7abd993faf3ace355cd6870b6f" category="paragraph">En este paso se garantiza que la base de datos esté en modo backup dinámico durante una ventana de cuatro minutos que rodea la instantánea de medianoche.</block>
  <block id="ccff7eb3ad0059a184886709c87f4889" category="paragraph">La replicación en el sitio de recuperación de desastres se configura de la siguiente manera:</block>
  <block id="42d3752a745fb0cdae528f6cc425b569" category="paragraph">El destino del volumen de registro se actualiza cada 15 minutos. Esto proporciona un objetivo de punto de recuperación de aproximadamente 15 minutos. El intervalo de actualización preciso varía un poco dependiendo del volumen total de datos que se deben transferir durante la actualización.</block>
  <block id="e272424001d72919ad498e0e9d3c2cc4" category="paragraph">El destino del volumen del archivo de datos se actualiza cada seis horas. Esto no afecta al objetivo de punto de recuperación ni al objetivo de tiempo de recuperación. Si se requiere recuperación ante desastres, uno de los primeros pasos es restaurar el volumen del archivo de datos en una instantánea de backup en caliente. La finalidad del intervalo de actualización más frecuente es suavizar la tasa de transferencia de este volumen. Si la actualización está programada para una vez al día, todos los cambios acumulados durante el día deben transferirse a la vez. Con actualizaciones más frecuentes, los cambios se replican más gradualmente a lo largo del día.</block>
  <block id="ce176ff569d716c1fa73d0754aba684b" category="paragraph">Si se produce un desastre, el primer paso es interrumpir los reflejos de ambos volúmenes:</block>
  <block id="4b9cdb6e2096c0828aeccd2ee5eecf42" category="paragraph">Ahora las réplicas son de lectura y escritura. El siguiente paso es verificar la marca de tiempo del volumen de registro.</block>
  <block id="b4d461e48f5be5d08f677045d11e8200" category="paragraph">La copia más reciente del volumen de registro es el 14th de marzo a las 13:30:00.</block>
  <block id="96f75a4b63f4377efdf64d571d71caec" category="paragraph">A continuación, identifique la snapshot de backup activo creada inmediatamente antes del estado del volumen de registro. Esto es necesario porque el proceso de reproducción de log requiere que todos los archive logs se creen durante el modo de copia de seguridad activa. Por lo tanto, la réplica del volumen de registro debe ser más antigua que las imágenes de backup activo o no contener los registros requeridos.</block>
  <block id="d358e4eb10a2f4e0b591e16941d7782c" category="paragraph">La instancia de Snapshot creada más recientemente es<block ref="c001e27abf0e66d13790bb8a7e00da54" prefix=" " category="inline-code"></block>. Esta es la imagen de backup en caliente más reciente de los archivos de datos y se restaura de la siguiente manera:</block>
  <block id="d2037035a976c9be71cf6f372300c8c3" category="paragraph">En esta etapa, la base de datos está ahora lista para ser recuperada. Si se trataba de un entorno SAN, el siguiente paso incluiría activar grupos de volúmenes y montar sistemas de archivos, un proceso fácilmente automatizado. Como este ejemplo utiliza NFS, los sistemas de archivos ya están montados y se han convertido en de lectura y escritura sin necesidad de montar o activar más el momento en el que se rompieron los reflejos.</block>
  <block id="2edce22eade45b42bc6b2665057fa082" category="paragraph">La base de datos se puede recuperar ahora al punto deseado en el tiempo o se puede recuperar completamente con respecto a la copia de los redo logs que se han replicado. En este ejemplo se ilustra el valor del archive log combinado, el archivo de control y el volumen redo log. El proceso de recuperación es significativamente más sencillo, ya que no hay necesidad de depender de los archivos de control de copia de seguridad ni de restablecer los archivos de registro.</block>
  <block id="51f74a82c7125b3b288755b6668091b1" category="section-title">Recuperación ante desastres con backups optimizados para Snapshot</block>
  <block id="3680a4757ddad43934237ab6a0ca955c" category="paragraph">El procedimiento de recuperación ante desastres mediante backups optimizados para Snapshot es prácticamente idéntico al procedimiento de recuperación ante desastres del backup activo. Al igual que con el procedimiento de copias Snapshot de backup en caliente, también es esencialmente una extensión de una arquitectura de backup local en la que los backups se replican para su uso en la recuperación ante desastres. En el siguiente ejemplo, se muestra el procedimiento detallado de configuración y recuperación. Este ejemplo también destaca las diferencias clave entre los backups activos y los backups optimizados para Snapshot.</block>
  <block id="330dadae5e2585726f41ed1f90e88f9f" category="paragraph">La base de datos de ejemplo se encuentra en una arquitectura de dos volúmenes básica.<block ref="f006bf17b06c884c47190c4225d3215a" prefix=" " category="inline-code"></block> contiene archivos de datos y.<block ref="894db1fc1592356880976f1b92c3e6a2" prefix=" " category="inline-code"></block> se utiliza para la combinación de redo logs, archive logs y archivos de control.</block>
  <block id="1669f47e046ce7e069e9d143f42e025d" category="paragraph">Se requieren dos programaciones: Una para los backups de archivos de datos nocturnos y otra para los backups de archivos de registro. Estos se llaman medianoche y 15minutes, respectivamente.</block>
  <block id="ef4adcab3e9bd572d0670f9f2073c311" category="paragraph">De este modo se controla la programación de backup definitiva de los volúmenes. Las copias Snapshot se crean a medianoche y se conservan durante 60 días. El volumen de registro contiene 72 copias de Snapshot creadas a intervalos de 15 minutos, lo que suma 18 horas de cobertura.</block>
  <block id="f9d5149b630a43ff5996adc26c6e1f08" category="paragraph">El destino del volumen de registro se actualiza cada 15 minutos. Esto proporciona un objetivo de punto de recuperación de aproximadamente 15 minutos, y el intervalo preciso de actualización varía ligeramente, en función del volumen total de datos que se deben transferir durante la actualización.</block>
  <block id="992398ebd9e9f825f0aa4415519abdba" category="paragraph">El destino del volumen de archivos de datos se actualiza cada 6 horas. Esto no afecta al objetivo de punto de recuperación ni al objetivo de tiempo de recuperación. Si se requiere recuperación ante desastres, primero debe restaurar el volumen del archivo de datos en una instantánea de backup activo. La finalidad del intervalo de actualización más frecuente es suavizar la tasa de transferencia de este volumen. Si la actualización se programó una vez al día, todos los cambios acumulados durante el día deben transferirse a la vez. Con actualizaciones más frecuentes, los cambios se replican más gradualmente a lo largo del día.</block>
  <block id="9e85b8590ac2f9ff5ebc8d1def51ae82" category="paragraph">Si se produce un desastre, el primer paso es interrumpir los reflejos en todos los volúmenes:</block>
  <block id="fd2834dcadb39f00eb897fdcdc07a03d" category="paragraph">La copia más reciente del volumen de registro es el 14th de marzo a las 13:30. A continuación, identifique la snapshot de archivo de datos creada inmediatamente antes del estado del volumen de registro. Esto es necesario porque el proceso de reproducción de log necesita todos los archive logs desde justo antes de la instantánea hasta el punto de recuperación deseado.</block>
  <block id="810e47566b9cd5aa3b28e6514ec95735" category="paragraph">La instancia de Snapshot creada más recientemente es<block ref="c001e27abf0e66d13790bb8a7e00da54" prefix=" " category="inline-code"></block>. Restaurar esta instantánea.</block>
  <block id="87d83a0406ac6622efcdf91c42784ecd" category="paragraph">La base de datos está ahora lista para ser recuperada. Si se trataba de un entorno SAN, activaría los grupos de volúmenes y montaría sistemas de archivos, un proceso fácilmente automatizado. Sin embargo, este ejemplo utiliza NFS, por lo que los sistemas de archivos ya están montados y se han convertido en de lectura y escritura sin necesidad de montaje o activación en el momento en que se rompieron los reflejos.</block>
  <block id="7a2e97f17454be76b7e522ce612ff961" category="paragraph">La base de datos se puede recuperar ahora al punto deseado en el tiempo o se puede recuperar completamente con respecto a la copia de los redo logs que se han replicado. En este ejemplo se ilustra el valor del archive log combinado, el archivo de control y el volumen redo log. El proceso de recuperación es significativamente más sencillo, ya que no hay necesidad de confiar en los archivos de control de copia de seguridad ni restablecer los archivos de registro.</block>
  <block id="5eda890cc07e4b7cd409730d8af8ddc3" category="paragraph">La replicación de grupo de consistencia puede ser tan sencilla como programar la replicación de un único volumen a través de SnapMirror. Esto incluye archivos de datos, archivos de control, archive logs y redo logs. Cada actualización de SnapMirror genera una nueva copia de la base de datos en el sitio de destino que resulta coherente y está lista para la activación interrumpiendo el mirroring.</block>
  <block id="89cb1432594ce7c25dadf229401874e7" category="paragraph">Donde una base de datos debe abarcar volúmenes, se requiere una snapshot de grupo de coherencia (cg-snapshot).</block>
  <block id="f96b125d1bacc785389957041be148e9" category="paragraph">Otra ventaja de esta estrategia cuando se usa con SnapMirror en el modo de replicación de nivel de bloque es la replicación completa de todas las instantáneas del sistema de almacenamiento de origen. Además de la copia de recuperación ante desastres, se replica todo el complemento de backups.</block>
  <block id="77fda44088666155052f9d4224878cbc" category="summary">Organización en niveles de archive log de Oracle</block>
  <block id="8625af69ad0b5f76799d87df777e3c86" category="paragraph">Quizás el uso más importante de FabricPool sea mejorar la eficiencia de los datos fríos conocidos, como los registros de transacciones de base de datos.</block>
  <block id="a98d546484d238b37b7e2584ae8d399d" category="summary">Organización en niveles de backup de Oracle</block>
  <block id="9f409a250e4be99904c9e90259cb747d" category="paragraph">Las copias de seguridad de aplicaciones tradicionales incluyen productos como Oracle Recovery Manager, que crea copias de seguridad basadas en archivos fuera de la ubicación de la base de datos original.</block>
  <block id="4627801bdbb24a1991e64f30a2d80cb1" category="paragraph">ONTAP tiene disponibles cuatro políticas que controlan cómo los datos de Oracle en el nivel de rendimiento se convierten en candidatos para reubicar al nivel de capacidad.</block>
  <block id="2eea2725f31529888b5e57b36492819f" category="paragraph">Aunque la organización en niveles de FabricPool opera a nivel de bloques, en algunos casos se puede utilizar para la organización en niveles de archivos.</block>
  <block id="f935a501eae76f9c13d430bc3879cd0d" category="paragraph">Dado que FabricPool funciona a nivel de bloque, los archivos que están sujetos a cambios se pueden organizar parcialmente en niveles en el almacenamiento de objetos y, al mismo tiempo, permanecen parcialmente en el nivel de rendimiento.</block>
  <block id="cc4e17c26faf6b70b383529b6215ba0f" category="doc">Interrupciones de acceso al almacén de objetos</block>
  <block id="ec35a176f3e7c086273baee0c7f374d5" category="paragraph">Comprender cómo afecta el almacenamiento por niveles FabricPool a Oracle y otras bases de datos requiere comprender la arquitectura de FabricPool de bajo nivel.</block>
  <block id="6edf1821ddc55278229c2156f42905f0" category="paragraph">Las políticas de organización en niveles controlan qué bloques de la base de datos de Oracle se organizan en niveles desde el nivel de rendimiento al nivel de capacidad. Las políticas de recuperación controlan lo que sucede cuando se lee un bloque que se ha organizado en niveles.</block>
  <block id="d01cbb2be77343ccdb1d3372c4b9891e" category="summary">Directrices para el dimensionamiento de LUN y el número de LUN de la base de datos de Oracle</block>
  <block id="51f96d1f8b50084e3a2ddc21ceef8b2f" category="paragraph">Seleccionar el tamaño óptimo de LUN y el número de LUN que se utilizarán es fundamental para lograr un rendimiento y una capacidad de gestión óptimos en las bases de datos de Oracle.</block>
  <block id="3d1bd23e74923cdc48fe992d0687809f" category="summary">Oracle Database y NFS leasing y bloqueos</block>
  <block id="cec6f8a988408ba212798e1cc32658c7" category="paragraph">NFSv3 está sin estado. Esto implica efectivamente que el servidor NFS (ONTAP) no realiza un seguimiento de qué sistemas de archivos están montados, quién o qué bloqueos están realmente instalados.</block>
  <block id="7c96331bd03e63c4eb3505c526b42244" category="paragraph">ONTAP dispone de algunas funciones que registrarán los intentos de montaje, por lo que tiene una idea de qué clientes pueden acceder a los datos y puede que haya bloqueos asesores, pero no se garantiza que esa información esté al 100% completa. No se puede completar, ya que el seguimiento del estado del cliente NFS no forma parte del estándar NFSv3.1.</block>
  <block id="20733ad7135aa0ede95fd8637fe05cf6" category="section-title">NFSv4 Estado</block>
  <block id="3f7c11f662fc6e07a91179fdf2322ef5" category="paragraph">Por el contrario, NFSv4 tiene estado. El servidor NFSv4 rastrea qué clientes están utilizando qué sistemas de archivos, qué archivos existen, qué archivos y/o regiones de archivos están bloqueados, etc. Esto significa que debe haber una comunicación regular entre un servidor NFSv4 para mantener los datos de estado actualizados.</block>
  <block id="6f7e4a1e570f45fa3db0b8a0ed80a38f" category="paragraph">Los estados más importantes que gestiona el servidor NFS son NFSv4 bloqueos y NFSv4 arrendamientos y están muy entrelazados. Necesitas entender cómo cada uno trabaja por sí mismo, y cómo se relacionan entre sí.</block>
  <block id="0d55fd4062f29237d0fb3b7f666fb8eb" category="section-title">NFSv4 bloqueos</block>
  <block id="bf4139ff42e411ae5483e062387b3f70" category="paragraph">Con NFSv3, las cerraduras son un aviso. Un cliente NFS aún puede modificar o eliminar un archivo «bloqueado». Un bloqueo NFSv3 no caduca por sí mismo, debe ser eliminado. Esto crea problemas. Por ejemplo, si tiene una aplicación en cluster que crea NFSv3 bloqueos y uno de los nodos falla, ¿qué debe hacer? Puede codificar la aplicación en los nodos supervivientes para eliminar los bloqueos, pero ¿cómo sabe que es seguro? ¿Puede que el nodo «fallido» esté operativo, pero no se comunica con el resto del clúster?</block>
  <block id="11d1c33ac6b190a233c00cdbdd6a355b" category="paragraph">Con NFSv4, las cerraduras tienen una duración limitada. Mientras el cliente que mantiene los bloqueos continúe registrando en el servidor NFSv4, no se permitirá a ningún otro cliente adquirir estos bloqueos. Si un cliente no se registra en NFSv4, el servidor eventualmente revoca los bloqueos y otros clientes podrán solicitar y obtener bloqueos.</block>
  <block id="c17985911e0182dc5e96c4d60aadf139" category="section-title">NFSv4 arrendamientos</block>
  <block id="596bcfef3aaccfe299bb45a969afcaf0" category="paragraph">NFSv4 bloqueos están asociados a un arrendamiento NFSv4. Cuando un cliente NFSv4 establece una conexión con un servidor NFSv4, obtiene un permiso. Si el cliente obtiene un bloqueo (hay muchos tipos de bloqueos), el bloqueo se asocia con la concesión.</block>
  <block id="b5248856b1835e14738aa32e053e30e0" category="paragraph">Esta concesión tiene un timeout definido. De forma predeterminada, ONTAP establecerá el valor de tiempo de espera en 30 segundos:</block>
  <block id="7e2a66190f452806ac1183721a43eaa1" category="paragraph">Esto significa que un cliente NFSv4 necesita registrarse con el servidor NFSv4 cada 30 segundos para renovar sus arrendamientos.</block>
  <block id="809c552ae0a4d377e87f495b4e3ac62b" category="paragraph">El arrendamiento se renueva automáticamente por cualquier actividad, por lo que si el cliente está haciendo trabajo no hay necesidad de realizar operaciones de adición. Si una aplicación se vuelve silenciosa y no está haciendo un trabajo real, tendrá que realizar una especie de operación de mantenimiento de la vida (llamada SECUENCIA) en su lugar. En esencia, es solo decir «sigo aquí, actualice mis contratos de arrendamiento».</block>
  <block id="70cb78bb7e91dcafab559f9b72e40bb6" category="paragraph">NFSv3 está sin estado. No se espera la comunicación de los clientes. NFSv4 aparece con estado y, una vez que transcurre el período de concesión, la concesión caduca, se revocan los bloqueos, y los archivos bloqueados se ponen a disposición de otros clientes.</block>
  <block id="2ee5d81cfa6306ae71ce534ed9b31431" category="paragraph">Con NFSv3, puede mover los cables de red, reiniciar los switches de red, realizar cambios de configuración y estar bastante seguro de que no sucedería nada malo. Las aplicaciones normalmente solo esperarían pacientemente a que la conexión de red vuelva a funcionar.</block>
  <block id="8900ff182e4197f8eb2acd7d2b7fd902" category="paragraph">Con NFSv4, tienes 30 segundos (a menos que hayas aumentado el valor de ese parámetro dentro de ONTAP) para completar tu trabajo. Si sobrepasa eso, se agota el tiempo de arrendamiento. Normalmente, esto provoca fallos de aplicación.</block>
  <block id="ffa8c7744b3e2d43b18c67aec0fe7743" category="paragraph">Por ejemplo, si tiene una base de datos Oracle y experimenta una pérdida de conectividad de red (a veces denominada «partición de red») que supera el tiempo de espera de concesión, bloqueará la base de datos.</block>
  <block id="33b9897348039594b4b17bf1e1629c74" category="paragraph">A continuación, se muestra un ejemplo de lo que ocurre en el log de alertas de Oracle si esto sucede:</block>
  <block id="85608585bf8e790a579c49ba9af705c6" category="paragraph">Si observa los syslogs, debería ver varios de estos errores:</block>
  <block id="e19b338de53dada4cf4da3837aaba76d" category="paragraph">Los mensajes de registro suelen ser el primer signo de un problema, aparte de la congelación de la aplicación. Normalmente, no verá nada durante la interrupción de la red, porque los procesos y el propio SO están bloqueados al intentar acceder al sistema de archivos NFS.</block>
  <block id="7a3c8c17a9dd10fa565f79e0ebb5bba7" category="paragraph">Los errores aparecen después de que la red vuelva a funcionar. En el ejemplo anterior, una vez que se restablece la conectividad, el sistema operativo intentó volver a adquirir los bloqueos, pero era demasiado tarde. El arrendamiento había caducado y se eliminaron los bloqueos. Esto produce un error que se propaga hasta la capa de Oracle y provoca el mensaje en el log de alertas. Es posible que vea variaciones en estos patrones en función de la versión y la configuración de la base de datos.</block>
  <block id="4bec5e793e34a5819aefb68e4f65db26" category="paragraph">En resumen, NFSv3 tolera la interrupción de la red, pero NFSv4 es más sensible e impone un período de arrendamiento definido.</block>
  <block id="069de2d717910b2677190b9a9b5ed1cf" category="paragraph">¿Qué pasa si un tiempo de espera de 30 segundos no es aceptable? ¿Qué pasa si administra una red que cambia dinámicamente en la que se reinician los switches o se reubican los cables y el resultado es la interrupción ocasional de la red? Puede optar por ampliar el período de arrendamiento, pero si lo desea, requiere una explicación de NFSv4 períodos de gracia.</block>
  <block id="4b84416146795544deb5c9de89187f91" category="section-title">NFSv4 periodos de gracia</block>
  <block id="7d98e091c5f7be92cd5fb85b985d8d20" category="paragraph">Si se reinicia un servidor NFSv3, está listo para servir IO casi al instante. No estaba manteniendo ningún tipo de estado sobre los clientes. El resultado es que la operación de toma de control de ONTAP parece estar casi al instante. En el momento en que un controlador está listo para comenzar a servir datos, enviará un ARP a la red que indica el cambio en la topología. En general, los clientes lo detectan de forma casi instantánea y se reanuda el flujo de los datos.</block>
  <block id="173d4fd05086441236dbee4710639d10" category="paragraph">NFSv4, sin embargo, producirá una breve pausa. Es solo parte de cómo funciona NFSv4.</block>
  <block id="21483115213b27583a07dc2ca994671c" category="paragraph">Los servidores NFSv4 necesitan realizar un seguimiento de los arrendamientos, los bloqueos y quién utiliza qué datos. Si un servidor NFS produce una alarma y se reinicia, pierde energía durante un momento, o se reinicia durante la actividad de mantenimiento, el resultado es la concesión/bloqueo y se pierde otra información del cliente. El servidor necesita averiguar qué cliente está utilizando qué datos antes de reanudar las operaciones. Aquí es donde entra el período de gracia.</block>
  <block id="09b6f386094bd895d3c9694f28bfdf65" category="paragraph">Si de repente apaga el servidor NFSv4. Cuando vuelva a estar activo, los clientes que intenten reanudar I/O obtendrán una respuesta que diga «He perdido información de arrendamiento/bloqueo. ¿Desea volver a registrar sus bloqueos? Ese es el comienzo del período de gracia. El valor predeterminado es 45 segundos en ONTAP:</block>
  <block id="e4f8aa90af36d76254e2f02e56232aed" category="paragraph">El resultado es que, después de un reinicio, una controladora pausará el I/O mientras todos los clientes recuperan sus concesiones y bloqueos. Una vez que finaliza el período de gracia, el servidor reanudará las operaciones de E/S.</block>
  <block id="bb2b26fdcb4e947cda6f8e38724ecfc9" category="section-title">Tiempos de espera de leasing frente a períodos de gracia</block>
  <block id="563494d7f0f6ebcb6698cac7f9705aaa" category="paragraph">El período de gracia y el período de arrendamiento están conectados. Como se ha mencionado anteriormente, el tiempo de espera predeterminado de la concesión es de 30 segundos, lo que significa que NFSv4 clientes deben realizar el check in con el servidor al menos cada 30 segundos o pierden sus arrendamientos y, a su vez, sus bloqueos. El período de gracia existe para permitir que un servidor NFS vuelva a generar los datos de concesión/bloqueo y, de forma predeterminada, es de 45 segundos. ONTAP requiere que el período de gracia sea 15 segundos más largo que el período de arrendamiento. Esto garantiza que un entorno de cliente NFS diseñado para renovar arrendamientos al menos cada 30 segundos pueda conectarse con el servidor después de un reinicio. Un período de gracia de 45 segundos asegura que todos aquellos clientes que esperan renovar sus arrendamientos al menos cada 30 segundos definitivamente tienen la oportunidad de hacerlo.</block>
  <block id="5e6b60906bbbb9a41b140c0749591489" category="paragraph">Si un tiempo de espera de 30 segundos no es aceptable, puede optar por ampliar el período de arrendamiento. Si desea aumentar el tiempo de espera de concesión a 60 segundos para soportar una interrupción de la red de 60 segundos, tendrá que aumentar el período de gracia a al menos 75 segundos. ONTAP requiere que sea 15 segundos superior al período de concesión. Esto significa que experimentará pausas más largas de I/O durante la recuperación tras fallos de la controladora.</block>
  <block id="4611c7c931fc15a6feba513fe72e22de" category="paragraph">Esto no debería ser normalmente un problema. Los usuarios habituales solo actualizan las controladoras de ONTAP una o dos veces al año, y las recuperaciones tras fallos no planificadas debido a fallos de hardware son extremadamente raras. Además, si tenía una red en la que una interrupción de la red de 60 segundos era preocupante y necesitaba un tiempo de espera de concesión de 60 segundos, es probable que no se oponga a una conmutación por error rara del sistema de almacenamiento, lo que provoca una pausa de 75 segundos. Ya ha reconocido que tiene una red que se detiene durante más de 60 segundos con bastante frecuencia.</block>
  <block id="c4fb6f7d31d205bc07dbff47d0ae4bb3" category="summary">NFS directo de Oracle</block>
  <block id="f58bdad9659176e411f064fdb414233f" category="doc">Oracle DirectNFS</block>
  <block id="1bd6ec1185ba67395dc6f9cd2b458ec8" category="paragraph">Las bases de datos de Oracle pueden utilizar NFS de dos maneras.</block>
  <block id="96997ca5c577dd19a3ba5f7ff771f27a" category="paragraph">En primer lugar, puede utilizar un sistema de archivos montado utilizando el cliente NFS nativo que forma parte del sistema operativo. A veces, esto se denomina nfs del núcleo o knfs. El sistema de archivos NFS es montado y utilizado por la base de datos Oracle exactamente igual que cualquier otra aplicación utilizaría un sistema de archivos NFS.</block>
  <block id="95c17c63df7ceea39a175b1d96955bb7" category="paragraph">El segundo método es Oracle Direct NFS (dNFS). Se trata de una implementación del estándar NFS dentro del software de base de datos Oracle. No cambia la forma en que el DBA configura o gestiona las bases de datos Oracle. Siempre que el sistema de almacenamiento disponga de la configuración correcta, el uso de dNFS debe ser transparente para el equipo de administradores de bases de datos y los usuarios finales.</block>
  <block id="43539d2fca21e5b644484efb94614a7b" category="paragraph">Una base de datos con la función dNFS activada todavía tiene montados los sistemas de archivos NFS habituales. Una vez abierta la base de datos, Oracle Database abre un conjunto de sesiones TCP/IP y ejecuta las operaciones NFS directamente.</block>
  <block id="26e7ebad3936387b4b3f7c4f5688ef27" category="section-title">NFS directo</block>
  <block id="6d431a52c8a41a7c2335f98e2ae8c454" category="paragraph">El valor principal de Direct NFS de Oracle es omitir el cliente NFS host y realizar operaciones de archivos NFS directamente en un servidor NFS. Para activarlo sólo es necesario cambiar la biblioteca de Oracle Disk Manager (ODM). Las instrucciones para este proceso se proporcionan en la documentación de Oracle.</block>
  <block id="8401d91735209aeccbe56f33b4e2db73" category="paragraph">El uso de dNFS permite mejorar considerablemente el rendimiento de I/O y disminuye la carga en el host y el sistema de almacenamiento, ya que el proceso de I/O se realiza de la forma más eficiente posible.</block>
  <block id="b0dedecb00787180a9e0c657cfb278c9" category="paragraph">Además, Oracle dNFS incluye una *opción* para el acceso múltiple de la interfaz de red y la tolerancia a fallos. Por ejemplo, se pueden enlazar dos interfaces de 10Gb GbE para ofrecer un ancho de banda de 20Gb Gb/s. El fallo de una interfaz provoca que se vuelvan a intentar I/O en la otra interfaz. El funcionamiento general es muy similar al multivía FC. La tecnología MultiPath era común hace años, cuando ethernet de 1GB Gb era el estándar más común. Una NIC de 10Gb es suficiente para la mayoría de las cargas de trabajo de Oracle, pero si se necesitan más, se pueden vincular 10Gb NIC.</block>
  <block id="11e50b3c816105439151db3a3b4fdda3" category="paragraph">Cuando se utiliza dNFS, es crítico que se instalen todos los parches descritos en Oracle Doc 1495104,1. Si no se puede instalar un parche, se debe evaluar el entorno para asegurarse de que los errores descritos en ese documento no causen problemas. En algunos casos, la imposibilidad de instalar los parches necesarios impide el uso de dNFS.</block>
  <block id="8f98002fee392ad6151679875de1a7cc" category="paragraph">No utilice dNFS con ningún tipo de resolución de nombres por turnos, incluidos DNS, DDNS, NIS o cualquier otro método. Esto incluye la función de equilibrio de carga DNS disponible en ONTAP. Cuando una base de datos Oracle que utiliza dNFS resuelve un nombre de host en una dirección IP, no debe cambiar en las consultas posteriores. Esto puede provocar fallos en la base de datos de Oracle y daños en los datos.</block>
  <block id="e80ad3efb180dc2d016b27506b7b24ce" category="section-title">Acceso directo a sistemas de archivos del host y NFS</block>
  <block id="4c38a8c0a49e721bf2a378d0b4fb2010" category="paragraph">En ocasiones, el uso de dNFS puede ocasionar problemas en las aplicaciones o actividades del usuario que se basan en los sistemas de archivos visibles montados en el host, ya que el cliente dNFS accede al sistema de archivos fuera de banda desde el sistema operativo host. El cliente dNFS puede crear, eliminar y modificar archivos sin el conocimiento del sistema operativo.</block>
  <block id="c03389fdb295f2acb079603123e6d0e3" category="paragraph">Cuando se utilizan las opciones de montaje para bases de datos de instancia única, se activa el almacenamiento en caché de atributos de archivo y directorio, lo que también significa que el contenido de un directorio está en caché. Por lo tanto, dNFS puede crear un archivo, y hay un breve retraso antes de que el sistema operativo vuelva a leer el contenido del directorio y el archivo se haga visible para el usuario. Esto no es generalmente un problema, pero, en raras ocasiones, utilidades como SAP BR*Tools pueden tener problemas. Si esto sucede, solucione el problema cambiando las opciones de montaje para utilizar las recomendaciones para Oracle RAC. Este cambio provoca la deshabilitación de todo el almacenamiento en caché del host.</block>
  <block id="a370a203383b565c3fb746c1c2e1a64b" category="paragraph">Cambie las opciones de montaje solo cuando (a) se utiliza dNFS y (b) se produce un problema debido a un desfase en la visibilidad de los archivos. Si no se utiliza dNFS, el rendimiento se reduce al utilizar las opciones de montaje de Oracle RAC en una base de datos de instancia única.</block>
  <block id="b1ced01e4bbcd95ec43a2756131f8f9d" category="admonition">Consulte la nota acerca de<block ref="4740c034d97ca90a96b8050082816605" prefix=" " category="inline-code"></block> pulg <block ref="657185beb26ec14433f7e083717fa98b" category="inline-link-macro-rx"></block> Para un problema de dNFS específico de Linux que puede producir resultados inusuales.</block>
  <block id="22a7a03175addfd9aa5b1fa2c351e833" category="summary">Configuración de NFS para bases de datos de Oracle</block>
  <block id="6cb2edd2369a17890dce007723d98a6f" category="paragraph">NetApp lleva más de 30 años proporcionando almacenamiento NFS de clase empresarial y su uso está creciendo con la tendencia hacia las infraestructuras basadas en cloud debido a la sencillez de la tecnología.</block>
  <block id="0f8a941fcc56687ad8e3914162c19a41" category="section-title">Versiones de NFS</block>
  <block id="d0972be450ccf257fb73d4878bce204e" category="paragraph">El cliente NFS del sistema operativo debe ser compatible con NetApp.</block>
  <block id="7722a2ae10cef9bccea115dfdfe78a99" category="list-text">NFSv3 es compatible con sistemas operativos que siguen el estándar NFSv3.</block>
  <block id="a3550edc6962850398d217f78cc4ad0d" category="list-text">NFSv3 es compatible con el cliente Oracle dNFS.</block>
  <block id="89c45ebba54478419aa679a7ece8593d" category="list-text">NFSv4 es compatible con todos los sistemas operativos que siguen el estándar NFSv4.</block>
  <block id="471ff51c89daf6e35e8e2b5111039744" category="inline-link-macro">NetApp IMT</block>
  <block id="8594659e8c4292db778973052a30ab86" category="list-text">NFSv4,1 y NFSv4,2 requieren soporte de SO específico. Consulte la <block ref="d98f827de8e80b3365d5f4160c243cdc" category="inline-link-macro-rx"></block> Para sistemas operativos compatibles.</block>
  <block id="d1eb4c2a4d74705a5aa7945f734eff7c" category="list-text">La compatibilidad de Oracle dNFS para NFSv4,1 requiere Oracle 12.2.0.2 o superior.</block>
  <block id="d8bacc1a7a9d6baaeb962e367920593b" category="inline-link-macro">Matriz de compatibilidad de NetApp</block>
  <block id="f16dcce07ca44aa38c7ebe3016b981b2" category="admonition">La <block ref="f1e4f72fb4419d4270270c5ed1e0d9f6" category="inline-link-macro-rx"></block> Para NFSv3 y NFSv4 no incluye sistemas operativos específicos. Todos los sistemas operativos que obedecen a RFC son generalmente compatibles. Al buscar en IMT en línea compatibilidad con NFSv3 o NFSv4, no seleccione un sistema operativo concreto porque no se mostrarán coincidencias. Todos los sistemas operativos están soportados implícitamente por la política general.</block>
  <block id="26ed9768d6a659a9768842d903d0025f" category="section-title">Tablas de ranuras TCP Linux NFSv3</block>
  <block id="c56ec9836fbbd9c0a426a40fc71c265c" category="paragraph">Las tablas de ranuras TCP son equivalentes a NFSv3 a la profundidad de la cola del adaptador de bus de host (HBA). En estas tablas se controla el número de operaciones de NFS que pueden extraordinarias a la vez. El valor predeterminado suele ser 16, que es demasiado bajo para un rendimiento óptimo. El problema opuesto ocurre en los kernels más nuevos de Linux, que pueden aumentar automáticamente el límite de la tabla de ranuras TCP a un nivel que sature el servidor NFS con solicitudes.</block>
  <block id="5270700baa50d07af667096293a27564" category="paragraph">Para obtener un rendimiento óptimo y evitar problemas de rendimiento, ajuste los parámetros del núcleo que controlan las tablas de ranuras TCP.</block>
  <block id="5b29db1d99e19013580fa375a5f87fa5" category="paragraph">Ejecute el<block ref="1a1e44f7a3390ed4647a7d5b7e8b08ed" prefix=" " category="inline-code"></block> command, y observe los siguientes parámetros:</block>
  <block id="8821adf56df4952370cfaa57ccaac68d" category="paragraph">Todos los sistemas Linux deben incluir<block ref="c5f48b899461d4c2b9ddc0b24ea87744" prefix=" " category="inline-code"></block>, pero solo algunos incluyen<block ref="6f72acaebcb9a0de6696aaf3508a6144" prefix=" " category="inline-code"></block>. Ambos deben establecerse en 128.</block>
  <block id="3a954c4e5e8d5ac3af590651efc5a2cb" category="cell">Si no se establecen estos parámetros, puede tener efectos significativos en el rendimiento. En algunos casos, el rendimiento es limitado porque el sistema operativo linux no está emitiendo suficiente I/O. En otros casos, las latencias de I/O aumentan cuando el sistema operativo linux intenta emitir más operaciones de I/O de las que se pueden mantener.</block>
  <block id="837f157b2f309f5415420467f7643e3a" category="section-title">ADR y NFS</block>
  <block id="c0e7bb1383be0bf1268d1d70280bef6d" category="paragraph">Algunos clientes han informado de problemas de rendimiento derivados de una cantidad excesiva de I/O en los datos de<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> ubicación. Por lo general, el problema no ocurre hasta que se acumulan muchos datos de rendimiento. Se desconoce el motivo del exceso de E/S, pero este problema parece ser el resultado de que los procesos de Oracle exploran repetidamente el directorio de destino en busca de cambios.</block>
  <block id="99be2ae95d50120a7c33c818afda1834" category="paragraph">Extracción del<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> y/o.<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> Las opciones de montaje permiten almacenar en caché el sistema operativo del host y reducen los niveles de I/O de almacenamiento.</block>
  <block id="8950578c587f9503f949dfc6a274b611" category="admonition">*NetApp recomienda* no colocar<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> datos en un sistema de archivos con<block ref="79fea224ffd9e8111e4e87cab732464b" prefix=" " category="inline-code"></block> o.<block ref="3504e2b0e7c968444314433be465518d" prefix=" " category="inline-code"></block> ya que son probables problemas de rendimiento. Separar<block ref="18ca3ed022c239421418de608ceb49c5" prefix=" " category="inline-code"></block> los datos en un punto de montaje diferente si es necesario.</block>
  <block id="cdb92b4a73ae99cde4df55c06e20dd3c" category="section-title">nfs-rootonly y mount-rootonly</block>
  <block id="c1f0a21ee026237bef11139a30b07040" category="paragraph">ONTAP incluye una opción de NFS denominada<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> Esto controla si el servidor acepta conexiones de tráfico NFS desde puertos altos. Como medida de seguridad, solo el usuario root puede abrir conexiones TCP/IP utilizando un puerto de origen inferior a 1024 porque dichos puertos normalmente están reservados para el uso del sistema operativo, no para los procesos del usuario. Esta restricción ayuda a garantizar que el tráfico NFS provenga de un cliente NFS del sistema operativo real y no de un proceso malicioso que emula un cliente NFS. El cliente dNFS de Oracle es un controlador de espacio de usuario, pero el proceso se ejecuta como raíz, por lo que generalmente no es necesario cambiar el valor de<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block>. Las conexiones se realizan a partir de puertos bajos.</block>
  <block id="832b4524bcec11d28ca777ef9cdb4084" category="paragraph">La<block ref="eb6c1a5ecd1e17d4cd46fa5c9d415816" prefix=" " category="inline-code"></block> La opción solo se aplica a NFSv3. Controla si la llamada DE MONTAJE RPC se acepta desde puertos superiores a 1024. Cuando se utiliza dNFS, el cliente vuelve a ejecutarse como raíz, por lo que puede abrir puertos por debajo de 1024. Este parámetro no tiene efecto.</block>
  <block id="57c47a1451485bec1ebb060afdf65cb4" category="paragraph">Los procesos que abren conexiones con dNFS a través de NFS versiones 4,0 y superiores no se ejecutan como raíz y, por lo tanto, requieren puertos a través de 1024. La<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> El parámetro debe estar establecido en disabled para que dNFS complete la conexión.</block>
  <block id="4dd73247734d116e5039cc04c4979f2c" category="paragraph">Si<block ref="77743dec92afc92eca95c255fd9333d7" prefix=" " category="inline-code"></block> Está habilitada, el resultado es un bloqueo durante la fase de montaje al abrir las conexiones dNFS. La salida sqlplus tiene un aspecto similar al siguiente:</block>
  <block id="f62d72479920ff0f8dc9a3ca6f301b5d" category="paragraph">El parámetro se puede cambiar de la siguiente manera:</block>
  <block id="47fc6c6691aed3ba0dbdc66c7896c61b" category="admonition">En raras ocasiones, es posible que necesite cambiar nfs-rootonly y mount-rootonly a disabled. Si un servidor administra un número extremadamente grande de conexiones TCP, es posible que no haya puertos por debajo de 1024 GbE disponibles y que el sistema operativo se vea forzado a utilizar puertos más altos. Estos dos parámetros de ONTAP necesitarían ser cambiados para permitir que la conexión se complete.</block>
  <block id="10b4eb170fe7bd035f21e7d863796683" category="section-title">Políticas de exportación NFS: Superusuario y setuid</block>
  <block id="98bfec37486e95443730cc3d462022fb" category="paragraph">Si los binarios de Oracle se encuentran en un recurso compartido NFS, la política de exportación debe incluir permisos de superusuario y setuid.</block>
  <block id="3c0699ba2c56cb17c145bbda5580ed67" category="paragraph">Las exportaciones NFS compartidas que se utilizan para servicios de archivos genéricos, como los directorios iniciales de usuario, suelen aplastar al usuario raíz. Esto significa que una solicitud del usuario root en un host que ha montado un sistema de archivos se vuelve a asignar como un usuario diferente con privilegios inferiores. Esto ayuda a proteger los datos al impedir que un usuario root de un servidor determinado acceda a los datos del servidor compartido. El bit setuid también puede ser un riesgo de seguridad en un entorno compartido. El bit setuid permite que un proceso se ejecute como un usuario diferente al usuario que llama al comando. Por ejemplo, un script de shell que era propiedad de root con el bit setuid se ejecuta como root. Si ese script de shell pudiera ser cambiado por otros usuarios, cualquier usuario que no sea root podría emitir un comando como root actualizando el script.</block>
  <block id="e341736b7d51c23cb7ef95615832e502" category="paragraph">Los binarios de Oracle incluyen archivos propiedad de root y utilizan el bit setuid. Si los binarios de Oracle se instalan en un recurso compartido NFS, la política de exportación debe incluir los permisos de superusuario y setuid adecuados. En el ejemplo siguiente, la regla incluye ambos<block ref="1efaeada4e3307369aca511f5da0498a" prefix=" " category="inline-code"></block> y permisos<block ref="0baea2f0ae20150db78f58cddac442a9" prefix=" " category="inline-code"></block> Acceso (root) para clientes NFS mediante la autenticación del sistema.</block>
  <block id="f1a0fa258c785ac546835a1a75017faf" category="section-title">Configuración de NFSv4/4,1</block>
  <block id="52f9ad2e353a42e61d9bf7dd9f59d0cb" category="paragraph">Para la mayoría de las aplicaciones, hay muy poca diferencia entre NFSv3 y NFSv4. Las operaciones de I/O de aplicaciones suelen ser muy sencillas y no se benefician de forma significativa de algunas de las funciones avanzadas disponibles en NFSv4. Las versiones superiores de NFS no deberían considerarse como una «actualización» desde el punto de vista del almacenamiento de base de datos, sino como versiones de NFS que incluyen funciones adicionales. Por ejemplo, si se requiere la seguridad de extremo a extremo del modo de privacidad de kerberos (krb5p), se necesita NFSv4.</block>
  <block id="a1dc4350330c061ae52050f5a3400e25" category="section-title">NFSv4 dominio</block>
  <block id="c30669603c950b31f6093d8beaf8060a" category="paragraph">Una explicación completa de la configuración de NFSv4/4,1 está fuera del alcance de este documento, pero un problema que se encuentra comúnmente es una discrepancia en la asignación de dominio. Desde un punto de vista sysadmin, los sistemas de archivos NFS parecen comportarse normalmente, pero las aplicaciones informan de errores sobre permisos y/o setuid en determinados archivos. En algunos casos, los administradores han concluido incorrectamente que los permisos de los binarios de la aplicación se han dañado y han ejecutado comandos chown o chmod cuando el problema real era el nombre de dominio.</block>
  <block id="f0c6c8a632eeaa954640907ee1da277d" category="paragraph">El nombre de dominio NFSv4 se establece en la SVM de ONTAP:</block>
  <block id="97a98ebe6ac1f4a8eaf69158419dd818" category="paragraph">El nombre de dominio NFSv4 del host se establece en<block ref="60969252b5b8391a3378335ae420d2e8" prefix=" " category="inline-code"></block></block>
  <block id="4ade50e8135e817e75aa3086851eaaa8" category="paragraph">Los nombres de dominio deben coincidir. Si no lo hacen, aparecerán errores de asignación similares a los siguientes en la<block ref="452905a167cf4509fd08acb964fdb20c" prefix=" " category="inline-code"></block>:</block>
  <block id="c0eb73bb35a4c58d87b330cd00f1986a" category="paragraph">Los binarios de aplicaciones, como los binarios de Oracle Database, incluyen archivos propiedad de root con el bit setuid, lo que significa que una discrepancia en los nombres de dominio NFSv4 provoca fallos en el inicio de Oracle y una advertencia sobre la propiedad o los permisos de un archivo llamado<block ref="dd440398b298ff16eb1188ba8afca6df" prefix=" " category="inline-code"></block>, que se encuentra en la<block ref="002f94d606ac06f290f33a5fcc67b264" prefix=" " category="inline-code"></block> directorio. Debería aparecer de la siguiente manera:</block>
  <block id="21cc6f8790de2a7022b344914915604e" category="paragraph">Si este archivo aparece con la propiedad de Nadie, puede haber un problema de asignación de dominio NFSv4.</block>
  <block id="203f1cdb2421d34e9eb7391e03ffcaf6" category="paragraph">Para solucionarlo, compruebe la<block ref="60969252b5b8391a3378335ae420d2e8" prefix=" " category="inline-code"></block> Haga un archivo con la configuración de v4-id-domain en ONTAP y asegúrese de que son consistentes. Si no lo son, realice los cambios necesarios, ejecute<block ref="1c7ebfbcaa2681599e41320ed491ca91" prefix=" " category="inline-code"></block>, y esperar un momento para que los cambios se propaguen. La propiedad del archivo debe reconocerse correctamente como root. Si un usuario había intentado ejecutar<block ref="05f0da969f2e0e6ecf3ab445e1e665ad" prefix=" " category="inline-code"></block> En este archivo antes de que se corrigiera la configuración de los dominios NFS, es posible que sea necesario ejecutarlo<block ref="05f0da969f2e0e6ecf3ab445e1e665ad" prefix=" " category="inline-code"></block> de nuevo.</block>
  <block id="748f6387bf49161b9a69b7bfd691dcd2" category="paragraph">La presencia de cualquiera de las siguientes opciones de montaje provoca la deshabilitación del almacenamiento en caché del host:</block>
  <block id="9f75df502ef11eaef4292c94110cb673" category="paragraph">Estos ajustes pueden tener un efecto negativo grave en la velocidad de la instalación del software, la aplicación de parches y las operaciones de copia de seguridad/restauración. En algunos casos, especialmente con aplicaciones en cluster, estas opciones son necesarias como consecuencia inevitable de la necesidad de proporcionar coherencia de la caché en todos los nodos del cluster. En otros casos, los clientes utilizan estos parámetros por error y el resultado es un daño innecesario en el rendimiento.</block>
  <block id="8d23519d53d6611bc42fef8dc4a432df" category="paragraph">Muchos clientes eliminan temporalmente estas opciones de montaje durante la instalación o aplicación de parches de los archivos binarios de la aplicación. Esta eliminación se puede realizar de forma segura si el usuario comprueba que ningún otro proceso está utilizando activamente el directorio de destino durante el proceso de instalación o aplicación de parches.</block>
  <block id="f73bede4039d47664f70de3c2d1f2b46" category="summary">Configuración de franjas de LVM para bases de datos de Oracle</block>
  <block id="1b5681ffc153e25d2a48ae3f3f01b9f5" category="paragraph">La segmentación de LVM hace referencia a distribuir datos entre varias LUN. El resultado es una mejora espectacular del rendimiento en muchas bases de datos.</block>
  <block id="358b9a846de3e04b423c68bac9bc6d53" category="summary">Alineación de LUN con bases de datos de Oracle</block>
  <block id="3e00e4d28b17eedd6f6c2c38233e06a8" category="paragraph">La alineación de LUN hace referencia a optimizar las I/O con respecto al diseño del sistema de archivos subyacente.</block>
  <block id="a6c7e85d51ae3b98197ceb3eafa3686a" category="inline-link-macro">Eficiencia</block>
  <block id="6e2524d5663b2bdc0c7985fa3e57cc55" category="section-title">Advertencias de desalineación</block>
  <block id="79e721357e358d77c4700c25c863fc37" category="inline-link">Configuración de host SAN ONTAP</block>
  <block id="268b1da3f1ff11d32e385d0223101718" category="paragraph">La alineación en entornos Solaris es más complicada. Consulte<block ref="2d33e0364c07dc165b4079892340d4fe" category="inline-link-rx"></block> si quiere más información.</block>
  <block id="6d017248f1e4f0ec7e2cd19d967b6bee" category="cell">En entornos Solaris x86, tenga cuidado adicional con la alineación correcta, ya que la mayoría de las configuraciones tienen varias capas de particiones. Los segmentos de partición de Solaris x86 normalmente existen en la parte superior de una tabla de particiones de registro de inicio maestro estándar.</block>
  <block id="b1230060a0220caf9d68d64b9dd85e6f" category="summary">Tamaños de transferencia de NFS con Oracle</block>
  <block id="fabe34ed4a5e432f4d1c4f6584956d8d" category="doc">Los tamaños de transferencia de NFS con bases de datos de Oracle</block>
  <block id="1e207db9a7c8127a6c43c771b89254fb" category="paragraph">De forma predeterminada, ONTAP limita el tamaño de I/O de NFS a 64K.</block>
  <block id="72d22e3b9af95e272859e64eb1d82df7" category="paragraph">La I/O aleatoria con la mayoría de aplicaciones y bases de datos utiliza un tamaño de bloque mucho más pequeño, que es muy inferior al máximo de 64K KB. Las operaciones de I/O de grandes bloques suelen estar en paralelo, por lo que el máximo de 64K KB tampoco se limita a obtener el ancho de banda máximo.</block>
  <block id="ebf61afddb34d070825eb696bea48813" category="paragraph">Hay algunas cargas de trabajo en las que el máximo de 64K crea una limitación. En particular, las operaciones de subproceso único como la operación de copia de seguridad o recuperación o una exploración de tabla completa de la base de datos se ejecutan de forma más rápida y eficiente si la base de datos puede realizar menos E/S pero más grandes. El tamaño óptimo de gestión de I/O para ONTAP es de 256K KB.</block>
  <block id="b0a5b394f3a29e64573049cda19fbacc" category="paragraph">El tamaño de transferencia máximo para una SVM de ONTAP determinada se puede cambiar de la siguiente manera:</block>
  <block id="b070b82d66be7116d5fd6dfd8172351b" category="cell">No reduzca nunca el tamaño máximo permitido de transferencia en ONTAP por debajo del valor de rsize/wsize de los sistemas de archivos NFS montados actualmente. Esto puede crear bloqueos o incluso corrupción de datos con algunos sistemas operativos. Por ejemplo, si los clientes NFS se establecen actualmente con un valor de rsize/wsize de 65536 000, el tamaño de transferencia máximo de ONTAP se podría ajustar entre 65536 000 y 1048576 000 sin que ello afecte a porque los propios clientes están limitados. Reducir el tamaño máximo de transferencia por debajo de 65536 puede dañar la disponibilidad o los datos.</block>
  <block id="8eb703f2756cafd21dbac4f23c0d6416" category="paragraph">ONTAP elimina de manera eficiente los bloques puestos a cero que se escriben en un archivo o LUN cuando se habilita la compresión en línea. Las utilidades como Oracle ASM Reclamation Utility (ASRU) funcionan escribiendo ceros en extensiones de ASM no utilizadas.</block>
  <block id="9de53c14f2bae0c5d4b6e19be495ee94" category="paragraph">Desde el punto de vista de la base de datos, el grupo de discos de ASM contiene ceros, y leer esas regiones de las LUN daría como resultado un flujo de ceros, pero ONTAP no almacena los ceros en las unidades. En su lugar, se realizan cambios sencillos en los metadatos que marcan internamente las regiones en cero de la LUN como vacías de datos.</block>
  <block id="06348c6e795160187e298a91b25a37a3" category="paragraph">Por motivos similares, las pruebas de rendimiento que involucran datos puestos a cero no son válidas porque en realidad los bloques de ceros no se procesan como escrituras en la cabina de almacenamiento.</block>
  <block id="cee584f1e6223f6dbb73c0d64d599228" category="admonition">Al utilizar ASRU, asegúrese de que todos los parches recomendados por Oracle están instalados.</block>
  <block id="17ff263bc6eb701aecb8e79f9ef53efd" category="summary">Cambio de tamaño de LUN y LVM con bases de datos de Oracle</block>
  <block id="ff15e8b125dae74c1231f09380e48886" category="paragraph">Cuando un sistema de archivos basado en SAN ha alcanzado su límite de capacidad, hay dos opciones para aumentar el espacio disponible:</block>
  <block id="4182200437c090276a01ad8ca54076b0" category="summary">Configurar NVFAIL para proteger bases de datos de Oracle</block>
  <block id="60e002164f8988e984cf4a95b240f19d" category="doc">Oracle y NVFAIL</block>
  <block id="370bdf5dd39278264774ea595054e243" category="paragraph">NVFAIL es una función de ONTAP que garantiza la integridad en situaciones catastróficas de conmutación por error.</block>
  <block id="80250c1f1d70fc693877be6f22cc134e" category="paragraph">Las bases de datos son vulnerables a daños durante eventos de conmutación por error de almacenamiento debido a que mantienen cachés internos de gran tamaño. Si un evento catastrófico requiere forzar una conmutación por error de ONTAP o forzar la conmutación por error de MetroCluster, independientemente del estado de la configuración general, el resultado es que los cambios confirmados previamente se pueden descartar de forma efectiva. El contenido de la cabina de almacenamiento se retrocede en el tiempo y el estado de la caché de base de datos ya no refleja el estado de los datos del disco. Esta inconsistencia provoca daños en los datos.</block>
  <block id="68114defc717054e7e3b02df438cdbe1" category="paragraph">El almacenamiento en caché puede tener lugar en la capa de aplicaciones o del servidor. Por ejemplo, una configuración de Oracle Real Application Cluster (RAC) con servidores activos tanto en un sitio primario como en un sitio remoto almacena datos en caché en Oracle SGA. Una operación de conmutación de sitios forzada que provocara una pérdida de datos pondría la base de datos en riesgo de dañarse, ya que los bloques almacenados en el SGA podrían no coincidir con los bloques del disco.</block>
  <block id="162de6d405c04ce8f152f1d246ed9187" category="paragraph">Un uso menos obvio del almacenamiento en caché se da en la capa del sistema de archivos del sistema de sistemas operativos. Los bloques de un sistema de archivos NFS montado se pueden almacenar en caché en el sistema operativo. Como alternativa, un sistema de archivos en clúster basado en las LUN ubicadas en el sitio primario podría montarse en servidores en el sitio remoto y una vez más podrían almacenarse los datos en caché. Un fallo de NVRAM o una toma de control forzada o una conmutación de sitios forzada en estas situaciones podría provocar daños en el sistema de archivos.</block>
  <block id="04ca8d9ad570a3bdf1d76e23bc108ae5" category="paragraph">ONTAP protege las bases de datos y los sistemas operativos de este escenario con NVFAIL y su configuración asociada.</block>
  <block id="82ef718f4ebe0c276814ee3d51e33361" category="doc">SnapRestore</block>
  <block id="863696626734d6591db8be57b41c7eec" category="paragraph">Restauración de datos rápida en ONTAP a partir de una copia Snapshot realizada por la tecnología NetApp SnapRestore.</block>
  <block id="9099b669f87419bc03914f11f5779c60" category="paragraph">Cuando un conjunto de datos críticos no está disponible, las operaciones empresariales fundamentales no funcionan. Las cintas pueden romperse e incluso las restauraciones de backups basados en discos pueden ser lentas para transferirse por la red. SnapRestore evita estos problemas al ofrecer una restauración casi instantánea de conjuntos de datos. Incluso las bases de datos con capacidad de petabytes se pueden restaurar por completo con tan solo unos minutos.</block>
  <block id="b02fb7dec22d0e276ca01cc60b9efb48" category="paragraph">Hay dos formas de SnapRestore: Basado en archivos/LUN y basado en volúmenes.</block>
  <block id="520e4b70b10aa2755a82b77e438a510f" category="list-text">Pueden restaurarse archivos o LUN individuales en segundos, tanto si se trata de un LUN de 2TB GB como de un archivo 4KB.</block>
  <block id="45e8a84fe4ac58c8b30a7bdaf17c0b7f" category="list-text">El contenedor de archivos o LUN se puede restaurar en segundos, ya sea 10GB o 100TB TB de datos.</block>
  <block id="4be4677be8cd434956b9b9af515b971a" category="paragraph">Un «contenedor de archivos o LUN» normalmente hace referencia a un volumen FlexVol. Por ejemplo, puede tener 10 LUN que componen un grupo de discos LVM en un único volumen o un volumen puede almacenar los directorios iniciales NFS de 1000 usuarios. En lugar de ejecutar una operación de restauración para cada archivo o LUN individuales, puede restaurar el volumen completo como una única operación. Este proceso también funciona con contenedores de escalado horizontal que incluyen múltiples volúmenes, como una FlexGroup o un grupo de consistencia ONTAP.</block>
  <block id="55abea92d64d6738f9e0ed48799696e7" category="paragraph">ONTAP solo permite el acceso de solo lectura a los datos de snapshots, pero los datos se pueden reactivar con SnapRestore. La copia de Snapshot se vuelve a habilitar como una vista de lectura y escritura de los datos, lo que devuelve los datos a su estado anterior. SnapRestore puede funcionar a nivel de volumen o archivo. La tecnología es esencialmente la misma con algunas pequeñas diferencias en el comportamiento.</block>
  <block id="f10f2af75e2770a8ed3c2fde594e986d" category="section-title">SnapRestore de volumen</block>
  <block id="ca9846346bc3b03cdec10f9fff456866" category="paragraph">La SnapRestore basada en volúmenes devuelve todo el volumen de datos a un estado anterior. Esta operación no requiere el movimiento de datos, lo que significa que el proceso de restauración es esencialmente instantáneo, aunque la operación de la API o la CLI puede tardar unos segundos en procesarse. La restauración de 1GB TB de datos no es más complicada ni requiere más tiempo que restaurar 1PB TB de datos. Esta funcionalidad es el principal motivo por el que muchos clientes empresariales migran a los sistemas de almacenamiento de ONTAP. Proporciona un objetivo de tiempo de recuperación que se mide en segundos incluso para los conjuntos de datos de mayor tamaño.</block>
  <block id="627436e77bb011a6a312ae87b12f98ea" category="paragraph">Una desventaja de la SnapRestore basada en el volumen se debe al hecho de que los cambios dentro de un volumen son acumulativos con el tiempo. Por lo tanto, cada instantánea y los datos del archivo activo dependen de los cambios que conduzcan a ese punto. Revertir un volumen a un estado anterior implica descartar todos los cambios posteriores que se habían realizado en los datos. Sin embargo, lo que no resulta tan obvio es que se incluyen las instantáneas creadas posteriormente. Esto no siempre es deseable.</block>
  <block id="5c956f2c1cfc5b9e5bac32ad1acba314" category="paragraph">Por ejemplo, un acuerdo de nivel de servicio de retención de datos puede especificar 30 días de backups nocturnos. Si se restaura un conjunto de datos en una snapshot creada hace cinco días con SnapRestore para volúmenes, se descartarán todas las snapshots creadas en los cinco días anteriores, lo que infringe el acuerdo de nivel de servicio.</block>
  <block id="8bf9e697004f47ed6133aef724a8a42c" category="paragraph">Hay varias opciones disponibles para abordar esta limitación:</block>
  <block id="ad3b75456e625de5fe347fb918f59a22" category="list-text">Los datos se pueden copiar a partir de una snapshot anterior, en lugar de realizar una SnapRestore de todo el volumen. Este método funciona mejor con conjuntos de datos más pequeños.</block>
  <block id="90541eb74c7c56cadc2f90ec6fb6f0c0" category="list-text">Una copia Snapshot puede clonarse en lugar de restaurarse. La limitación de este enfoque es que la copia Snapshot de origen depende del clon. Por lo tanto, no se puede eliminar a menos que también se elimine el clon o se divida en un volumen independiente.</block>
  <block id="ab6045d3463c0f68ce2fa405dce9d554" category="list-text">Uso de SnapRestore basado en archivos.</block>
  <block id="7f7599a8b92846b691484dc91e090164" category="section-title">SnapRestore de archivos</block>
  <block id="f03eebe4f07d362dbfe4c1d4e76c724d" category="paragraph">La SnapRestore basada en archivos es un proceso de restauración más granular basado en Snapshot. En lugar de revertir el estado de un volumen completo, se revierte el estado de un archivo individual o LUN. No es necesario eliminar ninguna instantánea, ni esta operación crea ninguna dependencia de una instantánea anterior. El archivo o el LUN estarán disponibles de inmediato en el volumen activo.</block>
  <block id="e432fdcc277fc74a1b2b94cfeec8a7d2" category="paragraph">No es necesario mover datos durante una restauración SnapRestore de un archivo o una LUN. Sin embargo, se requieren algunas actualizaciones internas de metadatos para reflejar el hecho de que los bloques subyacentes de un archivo o LUN ahora existen tanto en una snapshot como en el volumen activo. No debería afectar el rendimiento, pero este proceso bloquea la creación de snapshots hasta que se completa. La tasa de procesamiento es de aproximadamente 5Gbps (18TB TB/hora) en función del tamaño total de los archivos restaurados.</block>
  <block id="45c46768a1cb073f0d13245a0dc816f2" category="paragraph">La arquitectura de protección de datos empresariales adecuada depende de los requisitos empresariales relacionados con la retención de datos, la capacidad de recuperación y la tolerancia a interrupciones durante diversos eventos.</block>
  <block id="46e1b2893bdb002c0ede448cbfe1cb14" category="paragraph">Por ejemplo, piense en el número de aplicaciones, bases de datos y conjuntos de datos importantes. Crear una estrategia de backup para un único conjunto de datos que garantice el cumplimiento de los acuerdos de nivel de servicio típicos es bastante sencillo, ya que no hay muchos objetos que gestionar. A medida que aumenta el número de conjuntos de datos, la supervisión se hace más complicada y los administradores pueden verse forzados a invertir cada vez más tiempo en solucionar los fallos de backup. A medida que un entorno llega al cloud y escala el proveedor de servicios, se necesita un enfoque totalmente diferente.</block>
  <block id="b70d233428e03d072b1134a97d853ab2" category="paragraph">El tamaño del conjunto de datos también afecta a la estrategia. Por ejemplo, existen muchas opciones para backup y recuperación con una base de datos 100GB porque el conjunto de datos es tan pequeño. La simple copia de los datos de los medios de backup con herramientas tradicionales suele proporcionar un objetivo de tiempo de recuperación suficiente para la recuperación. Una base de datos de 100TB suele necesitar una estrategia completamente diferente a menos que el objetivo de tiempo de recuperación permita una interrupción de varios días, en cuyo caso puede ser aceptable un procedimiento tradicional de backup y recuperación basado en copia.</block>
  <block id="64848fee9c168231f5d0f13322ed0a87" category="paragraph">Por último, existen factores fuera del propio proceso de backup y recuperación. Por ejemplo, ¿existen bases de datos que respalden actividades de producción críticas, lo que convierte la recuperación en un evento raro que solo realizan los administradores de bases de datos cualificados? Alternativamente, ¿las bases de datos forman parte de un entorno de desarrollo de gran tamaño en el que la recuperación es una ocurrencia frecuente y gestionada por un EQUIPO de TECNOLOGÍA generalista?</block>
  <block id="e26b57887de9a65c0316a87d49bf6c44" category="section-title">¿Una snapshot es un backup?</block>
  <block id="c3fd105ab426caff0a0ade2e93476543" category="paragraph">Una objeción habitual al uso de copias Snapshot como estrategia de protección de datos es el hecho de que los datos «reales» y los de copias Snapshot se encuentran en las mismas unidades. La pérdida de esas unidades provocaría la pérdida de los datos primarios y el backup.</block>
  <block id="12d1adb01d24027626b2a47660fb5b81" category="paragraph">Este es un problema válido. Los snapshots locales se usan para necesidades de backup y recuperación diarias y, en ese sentido, la snapshot es un backup. Cerca del 99 % de todos los escenarios de recuperación en entornos NetApp utilizan copias Snapshot para satisfacer incluso los requisitos de objetivo de tiempo de recuperación más agresivos.</block>
  <block id="fc34c9966c8ecb7307468637d9e79933" category="paragraph">Sin embargo, las copias Snapshot locales nunca deberían ser la única estrategia de backup, por lo que NetApp ofrece tecnología como la replicación de SnapMirror para replicar de forma rápida y eficiente snapshots en un conjunto de unidades independiente. En una solución correctamente diseñada con copias Snapshot y replicación Snapshot, el uso de la cinta puede minimizarse tal vez a un archivo trimestral o eliminarse totalmente.</block>
  <block id="1ea948130a9dbbc02e3a80648a99ff57" category="section-title">Backups de grupos de consistencia</block>
  <block id="9b234a126e57777ab83807827d4e7078" category="paragraph">Un backup de grupo de consistencia implica capturar el estado de un conjunto de datos (o varios conjuntos de datos) en un único momento específico atómico. Como ejemplo de base de datos, incluye todos los componentes de la base de datos, como archivos de datos, archivos log y otros archivos directamente asociados a la base de datos. Esto funciona con casi todos los productos de bases de datos relacionales, incluidos Oracle RDBMS, Microsoft SQL Server, SAP HANA, PostgreSQL, MySQL y MariaDB. Proteger una configuración de VMware con un backup de grupo de consistencia sería similar: Capturar todos los almacenes de datos y, potencialmente, las LUN de arranque ESX en un único punto atómico del tiempo.</block>
  <block id="5a1f7038c74e54c08669efa6722f1091" category="paragraph">La creación de una snapshot de grupo de coherencia de este tipo simula esencialmente un bloqueo, por el cual estos backups se denominan backups consistentes con los fallos. A veces hay preocupaciones con el soporte para escenarios de recuperación, pero es importante entender que no se requiere ningún procedimiento de recuperación. Cuando la aplicación se inicia después de restaurar un backup de grupo de consistencia, ejecuta los procesos de recuperación de registros habituales, las reproducciones de diarios del sistema de archivos y otras tareas para reproducir cualquier I/O que estuviera en curso en el punto del backup. La aplicación entonces comienza como de costumbre.</block>
  <block id="aebdbddec25f7eba6434244a989fb659" category="paragraph">Básicamente, cualquier aplicación que pueda resistir un fallo de alimentación o un fallo del servidor sin corrupción de datos puede protegerse de esta manera. El hecho de que esto funcione también se puede demostrar por el enorme número de aplicaciones protegidas con productos de mirroring síncrono y asíncrono de muchos proveedores diferentes. Si un desastre golpea repentinamente el sitio principal, entonces el sitio de réplica contiene una imagen consistente del entorno original en el momento en que ocurrió el desastre. Una vez más, no se requiere ningún procedimiento de recuperación especial.</block>
  <block id="e085ffefd89f8fb66260a9720e3fb6f8" category="paragraph">El RPO de este método suele limitarse al punto del backup. Como regla general, el objetivo de punto de recuperación mínimo para copias Snapshot de volumen único es de una hora. Por ejemplo, es razonable realizar 48 instantáneas por hora y otros 30 días de instantáneas por noche y no requerirían la retención de un número excesivo de instantáneas. Se hace más difícil conseguir un objetivo de punto de recuperación inferior a una hora, algo que no se recomienda sin consultar primero los servicios profesionales de NetApp para comprender los requisitos de entorno, escala y protección de datos.</block>
  <block id="1fe119a790b393b7dd7e79b63f15f52b" category="paragraph">El RTO suele medirse en segundos. Una aplicación se apaga, se restauran los volúmenes y se reinicia la aplicación.</block>
  <block id="444cd304758b7607c8f7a3f627a5bc1f" category="paragraph">El enfoque más simple es colocar todos los archivos o LUN en un único grupo de consistencia de volúmenes, lo que permite programar una creación de copias Snapshot directamente en ONTAP. Donde un conjunto de datos debe abarcar volúmenes, se requiere una snapshot de grupo de coherencia (cg-snapshot). Esto puede configurarse mediante llamadas a la API RESTful o System Manager y, además, SnapCenter puede crear una snapshot de grupo de coherencia sencilla en una lista de volúmenes definida.</block>
  <block id="689b0155b42a554594a44cddc736eb67" category="section-title">Arquitectura de replicación y recuperación ante desastres</block>
  <block id="1749d12df3df2319d3eee218a277ff83" category="inline-link-macro">MetroCluster</block>
  <block id="f443592081a2b3ddc55b94abe49ba128" category="paragraph">El objetivo de punto de recuperación de desastres está limitado por el ancho de banda de red disponible y el tamaño total de los datos que se protegen. Una vez creada la transferencia básica, las actualizaciones solo se basan en los datos modificados, que normalmente son un bajo porcentaje de la huella de datos total, aunque existen excepciones.</block>
  <block id="89e87a831dae60244ba34496d70fd45d" category="paragraph">Por ejemplo, una base de datos de 10TB GB con una tasa de cambio semanal del 10% tiene un promedio de aproximadamente 6GB dólares por hora de cambios totales. Con 10Gb de conectividad, esta base de datos requiere aproximadamente seis minutos para transferirse. La tasa de cambio varía con la fluctuación en la tasa de cambios de la base de datos, pero en general un intervalo de actualización de 15 minutos y, por lo tanto, un objetivo de punto de recuperación de 15 minutos debería ser alcanzable. Si hay 100 bases de datos de este tipo, se necesitan 600 minutos para transferir los datos. Por lo tanto, no es posible un objetivo de punto de recuperación de una hora. Del mismo modo, una réplica de una única base de datos de 100TB GB de tamaño con una tasa de cambio semanal del 10% no se puede actualizar de forma fiable en una hora.</block>
  <block id="3c886a803aef21f5ac9f7bcea7408cbb" category="paragraph">Otros factores pueden afectar a la replicación, como la sobrecarga de la replicación y las limitaciones en el número de operaciones de replicación simultáneas. Sin embargo, la planificación general para una estrategia de replicación de un único volumen puede basarse en el ancho de banda disponible y, por lo general, es posible lograr un RPO de replicación de una hora. Un objetivo de punto de recuperación inferior a una hora se complica y solo debe llevarse a cabo tras consultar los Servicios profesionales de NetApp. En algunos casos, 15 minutos es factible con muy buena conectividad de red sitio a sitio. Sin embargo, en general, cuando se necesita un objetivo de punto de recuperación inferior a una hora, la arquitectura de repetición de registros de varios volúmenes ofrece mejores resultados.</block>
  <block id="5e2cbdd214e7a73bca1af8ed5cc04626" category="paragraph">El objetivo de tiempo de recuperación con replicación de grupos de consistencia en un escenario de recuperación ante desastres es excelente, normalmente se mide en segundos desde el punto de vista del almacenamiento. El enfoque más sencillo es simplemente romper la duplicación, y la base de datos está lista para iniciarse. El tiempo de inicio de la base de datos suele ser de unos 10 segundos, pero las bases de datos muy grandes con muchas transacciones registradas pueden tardar unos minutos.</block>
  <block id="1c18c939e73ddb1ceee34e8a33079d1a" category="paragraph">El factor más importante para determinar el objetivo de tiempo de recuperación no es el sistema de almacenamiento, sino más bien la aplicación y el sistema operativo del host en el que se ejecuta. Por ejemplo, los datos replicados pueden estar disponibles en un segundo o dos, pero esto solo representa los datos. También debe haber un sistema operativo configurado correctamente con binarios de aplicación que estén disponibles para utilizar los datos.</block>
  <block id="6fab898feea25b9d7fd4477911b90b31" category="paragraph">En algunos casos, los clientes han preparado instancias de recuperación ante desastres por adelantado con el almacenamiento detectado previamente en los sistemas operativos. En estos casos, activar el escenario de recuperación ante desastres no puede requerir más que interrumpir el reflejo e iniciar la aplicación. En otros casos, el SO y las aplicaciones asociadas pueden reflejarse junto con la base de datos como un disco de máquina virtual ESX (VMDK). En estos casos, el RPO se determina según la cantidad que ha invertido un cliente en automatización para arrancar rápidamente el VMDK de modo que las aplicaciones puedan iniciarse.</block>
  <block id="c7d5d755b896edf43189fbb020202913" category="paragraph">El tiempo de retención se controla en parte por el límite de instantáneas. Por ejemplo, los volúmenes de ONTAP tienen un límite de 1024 Snapshot. En algunos casos, los clientes tienen replicación multiplexada para aumentar el límite. Por ejemplo, si se necesitan 2000 días de backups, un origen se puede replicar en dos volúmenes con actualizaciones en días alternativos. Esto requiere un aumento en el espacio inicial requerido, pero sigue representando un método mucho más eficaz que un sistema de backup tradicional, que implica varios backups completos.</block>
  <block id="7ec0f114b69016879106b5018cdf10b9" category="section-title">Grupo de consistencia de volumen único</block>
  <block id="cd70f3e596e275fe80fbbe5d7858ce1a" category="paragraph">El enfoque más simple es colocar todos los archivos o LUN en un único grupo de consistencia de volúmenes, lo que permite programar las actualizaciones de SnapMirror y SnapVault directamente en el sistema de almacenamiento. No se requiere ningún software externo.</block>
  <block id="909e8df57072d0b3c6d7d64b11acb571" category="section-title">Grupo de coherencia de varios volúmenes</block>
  <block id="c7371eded617935ace6c71a33cfbf3fd" category="paragraph">Cuando una base de datos debe abarcar volúmenes, se necesita una snapshot de grupo de coherencia (cg-snapshot). Como se mencionó anteriormente, puede configurarse mediante llamadas a la API RESTful o System Manager y, además, SnapCenter puede crear una snapshot de grupo de coherencia sencilla en una lista de volúmenes definida.</block>
  <block id="9c991b38c054d7bec0632efd6667540c" category="paragraph">También existe una consideración adicional sobre el uso de snapshots consistentes y múltiples volúmenes para la recuperación ante desastres. Al realizar una actualización de varios volúmenes, es posible que se produzca un desastre mientras una transferencia aún está en curso. El resultado sería un conjunto de volúmenes que no son coherentes entre sí. Si esto sucedió, algunos de los volúmenes deben restaurarse a un estado de snapshot anterior para ofrecer una imagen de base de datos coherente con los fallos y lista para su uso.</block>
  <block id="fad8a5f46ebd89f74383b461e32dd6b9" category="section-title">Recuperación ante desastres: Activación</block>
  <block id="5ac319591298468b0af89c2c469201f8" category="paragraph">El proceso de activación de la copia de recuperación ante desastres depende del tipo de almacenamiento. Con NFS, los sistemas de archivos pueden premontarse en el servidor de recuperación ante desastres. Se encuentran en un estado de sólo lectura y pasan a ser de lectura y escritura cuando se rompe el espejo. Esto ofrece un objetivo de punto de recuperación extremadamente bajo y el proceso general de recuperación ante desastres es más fiable, ya que existen menos partes que gestionar.</block>
  <block id="b829fc11ff11b57af8d4632d38d7d7e8" category="paragraph">La activación de configuraciones SAN en caso de recuperación ante desastres es cada vez más complicada. La opción más sencilla es, por lo general, romper temporalmente las réplicas y montar los recursos SAN, incluidos pasos como detectar la configuración de LVM (incluidas las funciones específicas de la aplicación como Oracle Automatic Storage Management [ASM]) y agregar entradas a /etc/fstab.</block>
  <block id="335a5796fb106a877544d121062534be" category="paragraph">El resultado es que las rutas del dispositivo LUN, los nombres de los grupos de volúmenes y otras rutas de dispositivos se dan a conocer al servidor de destino. A continuación, estos recursos pueden apagarse y, después, se pueden restaurar los duplicados. El resultado es un servidor que se encuentra en un estado que puede conectar rápidamente la aplicación en línea. Los pasos para activar grupos de volúmenes, montar sistemas de archivos o iniciar bases de datos y aplicaciones están fácilmente automatizados.</block>
  <block id="b1a175c5f42da29f6c27f4ea29684b63" category="paragraph">Es necesario tener cuidado para asegurarse de que el entorno de recuperación ante desastres está actualizado. Por ejemplo, es probable que se añadan nuevas LUN al servidor de origen, lo que significa que se deben detectar previamente las nuevas LUN en el destino para asegurarse de que el plan de recuperación ante desastres funciona como se espera.</block>
  <block id="90426ba53f908049843b3ea392578d04" category="doc">Recuperación ante desastres de Oracle</block>
  <block id="2a4fa9d9434561574119e3086112023f" category="paragraph">La protección de los archivos de datos, los registros de archivo, los registros de recuperación y los archivos de control con una única snapshot es un método válido de copia de seguridad, restauración y replicación.  Sin embargo, el RPO se limita al punto del propio backup. Es adecuado para un objetivo de punto de recuperación de una hora o superior. Si una base de datos abarca volúmenes, se necesitan cg-snapshots utilizando una de las herramientas descritas anteriormente.</block>
  <block id="93310f4cebc752304c164f00d67e0bca" category="paragraph">A modo de ejemplo, toda la base de datos puede estar en un solo volumen con la siguiente programación Snapshot:</block>
  <block id="a33821be4b3522d65daed1ec317299f6" category="list-text">72 snapshots cada hora</block>
  <block id="0eea0679ac7bf43c19d603cd78e81de9" category="list-text">30 snapshots por noche</block>
  <block id="c4546c401776d279c5577011584577fa" category="list-text">12 snapshots mensuales</block>
  <block id="b63db1b650d128c342617b377baf928a" category="paragraph">Esto proporciona un objetivo de punto de recuperación de una hora durante el período de implementación de las 72 horas anteriores, además de backups adicionales mensuales y nocturnos. También se pueden incluir varias bases de datos o archivos de aplicaciones en el único volumen o conjunto de snapshots de cg para ofrecer backups consistentes en un entorno mayor.</block>
  <block id="686540783626106489734a1990d4930d" category="paragraph">ONTAP se ha diseñado para ofrecer la máxima disponibilidad de las bases de datos de Oracle. Este documento no incluye una descripción completa de las funciones de alta disponibilidad de ONTAP. Sin embargo, al igual que sucede con la protección de datos, un conocimiento básico de esta funcionalidad es importante cuando se diseña una infraestructura de base de datos.</block>
  <block id="b049fcbe8198301adc6bf87634a02845" category="section-title">Parejas de HA</block>
  <block id="1a7c11d1e2d03d3d1b57cff284ebd761" category="paragraph">La unidad básica de alta disponibilidad es el par de alta disponibilidad. Cada pareja contiene enlaces redundantes para admitir la replicación de datos hacia NVRAM. NVRAM no es una caché de escritura. La RAM dentro de la controladora funciona como caché de escritura. El objetivo de la NVRAM es registrar temporalmente los datos como protección frente a un fallo inesperado del sistema. En este sentido, es similar a un redo log de base de datos.</block>
  <block id="cd2e54027dfcfeddd07ddd580db527c0" category="paragraph">Tanto la NVRAM como un redo log de base de datos se utilizan para almacenar datos rápidamente, lo que permite que los cambios en los datos se confirmen lo más rápidamente posible. La actualización de los datos persistentes en las unidades (o archivos de datos) no se realiza hasta más adelante durante un proceso denominado punto de control en las plataformas ONTAP y en la mayoría de las bases de datos. Ni los datos de NVRAM ni los registros de recuperación de bases de datos se leen durante las operaciones normales.</block>
  <block id="4e044ec0c36e513506c77c0a97d53539" category="paragraph">Si una controladora falla abruptamente, es posible que existan cambios pendientes almacenados en la NVRAM que aún no se hayan escrito en las unidades. La controladora asociada detecta el fallo, toma el control de las unidades y aplica los cambios requeridos que se han almacenado en NVRAM.</block>
  <block id="310e46747ebab6a43d5a15998f6e2b33" category="section-title">Toma de control y retorno al nodo primario</block>
  <block id="1d739263e44469ad28f77fe7329fa78d" category="paragraph">La toma de control y la devolución hace referencia al proceso de transferencia de la responsabilidad de los recursos de almacenamiento entre los nodos de un par de alta disponibilidad. La toma de control y el retorno al nodo primario tienen dos aspectos:</block>
  <block id="f2d43d90397aa8140414437eda14febb" category="list-text">Gestión de la conectividad de red que permite el acceso a las unidades</block>
  <block id="6e1c794c81468e3286a23138460bb3fb" category="list-text">Gestión de las unidades en sí</block>
  <block id="89d3f6c60c53a11e16a6756bde03ca00" category="paragraph">Las interfaces de red que admiten el tráfico CIFS y NFS están configuradas tanto con un directorio raíz como con una ubicación de recuperación tras fallos. Una toma de control incluye mover las interfaces de red a su directorio raíz temporal en una interfaz física ubicada en las mismas subredes que la ubicación original. Un retorno primario incluye mover las interfaces de red de vuelta a sus ubicaciones originales. El comportamiento exacto se puede ajustar según sea necesario.</block>
  <block id="108018656caf59cc565f1172047dab38" category="paragraph">Las interfaces de red que admiten protocolos de bloques SAN como iSCSI y FC no se reubican durante la toma de control y el retorno al nodo primario. En su lugar, los LUN se deben aprovisionar con rutas que incluyan un par de HA completo, lo que da como resultado una ruta primaria y una secundaria.</block>
  <block id="80795d5dd590e432b4f5945aba47caf4" category="admonition">También se pueden configurar rutas adicionales a controladoras adicionales para admitir la reubicación de datos entre nodos de un clúster más grande, pero esto no forma parte del proceso de alta disponibilidad.</block>
  <block id="aae63904d16fd1c522dc5ff53eb695b5" category="paragraph">El segundo aspecto de la toma de control y la restauración es la transferencia de la propiedad del disco. El proceso exacto depende de múltiples factores, incluyendo la razón de la toma de control/devolución y las opciones de la línea de comandos emitidas. El objetivo es realizar la operación de la manera más eficiente posible. Aunque parezca que el proceso general requiera varios minutos, el momento en el que la propiedad de la unidad se realiza la transición de nodo a nodo generalmente se puede medir en segundos.</block>
  <block id="61775b9e8f759f26eafd6b03448d1f30" category="section-title">Tiempo de toma de control</block>
  <block id="3224b51e62790c4ce988d8c1876fb36e" category="paragraph">El host de I/O experimenta una breve pausa en I/O durante operaciones de toma de control y devolución; pero no debe producirse una interrupción en las aplicaciones en un entorno configurado correctamente. El proceso de transición real en el que se demora I/O suele medirse en segundos, pero el host puede requerir más tiempo para reconocer el cambio en las rutas de datos y volver a enviar las operaciones de I/O.</block>
  <block id="40f291752a9848bfecb7264cfd9aa8ee" category="paragraph">La naturaleza de la interrupción depende del protocolo:</block>
  <block id="cb44db7841f8fb68230a260c4c68bfe0" category="list-text">Una interfaz de red que admite problemas de tráfico NFS y CIFS una solicitud de Protocolo de resolución de direcciones (ARP) a la red después de la transición hacia una nueva ubicación física. Esto hace que los conmutadores de red actualicen sus tablas de direcciones de control de acceso a medios (MAC) y reanuden el procesamiento de E/S. Las interrupciones en el caso de toma de control y devolución planificadas suelen medirse en segundos y, en muchos casos, no se pueden detectar. Puede que algunas redes sean más lentas para reconocer completamente el cambio en la ruta de red y algunos sistemas operativos pueden poner en cola muchas E/S en muy poco tiempo que deben reintentarse. Esto puede ampliar el tiempo necesario para reanudar la actividad de I/O.</block>
  <block id="6a410522094e0b0f874dab5784e81ab8" category="list-text">Una interfaz de red que admite protocolos SAN no realiza la transición a una nueva ubicación. Un SO host debe cambiar la ruta o las rutas en uso. La pausa en I/O observada por el host depende de varios factores. Desde el punto de vista de un sistema de almacenamiento, el período en el que no se puede ofrecer I/O es solo unos segundos. Sin embargo, los sistemas operativos de host diferentes pueden requerir más tiempo para permitir que se agote el tiempo de espera de una E/S antes de volver a intentarlo. Los sistemas operativos más nuevos son más capaces de reconocer un cambio de ruta mucho más rápido, pero los sistemas operativos más antiguos normalmente requieren hasta 30 segundos para reconocer un cambio.</block>
  <block id="cabc4f9cda7d4bfb99181166c863a374" category="paragraph">En la siguiente tabla, se muestran los tiempos de toma de control esperados durante el que el sistema de almacenamiento no puede ofrecer datos a un entorno de aplicación. No debe haber ningún error en ningún entorno de aplicación, la toma de control debería aparecer como una breve pausa en el procesamiento de E/S.</block>
  <block id="c8984126713ed072b9cb0a44a162be4d" category="cell">AFF</block>
  <block id="b7b46ce5d1a547db89c0bc615ff272a5" category="cell">ASA</block>
  <block id="ed3467fac861f6a32cd66093ac415805" category="cell">Toma de control planificada</block>
  <block id="57a915dfa0e8469b25c1b8b947f7ee2c" category="cell">15 seg</block>
  <block id="cd5dce62294e9a79e9c2165ee0903f5f" category="cell">6-10 seg</block>
  <block id="cbfdbb11fd5eab0d9fdd078ae66a1c69" category="cell">2-3 seg</block>
  <block id="1a066f0304c1d3a279466c70359c5103" category="cell">Respaldo no planificado</block>
  <block id="0f4a6e109a34d3483995e427b6581130" category="cell">30 seg</block>
  <block id="dbfb054670bc82c6e08a7e101c0f0ef4" category="paragraph">La protección de datos lógicos en ONTAP consta de tres requisitos clave:</block>
  <block id="b6cc6762545d78ab663e39c37d172bd2" category="list-text">Los datos deben protegerse contra la corrupción de datos.</block>
  <block id="e7c7e14f4b6ca1b3ae32b2279243dba6" category="list-text">Los datos deben protegerse contra un fallo de unidad.</block>
  <block id="1168469b387027a850496f6cac9f3529" category="list-text">Los cambios en los datos deben protegerse contra la pérdida.</block>
  <block id="864a6ca5da4b36656beba11c90f4c4e5" category="paragraph">Estas tres necesidades se tratan en las siguientes secciones.</block>
  <block id="a05b54004946aa523bfe7c1e92a52f52" category="section-title">Corrupción de la red: Sumas de comprobación</block>
  <block id="ed95581a613a4f19be367c10cd063cc2" category="paragraph">El nivel más básico de protección de datos es la suma de comprobación, que es un código especial de detección de errores almacenado junto con los datos. La corrupción de datos durante la transmisión de red se detecta con el uso de una suma de comprobación y, en algunos casos, varias sumas de comprobación.</block>
  <block id="c1343e51090396cf011509389bc0adab" category="paragraph">Por ejemplo, una trama de FC incluye una forma de suma de comprobación denominada comprobación de redundancia cíclica (CRC) para asegurarse de que la carga útil no está dañada en tránsito. El transmisor envía tanto los datos como el CRC de los datos. El receptor de una trama FC vuelve a calcular el CRC de los datos recibidos para asegurarse de que coincida con el CRC transmitido. Si el CRC recién calculado no coincide con el CRC conectado a la trama, los datos están dañados y se descarta o rechaza la trama de FC. Las operaciones de I/O iSCSI incluyen sumas de comprobación en las capas TCP/IP y Ethernet y, para una protección adicional, también se puede incluir protección CRC opcional en la capa SCSI. Cualquier daño de bit en el cable se detecta mediante la capa TCP o la capa IP, lo que provoca la retransmisión del paquete. Al igual que con FC, los errores en el CRC de SCSI provocan un descarte o el rechazo de la operación.</block>
  <block id="1f08639c540e47068c16c3ac48ea7bbe" category="section-title">Daños en unidades: Sumas de comprobación</block>
  <block id="c5d50bc8d916a4b26166bbda091cd6d4" category="paragraph">También se utilizan sumas de comprobación para verificar la integridad de los datos almacenados en las unidades. Los bloques de datos escritos en las unidades se almacenan con una función de suma de comprobación que genera un número impredecible ligado a los datos originales. Cuando se leen datos de la unidad, la suma de comprobación se vuelve a calcular y se compara con la suma de comprobación almacenada. Si no coincide, los datos se han dañado y deben ser recuperados por la capa RAID.</block>
  <block id="8edc44db01815f20f6508db8b5630cfe" category="section-title">Datos dañados: Escrituras perdidas</block>
  <block id="972eab86b2aecd693914feabc5a3b65c" category="paragraph">Uno de los tipos de daños más difíciles de detectar es una escritura perdida o ubicada incorrectamente. Cuando se reconoce una escritura, se debe escribir en el soporte en la ubicación correcta. Los datos dañados in situ son relativamente fáciles de detectar usando una sencilla suma de comprobación almacenada con los datos. Sin embargo, si la escritura simplemente se pierde, es posible que aún exista la versión anterior de los datos y la suma de comprobación sea correcta. Si la escritura se realiza en una ubicación física incorrecta, la suma de comprobación asociada sería una vez más válida para los datos almacenados, aunque la escritura haya destruido otros datos.</block>
  <block id="53830741c46fbc560962b086f582e79a" category="paragraph">La solución a este reto es la siguiente:</block>
  <block id="656d064400822ca2ffb25f52c9fc95db" category="list-text">Una operación de escritura debe incluir metadatos que indiquen la ubicación donde se espera que se encuentre la escritura.</block>
  <block id="37a60b1c7392a26270880a361f85db55" category="list-text">Una operación de escritura debe incluir algún tipo de identificador de versión.</block>
  <block id="4275b2e68761baa23b112833facf4ca1" category="paragraph">Cuando ONTAP escribe un bloque, incluye los datos donde pertenece el bloque. Si una lectura posterior identifica un bloque, pero los metadatos indican que pertenece a la ubicación 123 cuando se encontró en la ubicación 456, la escritura se ha colocado de forma incorrecta.</block>
  <block id="009b13bf07c7db21c1e4769526e60694" category="paragraph">Detectar una escritura totalmente perdida es más difícil. La explicación es muy complicada, pero básicamente ONTAP almacena los metadatos de manera que una operación de escritura da como resultado actualizaciones en dos ubicaciones distintas en las unidades. Si se pierde una escritura, una lectura posterior de los datos y los metadatos asociados muestra dos identidades de versión diferentes. Esto indica que la unidad no completó la escritura.</block>
  <block id="3b04a99c209a31ad69e7865ea94e5c94" category="paragraph">Los daños en la escritura perdidos o mal ubicados son extremadamente raros, pero, a medida que las unidades siguen creciendo y los conjuntos de datos pasan a la escala de exabytes, el riesgo aumenta. La detección de escritura perdida debe incluirse en cualquier sistema de almacenamiento que admita cargas de trabajo de base de datos.</block>
  <block id="e978ccc010ec4d37148d52e2fbf439dd" category="section-title">Fallos de unidad: RAID, RAID DP y RAID-TEC</block>
  <block id="a9fffaaf2b1b518afb56ef273736c0c2" category="paragraph">Si se detecta que un bloque de datos en una unidad está dañado, o que toda la unidad falla y no está totalmente disponible, los datos deben reconstituirse. Esto se realiza en ONTAP utilizando unidades de paridad. Los datos se dividen entre varias unidades de datos y, a continuación, se generan datos de paridad. Se almacena por separado de los datos originales.</block>
  <block id="54abdf00b7122c16619266482eb09f43" category="paragraph">ONTAP utilizó originalmente RAID 4, que utiliza una sola unidad de paridad para cada grupo de unidades de datos. El resultado fue que cualquier unidad del grupo podría fallar sin producir una pérdida de datos. Si se produjo un error en la unidad de paridad, no se dañaron los datos y se pudo construir una nueva unidad de paridad. Si falla una unidad de datos única, las unidades restantes podrían usarse con la unidad de paridad para volver a generar los datos ausentes.</block>
  <block id="6d1ccb512ce2b25e53d90e6d8d459e18" category="paragraph">Cuando las unidades eran pequeñas, la posibilidad estadística de que fallaran en dos unidades a la vez era insignificante. A medida que aumenta la capacidad de las unidades, también aumenta el tiempo necesario para reconstruir los datos tras un fallo de unidad. Esto ha aumentado el intervalo en el que un segundo fallo de unidad provocaría la pérdida de datos. Además, el proceso de recompilación crea una gran cantidad de I/O adicionales en las unidades supervivientes. A medida que las unidades envejecen, también aumenta el riesgo de la carga adicional que produce un segundo fallo de unidad. Por último, incluso si el riesgo de pérdida de datos no aumentara con el uso continuado de RAID 4, las consecuencias de la pérdida de datos serían más graves. Cuantos más datos se pierdan en caso de un fallo de un grupo RAID, más tiempo se necesitaría para recuperar los datos, lo que prolonga la interrupción del negocio.</block>
  <block id="caef9e75bcd55d5a9a4ec855b5a6385c" category="paragraph">Estos problemas llevaron a NetApp a desarrollar la tecnología NetApp RAID DP, una variante de RAID 6. Esta solución incluye dos unidades de paridad, lo que significa que dos unidades cualesquiera de un grupo RAID pueden fallar sin crear pérdida de datos. El tamaño de las unidades ha continuado creciendo, lo que finalmente llevó a NetApp a desarrollar la tecnología NetApp RAID-TEC, que introduce una tercera unidad de paridad.</block>
  <block id="704c2697ee323569003b7b7ea203ae0f" category="paragraph">Algunas mejores prácticas históricas de bases de datos recomiendan el uso de RAID-10, también conocido como mirroring segmentado. Esto ofrece menos protección de datos que RAID DP, ya que existen varias situaciones de fallo de dos discos, mientras que en RAID DP no hay ninguna.</block>
  <block id="3d0147402d7506d1d3a5227fe447427a" category="paragraph">También hay algunas mejores prácticas históricas de bases de datos que indican que se prefiere RAID-10 a las opciones de RAID-4/5/6 debido a cuestiones de rendimiento. En ocasiones, estas recomendaciones se refieren a una penalización de RAID. Aunque estas recomendaciones son generalmente correctas, no son aplicables a las implementaciones de RAID en ONTAP. El problema de rendimiento está relacionado con la regeneración de paridad. Con las implementaciones de RAID tradicionales, procesar las escrituras aleatorias rutinarias realizadas por una base de datos requiere varias lecturas de disco para regenerar los datos de paridad y completar la escritura. La penalización se define como las IOPS de lectura adicional necesarias para ejecutar operaciones de escritura.</block>
  <block id="84ff015d2df40fc0ebb34485173f39e4" category="paragraph">ONTAP no incurre en una penalización de RAID, ya que las escrituras se almacenan en memoria donde se genera la paridad y se escriben en el disco como una única franja de RAID. No se requieren lecturas para completar la operación de escritura.</block>
  <block id="b7fe11ecbd8b434a231195335b4894ac" category="paragraph">En resumen, en comparación con RAID 10, RAID DP y RAID-TEC ofrecen mucha más capacidad utilizable, una mejor protección ante fallos de unidad y sin sacrificios de rendimiento.</block>
  <block id="e5e0dc0629a299f8e56ebe7de38f49f9" category="section-title">Protección contra fallos del hardware: NVRAM</block>
  <block id="1db5fde40e489d805029f9d5be6375e7" category="paragraph">Cualquier cabina de almacenamiento que sirva a una carga de trabajo de base de datos debe procesar operaciones de escritura lo más rápido posible. Además, una operación de escritura debe protegerse contra pérdidas provocadas por eventos inesperados, como un fallo de alimentación. Esto significa que cualquier operación de escritura debe almacenarse de forma segura en al menos dos ubicaciones.</block>
  <block id="ff540b857af868ec85f8f53ddc1f1bd1" category="paragraph">Los sistemas AFF y FAS confían en NVRAM para cumplir estos requisitos. El proceso de escritura funciona de la siguiente manera:</block>
  <block id="049f2df0de743a6be8d3ec69864f234a" category="list-text">Los datos de escritura entrantes se almacenan en la RAM.</block>
  <block id="976be2293c2f4499d079224003644acf" category="list-text">Los cambios que se deben realizar en los datos del disco se registran en NVRAM en el nodo local y el asociado. NVRAM no es una caché de escritura, sino un diario similar a un redo log de base de datos. En condiciones normales, no se lee. Solo se utiliza para recuperación, como después de un fallo de alimentación durante el procesamiento de I/O.</block>
  <block id="8ae87ed4a421bec56e020cd0e83bd748" category="list-text">A continuación, la escritura se reconoce en el host.</block>
  <block id="3a7682bcbb490353074b5ee69e18f01c" category="paragraph">El proceso de escritura en esta fase se completa desde el punto de vista de la aplicación y los datos están protegidos contra pérdidas debido a que están almacenados en dos ubicaciones diferentes. Eventualmente, los cambios se escriben en el disco, pero este proceso es fuera de banda desde el punto de vista de la aplicación, porque se produce una vez que se reconoce la escritura y, por lo tanto, no afecta a la latencia. Este proceso es una vez más similar al registro de la base de datos. Un cambio en la base de datos se registra en los redo logs lo antes posible y el cambio se confirma como confirmado. Las actualizaciones de los archivos de datos se producen mucho más tarde y no afectan directamente a la velocidad de procesamiento.</block>
  <block id="c17f09622da5f1e0064f7b6a65cb8b01" category="paragraph">En caso de que se produzca un fallo en la controladora, la controladora asociada toma la propiedad de los discos necesarios y reproduce los datos registrados en la NVRAM para recuperar las operaciones de I/O que estuvieran en curso al producirse el fallo.</block>
  <block id="24e6592d53b3bd56ed8827d2f51bb1ab" category="section-title">Protección contra fallos de hardware: NVFAIL</block>
  <block id="7965eb54acae120d25d0c77b012b8f90" category="paragraph">Como hemos visto anteriormente, la escritura no se reconoce hasta que se haya iniciado sesión en la NVRAM local y NVRAM en al menos otra controladora. Este método garantiza que un fallo de hardware o una interrupción del suministro eléctrico no provoquen la pérdida de operaciones de I/O en tránsito Si la NVRAM local falla o la conectividad con el partner de alta disponibilidad falla, estos datos en curso ya no se duplicarán.</block>
  <block id="307b6d3e63c12ada7fbcf75cdda0b574" category="paragraph">Si la NVRAM local informa de un error, el nodo se apaga. Este apagado hace que se produzca una conmutación al nodo de respaldo con una controladora asociada de alta disponibilidad. No se pierden datos porque la controladora que experimenta el fallo no reconoció la operación de escritura.</block>
  <block id="6e0c6c8fe69a50581a4ac18acb2c04dd" category="paragraph">ONTAP no permite una conmutación por error cuando los datos no están sincronizados a menos que se vean obligados a recurrir a la conmutación por error. Al forzar un cambio en las condiciones de esta manera, se reconoce que los datos podrían dejarse atrás en la controladora original y que la pérdida de datos es aceptable.</block>
  <block id="a3961862ed464a06ef6fa4e23935fef2" category="paragraph">Las bases de datos son especialmente vulnerables a los daños si se fuerza una conmutación por error porque las bases de datos mantienen grandes cachés internos de datos en el disco. Si se produce una conmutación por error forzada, los cambios previamente aceptados se descartan efectivamente. El contenido de la cabina de almacenamiento retrocede efectivamente en el tiempo y el estado de la caché de base de datos ya no refleja el estado de los datos del disco.</block>
  <block id="b46ce3019d702ee3ece327e5df990be0" category="paragraph">Para proteger datos contra esta situación, ONTAP permite configurar volúmenes para una protección especial contra un fallo NVRAM. Cuando se activa, este mecanismo de protección hace que un volumen entre en un estado denominado NVFAIL. Este estado provoca errores de I/O que provocan el cierre de una aplicación para que no utilicen datos obsoletos. No se deben perder los datos porque debe haber alguna escritura reconocida en la cabina de almacenamiento.</block>
  <block id="322e1f85910dfc206274f8bd58a54a9d" category="list-text">Cada conjunto de unidades en un sitio determinado se configura automáticamente como uno o varios grupos RAID-DP o RAID-TEC completamente redundantes, independientemente del uso del mirroring. Esto proporciona una protección de datos continua, incluso después de la pérdida de un sitio.</block>
  <block id="dee2dfce5ab0c47301b3c12970a57aa6" category="paragraph">La figura anterior muestra una configuración de SyncMirror de ejemplo. Se creó un agregado de 24 unidades en la controladora con 12 unidades de una bandeja asignada en el sitio A y 12 unidades de una bandeja asignada en el sitio B. Las unidades se agruparon en dos grupos RAID reflejados. RAID Group 0 incluye un plex de 6 unidades en el sitio A duplicado en un plex de 6 unidades en el sitio B. Del mismo modo, RAID Group 1 incluye un plex de 6 unidades en el sitio A duplicado en un plex de 6 unidades en el sitio B.</block>
  <block id="4fbc0abe91c0c1381d0a742f58b4e537" category="paragraph">Normalmente, SyncMirror se utiliza para proporcionar mirroring remoto con sistemas MetroCluster, con una copia de los datos de cada sitio. En ocasiones, se ha utilizado para proporcionar un nivel adicional de redundancia en un único sistema. En particular, proporciona redundancia a nivel de bandeja. Una bandeja de unidades ya contiene fuentes de alimentación y controladoras duales y en general es poco más que chapa metálica, pero en algunos casos, la protección adicional puede estar garantizada. Por ejemplo, un cliente de NetApp ha puesto en marcha SyncMirror para una plataforma móvil de análisis en tiempo real que se usa durante las pruebas de automoción. El sistema se separó en dos racks físicos alimentados por fuentes de alimentación independientes de sistemas UPS independientes.</block>
  <block id="95a3cc99b05998d49d8e035b994815bc" category="paragraph">==sumas de comprobación</block>
  <block id="0cac56685de94a3ef0e1fd2bfca0c112" category="paragraph">El tema de las sumas de comprobación es de particular interés para los administradores de bases de datos que están acostumbrados a usar backups en streaming de Oracle RMAN, que migran a backups basados en instantáneas. Una función de RMAN es que realiza comprobaciones de integridad durante las operaciones de copia de seguridad. Aunque esta función posee cierto valor, su principal ventaja es en una base de datos que no se utiliza en una cabina de almacenamiento moderna. Cuando se utilizan unidades físicas en una base de datos de Oracle, resulta casi seguro que los daños eventualmente se producen cuando las unidades envejecen, un problema que resuelven las sumas de comprobación basadas en cabinas de almacenamiento reales.</block>
  <block id="58d7088c13cf2013ef373d85e3c27de7" category="paragraph">Con una cabina de almacenamiento real, la integridad de los datos se protege utilizando sumas de comprobación en varios niveles. Si los datos están dañados en una red basada en IP, la capa Protocolo de control de transmisión (TCP) rechaza los datos del paquete y solicita la retransmisión. El protocolo FC incluye sumas de comprobación, al igual que los datos SCSI encapsulados. Después de que se encuentra en la cabina, ONTAP tiene protección RAID y suma de comprobación. La corrupción puede ocurrir, pero, como en la mayoría de las matrices empresariales, se detecta y corrige. Normalmente, falla una unidad completa, solicita una reconstrucción de RAID y la integridad de la base de datos no se ve afectada. Con menos frecuencia, ONTAP detecta un error de suma de comprobación, lo que significa que los datos de la unidad están dañados. Entonces, la unidad conmuta al nodo de respaldo y se inicia una reconstrucción de RAID. Una vez más, la integridad de los datos no se ve afectada.</block>
  <block id="8b7b33533c2b36c157a0a482bdd52a8e" category="paragraph">La arquitectura de archivo de datos y redo log de Oracle también está diseñada para ofrecer el nivel más alto posible de integridad de datos, incluso en circunstancias extremas. En el nivel más básico, los bloques de Oracle incluyen suma de comprobación y comprobaciones lógicas básicas con casi todas las E/S. Si Oracle no se ha bloqueado o ha puesto un tablespace fuera de línea, los datos estarán intactos. El grado de comprobación de la integridad de los datos es ajustable y Oracle también puede configurarse para confirmar las escrituras. Como resultado, casi todos los escenarios de accidente y fallo se pueden recuperar, y en el caso extremadamente raro de una situación irrecuperable, la corrupción se detecta rápidamente.</block>
  <block id="4066c36b811913c85aa86346e30cee4d" category="paragraph">La mayoría de los clientes de NetApp que utilizan bases de datos Oracle interrumpen el uso de RMAN y otros productos de backup después de la migración a backups basados en snapshots. Todavía hay opciones en las que se puede utilizar RMAN para realizar la recuperación a nivel de bloque con SnapCenter. Sin embargo, en el día a día, RMAN, NetBackup y otros productos sólo se utilizan ocasionalmente para crear copias de archivado mensuales o trimestrales.</block>
  <block id="d0cf0e689669c61d564607d2ef7deb79" category="paragraph">Algunos clientes eligen correr<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block> periódicamente para realizar comprobaciones de integridad de sus bases de datos existentes. NetApp desaconseja esta práctica porque crea una carga de I/O innecesaria. Como se mencionó anteriormente, si la base de datos no estaba experimentando problemas anteriormente, la posibilidad de<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block> La detección de un problema es cercana a cero, y esta utilidad crea una carga secuencial de I/O muy elevada en la red y el sistema de almacenamiento. A menos que exista un motivo para creer que existe corrupción, como la exposición a un bug de Oracle conocido, no hay motivo para ejecutarse<block ref="d308cbfce7e270e5b41a84d84385645f" prefix=" " category="inline-code"></block>.</block>
  <block id="431bbcf828b8d3513280cb1207824991" category="doc">Backups optimizados para Oracle Storage Snapshot</block>
  <block id="c9447fe684870cf68e9cb4f23f44db43" category="paragraph">Aunque el procedimiento de recuperación de backup dinámico es más familiar para los administradores de bases de datos, durante mucho tiempo ha sido posible usar snapshots que no se crearon mientras la base de datos estaba en modo de backup dinámico. Oracle 10g y 11g requerían pasos manuales adicionales durante la recuperación para hacer que la base de datos fuera coherente. Con Oracle 12c,<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> y..<block ref="075b7d3bd3bbe7767f7ef62f430bc22b" prefix=" " category="inline-code"></block> contienen la lógica adicional para reproducir archive logs en copias de seguridad de archivos de datos que no estaban en modo de copia de seguridad activa.</block>
  <block id="5c7dba68615d3fa5c4c90a36dab57bcb" category="paragraph">Como hemos visto anteriormente, la recuperación de un backup en caliente basado en instantáneas requiere dos conjuntos de datos:</block>
  <block id="50a7086972cada154c8164dc1c6b3539" category="list-text">Instantánea de los archivos de datos creados en modo de backup</block>
  <block id="c72d009669a638aab75c21a28a2101de" category="list-text">Los registros de archivos generados mientras los archivos de datos estaban en modo de backup dinámico</block>
  <block id="b8de4b1201e5595bc3de878f2bf59d9b" category="paragraph">Durante la recuperación, la base de datos lee los metadatos de los archivos de datos para seleccionar los archive logs requeridos para la recuperación.</block>
  <block id="66ee0a6fd90f3cfab8320e1de1341cbd" category="paragraph">La recuperación optimizada para snapshot de almacenamiento requiere conjuntos de datos ligeramente diferentes para lograr los mismos resultados:</block>
  <block id="6030a1d9761fca3806ef0a0329438071" category="list-text">Una instantánea de los archivos de datos, además de un método para identificar la hora a la que se creó la instantánea</block>
  <block id="4e822d4c19600b654f176d335c158829" category="list-text">Archive logs desde la hora del punto de control del archivo de datos más reciente hasta la hora exacta de la instantánea</block>
  <block id="604432b50055c69f34df17a8ed5befb5" category="paragraph">Durante la recuperación, la base de datos lee metadatos de los archivos de datos para identificar el primer archive log necesario. Se puede realizar una recuperación completa o a un momento específico. Al realizar una recuperación puntual, es fundamental conocer la hora de la instantánea de los archivos de datos. El punto de recuperación especificado debe ser posterior a la hora de creación de las instantáneas. NetApp recomienda añadir al menos unos minutos al tiempo de la snapshot para justificar la variación de reloj.</block>
  <block id="08bfe39c49a2dc07b08bd2ccd77d8281" category="paragraph">Para obtener más información, consulte la documentación de Oracle sobre el tema «Recuperación mediante la optimización de instantáneas de almacenamiento» disponible en varias versiones de la documentación de Oracle 12c. Además, consulte el ID de documento de Oracle 604683,1 con respecto al soporte de instantáneas de terceros de Oracle.</block>
  <block id="d22a890163762fcf7a4cb7605c29b7e6" category="section-title">Distribución de datos</block>
  <block id="6a7fc1f74262f6973420f4fc849ba7f7" category="paragraph">El diseño más sencillo es aislar los archivos de datos en uno o varios volúmenes dedicados. No deben estar contaminados por ningún otro tipo de archivo. De este modo, se garantiza que los volúmenes de archivos de datos se puedan restaurar rápidamente con una operación de SnapRestore sin destruir un registro de recuperación, un archivo de control o un archivo importante.</block>
  <block id="ff6fb5d2136ab516e182f4b23f45886d" category="paragraph">SAN tiene requisitos similares para aislamiento de archivos de datos en volúmenes dedicados. Con un sistema operativo como Microsoft Windows, un único volumen puede contener varios LUN de archivos de datos, cada uno con un sistema de archivos NTFS. Con otros sistemas operativos, generalmente hay un gestor de volúmenes lógicos también. Por ejemplo, con Oracle ASM, la opción más sencilla sería restringir los grupos de discos en un único volumen del que se pueda realizar un backup y restaurar como unidad. Si se necesitan volúmenes adicionales por motivos de rendimiento o gestión de capacidad, crear un grupo de discos adicional en el nuevo volumen simplifica la gestión.</block>
  <block id="a06956ba6de69aec2dc2b015074e5821" category="paragraph">Si se siguen estas directrices, se pueden programar Snapshot directamente en ONTAP sin requisitos para realizar una snapshot de grupo de coherencia. El motivo es que las copias de seguridad optimizadas para instantáneas no necesitan que se realice una copia de seguridad de los archivos de datos al mismo tiempo.</block>
  <block id="9e422c12420f1bd8c73e3c0f63da55e9" category="paragraph">Se produce una complicación en situaciones como un grupo de discos de ASM que se distribuye entre volúmenes. En estos casos, se debe realizar una cg-snapshot para garantizar que los metadatos de ASM sean coherentes en todos los volúmenes constituyentes.</block>
  <block id="7a7969d6a47ed242c25f6a38f2da0e36" category="paragraph">[Nota]Verifique que los archivos spfile y passwd de ASM no estén en el grupo de discos que aloja los archivos de datos. Esto interfiere con la capacidad de restaurar selectivamente archivos de datos y solo archivos de datos.</block>
  <block id="12eb3ceede91a01c74368e0fab03dbe4" category="section-title">Procedimiento de recuperación local: NFS</block>
  <block id="e1a03fcc478ae212f07b5044b11ff369" category="paragraph">Este procedimiento se puede realizar manualmente o a través de una aplicación como SnapCenter. El procedimiento básico es el siguiente:</block>
  <block id="abb0083d6ab87bbe9d906632fea121ae" category="list-text">Recupere los volúmenes del archivo de datos en la instantánea inmediatamente antes del punto de restauración deseado.</block>
  <block id="3450fe1e1eea00fa55cfb5cb835a3d80" category="paragraph">En este procedimiento se asume que los archive logs deseados siguen presentes en el sistema de archivos activo. Si no lo son, se deben restaurar los registros de archivos<block ref="075b7d3bd3bbe7767f7ef62f430bc22b" prefix=" " category="inline-code"></block> o.<block ref="a84f4f3da79386c29ab6dfa560af786e" prefix=" " category="inline-code"></block> se puede dirigir a los datos de la<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> directorio.</block>
  <block id="e43e33171833b26f6b024d28cb8b1afd" category="paragraph">Además, para bases de datos más pequeñas, un usuario final puede recuperar archivos de datos directamente desde<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> Directorio sin ayuda de las herramientas de automatización o de un administrador del almacenamiento para ejecutar un comando de la SnapRestore.</block>
  <block id="097230f6ad5345abbe261eabbf533a68" category="section-title">Procedimiento de recuperación local: San</block>
  <block id="4e3110543ebf2a771c16b3b2101f1f88" category="list-text">Desactive los grupos de discos que alojan los archivos de datos. El procedimiento varía en función del gestor de volúmenes lógico elegido. Con ASM, el proceso requiere desmontar el grupo de discos. Con Linux, los sistemas de archivos deben desmontarse y los volúmenes lógicos y los grupos de volúmenes están desactivados. El objetivo es detener todas las actualizaciones en el grupo de volúmenes objetivo que se va a restaurar.</block>
  <block id="1d0ecd206531f96737f8e8002be4a047" category="list-text">Restaure los grupos de discos de archivos de datos en la instantánea inmediatamente antes del punto de restauración deseado.</block>
  <block id="946fe41f610ab658e270a1844c992bcc" category="list-text">Vuelva a activar los grupos de discos recién restaurados.</block>
  <block id="c21d8f41541fc2a0259e7ea5e51edac3" category="paragraph">En este procedimiento se asume que los archive logs deseados siguen presentes en el sistema de archivos activo. Si no lo son, los registros de archivos se deben restaurar desconectando las LUN del registro de archivos y ejecutando una restauración. Este es también un ejemplo en el que la división de archive logs en volúmenes dedicados es útil. Si los registros de archivos comparten un grupo de volúmenes con redo logs, los redo logs se deben copiar en otro lugar antes de restaurar el conjunto general de LUN para evitar perder las transacciones finales registradas.</block>
  <block id="3fd5b2a08b3d7c4db29da8590ef6013f" category="section-title">Ejemplo de recuperación completa</block>
  <block id="31679daa394b7091acfd728d940b7322" category="paragraph">Supongamos que los archivos de datos se han dañado o destruido y se necesita una recuperación completa. El procedimiento para hacerlo es el siguiente:</block>
  <block id="aa09ca247daac25fc18c2633124ca9b6" category="section-title">Ejemplo de recuperación a un momento específico</block>
  <block id="935ff627038d1f5001220c8df7f0e1b9" category="paragraph">Todo el procedimiento de recuperación es un único comando:<block ref="3df448f0a5ec82cac76d91ba14c0fa1d" prefix=" " category="inline-code"></block>.</block>
  <block id="dcd27cf8b8ceae2cd84c898d3c1b9fdb" category="paragraph">Si se requiere una recuperación a un momento específico, es necesario conocer la marca de hora de las instantáneas y se puede identificar de la siguiente manera:</block>
  <block id="17108ef3ad2e1e613b844beb5f2c6d29" category="paragraph">La hora de creación de la copia Snapshot se muestra como 9th de marzo y 10:10:06. Para estar seguro, se añade un minuto a la hora de la copia Snapshot:</block>
  <block id="904b0a17b003c70e398ea85996f0f9ba" category="paragraph">La recuperación se inicia ahora. Especificó una hora de instantánea de 10:11:00, un minuto después del tiempo registrado para contabilizar la posible variación de reloj y un tiempo de recuperación objetivo de 10:44. A continuación, sqlplus solicita los archive logs necesarios para alcanzar el tiempo de recuperación deseado de 10:44.</block>
  <block id="91f99c5ad04365fb4d00e509963e2a0c" category="admonition">Recuperación completa de una base de datos utilizando instantáneas utilizando el<block ref="3df448f0a5ec82cac76d91ba14c0fa1d" prefix=" " category="inline-code"></block> el comando no requiere una licencia específica, sino un uso de recuperación puntual<block ref="72104026d9850e8c478c23b2e2e4e8e9" prefix=" " category="inline-code"></block> Necesita la licencia de Oracle Advanced Compression.</block>
  <block id="9173402b63dc5f55506a692258f185e8" category="doc">SnapCenter y otras herramientas</block>
  <block id="5459c1727c923baa303ff472498dbe97" category="paragraph">En algunos casos, la simple configuración de estas funciones básicas directamente en ONTAP satisface los requisitos, pero las necesidades más complicadas requieren una capa de orquestación.</block>
  <block id="aeeb3212c35c26d321183e81d4926e57" category="paragraph">SnapCenter es el producto estrella de protección de datos de NetApp. A un nivel muy bajo, es similar a los productos de SnapManager en cuanto a cómo se ejecutan backups de bases de datos, pero se creó desde cero para proporcionar un panel único para la gestión de la protección de datos en sistemas de almacenamiento de NetApp.</block>
  <block id="50780f47f6839d47d60bc4555ee00c3f" category="section-title">DESCANSO</block>
  <block id="a0bac638f30c704da8e03aba136da86d" category="paragraph">ONTAP también contiene un amplio conjunto de API RESTful. Esto permite que 3rd proveedores de partes creen protección de datos y otras aplicaciones de gestión con la profunda integración con ONTAP. Además, los clientes que desean crear sus propios flujos de trabajo y utilidades de automatización pueden consumir fácilmente la API RESTful.</block>
  <block id="a3b43ae3d4028e3c7ccac3d5720e9fb0" category="paragraph">Se necesitan dos conjuntos de datos para proteger y recuperar una base de datos de Oracle en modo de backup. Tenga en cuenta que esta no es la única opción de copia de seguridad de Oracle, pero es la más común.</block>
  <block id="8e523970ff7c41dba74e723511d14717" category="list-text">Instantánea de los archivos de datos en modo de copia de seguridad</block>
  <block id="deeddf207b1a29c63ae7c1943f90f3d9" category="list-text">Los registros de archivos creados mientras los archivos de datos estaban en modo de backup</block>
  <block id="fa1229103a2e02a4ed8790098c98f71f" category="paragraph">Si se necesita una recuperación completa, incluidas todas las transacciones confirmadas, se requiere un tercer elemento:</block>
  <block id="7c11b244c2549a2cc477c134ec4c5635" category="list-text">Juego de redo logs actuales</block>
  <block id="8522faf14bc9d4ab497945bb48adc870" category="paragraph">Existen varias formas de impulsar la recuperación de un backup en línea. Muchos clientes restauran snapshots mediante la interfaz de línea de comandos de ONTAP y, a continuación, usando Oracle RMAN o sqlplus para completar la recuperación. Esto es especialmente habitual en entornos de producción de gran tamaño en los que la probabilidad y frecuencia de las restauraciones de bases de datos es extremadamente baja y cualquier procedimiento de restauración lo gestiona un administrador de bases de datos cualificado. Para obtener una automatización completa, las soluciones como NetApp SnapCenter incluyen un complemento de Oracle con interfaces gráficas y de línea de comandos.</block>
  <block id="f88f41d4801183a5d53a4b71f383d144" category="paragraph">Algunos clientes a gran escala han adoptado un enfoque más simple mediante la configuración de secuencias de comandos básicas en los hosts para colocar las bases de datos en modo de backup en un momento específico de preparación para una copia Snapshot programada. Por ejemplo, programe el comando<block ref="56f72994c4cc84b13a4c20dab49fea35" prefix=" " category="inline-code"></block> a las 23:58,<block ref="84c8391d82cbfe300a9615844e0a167f" prefix=" " category="inline-code"></block> a las 00:02, y después programe copias snapshot directamente en el sistema de almacenamiento a medianoche. El resultado es una estrategia de backup sencilla y altamente escalable que no requiere software ni licencias externas.</block>
  <block id="719fbeb74939b8c065321f175de3d222" category="paragraph">El diseño más sencillo es aislar los archivos de datos en uno o varios volúmenes dedicados. No deben estar contaminados por ningún otro tipo de archivo. De este modo, se garantiza que los volúmenes de archivos de datos puedan restaurarse rápidamente mediante una operación SnapRestore sin destruir un registro de recuperación, un archivo de control o un archivo importante.</block>
  <block id="19156bdcbf322e8e3189909bbb7a69e8" category="paragraph">SAN tiene requisitos similares para aislamiento de archivos de datos en volúmenes dedicados. Con un sistema operativo como Microsoft Windows, un único volumen puede contener varios LUN de archivos de datos, cada uno con un sistema de archivos NTFS. Con otros sistemas operativos, generalmente hay un administrador de volúmenes lógicos. Por ejemplo, con Oracle ASM, la opción más sencilla sería confinar los LUN de un grupo de discos ASM en un único volumen del que se pueda incluir y restaurar como unidad en un backup. Si se necesitan volúmenes adicionales por motivos de rendimiento o gestión de capacidad, crear un grupo de discos adicional en el nuevo volumen simplifica la gestión.</block>
  <block id="993afa8643b7200c5c9e527c24c1d8b2" category="paragraph">Si se siguen estas directrices, se pueden programar Snapshot directamente en el sistema de almacenamiento sin requisitos para realizar una snapshot de grupo de coherencia. El motivo es que las copias de seguridad de Oracle no necesitan que se realice una copia de seguridad de los archivos de datos al mismo tiempo. El procedimiento de backup online se diseñó para permitir que los archivos de datos sigan actualizándose a medida que se transmiten lentamente a la cinta durante horas.</block>
  <block id="a2ea5ea024e4a68e4d7f4abeca3441a1" category="paragraph">Se produce una complicación en situaciones como el uso de un grupo de discos de ASM que se distribuye entre volúmenes. En estos casos, se debe realizar una cg-snapshot para garantizar que los metadatos de ASM sean coherentes en todos los volúmenes constituyentes.</block>
  <block id="0a3ecb97c1b7c97e5075bae0daaa45aa" category="paragraph">*Precaución:* Verifique que el ASM<block ref="1737629d60b511cf45957529a8f046e2" prefix=" " category="inline-code"></block> y..<block ref="76a2173be6393254e72ffa4d6df1030a" prefix=" " category="inline-code"></block> los archivos no están en el grupo de discos que aloja los archivos de datos. Esto interfiere con la capacidad de restaurar selectivamente archivos de datos y solo archivos de datos.</block>
  <block id="2f8a5e254c86a42ebcc8b7d3c84cd22e" category="paragraph">En este procedimiento se asume que los archive logs deseados siguen presentes en el sistema de archivos activo. De lo contrario, se deben restaurar los archive logs o se puede dirigir rman/sqlplus a los datos del directorio de instantáneas.</block>
  <block id="a67a69f712a877950e94edd27310b40e" category="paragraph">Además, para bases de datos más pequeñas, un usuario final puede recuperar archivos de datos directamente desde<block ref="a15da8cecb1f1192c4d913b8ba676121" prefix=" " category="inline-code"></block> directorio sin la ayuda de herramientas de automatización o administradores del almacenamiento para ejecutar un<block ref="a4c0ce4da6fb04943b499690fb3afd6e" prefix=" " category="inline-code"></block> comando.</block>
  <block id="6da8ebf3245e4fbe4654e7f92f0330d7" category="list-text">Desactive los grupos de discos que alojan los archivos de datos. El procedimiento varía en función del gestor de volúmenes lógico elegido. Con ASM, el proceso requiere desmontar el grupo de discos. Con Linux, los sistemas de archivos deben desmontarse y los volúmenes lógicos y los grupos de volúmenes deben desactivarse. El objetivo es detener todas las actualizaciones en el grupo de volúmenes objetivo que se va a restaurar.</block>
  <block id="931ab211ac6773d20c03a998f9f921ce" category="list-text">Vuelva a reproducir todos los redo logs si desea realizar una recuperación completa.</block>
  <block id="b6575c3fca5eaaa56eeb8e9ce8867f05" category="paragraph">En este procedimiento se asume que los archive logs deseados siguen presentes en el sistema de archivos activo. Si no lo son, los registros de archivos se deben restaurar desconectando las LUN del registro de archivos y ejecutando una restauración. Este es también un ejemplo en el que la división de archive logs en volúmenes dedicados es útil. Si los registros de archivos comparten un grupo de volúmenes con registros de recuperación, se deben copiar en otro lugar los registros de recuperación antes de restaurar el conjunto general de LUN. Este paso evita la pérdida de las transacciones registradas finales.</block>
  <block id="65fd6f7f97414140b4d6060b743dc645" category="paragraph">Entre estos requisitos se incluyen factores como la velocidad de recuperación, la pérdida de datos máxima permitida y las necesidades de retención de backup. El plan de protección de datos también debe tener en cuenta varios requisitos normativos para la retención y restauración de datos. Por último, deben tenerse en cuenta diferentes escenarios de recuperación de datos, que van desde la recuperación típica y previsible que se produce por errores de usuarios o aplicaciones hasta escenarios de recuperación de desastres que incluyen la pérdida completa de un sitio.</block>
  <block id="2bd1d35ff88de136066c33905c0fd677" category="paragraph">Los cambios pequeños en las políticas de protección y recuperación de datos pueden tener un efecto significativo en la arquitectura general de almacenamiento, respaldo y recuperación. Es crucial definir y documentar los estándares antes de comenzar a trabajar de diseño, para evitar complicar la arquitectura de protección de datos. Las funciones o niveles de protección innecesarios generan costes innecesarios y gastos generales de gestión, y un requisito que al principio se pasa por alto puede dirigir un proyecto en la dirección equivocada o requerir cambios de diseño de última hora.</block>
  <block id="a60e6b87ede45aef49d8d095435db22b" category="section-title">Objetivo de tiempo de recuperación</block>
  <block id="3d3b341e14c584d1edcea9fe13619ee1" category="paragraph">El objetivo de tiempo de recuperación (RTO) define el tiempo máximo permitido para la recuperación de un servicio. Por ejemplo, una base de datos de recursos humanos podría tener un objetivo de tiempo de recuperación de 24 horas porque, si bien sería un inconveniente perder el acceso a estos datos durante la jornada laboral, la empresa aún puede seguir funcionando. Por el contrario, una base de datos que respalde el libro mayor general de un banco tendría un RTO medido en minutos o incluso segundos. Un RTO de cero no es posible, porque debe haber una manera de diferenciar entre una interrupción real del servicio y un evento rutinario, como un paquete de red perdido. Sin embargo, un objetivo de tiempo de recuperación de casi cero es un requisito típico.</block>
  <block id="5a27873285a0397cc06f9f47280c9426" category="section-title">Objetivo de punto de recuperación</block>
  <block id="f3ae061e139f47d793058ee596a5243f" category="paragraph">El objetivo de punto de recuperación (RPO) define la pérdida de datos máxima tolerable. En muchos casos, el objetivo de punto de recuperación solo viene determinado por la frecuencia de las copias Snapshot o las actualizaciones de snapmirror.</block>
  <block id="2d68fbd3cefeb34bfd64c8f89caba64d" category="paragraph">En algunos casos, el objetivo de punto de recuperación puede hacerse más agresivo ya que protege de forma selectiva ciertos datos con mayor frecuencia. En un contexto de base de datos, el RPO suele ser una cuestión de cuántos datos de registro se pueden perder en una situación específica. En un escenario típico de recuperación en el que una base de datos está dañada debido a un error de producto o de usuario, el RPO debe ser cero, lo que significa que no debe haber pérdida de datos. El procedimiento de recuperación implica restaurar una copia anterior de los archivos de base de datos y, a continuación, volver a reproducir los archivos de registro para que el estado de la base de datos alcance el momento deseado. Los archivos de registro necesarios para esta operación ya deben estar en su lugar en la ubicación original.</block>
  <block id="57df8b025934bcd0f7e96bae19cf0688" category="paragraph">En escenarios inusuales, los datos de registro pueden perderse. Por ejemplo, un ataque accidental o malintencionado<block ref="4609acba202877f99742342f4195d95e" prefix=" " category="inline-code"></block> de archivos de base de datos podría resultar en la eliminación de todos los datos. La única opción sería restaurar desde la copia de seguridad, incluidos los archivos de registro, y algunos datos inevitablemente se perderían. La única opción para mejorar el RPO en un entorno de backup tradicional sería realizar backups repetidos de los datos de registro. Sin embargo, esto tiene limitaciones debido al movimiento constante de datos y la dificultad de mantener un sistema de backup como un servicio en constante ejecución. Una de las ventajas de los sistemas de almacenamiento avanzados es la capacidad de proteger los datos frente a daños accidentales o malintencionados en los archivos para proporcionar, de este modo, un mejor objetivo de punto de recuperación sin transferir datos.</block>
  <block id="3d08c71e26ac92e34925e02570c4bd22" category="paragraph">La recuperación tras desastres incluye la arquitectura de TI, las políticas y los procedimientos necesarios para recuperar un servicio en caso de desastre físico. Esto puede incluir inundaciones, incendios o personas que actúen con intención maliciosa o negligente.</block>
  <block id="78f4e749ec0c6bb2627abbbc00bce296" category="paragraph">La recuperación ante desastres va más allá de un conjunto de procedimientos de recuperación. Se trata del proceso completo de identificar los diversos riesgos, de definir los requisitos de recuperación de datos y continuidad del servicio, y de proporcionar la arquitectura correcta con los procedimientos asociados.</block>
  <block id="75bcd60b234aba82b5827cd7a5171563" category="paragraph">Cuando se establecen requisitos de protección de datos, es fundamental diferenciar entre los requisitos típicos de RPO y RTO, así como los requisitos de RPO y RTO necesarios para la recuperación ante desastres. Algunos entornos de aplicaciones requieren un objetivo de punto de recuperación de cero y un objetivo de tiempo de recuperación de casi cero para situaciones de pérdida de datos, que van desde un error relativamente normal del usuario hasta un incendio que destruya un centro de datos. Sin embargo, estos altos niveles de protección tienen consecuencias administrativas y de costes.</block>
  <block id="756651fea87d05811d7a42451d074b60" category="paragraph">En general, los requisitos de recuperación de datos sin desastre deben ser estrictos por dos motivos. En primer lugar, los errores en las aplicaciones y los errores de los usuarios que dañan los datos son previsibles hasta el punto de que son casi inevitables. En segundo lugar, no es difícil diseñar una estrategia de backup que proporcione un RPO de cero y un RTO bajo, siempre que el sistema de almacenamiento no esté destruido. No hay motivo para no abordar un riesgo significativo que sea fácil de solucionar, por lo que los objetivos de RPO y RTO para la recuperación local deben ser agresivos.</block>
  <block id="cb6faee28dd34d25f06bd0b33abe1c2f" category="paragraph">Los requisitos del objetivo de tiempo de recuperación ante desastres y del objetivo de punto de recuperación varían mucho más según la probabilidad de que se produzca un desastre y las consecuencias de la pérdida de datos o las interrupciones de un negocio. Los requisitos del objetivo de punto de recuperación y del objetivo de tiempo de recuperación deben basarse en las necesidades reales de la empresa, no en los principios generales. Deben explicar múltiples escenarios de desastre lógicos y físicos.</block>
  <block id="68f31611fc8a5e6a20793905280a7001" category="section-title">Desastres lógicos</block>
  <block id="07f5727077caaf8dedf895542181d26b" category="paragraph">Entre los desastres lógicos se encuentra la corrupción de datos causada por los usuarios, errores de la aplicación o del SO y mal funcionamiento del software. Los desastres lógicos también pueden incluir ataques maliciosos de terceros con virus o gusanos, o mediante la explotación de las vulnerabilidades de las aplicaciones. En estos casos, la infraestructura física permanece intacta, pero los datos subyacentes ya no son válidos.</block>
  <block id="3cb5ee5f24e42f56ba6dac48b7b046d2" category="paragraph">Un tipo cada vez más común de desastre lógico se conoce como ransomware, en el que se utiliza un vector de ataque para cifrar los datos. El cifrado no daña los datos, pero no los hace disponibles hasta que se realiza el pago a un tercero. Un número cada vez mayor de empresas se dirigen específicamente a ataques de ransomware. Para esta amenaza, NetApp ofrece copias Snapshot a prueba de manipulaciones donde ni siquiera el administrador de almacenamiento puede cambiar los datos protegidos antes de la fecha de caducidad configurada.</block>
  <block id="91c87f53ce0a1f416308a67ce119c623" category="section-title">Desastres físicos</block>
  <block id="79055ca11f54a97d22617a656eab8b9b" category="paragraph">Los desastres físicos incluyen la falla de los componentes de una infraestructura que supera sus capacidades de redundancia y dan lugar a una pérdida de datos o una prolongada pérdida de servicio. Por ejemplo, la protección RAID proporciona redundancia de unidades de disco y el uso de HBA proporciona redundancia de puertos FC y cables FC. Los errores de hardware de dichos componentes son previsibles y no afectan a la disponibilidad.</block>
  <block id="3f7c55fe5f35f94cd2c4bd73b9cbb11b" category="paragraph">En un entorno empresarial, generalmente es posible proteger la infraestructura de todo un sitio con componentes redundantes hasta el punto en que el único escenario de desastre físico previsible es la pérdida completa del sitio. En ese caso, el plan de la recuperación ante desastres depende de la replicación entre sitios.</block>
  <block id="7f3dd7bdd41f7af6853732a383bbd7e2" category="section-title">Protección de datos síncrona y asíncrona</block>
  <block id="c5ac17d5693914368f39b40a07af23d4" category="paragraph">En un mundo ideal, todos los datos se replicarían de forma sincrónica en sitios dispersos geográficamente. Dicha replicación no siempre es factible o incluso posible por varias razones:</block>
  <block id="28c59a675d03e1f62a48958bb53ae523" category="list-text">La replicación síncrona aumenta inevitablemente la latencia de escritura porque todos los cambios deben replicarse en ambas ubicaciones antes de que la aplicación o base de datos pueda continuar con el procesamiento. El efecto sobre el rendimiento resultante es a veces inaceptable, lo que descarta el uso del mirroring síncrono.</block>
  <block id="50a05ceeb998c4dac7e8b5d706fe2029" category="list-text">Al aumentar la adopción del almacenamiento SSD del 100 %, es más probable que se note latencia de escritura adicional, ya que las expectativas de rendimiento incluyen cientos de miles de IOPS y latencia inferior al milisegundo. Para obtener todas las ventajas del uso del 100 % de las unidades SSD es necesario volver a analizar la estrategia de recuperación ante desastres.</block>
  <block id="04d90fe6288ce6cceba54a2b71e55727" category="list-text">Los conjuntos de datos siguen creciendo en términos de bytes, generando retos que exigen un ancho de banda suficiente para sostener la replicación síncrona.</block>
  <block id="d3aaae220bd5b3d68dd4ccec3bf78197" category="list-text">Los conjuntos de datos también crecen en términos de complejidad, lo que genera retos con la gestión de la replicación síncrona a gran escala.</block>
  <block id="c3a841e0bfc640f91b0a00c4af8c6f5c" category="list-text">Las estrategias basadas en cloud a menudo implican mayores distancias de replicación y latencia, lo que excluye aún más el uso del mirroring síncrono.</block>
  <block id="7df1515e247dfa2063c433b9339c2d4a" category="paragraph">NetApp ofrece soluciones que incluyen replicación sincrónica para las exigencias de recuperación de datos más exigentes y soluciones asincrónicas que permiten un mejor rendimiento y flexibilidad. Además, la tecnología de NetApp se integra sin problemas con muchas soluciones de replicación de terceros, como Oracle DataGuard</block>
  <block id="4d2c802af835583121763e1a6acc3f9b" category="section-title">Tiempo de retención</block>
  <block id="123dbb4c09a5c8fb993a856cf65c9d25" category="paragraph">El aspecto final de una estrategia de protección de datos es el tiempo de retención, que puede variar drásticamente.</block>
  <block id="d3a424909a8559a2d076e5d9a28d834f" category="list-text">Normalmente, se requieren 14 días de backups nocturnos en el sitio principal y 90 días de backups almacenados en un sitio secundario.</block>
  <block id="1d7c2d97c3bfd5ca9489e0ffeb06b150" category="list-text">Muchos clientes crean archivos trimestrales independientes almacenados en diferentes medios.</block>
  <block id="61ae175e4a0c88c4624184a0cb9b04d2" category="list-text">Es posible que una base de datos constantemente actualizada no necesite datos históricos y que las copias de seguridad solo se conserven durante unos pocos días.</block>
  <block id="8bb85c2149e1e808032e7025b0a27b80" category="list-text">Los requisitos normativos pueden requerir la capacidad de recuperación hasta el punto de cualquier transacción arbitraria en un periodo de 365 días.</block>
  <block id="05280349760feacdd6227fb8012e39d7" category="doc">Backups basados en Snapshot</block>
  <block id="a4c2aeedbfeeda21f232cbf45be91693" category="paragraph">Los valores clave son los siguientes:</block>
  <block id="d06c89cff665ecdde6eded3c9d44cd2b" category="list-text">*Simplicidad.* Una instantánea es una copia de solo lectura del contenido de un contenedor de datos en un momento específico.</block>
  <block id="175888ba89c31a851f719bdd271cae9c" category="list-text">*Eficiencia.* Las instantáneas no requieren espacio en el momento de la creación. El espacio solo se consume cuando se modifican los datos.</block>
  <block id="d853e9e275a6e58b3a9a56fa641cbb9f" category="list-text">*Capacidad de gestión.* Una estrategia de copia de seguridad basada en instantáneas es fácil de configurar y administrar porque las instantáneas son una parte nativa del sistema operativo de almacenamiento. Si el sistema de almacenamiento está encendido, está listo para crear backups.</block>
  <block id="b564e5fbab71af776ed54a19d09b268c" category="list-text">*Escalabilidad.* Se pueden conservar hasta 1024 copias de seguridad de un único contenedor de archivos y LUN. En el caso de conjuntos de datos complejos, es posible proteger varios contenedores de datos con un único conjunto coherente de copias Snapshot.</block>
  <block id="7159872a568b97a971b9ea182fb23b7c" category="list-text">El rendimiento no se ve afectado, independientemente de que un volumen contenga 1024 snapshots o ninguna.</block>
  <block id="1a54f7e14e6e652bb32b12df22faf387" category="paragraph">Aunque muchos proveedores de almacenamiento ofrecen tecnología Snapshot, la tecnología Snapshot dentro de ONTAP es única y ofrece beneficios importantes para los entornos de aplicaciones y bases de datos empresariales:</block>
  <block id="d77b23e355dc2f65b90fb52ed9a90f9c" category="list-text">Las copias Snapshot forman parte del sistema de archivos WAFL (Write-Anywhere File Layout) subyacente. No son una tecnología complementaria ni externa. Esto simplifica la gestión, ya que el sistema de almacenamiento es el sistema de backup.</block>
  <block id="8b888e6a2d883c0111428c101532294a" category="list-text">Las copias Snapshot no afectan al rendimiento, a excepción de algunos casos periféricos como cuando se almacenan tantos datos en copias snapshot que el sistema de almacenamiento subyacente llena.</block>
  <block id="2283ea50a243a5d1ad551f7d21f39895" category="list-text">El término «grupo de coherencia» se utiliza a menudo para referirse a una agrupación de objetos de almacenamiento que se gestionan como una colección consistente de datos. Una Snapshot de un volumen ONTAP determinado constituye un backup de grupo de coherencia.</block>
  <block id="ac72c83a8204d600d567261b41c5488c" category="paragraph">Las copias Snapshot de ONTAP también ofrecen una escalabilidad mejor que la tecnología de la competencia. Los clientes pueden almacenar 5, 50 o 500 copias Snapshot sin que esto afecte al rendimiento. El número máximo de snapshots que se permite actualmente en un volumen es 1024. Si se requiere más retención de instantáneas, existen opciones para configurar las instantáneas en cascada a volúmenes adicionales.</block>
  <block id="3b7ff39ba50f1bc3f56d38c41ba51855" category="paragraph">Como resultado, proteger un conjunto de datos alojado en ONTAP es sencillo y altamente escalable. Los backups no requieren el traslado de datos, por lo que puede adaptarse a las necesidades del negocio en lugar de a las limitaciones de las tasas de transferencia de red, un gran número de unidades de cinta o áreas de almacenamiento provisional de discos.</block>
  <block id="55c5bbb3aad88266600eaa1a526406d4" category="paragraph">Una pregunta frecuente acerca del uso de las copias Snapshot como estrategia de protección de datos es el hecho de que los datos «reales» y los datos de copias Snapshot se encuentran en las mismas unidades. La pérdida de esas unidades provocaría la pérdida de los datos primarios y el backup.</block>
  <block id="68870deb35eeb53373325a314030bd11" category="paragraph">Sin embargo, las copias Snapshot locales nunca deberían ser la única estrategia de backup, por lo que NetApp ofrece tecnología como la replicación de SnapMirror y SnapVault para replicar de forma rápida y eficiente copias Snapshot en un conjunto de unidades independiente. En una solución correctamente diseñada con copias Snapshot y replicación Snapshot, el uso de la cinta puede minimizarse tal vez a un archivo trimestral o eliminarse totalmente.</block>
  <block id="73d3fd255835ca3dc926f59d50223f91" category="paragraph">Existen muchas opciones para usar las copias Snapshot de ONTAP para proteger los datos, y las copias Snapshot son la base de muchas otras funciones de ONTAP, como replicación, recuperación ante desastres y clonación. Una descripción completa de la tecnología de instantáneas está fuera del alcance de este documento, pero en las siguientes secciones se proporciona una descripción general.</block>
  <block id="7441577327d1d49b71cc2f6403e17e7b" category="paragraph">Existen dos métodos principales para crear una copia Snapshot de un conjunto de datos:</block>
  <block id="b38ba43128207852ef5149e6c578ba89" category="list-text">Backups coherentes con los fallos</block>
  <block id="dc64a2f6075820724476e435a1ebd7fa" category="list-text">Backups para aplicaciones</block>
  <block id="7733cc553d118547b64c858cb4281f24" category="paragraph">Un backup coherente con los fallos de un conjunto de datos hace referencia a la captura de toda la estructura del conjunto de datos en un único punto de tiempo. Si el conjunto de datos se almacena en un único volumen de NetApp FlexVol, el proceso es sencillo; se puede crear una copia Snapshot en cualquier momento. Si un conjunto de datos abarca volúmenes, es necesario crear una snapshot de grupo de coherencia (CG). Existen varias opciones para crear snapshots de CG, como el software NetApp SnapCenter, funciones nativas del grupo de coherencia ONTAP y scripts que se mantienen por el usuario.</block>
  <block id="32561979f55bc68c4f028fd26a9975f6" category="paragraph">Los backups coherentes con los fallos se utilizan principalmente cuando la recuperación punto del backup es suficiente. Cuando se necesita una recuperación más granular, por lo general se necesitan backups coherentes con las aplicaciones.</block>
  <block id="367735591e5e6e04c17b7930acb29b7d" category="paragraph">A menudo, la palabra «consistente» en «coherente con las aplicaciones» resulta una denominación errónea. Por ejemplo, colocar una base de datos de Oracle en modo de backup se denomina backup coherente con las aplicaciones, pero los datos no se hacen coherentes ni se ponen en modo inactivo de ninguna forma. Los datos siguen cambiando durante el backup. Por el contrario, la mayoría de los backups de MySQL y Microsoft SQL Server realmente ralentizan los datos antes de ejecutar el backup. VMware puede o no hacer que ciertos archivos sean consistentes.</block>
  <block id="ebf90723e7659cb5381545104b618612" category="paragraph">El término «grupo de coherencia» hace referencia a la capacidad de una cabina de almacenamiento para gestionar varios recursos de almacenamiento como una sola imagen. Por ejemplo, una base de datos puede consistir en 10 LUN. La cabina debe ser capaz de realizar backup, restaurar y replicar esos 10 LUN de forma coherente. La restauración no es posible si las imágenes de las LUN no eran consistentes en el punto de backup. Para replicar estos 10 LUN es necesario que todas las réplicas estén perfectamente sincronizadas entre sí.</block>
  <block id="3f8a43f1defaa984435092f616876545" category="paragraph">El término «grupo de coherencia» no se utiliza con frecuencia cuando se habla de ONTAP, porque la coherencia siempre ha sido una función básica del volumen y de la arquitectura de agregado en ONTAP. Muchas otras cabinas de almacenamiento gestionan LUN o sistemas de archivos como unidades individuales. Podrían configurarse opcionalmente como «grupo de consistencia» para fines de protección de datos, pero este es un paso adicional en la configuración.</block>
  <block id="74e816c3c784f5c30c79dca4590d7f59" category="paragraph">ONTAP siempre ha podido capturar imágenes de datos replicadas y locales coherentes. Aunque los distintos volúmenes de un sistema ONTAP no suelen describirse formalmente como un grupo de coherencia, eso es lo que son. Una copia Snapshot de ese volumen es una imagen de grupo de coherencia, la restauración de esa copia Snapshot es una restauración de grupo de coherencia, y tanto SnapMirror como SnapVault ofrecen replicación de grupo de coherencia.</block>
  <block id="15cc4389a08c3f4748e98622e630ad3e" category="section-title">Snapshots de grupo de coherencia</block>
  <block id="d286b747757ef3d8d3abac27bfae65f9" category="paragraph">Las snapshots de grupo de consistencia (cg-snapshots) son una extensión de la tecnología Snapshot básica de ONTAP. Una operación Snapshot estándar crea una imagen coherente de todos los datos dentro de un único volumen, pero a veces es necesario crear un conjunto coherente de instantáneas en varios volúmenes e incluso entre varios sistemas de almacenamiento. El resultado es un conjunto de instantáneas que se pueden utilizar de la misma manera que una instantánea de un solo volumen individual. Se pueden utilizar para la recuperación de datos locales, replicar para la recuperación ante desastres o clonar como una única unidad coherente.</block>
  <block id="7c199465bc6344e648e2f73c88131605" category="paragraph">El mayor uso conocido de cg-snapshots es para un entorno de base de datos de aproximadamente 1PB GB de tamaño que abarca 12 controladoras. Las cg-snapshots creadas en este sistema se han utilizado para backup, recuperación y clonado.</block>
  <block id="e5c199b4a97409f33d5caae984957744" category="paragraph">La mayoría de las veces, cuando un conjunto de datos abarca volúmenes y se debe conservar el orden de escritura, el software de gestión elegido utiliza automáticamente una instantánea de cg. No es necesario comprender los detalles técnicos de cg-snapshots en estos casos. No obstante, hay situaciones en las que los complejos requisitos de protección de datos requieran un control detallado del proceso de protección y replicación de datos. Los flujos de trabajo de automatización o el uso de scripts personalizados para llamar a las API de cg-snapshot son algunas de las opciones. Para comprender la mejor opción y el rol de cg-snapshot se requiere una explicación más detallada de la tecnología.</block>
  <block id="cf3c30ea5c240a8aef02d240f42cdff7" category="paragraph">La creación de un conjunto de cg-snapshots es un proceso de dos pasos:</block>
  <block id="f30455406a91bd776afbc88e60b9697e" category="list-text">Establezca el aislamiento de escritura en todos los volúmenes de destino.</block>
  <block id="c7afe45d94f2fd172a01e851d7f92a2f" category="list-text">Crear snapshots de dichos volúmenes mientras se encuentra en estado protegido.</block>
  <block id="c464d4671e489eaad9a8cbf0a8086ea9" category="paragraph">El cercado de escritura se establece en serie. Esto significa que, a medida que se configura el proceso de barrera en varios volúmenes, las operaciones de I/O de escritura se congelan en el primer volumen de la secuencia, a medida que sigue confirmándose con los volúmenes que aparecen más adelante. Esto puede parecer que, en un principio, no cumple el requisito de conservación de la orden de escritura, pero eso solo se aplica a I/O que se emite de forma asíncrona en el host y no depende de ninguna otra escritura.</block>
  <block id="688656b1f8644ee299edf7be87a8fc75" category="paragraph">Por ejemplo, una base de datos puede emitir muchas actualizaciones de archivos de datos asíncronos y permitir que el sistema operativo vuelva a ordenar la I/O y completarlas de acuerdo con su propia configuración del programador. El orden de este tipo de I/O no se puede garantizar porque la aplicación y el sistema operativo ya han liberado el requisito de conservar el orden de escritura.</block>
  <block id="599ce07d1bae0fa6169959e2bdb97ada" category="paragraph">Como ejemplo de contador, la mayor parte de la actividad de registro de la base de datos es síncrona. La base de datos no continúa con más escrituras de registro hasta que se reconozca la E/S y se mantenga el orden de esas escrituras. Si un registro de I/O llega a un volumen cercado, no se reconoce y la aplicación se bloquea en otras escrituras. Del mismo modo, la I/O de metadatos del sistema de archivos suele ser síncrona. Por ejemplo, no se debe perder una operación de eliminación de archivos. Si un sistema operativo con un sistema de archivos xfs suprimió un archivo y la E/S que actualizó los metadatos del sistema de archivos xfs para eliminar la referencia a ese archivo aterrizó en un volumen cercado, la actividad del sistema de archivos se detendría. De este modo se garantiza la integridad del sistema de archivos durante las operaciones cg-snapshot.</block>
  <block id="0f0c0f05310f9cf257d65bfd936f15c5" category="paragraph">Después de configurar el control de escritura en los volúmenes de destino, están listos para la creación de las copias Snapshot. No es necesario crear las copias Snapshot precisamente al mismo tiempo, ya que el estado de los volúmenes se congela desde un punto de vista de escritura dependiente. Para protegerse frente a un defecto en la aplicación que crea las copias cg-snapshots, la barrera de escritura inicial incluye un tiempo de espera configurable en el que ONTAP libera automáticamente la barrera y reanuda el procesamiento de escritura transcurridos un número de segundos definido. Si todas las Snapshot se crean antes de que se agote el tiempo de espera, el conjunto de snapshots resultante es un grupo de coherencia válido.</block>
  <block id="df4925d1c6c3f3258e80ff35ce62b17d" category="section-title">Orden de escritura dependiente</block>
  <block id="6c78ee478b93fbb573157b85fb1114db" category="paragraph">Desde un punto de vista técnico, la clave para un grupo de consistencia es preservar el orden de escritura y, específicamente, el orden de escritura dependiente. Por ejemplo, una base de datos que escribe en 10 LUN escribe simultáneamente en todas ellas. Muchas escrituras se emiten de forma asíncrona, por lo que el orden en que se completan no es importante y el orden en que se realizan varía según el comportamiento del sistema operativo y de la red.</block>
  <block id="69d87c00869001f3f06ad4a1494eac21" category="paragraph">Algunas operaciones de escritura deben estar presentes en el disco antes de que la base de datos pueda continuar con escrituras adicionales. Estas operaciones de escritura cruciales se denominan escrituras dependientes. La E/S de escritura posterior depende de la presencia de estas escrituras en el disco. Cualquier snapshot, recuperación o replicación de estas 10 LUN debe asegurarse de que la orden de escritura dependiente está garantizada. Las actualizaciones del sistema de archivos son otro ejemplo de escrituras dependientes del orden de escritura. El orden en el que se realizan los cambios en el sistema de archivos debe conservarse o todo el sistema de archivos podría dañarse.</block>
  <block id="74fbae5d0b3c16e1774c5f4dce2c1c36" category="section-title">Estrategias</block>
  <block id="53e858edb9bd9ff3f9ead52cebf5731d" category="paragraph">Existen dos enfoques principales para los backups basados en Snapshot:</block>
  <block id="f87f61f625a005bd32c53f808d235eea" category="list-text">Backups activos protegidos de Snapshot</block>
  <block id="c81725eb350a685210d69762bd5d725d" category="paragraph">Una copia de seguridad coherente con los fallos de una base de datos se refiere a la captura de toda la estructura de la base de datos, incluidos archivos de datos, redo logs y archivos de control, en un único punto en el tiempo. Si la base de datos se almacena en un único volumen de NetApp FlexVol, el proceso es sencillo; se puede crear una copia Snapshot en cualquier momento. Si una base de datos abarca volúmenes, debe crearse una snapshot de grupo de coherencia (CG). Existen varias opciones para crear snapshots de CG, como el software NetApp SnapCenter, funciones nativas del grupo de coherencia ONTAP y scripts que se mantienen por el usuario.</block>
  <block id="c32eba270db95747b471fd53e203a47b" category="paragraph">Los backups de Snapshot coherentes con los fallos se usan principalmente cuando es suficiente con la recuperación punto del backup. Los registros de archivos se pueden aplicar bajo ciertas circunstancias, pero cuando se requiere una recuperación puntual más granular, es preferible un backup online.</block>
  <block id="82cc23cd5dc667cc9fb78ff6e76ac15b" category="paragraph">El procedimiento básico para un backup en línea basado en Snapshot es el siguiente:</block>
  <block id="dbaf4855045e45fbcf678fa4cd1ab2db" category="list-text">Coloque la base de datos en<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> modo.</block>
  <block id="c3e07fb8aef84ef3d94e3f9d5376c091" category="list-text">Cree una instantánea de todos los volúmenes que alojan archivos de datos.</block>
  <block id="2d0e58ff1a25bd9fd8a85ad8ce6f2665" category="list-text">Salga<block ref="402051f4be0cc3aad33bcf3ac3d6532b" prefix=" " category="inline-code"></block> modo.</block>
  <block id="4196c5674aaa9e4317b2b4c54f94a905" category="list-text">Ejecute el comando<block ref="9d2840394bc37850da4e360dbf60c0dc" prefix=" " category="inline-code"></block> para forzar el archivado de registros.</block>
  <block id="f2736e795871e2fc2d36addb9436f337" category="list-text">Crear instantáneas de todos los volúmenes que alojan los archive logs.</block>
  <block id="f24880a3fe8b242fdd1aba5a2d11196f" category="paragraph">Este procedimiento produce un juego de instantáneas que contienen archivos de datos en modo de backup y los archive logs críticos generados durante el modo de backup. Estos son los dos requisitos para recuperar una base de datos. Los archivos, como los archivos de control, también deben protegerse por conveniencia, pero el único requisito absoluto es la protección de los archivos de datos y los registros de archivos.</block>
  <block id="0c32649da44277db19fcfa3fe4dac28f" category="paragraph">Aunque los diferentes clientes pueden tener estrategias muy diferentes, casi todas estas estrategias se basan en última instancia en los mismos principios descritos a continuación.</block>
  <block id="88f451afed04f47352987f617f805826" category="section-title">Recuperación basada en Snapshot</block>
  <block id="c092a9763068c8382be82f9c77bb9658" category="paragraph">Al diseñar diseños de volúmenes para bases de datos Oracle, la primera decisión es si utilizar tecnología NetApp SnapRestore basada en volúmenes (VBSR).</block>
  <block id="15a0b8dc4d1b340d403bf6515f7e61b8" category="paragraph">El SnapRestore basado en volúmenes permite revertir un volumen casi instantáneamente a un momento específico anterior. Debido a que se revierten todos los datos del volumen, es posible que VBSR no sea apropiado para todos los casos de uso. Por ejemplo, si se almacena una base de datos completa, incluidos archivos de datos, registros de recuperación y registros de archivos, en un solo volumen y este volumen se restaura con VBSR, los datos se pierden porque se descartan los datos de archive log y redo más recientes.</block>
  <block id="e63c0ca12b07a654ccadd92527a95c47" category="paragraph">VBSR no se requiere para la restauración. Muchas bases de datos pueden restaurarse utilizando SnapRestore de archivo único (SFSR) basado en archivos o simplemente copiando archivos del snapshot al sistema de archivos activo.</block>
  <block id="2093e578085fede0f022c4efdb79c336" category="paragraph">Se prefiere VBSR cuando una base de datos es muy grande o cuando se debe recuperar lo antes posible, y el uso de VBSR requiere aislamiento de los archivos de datos. En un entorno NFS, los archivos de datos de una base de datos determinada deben estar almacenados en volúmenes dedicados que no estén contaminados por ningún otro tipo de archivo. En un entorno SAN, los archivos de datos deben almacenarse en LUN dedicadas en volúmenes de FlexVol dedicados. Si se utiliza un gestor de volúmenes (incluido Oracle Automatic Storage Management [ASM]), el grupo de discos también debe estar dedicado a los archivos de datos.</block>
  <block id="b38bd603a952c93872eae2ea858cb15f" category="paragraph">El aislamiento de archivos de datos de esta manera permite que se reviertan a un estado anterior sin dañar otros sistemas de archivos.</block>
  <block id="5755a6275c3ecd99e8159efc58a8ff6c" category="section-title">Reserva de Snapshot</block>
  <block id="957abb72f2db3a20e0b570a5fa3a1dcc" category="paragraph">Para cada volumen con datos de Oracle en un entorno SAN, el<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> Debe establecerse en cero porque reservar espacio para una snapshot en un entorno de LUN no es útil. Si la reserva fraccionaria se establece en 100, una copia snapshot de un volumen con unidades lógicas requiere suficiente espacio libre en el volumen, excluida la reserva de snapshot, para absorber un 100% de renovación de todos los datos. Si la reserva fraccionaria se define en un valor menor, se requiere una cantidad de espacio libre correspondiente menor, pero siempre excluye la reserva de instantáneas. Esto significa que se desperdicia el espacio de reserva de snapshot en un entorno de LUN.</block>
  <block id="d5a06adf11e69f265f3ee3277212764e" category="paragraph">En un entorno NFS, hay dos opciones:</block>
  <block id="7631336a8e2e03f6ac500c145445b2d7" category="list-text">Ajuste la<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> basado en el consumo de espacio esperado de la instantánea.</block>
  <block id="acc4c5d06fc4a9ac93880c9c2d0a6e76" category="list-text">Ajuste la<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> a cero y gestione el consumo de espacio activo y snapshot de forma colectiva.</block>
  <block id="44806986c5abfcd6261803f4f75a7b56" category="paragraph">Con la primera opción,<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> se establece en un valor distinto de cero, normalmente alrededor del 20%. Este espacio se oculta al usuario. Sin embargo, este valor no crea un límite de utilización. Si una base de datos con una reserva del 20% experimenta una rotación del 30%, el espacio de la instantánea puede crecer más allá de los límites de la reserva del 20% y ocupar espacio sin reservar.</block>
  <block id="c8910acb0bfa30f82b423ff09a9710ca" category="paragraph">La principal ventaja de establecer una reserva en un valor como 20% es verificar que algo de espacio esté siempre disponible para las instantáneas. Por ejemplo, un volumen de 1TB GB con una reserva del 20% solo permitiría que un administrador de bases de datos (DBA) almacene 800GB TB de datos. Esta configuración garantiza al menos 200GB MB de espacio para el consumo de snapshots.</block>
  <block id="be233226a8cb890c0a8bbf041c06ac6b" category="paragraph">Cuando<block ref="9ca25b30dcc119f9115aad6d85fd12ce" prefix=" " category="inline-code"></block> se establece en cero, todo el espacio del volumen está disponible para el usuario final, lo que proporciona una mejor visibilidad. Un administrador de bases de datos debe comprender que, si ve un volumen de 1TB GB que aprovecha las copias Snapshot, este espacio de 1TB TB se compartirá entre los datos activos y la rotación de copias Snapshot.</block>
  <block id="b10efee713968b90d211d08ec8345d20" category="paragraph">No hay una preferencia clara entre la opción uno y la opción dos entre los usuarios finales.</block>
  <block id="8112d08173571f2d01372cadea3ea76d" category="section-title">Snapshots de ONTAP y de terceros</block>
  <block id="0cc082f7cc7618a904f6cde556295cbd" category="paragraph">El ID de documento de Oracle 604683,1 explica los requisitos para la compatibilidad con Snapshot de terceros y las múltiples opciones disponibles para las operaciones de backup y restauración.</block>
  <block id="130a02f8381e6c54b2ea07d2bdaf6f0b" category="paragraph">El proveedor externo debe garantizar que las copias Snapshot de la empresa cumplen con los requisitos siguientes:</block>
  <block id="97eb59a0f249226523b31dd52d557e00" category="list-text">Las copias Snapshot deben integrarse con las operaciones de restauración y recuperación recomendadas de Oracle.</block>
  <block id="083e9332dc2b6bf064139ac2e670eee9" category="list-text">Las instantáneas deben ser consistentes con los fallos de la base de datos en el punto de la instantánea.</block>
  <block id="9dae8634b638a6949dab0f7eaf7988bd" category="list-text">El orden de escritura se conserva para cada archivo dentro de una instantánea.</block>
  <block id="7bc868657652757ca8505ddcd297456f" category="paragraph">Los productos de gestión de Oracle de ONTAP y NetApp cumplen estos requisitos.</block>
  <block id="9e19caeb431a5e29a1a63e3cee4b36c9" category="doc">Protección de datos de Oracle con ONTAP</block>
  <block id="848aab87f65bfade12f80d4e864ec046" category="paragraph">Una empresa no puede operar sin acceso a sus datos y, a veces, los datos definen el negocio. Estos datos deben protegerse; sin embargo, la protección de datos no solo garantiza un backup utilizable; se trata de realizar backups de forma rápida y fiable, además de almacenarlos de forma segura.</block>
  <block id="28a0304f97f876b27cf541f4ad9a30d7" category="paragraph">El otro lado de la protección de datos es la recuperación de datos. Cuando no se puede acceder a los datos, la empresa se ve afectada y puede dejar de funcionar hasta que se restauren los datos. Este proceso debe ser rápido y fiable. Por último, la mayoría de las bases de datos deben protegerse frente a desastres, lo que significa mantener una réplica de la base de datos. La réplica debe estar lo suficientemente actualizada. También debe ser rápido y sencillo hacer de la réplica una base de datos completamente operativa.</block>
  <block id="3d601b26d05eac41fc6a7eba92fdc8b9" category="admonition">Esta documentación sustituye al informe técnico _TR-4591 publicado anteriormente: Protección de datos de Oracle: Backup, recuperación y replicación._</block>
  <block id="21d28aa03f67eb242b1c95a6a0594ff5" category="section-title">Planificación</block>
  <block id="355ba59494fea8b20be391a73cc755eb" category="paragraph">Las pruebas precisas del rendimiento del almacenamiento de la base de datos son un tema muy complicado. Requiere una comprensión de los siguientes problemas:</block>
  <block id="b57041cc3b57577b5c21eff44739e3f9" category="list-text">IOPS y rendimiento</block>
  <block id="236e7fd957ada95e8094e302623980d3" category="list-text">La diferencia entre las operaciones de I/O en primer plano y en segundo plano</block>
  <block id="902f90cc4ab59808cac5606f767f61c4" category="list-text">El efecto de la latencia sobre la base de datos</block>
  <block id="196198dbaa1d1ea17cfc478fbb2f419f" category="list-text">Numerosos sistemas operativos y configuraciones de red que también afectan al rendimiento del almacenamiento</block>
  <block id="5ff18eadb2ef3fc20e13bed3e5b61d79" category="paragraph">Además, hay tareas que no son de almacenamiento que se deben tener en cuenta. Hay un punto en el cual la optimización del rendimiento del almacenamiento no proporciona ventajas útiles, porque el rendimiento del almacenamiento ya no es un factor limitador del rendimiento.</block>
  <block id="32a993d3f497a6dd4392d3348b05ebc3" category="list-text">El ancho de banda de red es una fuente cada vez más común de limitaciones de rendimiento. Por ejemplo, las soluciones de discos giratorios suelen ser cuellos de botella en el rendimiento de las bases de datos porque la latencia de I/O es muy alta. Cuando una cabina all-flash elimina las limitaciones de latencia, la barrera cambia frecuentemente a la red. Esto es especialmente notable en entornos virtualizados y sistemas blade donde la verdadera conectividad de red es difícil de visualizar. Esto puede complicar las pruebas de rendimiento si el sistema de almacenamiento en sí no se puede utilizar completamente debido a las limitaciones de ancho de banda.</block>
  <block id="8caa382fb0f5f7a8279424d306dd003d" category="list-text">Comparar el rendimiento de una cabina all-flash con una cabina que contiene discos giratorios no es posible debido a la latencia drásticamente mejorada de las cabinas all-flash. Los resultados de las pruebas no suelen ser significativos.</block>
  <block id="bc2b8b37bdda467f2ce639ab28bf4646" category="list-text">La comparación del rendimiento máximo de IOPS con una cabina all-flash no suele ser una prueba útil porque las bases de datos no están limitadas por las operaciones de I/O de almacenamiento Por ejemplo, supongamos que una cabina puede admitir 500K 000 IOPS aleatorias, mientras que otra puede admitir 300K. La diferencia no es relevante en el mundo real si la base de datos gasta el 99% de su tiempo en procesamiento de CPU. Las cargas de trabajo nunca utilizan todas las funcionalidades de la cabina de almacenamiento. En cambio, las funcionalidades de IOPS máximo pueden ser cruciales en una plataforma de consolidación en la cual se espera que la cabina de almacenamiento se cargue en sus capacidades máximas.</block>
  <block id="0c2cbb26e6baa58b7d3a3309f95a2786" category="list-text">Considere siempre la latencia así como IOPS en cualquier prueba de almacenamiento. Muchas cabinas de almacenamiento del mercado afirman niveles extremos de IOPS, pero la latencia hace que dichas IOPS sean inútiles en dichos niveles. El destino típico de las cabinas all-flash es la marca 1ms. Un método mejor de prueba no es medir el máximo de IOPS posibles, sino determinar cuántas IOPS puede admitir una cabina de almacenamiento antes de que la latencia media sea superior a 1ms ms.</block>
  <block id="e6d8362588e550c19912b0f3f0e1a129" category="section-title">Oracle Automatic Workload Repository y benchmarking</block>
  <block id="d035df494751722dd56d4cf4a8d1f795" category="paragraph">El estándar oro para las comparaciones de rendimiento de Oracle es un informe de Oracle Automatic Workload Repository (AWR).</block>
  <block id="95f7e55383674168e90b01b708bc88db" category="paragraph">Hay varios tipos de informes de AWR. Desde el punto de vista del almacenamiento, un informe generado por la ejecución del<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> Command es el más completo y valioso porque se dirige a una instancia de base de datos específica e incluye algunos histogramas detallados que desglosan eventos de I/O de almacenamiento en función de la latencia.</block>
  <block id="7b79802e5668e6e5b990081db481505d" category="paragraph">La comparación ideal de dos cabinas de rendimiento implica ejecutar la misma carga de trabajo en cada cabina y producir un informe de AWR que apunte con precisión a la carga de trabajo. En el caso de una carga de trabajo de ejecución muy prolongada, se puede utilizar un único informe de AWR con un tiempo transcurrido que abarque el tiempo de inicio y de finalización, pero es preferible dividir los datos de AWR como varios informes. Por ejemplo, si un trabajo por lotes se ejecutó desde la medianoche hasta las 6 a.m., cree una serie de informes de AWR de una hora de medianoche a las 1 a.m., de 1 a.m. a 2 a.m., etc.</block>
  <block id="e39ecb86ad7d25413ba8ad2976fd3e4a" category="paragraph">En otros casos, se debe optimizar una consulta muy corta. La mejor opción es un informe de AWR basado en una instantánea de AWR creada cuando se inicia la consulta y una segunda instantánea de AWR creada cuando finaliza la consulta. El servidor de la base de datos debería ser silencioso para minimizar la actividad en segundo plano que oscurecería la actividad de la consulta en análisis.</block>
  <block id="2fe7152c186ec1b5b0451e13ec8b968b" category="admonition">Cuando los informes de AWR no están disponibles, los informes de Oracle statspack son una buena alternativa. Contienen la mayoría de las mismas estadísticas de E/S que un informe AWR.</block>
  <block id="8b8c73ac7e509a897688356d1d283d75" category="section-title">Oracle AWR y solución de problemas</block>
  <block id="42a92c79ee82f4343e7d65f2f1cf2dd2" category="paragraph">Un informe AWR es también la herramienta más importante para analizar un problema de rendimiento.</block>
  <block id="ad5387afbab7c506c781c8b12b0a4b24" category="paragraph">Al igual que sucede con las pruebas de rendimiento, la solución de problemas de rendimiento requiere medir con precisión una carga de trabajo determinada. Siempre que sea posible, facilite los datos de AWR cuando notifique un problema de rendimiento al centro de soporte de NetApp o cuando trabaje con un NetApp o con un equipo de cuentas de partners sobre una nueva solución.</block>
  <block id="6471146c0e33e2a8ec8a5c6635c837bc" category="paragraph">Al proporcionar datos de AWR, tenga en cuenta los siguientes requisitos:</block>
  <block id="5c3ba265890805919f93c246b3f8d2d6" category="list-text">Ejecute el<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> comando para generar el informe. La salida puede ser texto o HTML.</block>
  <block id="25db65f9a36910f3e488a8b7407130de" category="list-text">Si se utiliza Oracle Real Application Clusters (RAC), genere informes de AWR para cada instancia del cluster.</block>
  <block id="96d55341f8208c60720e68b3155f3aa1" category="list-text">Indique la hora específica a la que ha existido el problema. El tiempo transcurrido máximo aceptable de un informe de AWR suele ser de una hora. Si un problema persiste durante varias horas o implica una operación de varias horas, como un trabajo por lotes, proporcione varios informes de AWR de una hora que cubran todo el período que se va a analizar.</block>
  <block id="4533b15b837909c68a0171d2638494d2" category="list-text">Si es posible, ajuste el intervalo de instantáneas de AWR a 15 minutos. Este ajuste permite realizar un análisis más detallado. Esto también requiere ejecuciones adicionales de<block ref="5053a9940effa118d38161a53f3b80f8" prefix=" " category="inline-code"></block> para proporcionar un informe para cada intervalo de 15 minutos.</block>
  <block id="97eb6d04cc93934c1be4ab95054cd0b0" category="list-text">Si el problema es una consulta de ejecución muy corta, proporcione un informe AWR basado en una instantánea AWR creada al iniciar la operación y una segunda instantánea AWR creada al finalizar la operación. El servidor de base de datos debería ser silencioso para minimizar la actividad en segundo plano que oscurecería la actividad de la operación en análisis.</block>
  <block id="5186f459ce7d75e587a083bcb7c5927a" category="list-text">Si se informa de un problema de rendimiento en determinados momentos pero no en otros, proporcione datos de AWR adicionales que demuestren un buen rendimiento para la comparación.</block>
  <block id="108a72dad388aa310cc52ee3bac7d1cc" category="section-title">calibrar_io</block>
  <block id="f1c07dfccef6a6c47a5ccef938e10e3d" category="paragraph">La<block ref="108a72dad388aa310cc52ee3bac7d1cc" prefix=" " category="inline-code"></block> nunca se debe usar el comando para probar, comparar ni hacer pruebas de rendimiento de los sistemas de almacenamiento. Tal y como se indica en la documentación de Oracle, este procedimiento calibra las capacidades de E/S del almacenamiento.</block>
  <block id="872892cce56a2665ad7ceecc44b38166" category="paragraph">La calibración no es lo mismo que la evaluación comparativa. El objetivo de este comando es emitir E/S para ayudar a calibrar las operaciones de base de datos y mejorar su eficiencia mediante la optimización del nivel de E/S emitidas al host. Debido al tipo de I/O que realiza el<block ref="108a72dad388aa310cc52ee3bac7d1cc" prefix=" " category="inline-code"></block> La operación no representa la E/S real del usuario de la base de datos, los resultados no son predecibles y, con frecuencia, ni siquiera se pueden reproducir.</block>
  <block id="e66807fad19acd41db50eedff918a4dd" category="section-title">SLOB2</block>
  <block id="0a6192ff5412539c31db2c7a98f408b3" category="inline-link-macro"><block ref="0a6192ff5412539c31db2c7a98f408b3" category="inline-link-rx"></block></block>
  <block id="d1f6fb23f52090ffd944dc54549735b8" category="paragraph">SLOB2, el Silly Little Oracle Benchmark, se ha convertido en la herramienta preferida para evaluar el rendimiento de la base de datos. Fue desarrollado por Kevin Closson y está disponible en <block ref="3ccce0719b1965cd915da75778e4e706" category="inline-link-macro-rx"></block>. Se necesitan minutos para instalar y configurar, y utiliza una base de datos Oracle real para generar patrones de E/S en un tablespace definido por el usuario. Es una de las pocas opciones de prueba disponibles que puede saturar una cabina all-flash con I/O. También es útil para generar niveles mucho más bajos de I/O para simular cargas de trabajo de almacenamiento que son bajas IOPS, pero sensibles a la latencia.</block>
  <block id="baffd8ac40ca7b966340e7b257b4c7b4" category="section-title">Swingbench</block>
  <block id="905a59d6f73f4e2aea1dc232a3bcd195" category="paragraph">Swingbench puede ser útil para probar el rendimiento de las bases de datos, pero es extremadamente difícil utilizar Swingbench de una manera que pone a prueba el almacenamiento. NetApp no ha observado ninguna prueba de Swingbench que haya producido suficientes I/O como para representar una carga significativa en ninguna cabina AFF. En casos limitados, la prueba de entrada de órdenes (OET) puede utilizarse para evaluar el almacenamiento desde un punto de vista de latencia. Esto podría ser útil en situaciones en las que una base de datos tiene una dependencia de latencia conocida para consultas particulares. Se debe tener precaución para asegurarse de que el host y la red estén correctamente configurados de modo que se puedan aprovechar las posibilidades de latencia de una cabina all-flash.</block>
  <block id="e3cf940afa524b20b15c43b20405be77" category="section-title">HammerDB</block>
  <block id="5c9408da71d2ff7554b9fd11add795cf" category="paragraph">HammerDB es una herramienta de prueba de bases de datos que simula las pruebas TPC-C y TPC-H. Construir un conjunto de datos lo suficientemente grande puede llevar mucho tiempo para ejecutar correctamente una prueba, pero puede ser una herramienta eficaz para evaluar el rendimiento de las aplicaciones de almacén de datos y OLTP.</block>
  <block id="7e1ad070b7fff621d9d64a71cec87684" category="section-title">Orión</block>
  <block id="56fedcbec2842fb62a743c5f84311597" category="paragraph">La herramienta Oracle Orion se usaba comúnmente con Oracle 9, pero no se ha mantenido para garantizar la compatibilidad con los cambios en varios sistemas operativos de host. Rara vez se utiliza con Oracle 10 u Oracle 11 debido a incompatibilidades con el sistema operativo y la configuración del almacenamiento.</block>
  <block id="38622bf572fa7bec2dc7f3915ebd345f" category="paragraph">Oracle reescribió la herramienta y se instala por defecto con Oracle 12c. Aunque este producto se ha mejorado y utiliza muchas de las mismas llamadas que utiliza una base de datos Oracle real, no utiliza exactamente la misma ruta de acceso de código o el comportamiento de E/S utilizado por Oracle. Por ejemplo, la mayoría de las operaciones de I/O de Oracle se realizan de forma síncrona, lo que significa que la base de datos se detiene hasta que la E/S se completa a medida que la operación de E/S se completa en primer plano. Un inundamiento simple de un sistema de almacenamiento con I/O aleatorias no es una reproducción de las operaciones de I/O de Oracle reales y no ofrece un método directo de comparar matrices de almacenamiento o medir el efecto de los cambios de configuración.</block>
  <block id="bb68dfada5ca20e256bbd3ffbbfab9e6" category="paragraph">Dicho esto, existen algunos casos de uso de Orion, como la medición general del rendimiento máximo posible de una determinada configuración host-red-almacenamiento o para medir el estado de un sistema de almacenamiento. Con una cuidadosa realización de pruebas, podrían concebirse pruebas de Orion útiles para comparar cabinas de almacenamiento o evaluar el efecto de un cambio en la configuración, siempre y cuando los parámetros incluyan considerar la consideración de IOPS, el rendimiento y la latencia, y tratar de replicar fielmente una carga de trabajo realista.</block>
  <block id="6b64090d226d30776368e89b08c7c71b" category="summary">Alineación de WAFL para bases de datos Oracle</block>
  <block id="03a35ba2b6191f8cfbd1cca378eefc91" category="doc">Verificación de la alineación de WAFL para bases de datos de Oracle</block>
  <block id="219900dcd21cee2f958254a708ad36f6" category="paragraph">La correcta alineación de WAFL es fundamental para un buen rendimiento. Aunque ONTAP gestiona bloques en 4KB unidades, este hecho no significa que ONTAP realice todas las operaciones en 4KB unidades. De hecho, ONTAP admite operaciones de bloque de diferentes tamaños, pero la contabilidad subyacente es administrada por WAFL en 4KB unidades.</block>
  <block id="5d3a5c290e14d74acf49b20d15120886" category="paragraph">El término “alineación” se refiere a cómo Oracle I/O corresponde a estas 4KB unidades. Para obtener un rendimiento óptimo, el bloque de 8KB KB de Oracle debe residir en dos bloques físicos de 4KB WAFL en una unidad. Si un bloque se equipara con 2KB, este bloque reside en la mitad de un bloque de 4KB KB, un 4KB bloque completo independiente y, a continuación, la mitad de un tercer bloque de 4KB KB. Esta disposición provoca una degradación del rendimiento.</block>
  <block id="0073ce99d632b066d5ac09a4ad0cf7fc" category="paragraph">La alineación no es un problema en los sistemas de archivos NAS. Los archivos de datos de Oracle se alinean con el inicio del archivo en función del tamaño del bloque de Oracle. Por lo tanto, los tamaños de bloque de 8KB, 16KB y 32KB se alinean siempre. Todas las operaciones de bloque se desplazan desde el inicio del archivo en unidades de 4 kilobytes.</block>
  <block id="d7f7edd61ab216efc34578584a7d0e7c" category="paragraph">Por el contrario, los LUN suelen contener algún tipo de encabezado de controlador o metadatos del sistema de archivos en su inicio que crea una desviación. La alineación rara vez es un problema en los sistemas operativos modernos, ya que estos sistemas operativos están diseñados para unidades físicas que podrían utilizar un sector nativo de 4KB, que también requiere que la E/S se alinee con los límites de 4KB para un rendimiento óptimo.</block>
  <block id="38b3d1cd67903560954ad297a92e3de1" category="paragraph">Sin embargo, hay algunas excepciones. Es posible que una base de datos se haya migrado desde un SO antiguo que no estaba optimizado para 4KB E/S, o que se haya producido un error de usuario durante la creación de la partición que podría haber producido un desplazamiento que no está en unidades de 4KB GB de tamaño.</block>
  <block id="612eeadd26ceeace7b043d37f8e24b1f" category="paragraph">Los siguientes ejemplos son específicos de Linux, pero el procedimiento se puede adaptar para cualquier sistema operativo.</block>
  <block id="1d5b772bea21e5e949413e09eedf17de" category="section-title">Alineado</block>
  <block id="594b0fc1af44897ff4b26f2e6b866685" category="paragraph">El siguiente ejemplo muestra una comprobación de alineación en una sola LUN con una partición única.</block>
  <block id="dc2c18402c86861702fc1d94a6495ac3" category="paragraph">En primer lugar, cree la partición que utiliza todas las particiones disponibles en la unidad.</block>
  <block id="adff8cc6319e96d2685fd082a5aa043c" category="paragraph">La alineación se puede comprobar matemáticamente con el siguiente comando:</block>
  <block id="4bc7aba328a710bb7d0935cf830634aa" category="paragraph">La salida muestra que las unidades son de 512 bytes, y el inicio de la partición es de 32 unidades. Esto es un total de 32 x 512 = 16.834 bytes, que es un múltiplo completo de bloques de 4KB WAFL. Esta partición está correctamente alineada.</block>
  <block id="dd343941469b5360af52eb1b94fe5de6" category="paragraph">Para verificar la alineación correcta, lleve a cabo los siguientes pasos:</block>
  <block id="7d84e72acd05d0c93d99e414f5b092b5" category="list-text">Identifique el identificador único universal (UUID) de la LUN.</block>
  <block id="92af2a93f00a6297c490ba0be5fd7a8a" category="list-text">Introduzca el shell del nodo en la controladora ONTAP.</block>
  <block id="5274579d5eff6fe6d1e8ecbf54e84993" category="list-text">Inicie recopilaciones estadísticas en el UUID de destino identificado en el primer paso.</block>
  <block id="52df0a2ea976123bf02330300b2392e3" category="list-text">Realice algunas operaciones de I/O. Es importante utilizar el<block ref="3c908d68ba53922b92c5595b72fa011c" prefix=" " category="inline-code"></block> Argumento para asegurarse de que la E/S es síncrona y no se almacena en búfer.</block>
  <block id="fac8a5b490ea29eca93ec213d79e6ff2" category="admonition">Tenga mucho cuidado con este comando. Inversión del<block ref="39c8942e1038872a822c0dc75eedbde3" prefix=" " category="inline-code"></block> y..<block ref="8bf8854bebe108183caeb845c7676ae4" prefix=" " category="inline-code"></block> los argumentos destruyen los datos.</block>
  <block id="4f7dce34a21e3de727f3e3ad05e6e7d8" category="list-text">Detenga las estadísticas y visualice el histograma de alineación. Todas las operaciones de I/O deben estar en la<block ref="c6bd178b372b0ddd17fff48819badc6a" prefix=" " category="inline-code"></block> Bucket, que indica las I/O alineadas con un límite de bloque de 4KB KB.</block>
  <block id="5df81374c01d1b7c20fe8cb3883117eb" category="section-title">Mal alineado</block>
  <block id="5ff266dadf965b3c304513f516a13c12" category="paragraph">En el siguiente ejemplo, se muestran operaciones de I/O mal alineadas:</block>
  <block id="25be03b87e6a5d8170ce85b16ea506ab" category="list-text">Cree una partición que no se alinee con un límite 4KB. Este no es el comportamiento predeterminado en los sistemas operativos modernos.</block>
  <block id="4adda0e871000c2b13a4faef6ce4e21b" category="paragraph">La desalineación es clara. La E/S cae principalmente en el* <block ref="66c8d76cad709856ccec680cab8ab35a" prefix="*" category="inline-code"></block> período, que coincide con el desplazamiento esperado. Cuando se creó la partición, se movió 512 bytes más al dispositivo que el valor predeterminado optimizado, lo que significa que el histograma está compensado en 512 bytes.</block>
  <block id="b53cb977228ac351c16dfacc3c427a99" category="paragraph">Además, el<block ref="20e637b3ddd562732de038fba736c7ee" prefix=" " category="inline-code"></block> La estadística es diferente de cero, lo que significa que se han realizado I/O que no han llenado todo un bloque de 4KB KB.</block>
  <block id="d3d92f87c5235ad11c8bc69e85fb2fd0" category="section-title">Registro de repetición</block>
  <block id="162b54d51a30629d78e153f8da201780" category="paragraph">Los procedimientos que se explican aquí son aplicables a los archivos de datos. Los redo logs y archive logs de Oracle tienen patrones de E/S diferentes. Por ejemplo, redo log es una sobrescritura circular de un único archivo. Si se utiliza el tamaño predeterminado de bloque de 512 bytes, las estadísticas de escritura se ven algo así:</block>
  <block id="d36dbaa617441d3308f5a9b50cb6f5ca" category="paragraph">La E/S se distribuiría en todos los bloques de histograma, pero esto no supone un problema de rendimiento. Sin embargo, las tasas de redo-log extremadamente altas podrían beneficiarse del uso de un tamaño de bloque de 4KB KB. En este caso, es conveniente asegurarse de que los LUN de redo registro están alineados correctamente. Sin embargo, esto no es tan importante para un buen rendimiento como la alineación de archivos de datos.</block>
  <block id="91d9710c9fee248ae3e9c4b810ae704f" category="doc">Bloqueos de NFSv3 obsoletos y bases de datos de Oracle</block>
  <block id="3f9e1e3abd12ad7445baea4b681b9ceb" category="paragraph">Si un servidor de base de datos Oracle se bloquea, es posible que tenga problemas con los bloqueos NFS obsoletos al reiniciar. Este problema se puede evitar prestando especial atención a la configuración de la resolución de nombres en el servidor.</block>
  <block id="288ebefc25180862eb0448b786b1b9fc" category="paragraph">Este problema surge porque la creación de un bloqueo y la eliminación de un bloqueo utilizan dos métodos ligeramente diferentes de resolución de nombres. Existen dos procesos, el Network Lock Manager (NLM) y el cliente NFS. El NLM utiliza<block ref="e5caaf154dfeed411b9eec65b903a22a" prefix=" " category="inline-code"></block> para determinar el nombre de host, mientras que el<block ref="d49331f31f40041ebcee19fca74fd9d4" prefix=" " category="inline-code"></block> usos de procesos<block ref="330c4316ae6124616389eb1ca9912f7a" prefix=" " category="inline-code"></block>. Estos nombres de host deben coincidir para que el sistema operativo borre correctamente los bloqueos obsoletos. Por ejemplo, es posible que el host esté buscando bloqueos propiedad de<block ref="c7169a6dd344d0f0a38071a1262e4973" prefix=" " category="inline-code"></block>, pero las cerraduras fueron registradas por el anfitrión como<block ref="0c32c65f5ac66d0bdb4e63bd5fde7f75" prefix=" " category="inline-code"></block>. Si<block ref="330c4316ae6124616389eb1ca9912f7a" prefix=" " category="inline-code"></block> no devuelve el mismo valor que<block ref="5c020b5bb8d1ce1ace51c2a2f4c06fc2" prefix=" " category="inline-code"></block>, entonces el proceso de liberación de bloqueo no se ha realizado correctamente.</block>
  <block id="19b9a1f540971d74c69042125bab2abc" category="paragraph">El siguiente script de ejemplo verifica si la resolución de nombres es totalmente coherente:</block>
  <block id="ee04b3fa3b28391874763596275e09c9" category="paragraph">Si<block ref="b64c6f211add16fd66ac17ef14c2a2b4" prefix=" " category="inline-code"></block> no coincide<block ref="4040592cec1880aa70936989f05e7c31" prefix=" " category="inline-code"></block>, los bloqueos obsoletos son probables. Por ejemplo, este resultado revela un problema potencial:</block>
  <block id="2b500e5914ea5a219ade17dea0808f51" category="paragraph">La solución se encuentra generalmente cambiando el orden en el que aparecen los hosts en<block ref="ad942c725cd0cae65ca4c63717ec464c" prefix=" " category="inline-code"></block>. Por ejemplo, supongamos que el archivo hosts incluye esta entrada:</block>
  <block id="22b58ec1cec48707dfc018e6e216e966" category="paragraph">Para resolver este problema, cambie el orden en el que aparecen el nombre de dominio completo y el nombre de host corto:</block>
  <block id="e357ccd0745db58f22ea5c0947b613ee" category="paragraph"><block ref="330c4316ae6124616389eb1ca9912f7a" prefix="" category="inline-code"></block> ahora devuelve el corto<block ref="c7169a6dd344d0f0a38071a1262e4973" prefix=" " category="inline-code"></block> nombre de host, que coincide con la salida de<block ref="4040592cec1880aa70936989f05e7c31" prefix=" " category="inline-code"></block>. Por lo tanto, los bloqueos se borran automáticamente después de un fallo del servidor.</block>
  <block id="ea4c55be196897a16d86999f5c16d582" category="doc">Virtualización</block>
  <block id="9e28dbd7a4f5940eeaf6d3893c5c4b1f" category="section-title">Presentación de almacenamiento</block>
  <block id="151ae53a4100e0a6e83bde4d78083f81" category="list-text">LUN iSCSI gestionadas por el iniciador iSCSI en la máquina virtual, no el hipervisor</block>
  <block id="36f9cea3dc0f65698a9fbe15460591c1" category="list-text">*Portabilidad.* Cuando una VM posee sus sistemas de archivos, el proceso de mover un entorno de Oracle se vuelve mucho más sencillo. Los sistemas de archivos se pueden mover fácilmente entre huéspedes virtualizados y no virtualizados.</block>
  <block id="f114856edc6cd8d6a9add5ec3f67656f" category="section-title">Controladores paravirtualizados</block>
  <block id="beeb10ceee6c9aabe178fb51edea7d22" category="paragraph">Para un rendimiento óptimo, el uso de controladores de red paravirtualizados es fundamental. Cuando se utiliza un almacén de datos, se requiere un controlador SCSI paravirtualizado. Un controlador de dispositivo paravirtualizado permite a un invitado integrarse más profundamente en el hipervisor, en lugar de un controlador emulado en el que el hipervisor pasa más tiempo de CPU imitando el comportamiento del hardware físico.</block>
  <block id="7c5996fc15a24ce96b30160b60ac2b96" category="section-title">RAM de sobrecompromiso</block>
  <block id="5bccdd812c4af1cb5b9e36ddce656b60" category="paragraph">Sobrecomprometer RAM significa configurar más RAM virtualizada en varios hosts de la que existe en el hardware físico. Si lo hace, se pueden producir problemas de rendimiento inesperados. Al virtualizar una base de datos, el hipervisor no debe intercambiar los bloques subyacentes del SGA de Oracle en el almacenamiento. Si lo hace, los resultados de rendimiento son muy inestables.</block>
  <block id="be493f1fc0b02ae45602c7c13f7b5dc7" category="summary">El TR-4792 proporciona directrices para el uso de NetApp HCI 615C para cargas de trabajo de gráficos 3D en un entorno VMware Horizon impulsado por las unidades de procesamiento gráfico (GPU) de NVIDIA y el software de virtualización.</block>
  <block id="ff1d278a485c443dc5d8fc9f10f1a702" category="doc">NetApp HCI para la infraestructura de puestos de trabajo virtuales con VMware Horizon 7: Impulse a los usuarios avanzados con gráficos 3D</block>
  <block id="e3162938e0d7b1bbc74111cc5b5871c5" category="paragraph">El informe técnico TR-4792 proporciona orientación sobre el uso del nodo de computación H615C de NetApp para cargas de trabajo de gráficos 3D en un entorno VMware Horizon impulsado por las unidades de procesamiento gráfico (GPU) de NVIDIA y el software de virtualización. También proporciona los resultados de las pruebas preliminares de SPECviewperf 13 para el H615C.</block>
  <block id="1de37c09602b46db5de57a946efe2768" category="paragraph"><block ref="1de37c09602b46db5de57a946efe2768" category="inline-link-macro-rx"></block></block>
  <block id="93b94e62ad8cb02a1d1a7b0944a5445d" category="summary">En este documento se trata la seguridad de productos de las herramientas de ONTAP para VMware vSphere.</block>
  <block id="57a033c33a8be6110be46b2914cc4989" category="doc">Usar vVols con ONTAP</block>
  <block id="69556d50c944e0a07ade0bea62f078a3" category="paragraph">La clave para usar vVols con ONTAP es el software VASA Provider incluido como parte de las herramientas de ONTAP para el dispositivo virtual VMware vSphere.</block>
  <block id="5e484430124a3d64541b75bbf3c8f529" category="paragraph">Las herramientas de ONTAP también incluyen extensiones de interfaz de usuario de vCenter, servidor de API de REST, adaptador de replicación de almacenamiento para el administrador de recuperación del sitio de VMware, herramientas de supervisión y configuración de host, y una serie de informes que le ayudan a gestionar mejor su entorno de VMware.</block>
  <block id="21247c4392dc3c243f693dbf5b762553" category="section-title">Productos y Documentación</block>
  <block id="bf03408d75f93f6e28c07c3c2300b98a" category="section-title">ONTAP herramientas para la arquitectura VASA Provider al utilizar iSCSI o FCP</block>
  <block id="94ef809dc16e728151bda996f8b4f8aa" category="inline-image-macro">Arquitectura del proveedor VASA de herramientas de ONTAP,240</block>
  <block id="d78de3410d86d345a548abdf67aff375" category="paragraph"><block ref="d78de3410d86d345a548abdf67aff375" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e5421e75636200787a4449a2cdaa1f1" category="section-title">Instalación del producto</block>
  <block id="3ef3033a2b9a744a1e4e7e93fa01f909" category="paragraph">En el caso de nuevas instalaciones, implemente el dispositivo virtual en el entorno de vSphere. Las versiones actuales de las herramientas de ONTAP se registrarán automáticamente en el vCenter y se habilitarán el proveedor VASA de forma predeterminada. Además de la información del host ESXi y de vCenter Server, también necesitará los detalles de configuración de la dirección IP del dispositivo. Como se ha indicado anteriormente, el proveedor VASA requiere que la licencia de FlexClone de ONTAP ya esté instalada en todos los clústeres de ONTAP que se vayan a utilizar para vVols. El dispositivo cuenta con una vigilancia integrada para garantizar la disponibilidad y, como práctica recomendada, se debe configurar con las funciones de alta disponibilidad de VMware y, opcionalmente, tolerancia a fallos. Consulte la sección 4,1 para obtener más información. No instale ni mueva el dispositivo de herramientas ONTAP ni el dispositivo vCenter Server (VCSA) al almacenamiento vVols, ya que esto podría impedir que los dispositivos se reinicien.</block>
  <block id="6a5c862f634c8967f7246f42eb9de6e1" category="paragraph">Las actualizaciones in situ de las herramientas de ONTAP son compatibles con el archivo ISO de actualización que se puede descargar en el sitio de soporte de NetApp (NSS). Siga las instrucciones de la guía de puesta en marcha y configuración para actualizar el dispositivo.</block>
  <block id="3c07c9b4b562a16890d9fee571f0441e" category="inline-link">Guía de configuración para herramientas de ONTAP para VMware vSphere</block>
  <block id="e4e51979718d88ce483f9477be981a76" category="paragraph">Para obtener el ajuste de tamaño de su dispositivo virtual y conocer los límites de configuración, consulte este artículo de base de conocimientos:<block ref="a75738ed95b0811ed0edd1b8ef0d9568" category="inline-link-rx"></block></block>
  <block id="72333dadacbc964761fb14f718f6d411" category="section-title">Documentación de producto</block>
  <block id="e0644c46fdc2ced2c094f7db15e15a8a" category="paragraph">La siguiente documentación puede ayudarle a poner en marcha las herramientas de ONTAP.</block>
  <block id="09e308ed60d47b80b6cd16eb233f1bb9" category="inline-link">Para consultar el repositorio de documentación completo&amp;amp;#44; visite este enlace a docs.netapp.com</block>
  <block id="7f21741a70426baea3ee41488da86af4" category="paragraph"><block ref="56b49132b20e341764c8aa067751e8a5" category="inline-link-rx"></block></block>
  <block id="be11c74c1dd7f307bb80183a90dc2067" category="section-title">Manos a la obra</block>
  <block id="7d0ee6fed10d3d4e5c9ee496729ab519" category="inline-link">Notas de la versión</block>
  <block id="2645deadffb8af180b8a35da3d034ad8" category="list-text"><block ref="2645deadffb8af180b8a35da3d034ad8" category="inline-link-rx"></block></block>
  <block id="b1555cd6358e57b76c72e343dbe31846" category="inline-link">Obtenga más información sobre las herramientas de ONTAP para VMware vSphere</block>
  <block id="a0aaeda90fe2ef02fba791bc7c35645c" category="list-text"><block ref="a0aaeda90fe2ef02fba791bc7c35645c" category="inline-link-rx"></block></block>
  <block id="e695b432b77d6bddfcb785c76f5e5442" category="inline-link">Herramientas de ONTAP Inicio rápido</block>
  <block id="324b0410f22fb210bbf88e1ee7e97428" category="list-text"><block ref="324b0410f22fb210bbf88e1ee7e97428" category="inline-link-rx"></block></block>
  <block id="3d7fe3e43f9f24fffe5ed0d546d12f13" category="inline-link">Ponga en funcionamiento las herramientas de ONTAP</block>
  <block id="354336d78d1f0a156dcd5221d341dfd0" category="list-text"><block ref="354336d78d1f0a156dcd5221d341dfd0" category="inline-link-rx"></block></block>
  <block id="a2fa58344be7fbd9a2be0320a8df0f77" category="inline-link">Actualice las herramientas de ONTAP</block>
  <block id="33a77e1014f1325d6ba19639a6c95d48" category="list-text"><block ref="33a77e1014f1325d6ba19639a6c95d48" category="inline-link-rx"></block></block>
  <block id="21e2a89d708329706ec6ed3fc989a1f6" category="section-title">Utilice las herramientas de ONTAP</block>
  <block id="91a9cfdbaaa44e0a9ad72e92533f763f" category="inline-link">Aprovisione almacenes de datos tradicionales</block>
  <block id="f27fe8f858d8a91950e214753b95722c" category="list-text"><block ref="f27fe8f858d8a91950e214753b95722c" category="inline-link-rx"></block></block>
  <block id="fc7d7e475ac8c3868d7426bb41df9b09" category="inline-link">Aprovisionamiento de almacenes de datos vVols</block>
  <block id="0c2552c3930f472b2d120f30d7aa0415" category="list-text"><block ref="0c2552c3930f472b2d120f30d7aa0415" category="inline-link-rx"></block></block>
  <block id="317bbf73ff27c5f981628c8fb83ebf22" category="inline-link">Configure el control de acceso basado en roles</block>
  <block id="644ae78061acbb2254be4de3ea454b06" category="list-text"><block ref="644ae78061acbb2254be4de3ea454b06" category="inline-link-rx"></block></block>
  <block id="48bc2d028cb2a507ef974230ca3ba793" category="inline-link">Configurar el diagnóstico remoto</block>
  <block id="fc0330812838aba14025bd70d41b943d" category="list-text"><block ref="fc0330812838aba14025bd70d41b943d" category="inline-link-rx"></block></block>
  <block id="641e9457539249e880725760f91d5ee2" category="inline-link">Configuración de la alta disponibilidad</block>
  <block id="5027a18a60c68e05df84cd699af74497" category="list-text"><block ref="5027a18a60c68e05df84cd699af74497" category="inline-link-rx"></block></block>
  <block id="04edeb5424c826c14a69edb777edf395" category="section-title">Proteja y gestione almacenes de datos</block>
  <block id="e17534281670c5ea4e8d55420a63c98f" category="inline-link">Protección de almacenes de datos tradicionales</block>
  <block id="c8ac931d575d89c007212a35c8dde74c" category="list-text"><block ref="8f91d2113ff32de18906bad1cd446b0d" category="inline-link-rx"></block> Con SRM</block>
  <block id="bff05cbbc19cad2bd10b9fe25dc34a1b" category="inline-link">Proteger máquinas virtuales basadas en vVols</block>
  <block id="710b15d782f0c2c0411066b86644a12d" category="list-text"><block ref="7741c74d7508dc983fa4af0dff0bdda1" category="inline-link-rx"></block> Con SRM</block>
  <block id="5267febc97a2cc385cc5c73995dc64df" category="inline-link">Supervisión de almacenes de datos tradicionales y máquinas virtuales</block>
  <block id="bac3b262bb348a54f9986c2b5dbf6024" category="list-text"><block ref="bac3b262bb348a54f9986c2b5dbf6024" category="inline-link-rx"></block></block>
  <block id="3123ece3c3b36f605758cb0c9a28f904" category="inline-link">Supervise almacenes de datos vVols y máquinas virtuales</block>
  <block id="75c07b623699e1947d011983a7823584" category="list-text"><block ref="75c07b623699e1947d011983a7823584" category="inline-link-rx"></block></block>
  <block id="73751ced5959ea3089346b01d42dde76" category="paragraph">Además de la documentación del producto, también existen artículos de la base de conocimientos de soporte que pueden ser de utilidad.</block>
  <block id="dd5138e8a4207a5b2fde43b411a4b5e1" category="section-title">Consola del proveedor de VASA</block>
  <block id="6da01a643ea28efe37fa2d6fd06a634b" category="paragraph">VASA Provider incluye una consola con información de rendimiento y capacidad para máquinas virtuales de vVols individuales. Esta información proviene directamente de ONTAP para los archivos y LUN VVOL, como la latencia, IOPS, el rendimiento y el tiempo de actividad de las 5 máquinas virtuales principales, así como la latencia e IOPS de los 5 almacenes de datos principales. Está habilitada de forma predeterminada al utilizar ONTAP 9,7 o una versión posterior. Los datos iniciales pueden tardar hasta 30 minutos en recuperarse y mostrarse en la consola.</block>
  <block id="9b78e1fecb2bcc40733f2180691c7507" category="section-title">Consola vVols de herramientas de ONTAP</block>
  <block id="4adf016da96258b45a1cf762298729b5" category="inline-image-macro">Panel de herramientas de ONTAP vVols, 400</block>
  <block id="73c1e14ddf3f32984f869ac3f122b2ca" category="paragraph"><block ref="73c1e14ddf3f32984f869ac3f122b2ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd47dd01745339787e4c7300389401f2" category="section-title">Mejores prácticas</block>
  <block id="9ae938622297e9d4b14dd0006a8f0bf4" category="paragraph">*Límites*</block>
  <block id="b4f52a4fd0b07c9d904b95fc98a1cd45" category="inline-link">Valores máximos de configuración</block>
  <block id="bc8259e306c73b2969e7ac6297000e64" category="paragraph">En general, ONTAP admite los límites de vVols definidos por VMware (consulte la publicación<block ref="a6efdd9b1a19df6105024b4869e0582b" category="inline-link-rx"></block>). La siguiente tabla resume los límites específicos de tamaño y número de vVols de ONTAP. Compruebe siempre la<block ref="bb9c67b5a4c15a85b5e6aa6c9afd0285" category="inline-link-rx"></block> Para conocer los límites actualizados de números y tamaños de LUN y archivos.</block>
  <block id="9b7ad553354519b31ec860eef39e5f6b" category="paragraph">*ONTAP vVols Limits*</block>
  <block id="130b78bfd6c9b050a912fec77e285e3f" category="cell">Capacidad/función</block>
  <block id="6231ad61105cd983d3f0042762d3233d" category="cell">SAN (SCSI o NVMe-oF)</block>
  <block id="75d4e7871261a858356a58d682ab71de" category="cell">Tamaño máximo de vVols</block>
  <block id="9cfd7100738cee4daf7acd5e01d31e14" category="cell">62 TiB*</block>
  <block id="9a728251ad1e90577975ae9395374772" category="cell">Número máximo de vVols por volumen FlexVol</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="46ba990c143630f55072434a6ea958c0" category="cell">2 mil millones de dólares</block>
  <block id="cdbcf58620f0b4b0bbf3291386a99407" category="cell">Número máximo de vVols por nodo ONTAP</block>
  <block id="342264031889898ec1a553b4dd58d98c" category="cell">Hasta 12.288**</block>
  <block id="659e5faa0bdb08327ba0719230e95be2" category="cell">50 mil millones de dólares</block>
  <block id="43b49f27d93c6f55f54a68e8983d5479" category="cell">Número máximo de vVols por par ONTAP</block>
  <block id="3941694d19c2d1fc406f055ab62cb9eb" category="cell">Hasta 24.576**</block>
  <block id="d6b3e65f296fd23975dd6f1a915c4b22" category="cell">Número máximo de vVols por clúster ONTAP</block>
  <block id="2702ff8627a3990fc940d6f53463925e" category="cell">Hasta 98.304**</block>
  <block id="4f0c25d6c688cf50460d11fecaa97fa8" category="cell">No hay límite de clúster específico</block>
  <block id="855ecc47bb0d239e1fdf6fee84e24c75" category="cell">Objetos máximos de QoS (grupo de políticas compartido y nivel de servicio de vVols individuales)</block>
  <block id="26890bd9dcb27c05f1ab5bcc859501b8" category="cell">12.000 a ONTAP 9,3; 40.000 con ONTAP 9,4 y posterior</block>
  <block id="0e38f856cb713ce9eea79fa1c6b7dc32" category="list-text">Límite de tamaño basado en sistemas ASA o en sistemas AFF y FAS que ejecutan ONTAP 9.12.1P2 y versiones posteriores.</block>
  <block id="d27c43bb3cdcbfa3852bb91192ffb849" category="list-text">El número de vVols de SAN (espacios de nombres o LUN de NVMe) varía según la plataforma. Compruebe siempre la<block ref="bb9c67b5a4c15a85b5e6aa6c9afd0285" category="inline-link-rx"></block> Para conocer los límites actualizados de números y tamaños de LUN y archivos.</block>
  <block id="72e0ee397942f7233122887584f94b8b" category="paragraph">El uso de vVols de ONTAP con vSphere es sencillo y sigue los métodos de vSphere publicados (consulte Trabajar con volúmenes virtuales en la documentación de vSphere Storage en VMware para su versión de ESXi). A continuación, se muestran algunas prácticas adicionales que se deben tener en cuenta junto con ONTAP.</block>
  <block id="83583580d98b69cb8317f9b285f3c8df" category="cell">*Utilice las herramientas de ONTAP para las extensiones de interfaz de usuario de VMware vSphere o API REST para aprovisionar almacenes de datos vVols* *y puntos finales de protocolo.*</block>
  <block id="9507d4f97aceb8d05fc962dd53f082af" category="cell">Si bien es posible crear almacenes de datos vVols con la interfaz general de vSphere, mediante las herramientas de ONTAP se crearán automáticamente extremos de protocolo según sea necesario y se crearán volúmenes FlexVol mediante prácticas recomendadas de ONTAP y cumpliendo los perfiles de capacidad de almacenamiento definidos. Solo tiene que hacer clic con el botón derecho en host/clúster/centro de datos y, a continuación, seleccionar _ONTAP TOOLS_ y _PROVISION datastore_. A partir de ahí, simplemente elija las opciones de vVols deseadas en el asistente.</block>
  <block id="e8d5f9dc0bff953a9e59755813c7e8bf" category="cell">*Nunca almacene el dispositivo de herramientas ONTAP o el dispositivo vCenter Server (VCSA) en un almacén de datos vVols que estén administrando.*</block>
  <block id="c6ac0465bff03857ee851d98f6bd782b" category="cell">Esto puede resultar en una “situación de pollo y huevo” si necesita reiniciar los aparatos porque no podrán volver a ensamblar sus propios vVols mientras se reinician. Puede almacenarlos en un almacén de datos de vVols que se gestiona con otras herramientas de ONTAP y en una puesta en marcha de vCenter.</block>
  <block id="ab8d352870fb5334773c7177d3d5dcd1" category="cell">*Evite las operaciones vVols a través de diferentes versiones de ONTAP.*</block>
  <block id="8b2bcef781b7e1f6d64739147d50aae7" category="cell">Las funcionalidades de almacenamiento compatibles como calidad de servicio, personalidad y otras han cambiado en varias versiones del proveedor VASA; algunas dependen de la versión de ONTAP. El uso de diferentes versiones de un clúster de ONTAP o el movimiento de vVols entre clústeres con diferentes versiones puede provocar un comportamiento inesperado o alarmas de cumplimiento de normativas.</block>
  <block id="b2da0eca57c759eff034e6fe26f153e6" category="cell">*Zone su estructura Fibre Channel antes de usar NVMe/FC o FCP para vVols.*</block>
  <block id="cd7bf0e1e61341c1aa3fa23401af8a27" category="inline-image-macro">La división en zonas de un único iniciador con cuatro nodos,400</block>
  <block id="51591d05b7e084ba8e5ae7f63172177e" category="inline-link">_TR-4080 Mejores prácticas para ONTAP SAN moderno 9_</block>
  <block id="c1723e6a0e1d3dd28232b33e0cb6e61d" category="inline-link">_TR-4684 Implementación y configuración de SAN modernas con NVMe-oF_</block>
  <block id="9a36c8f0464a7ffce114044f1859c7ff" category="cell">*Planifica tu soporte FlexVols de acuerdo a tus necesidades.*</block>
  <block id="03d2e894fa9a05efefa4e8d6b2008a19" category="cell">Puede resultar conveniente añadir distintos volúmenes de backup al almacén de datos vVols para distribuir la carga de trabajo en el clúster de ONTAP, admitir distintas opciones de normativas o aumentar el número de LUN o archivos permitidos. Sin embargo, si se requiere una eficiencia del almacenamiento máxima, coloque todos los volúmenes de backup en un único agregado. O, si es necesario un rendimiento de clonación máximo, considere la posibilidad de usar un único volumen de FlexVol y mantener sus plantillas o biblioteca de contenido en el mismo volumen. El proveedor VASA libera muchas operaciones de almacenamiento de vVols en ONTAP, incluidas la migración, el clonado y las copias Snapshot. Cuando esta operación se realiza en un único volumen FlexVol, se usan clones de archivos con gestión eficiente del espacio y están disponibles casi al instante. Cuando esto se realiza en volúmenes de FlexVol, las copias se encuentran disponibles rápidamente y utilizan deduplicación y compresión en línea, pero es posible que no se recupere la máxima eficiencia del almacenamiento hasta que se ejecuten trabajos en segundo plano en volúmenes con deduplicación y compresión en segundo plano. En función del origen y el destino, se puede degradar cierta eficiencia.</block>
  <block id="80b15469535d95a1690f308427545c7e" category="cell">* Mantenga los perfiles de capacidad de almacenamiento (SCPs) simples.*</block>
  <block id="33e2905cb722c14575a9bff81ba78b39" category="cell">Evite especificar capacidades que no sean necesarias si las establece en ninguna. Esto minimizará los problemas al seleccionar o crear volúmenes de FlexVol. Por ejemplo, con el Proveedor VASA 7,1 y versiones anteriores, si la compresión se deja en el valor predeterminado de SCP de No, intentará deshabilitar la compresión, incluso en un sistema AFF.</block>
  <block id="5a6d5fdddf6fbd82f1952b532b03c9ef" category="cell">*Utilice los SCPs predeterminados como plantillas de ejemplo para crear su propio.*</block>
  <block id="ee3cbda1c3c4a14ae024478c7ada6d11" category="cell">*Siga todas las mejores prácticas del protocolo.*</block>
  <block id="6a2c1ac1da51eca0c1a65afffab8dfab" category="inline-image-macro">Configuración de red mediante vVols mediante NFS v3.500</block>
  <block id="918febfed3d070cf1250909e5cdcf31d" category="paragraph">Este documento trata las funcionalidades de ONTAP para VMware vSphere Virtual Volumes (vVols), incluida la información más reciente sobre el producto y los casos de uso, junto con las prácticas recomendadas y otra información para optimizar la puesta en marcha y reducir los errores.</block>
  <block id="d30f04665be7a6d9663004b1b5e61a9a" category="paragraph">Las prácticas recomendadas complementan otros documentos, como guías y listas de compatibilidad. Se desarrollan según pruebas de laboratorio y una amplia experiencia de campo por parte de ingenieros y clientes de NetApp. Puede que no sean las únicas prácticas que funcionan o son compatibles, pero generalmente son las soluciones más simples que satisfacen las necesidades de la mayoría de los clientes.</block>
  <block id="b010d2e253827dbb44b7ba4e1332e24e" category="admonition">Este documento se ha actualizado para incluir las nuevas funciones de vVols que se encuentran en vSphere 8,0 update 1 que son compatibles con la versión ONTAP tools 9,12.</block>
  <block id="cc713c330b9c4e00d3ed7233bc54a889" category="section-title">Información general sobre Virtual Volumes (vVols)</block>
  <block id="64f0863a7fb5f52a7ac6a911e1ad6862" category="paragraph">NetApp comenzó trabajando con VMware para dar soporte a las API vSphere de Storage Awareness (VASA) para vSphere 5 en 2012. Este primer proveedor de VASA permitía definir las capacidades de almacenamiento en un perfil que podía utilizarse para filtrar almacenes de datos al aprovisionar y comprobar después el cumplimiento de la política. Con el tiempo, esta evolución evolucionó y se añadieron nuevas funcionalidades que permitían una mayor automatización en el aprovisionamiento, y nuevos volúmenes virtuales o vVols, donde se utilizan objetos de almacenamiento individuales para archivos de máquinas virtuales y discos virtuales. Estos objetos podrían ser LUN y archivos y ahora con vSphere 8. NVMe namespaces.NetApp trabajó estrechamente con VMware como partner de referencia de vVols lanzado con vSphere 6 en 2015 y de nuevo como partner de diseño de vVols utilizando NVMe over Fabrics en vSphere 8. NetApp sigue mejorando vVols para aprovechar las últimas funcionalidades de ONTAP.</block>
  <block id="cbf0aa9daeb855e4eace1a3bdc474ce2" category="paragraph">Hay varios componentes a tener en cuenta:</block>
  <block id="e2f6b83160ea0712fbc59dd84410c4b2" category="cell">*Proveedor VASA*</block>
  <block id="919601826e1d58bccaaab76d787871d2" category="cell">Este es el componente de software que gestiona la comunicación entre VMware vSphere y el sistema de almacenamiento. Para ONTAP, VASA Provider se ejecuta en un dispositivo conocido como herramientas de ONTAP para VMware vSphere (herramientas de ONTAP para abreviar). Las herramientas de ONTAP también incluyen un complemento para vCenter, un adaptador de replicación de almacenamiento (SRA) para el administrador de recuperación de sitio de VMware y un servidor API de REST para crear su propia automatización. Una vez que las herramientas de ONTAP se han configurado y registrado con vCenter, ya no es necesario interactuar directamente con el sistema ONTAP, ya que casi todas sus necesidades de almacenamiento pueden gestionarse desde la interfaz de usuario de vCenter o mediante la automatización de la API de REST.</block>
  <block id="05ad8543ff165c6b8cd0cc5e976d3245" category="cell">*Punto final del protocolo (PE)*</block>
  <block id="3b2cd9018385f55c53c9a8b756df8bb5" category="cell">El extremo de protocolo es un proxy para I/O entre los hosts ESXi y el almacén de datos vVols. El proveedor VASA de ONTAP crea estos automáticamente, ya sea un LUN de extremo de protocolo (4MB TB de tamaño) por volumen FlexVol del almacén de datos vVols, o un punto de montaje de NFS por interfaz NFS (LIF) en el nodo de almacenamiento que aloja un volumen FlexVol en el almacén de datos. El host ESXi monta estos extremos de protocolo de forma directa en lugar de LUN VVol individuales y archivos de disco virtual. No es necesario gestionar los extremos de protocolo, ya que el proveedor VASA los crea, monta, desmonta y elimina automáticamente, junto con los grupos de interfaces necesarios o las políticas de exportación.</block>
  <block id="d3f051e8316cfd36651af1e65be24a75" category="cell">*Punto final de protocolo virtual (VPE)*</block>
  <block id="71afca0aa1a505ea2ac3ce5a1a681549" category="paragraph">Como novedad en vSphere 8, cuando se usa NVMe over Fabrics (NVMe-oF) con vVols, el concepto de extremo de protocolo ya no es relevante en ONTAP. En su lugar, el host ESXi crea una instancia de PE virtual automáticamente para cada grupo ANA en cuanto se enciende la primera máquina virtual. ONTAP crea automáticamente grupos ANA para cada volumen de FlexVol que usa el almacén de datos.</block>
  <block id="8202498953d2ebcf9968c37a7e47f4f6" category="paragraph">Otra ventaja de usar NVMe-oF para vVols es que no hay solicitudes de enlace requeridas del proveedor VASA. En su lugar, el host ESXi gestiona la funcionalidad de vinculación de VVol internamente según VPE. Esto reduce la posibilidad de que un enlace masivo de VVOL afecte al servicio.</block>
  <block id="70532c0374111d897ef1176b34b6396c" category="inline-link">NVMe y Virtual Volumes</block>
  <block id="50ec55042a7f4e8c2c66219ac096cfb3" category="inline-link">vmware.com</block>
  <block id="113c9d4e642d1ba4cc469267fb7fd0de" category="paragraph">Para obtener más información, consulte<block ref="f8d477cd77073d731aafe4f52026608a" category="inline-link-rx"></block> encendido<block ref="1f1565cca975c4a703345d21e7f273b8" category="inline-link-rx"></block></block>
  <block id="61def0b14af00df4eb90bcd79d858a8b" category="cell">*Almacén de datos de volumen virtual*</block>
  <block id="b945cda41d7a84e7152e09343a17cbe6" category="cell">El almacén de datos del volumen virtual es una representación lógica del almacén de datos de un contenedor de vVols que crea y mantiene un proveedor de VASA. El contenedor representa un pool de capacidad de almacenamiento aprovisionado a partir de los sistemas de almacenamiento gestionados por el proveedor VASA. Las herramientas de ONTAP admiten la asignación de varios volúmenes de FlexVol (conocidos como volúmenes de backup) a un único almacén de datos vVols, y estos almacenes de datos de vVols pueden abarcar varios nodos de un clúster de ONTAP, que combina sistemas flash e híbridos con distintas funcionalidades. El administrador puede crear nuevos volúmenes de FlexVol con el asistente de aprovisionamiento o la API DE REST, o bien seleccionar volúmenes de FlexVol creados previamente para respaldar el almacenamiento si están disponibles.</block>
  <block id="c25d2cc7c6540f6ac98af67455eecc39" category="cell">*Volúmenes virtuales (vVols)*</block>
  <block id="9664cdf7951789389813facac649fec1" category="cell">VVols son los archivos y discos de máquina virtual reales almacenados en el almacén de datos vVols. El uso del término VVol (singular) está haciendo referencia a un archivo, LUN o espacio de nombres específico. ONTAP crea espacios de nombres, LUN o archivos de NVMe según el protocolo que utiliza el almacén de datos. Existen varios tipos distintos de vVols; los más comunes son Config (archivos de metadatos), Data (disco virtual o VMDK) e Swap (creado cuando el equipo virtual está encendido). Los vVols protegidos por el cifrado de VM de VMware serán de otro tipo. El cifrado de equipos virtuales de VMware no se debe confundir con el cifrado de volúmenes de ONTAP o agregados.</block>
  <block id="937251054fa0c1a7b946f8928cc857b9" category="section-title">Gestión basada en políticas</block>
  <block id="34d2b7d8b570ede7a638d070656b7b81" category="paragraph">Las API de VMware vSphere para Storage Awareness (VASA) facilitan que un administrador de VM utilice cualquier capacidad de almacenamiento necesaria para aprovisionar máquinas virtuales sin tener que interactuar con su equipo de almacenamiento. Antes de VASA, los administradores de máquinas virtuales podían definir políticas de almacenamiento de máquinas virtuales, pero debían trabajar con sus administradores de almacenamiento para identificar los almacenes de datos adecuados, a menudo mediante la documentación o las convenciones de nomenclatura. Con VASA, los administradores de vCenter con los permisos adecuados pueden definir una serie de funcionalidades de almacenamiento que los usuarios de vCenter pueden usar luego para aprovisionar máquinas virtuales. La asignación entre la política de almacenamiento de las máquinas virtuales y el perfil de funcionalidades de almacenamiento de almacenes de datos permite a vCenter mostrar una lista de almacenes de datos compatibles para su selección, además de permitir que otras tecnologías, como Aria (antes conocida como vRealize) Automation o Tanzu Kubernetes Grid, seleccionen automáticamente el almacenamiento de una política asignada. Este enfoque se conoce como gestión basada en políticas de almacenamiento. Si bien las políticas y perfiles de la capacidad de almacenamiento también se pueden utilizar con almacenes de datos tradicionales, nuestro enfoque se centra en los almacenes de datos vVols.</block>
  <block id="631bdc7de6608fd57c3fa0b397c3c26f" category="paragraph">Hay dos elementos:</block>
  <block id="a156a7f38a3727ce705b5466eb11e0bf" category="cell">*Perfil de capacidad de almacenamiento (SCP)*</block>
  <block id="43a258e66ca875fa9c5d3e35e06ba2b7" category="cell">Un perfil de funcionalidad de almacenamiento (SCP) es una forma de plantilla de almacenamiento que permite que el administrador de vCenter defina qué funciones de almacenamiento necesitan sin necesidad de comprender cómo gestionar esas funciones en ONTAP. Al adoptar el enfoque de estilo de plantilla, permite al administrador prestar servicios de almacenamiento de forma coherente y previsible. Las funcionalidades descritas en un SCP incluyen rendimiento, protocolo, eficiencia de almacenamiento y otras características. Las características específicas varían según la versión. Se crean mediante el menú de las herramientas de ONTAP para VMware vSphere dentro de la interfaz de usuario de vCenter. También puede utilizar las API REST para crear SCPs. Se pueden crear manualmente seleccionando funcionalidades individuales o se pueden generar automáticamente a partir de almacenes de datos existentes (tradicionales).</block>
  <block id="8f50a0757d99fe5dd0df8d19478d4921" category="cell">*VM Storage Policy*</block>
  <block id="f99c5cf9298b040025bd3dfe966cb86e" category="cell">Las políticas de almacenamiento de máquinas virtuales se crean en vCenter en Políticas y perfiles. Para vVols, cree un conjunto de reglas mediante reglas del proveedor de tipo de almacenamiento de NetApp vVols. Las herramientas de ONTAP proporcionan un enfoque simplificado al permitirle simplemente seleccionar un SCP en lugar de obligarlo a especificar reglas individuales.</block>
  <block id="5dda8b04866334dc92ee08001b15701a" category="paragraph">Tal como se ha mencionado anteriormente, el uso de políticas puede ayudar a simplificar la tarea de aprovisionar un volumen. Solo tiene que seleccionar una política adecuada y el proveedor VASA mostrará los almacenes de datos de vVols compatibles con esa política y colocará el VVOL en un volumen FlexVol individual conforme a la normativa (figura 1).</block>
  <block id="2ce0d6ec59cca7e0b6e0bdc389301e63" category="section-title">Puesta en marcha de equipos virtuales mediante políticas de almacenamiento</block>
  <block id="e0795f8b847058e171dec5a519757ece" category="image-alt">Ponga en marcha equipos virtuales mediante la normativa de almacenamiento</block>
  <block id="f0d0f0a6174a5a9dde27782042e22ccf" category="paragraph">Una vez que se aprovisiona una máquina virtual, el proveedor VASA seguirá comprobando el cumplimiento de normativas y alertará al administrador de máquinas virtuales con una alarma en vCenter cuando el volumen de respaldo ya no cumpla con la política (figura 2).</block>
  <block id="941431bc1cecb0ec5e89e78e9a5a96fc" category="section-title">Cumplimiento de políticas de almacenamiento de máquinas virtuales</block>
  <block id="bfd6dec22a6a1724ff1b67f1f289cdfc" category="image-alt">Cumplimiento de la política de almacenamiento de máquinas virtuales</block>
  <block id="e08bc5b354c3e8058003a662e0f7cade" category="section-title">Suppor de NetApp vVols</block>
  <block id="9fe1fd556b933358881222d5c3da127c" category="paragraph">En el momento de la publicación, los entornos de los proveedores a hiperescala se limitan solo a los almacenes de datos NFS v3 tradicionales, por lo tanto, los vVols solo están disponibles con sistemas ONTAP en las instalaciones o sistemas conectados al cloud que ofrecen la funcionalidad completa de sistemas en las instalaciones como los alojados por partners de NetApp y proveedores de servicios de todo el mundo.</block>
  <block id="274bc582ca884fc158ea9ac9f79f9067" category="inline-link">Documentación de productos de ONTAP</block>
  <block id="5ca60fe92dec435059ba5acefa4ce2c9" category="paragraph">_Para obtener más información sobre ONTAP, consulte<block ref="8a9b15dc18a16e0b1acfa438e27f6aa6" category="inline-link-rx"></block>_</block>
  <block id="3dffa984dadf9ff0006ee9cebd3b04b9" category="inline-link">CONSULTE TR-4597</block>
  <block id="d3fb76da5fbbcd6fa32e40910b5b9a47" category="section-title">Ventajas del uso de vVols con ONTAP</block>
  <block id="d0f004282063136e91d76d1d43d7c95f" category="paragraph">Cuando VMware introdujo la compatibilidad de vVols con VASA 2,0 en 2015, lo describió como «un marco de integración y gestión que ofrece un nuevo modelo operativo para almacenamiento externo (SAN/NAS)». Este modelo operativo ofrece varios beneficios junto con el almacenamiento de ONTAP.</block>
  <block id="6a74f7c0a9021e009a9c030e54084978" category="paragraph">Tal como se explica en la sección 1,2, la gestión basada en políticas permite aprovisionar máquinas virtuales y gestionarse posteriormente usando políticas predefinidas. Esto puede ayudar a las operaciones DE TI DE varias maneras:</block>
  <block id="e0eb51b6d319e14c2fbfc1f628021a26" category="list-text">* Aumentar velocidad.* Las herramientas ONTAP eliminan la necesidad de que el administrador de vCenter abra tickets con el equipo de almacenamiento para las actividades de aprovisionamiento de almacenamiento. Sin embargo, las funciones de RBAC de las herramientas de ONTAP en vCenter y en el sistema de ONTAP aún permiten equipos independientes (como equipos de almacenamiento) o actividades independientes del mismo equipo restringiendo el acceso a funciones específicas si se desea.</block>
  <block id="3f4dbd6687bd0d55bf69fe5fdd0137c4" category="list-text">* Provisionamiento más inteligente. * Las capacidades del sistema de almacenamiento se pueden exponer a través de las API de VASA, lo que permite que los flujos de trabajo de aprovisionamiento aprovechen las capacidades avanzadas sin que el administrador de VM tenga que entender cómo administrar el sistema de almacenamiento.</block>
  <block id="a13fcc9220d042cae454e9ac073636ca" category="list-text">* Provisionamiento más rápido.* Se pueden admitir diferentes capacidades de almacenamiento en un único almacén de datos y seleccionarlas automáticamente según sea apropiado para una VM basada en la política de VM.</block>
  <block id="eb4c052226108afebf26e670208b9a55" category="list-text">*Evite errores.* Las políticas de almacenamiento y VM se desarrollan con anticipación y se aplican según sea necesario sin tener que personalizar el almacenamiento cada vez que se aprovisiona una VM. Las alarmas de cumplimiento de normativas se generan cuando las funcionalidades de almacenamiento van más allá de las políticas definidas. Como se ha mencionado anteriormente, los SCPs hacen que el aprovisionamiento inicial sea predecible y repetible, mientras que basar las políticas de almacenamiento de los equipos virtuales en los SCPs garantiza una ubicación precisa.</block>
  <block id="9c520768a1d84268417335cf19a423b9" category="list-text">* Mejor gestión de la capacidad.* Las herramientas VASA y ONTAP permiten ver la capacidad de almacenamiento hasta el nivel agregado induvial si es necesario y proporcionar múltiples capas de alerta en el caso de que la capacidad comience a agotarse.</block>
  <block id="f9878e32fdf258284c007eaae38773cd" category="section-title">Gestión granular de máquinas virtuales en el SAN moderno</block>
  <block id="7e673a7c12cc256f29bcd7b2028d9d5a" category="paragraph">Los sistemas de ALMACENAMIENTO SAN que utilizan Fibre Channel e iSCSI fueron los primeros en admitir VMware para ESX, pero no han podido gestionar archivos y discos de máquina virtual individuales desde el sistema de almacenamiento. En su lugar, se aprovisionan los LUN y VMFS gestiona los archivos individuales. Esto hace que sea difícil para el sistema de almacenamiento gestionar directamente el rendimiento, clonación y protección del almacenamiento de equipos virtuales individuales. VVols ofrece la granularidad del almacenamiento de la que los clientes que utilizan almacenamiento NFS ya disfrutan con las funciones SAN sólidas y de alto rendimiento de ONTAP.</block>
  <block id="25a46370807e0eab0dfe3853abfb9b6e" category="paragraph">Ahora, con las herramientas vSphere 8 y ONTAP para VMware vSphere 9,12 y versiones posteriores, esos mismos controles granulares que utilizan vVols para los protocolos heredados basados en SCSI están ahora disponibles en la SAN Fibre Channel moderna que utiliza NVMe over Fabrics para obtener un rendimiento aún mayor a escala. Con la actualización 1 de vSphere 8,0, ahora es posible implementar una solución NVMe integral completa usando vVols sin ninguna traducción de I/O en la pila de almacenamiento del hipervisor.</block>
  <block id="f61f57f748f5f0b52c7f11f1f1bd43f0" category="section-title">Mayor capacidad de descarga de soluciones de almacenamiento</block>
  <block id="911fa02c34dda38cd69be06e524ed9d0" category="inline-link">Garantía de eficiencia</block>
  <block id="3170031d77f241bc872afcb490c0a806" category="paragraph">Si bien VAAI ofrece varias operaciones que se descargan en el almacenamiento, existen algunas lagunas que se solucionan por el proveedor VASA. VAAI de SAN no puede descargar las snapshots gestionadas de VMware en el sistema de almacenamiento. VAAI de NFS puede descargar las copias Snapshot gestionadas por máquinas virtuales, pero existen limitaciones para colocar una máquina virtual con copias Snapshot de almacenamiento nativas. Dado que los vVols utilizan LUN, espacios de nombres o archivos individuales para discos de máquinas virtuales, ONTAP puede clonar de forma rápida y eficiente los archivos o LUN para crear copias Snapshot granulares de máquina virtual que ya no requieren archivos delta. VAAI de NFS tampoco admite operaciones de descarga de copias para migraciones activas de Storage vMotion (activadas). La máquina virtual debe apagarse para permitir la descarga de la migración cuando utilice VAAI con almacenes de datos NFS tradicionales. El proveedor VASA en las herramientas de ONTAP permite clones casi instantáneos con un uso eficiente del almacenamiento para migraciones activas e inactivas, y también admite copias casi instantáneas para migraciones entre volúmenes de vVols. Gracias a estas importantes ventajas en términos de eficiencia del almacenamiento, puede que pueda aprovechar al máximo las cargas de trabajo vVols de la<block ref="9d1af7a9d4f98887e53c1a9bedbce044" category="inline-link-rx"></block> programa. De la misma manera, si los clones entre volúmenes que utilizan VAAI no cumplen sus requisitos, probablemente podrá solucionar su reto empresarial gracias a las mejoras en la experiencia de copia con vVols.</block>
  <block id="a8567b4dc683947384ef2e1dd0fc6ac1" category="section-title">Casos de uso comunes para vVols</block>
  <block id="48e535b80538b088fd868fde9372715c" category="paragraph">Además de estos beneficios, también se observan estos casos de uso comunes para el almacenamiento de VVOL:</block>
  <block id="441f01ec38e91fad1b235a0e7422a178" category="list-text">*Provisionamiento bajo demanda de VMs*</block>
  <block id="bd652a918164d8fa5176b5f9b92c2e61" category="list-text">Cloud privado o IaaS de proveedor de servicios.</block>
  <block id="fddccd9595370687015a5ab02bcff60f" category="list-text">Aproveche la automatización y la orquestación mediante la suite Aria (anteriormente vRealize), OpenStack, etc.</block>
  <block id="4fbc1141a40f5259e3ab1545de52b1ea" category="list-text">*Discos de primera clase (FCDs)*</block>
  <block id="e83f2e4e8676ee8faac4d6af599fd7e7" category="list-text">Volúmenes persistentes de VMware Tanzu Kubernetes Grid [TKG].</block>
  <block id="b2b81490f2245d3d566e0ccc6a29cfc2" category="list-text">Proporcione servicios similares a los de Amazon EBS mediante la gestión independiente del ciclo de vida de VMDK.</block>
  <block id="2511e4e8cbb72027ae20f24008d4b939" category="list-text">*Provisionamiento bajo demanda de VMs temporales*</block>
  <block id="eeb1044cc319a5d53503e45dbf762291" category="list-text">Laboratorios de prueba/desarrollo</block>
  <block id="858d314810762abccaa7baf230e3dc18" category="list-text">Entornos de formación</block>
  <block id="ab7bbc294bf0f0354980a3014e8f4219" category="section-title">Beneficios comunes con vVols</block>
  <block id="ccd6ea8c57e93a5401d07aab9c60f371" category="paragraph">Cuando se utiliza a su máximo beneficio, como en los casos de uso anteriores, vVols proporciona las siguientes mejoras específicas:</block>
  <block id="13491b3af50183642ea0035b2d1f95f9" category="list-text">Los clones se crean rápidamente en un solo volumen, o entre varios volúmenes de un clúster de ONTAP, lo cual es una ventaja en comparación con los clones tradicionales con VAAI habilitada. Además, hacen un almacenamiento eficiente. Los clones dentro de un volumen utilizan el clon de archivos de ONTAP, que es como volúmenes FlexClone y solo almacenan cambios del archivo VVol/LUN/espacio de nombres de origen. Con el fin de que los equipos virtuales a largo plazo para la producción u otras aplicaciones se creen con rapidez, ocupan un espacio mínimo y pueden beneficiarse de la protección a nivel de equipo virtual (con el complemento SnapCenter de NetApp para VMware vSphere, copias Snapshot gestionadas de VMware o backup VADP) y gestión del rendimiento (con la calidad de servicio de ONTAP).</block>
  <block id="1c21847cdc5616af138ba0c03aad7adb" category="list-text">Los vVols son la tecnología de almacenamiento ideal cuando se utiliza TKG con vSphere CSI, lo que proporciona capacidades y clases de almacenamiento discretas gestionadas por el administrador de vCenter.</block>
  <block id="d5f068caef73978a5483badd927a7e98" category="list-text">Los servicios similares a Amazon EBS se pueden entregar a través de FCDs porque un VMDK FCD, como su nombre indica, es un ciudadano de primera clase en vSphere y tiene un ciclo de vida que se puede administrar de forma independiente, independientemente de las VM a las que pueda estar conectado.</block>
  <block id="7e7040600922b2a78715f856613a3c08" category="doc">Protección de vVols</block>
  <block id="de92c927f248723e4668aec459709995" category="section-title">Alta disponibilidad del proveedor de VASA</block>
  <block id="f4d4cb8868f07cad16bd7de7e36c5201" category="paragraph">El proveedor VASA de NetApp se ejecuta como parte del dispositivo virtual junto con el complemento para vCenter y el servidor de la API de REST (anteriormente conocido como Virtual Storage Console [VSC]) y Storage Replication Adapter. Si el proveedor VASA no está disponible, se seguirán ejecutando las máquinas virtuales que utilizan vVols. Sin embargo, no se pueden crear nuevos almacenes de datos vVols y no se puede crear ni enlazar vVols mediante vSphere. Esto significa que las máquinas virtuales que usan vVols no se pueden encender ya que vCenter no podrá solicitar la creación del VVol de intercambio. Y las máquinas virtuales en ejecución no pueden usar vMotion para migrar a otro host porque vVols no puede vincularse al nuevo host.</block>
  <block id="3958bf41787d7fcc6a9f8dd9348c947f" category="paragraph">VASA Provider 7,1 y versiones posteriores admiten nuevas funcionalidades para garantizar que los servicios estén disponibles cuando se necesiten. Incluye nuevos procesos de vigilancia que supervisan el proveedor VASA y los servicios integrados de base de datos. Si detecta un fallo, actualiza los archivos de registro y, a continuación, reinicia los servicios automáticamente.</block>
  <block id="1acc458c695b0d3dfbf588309801fda2" category="paragraph">El administrador de vSphere debe configurar una mayor protección con las mismas funciones de disponibilidad utilizadas para proteger otras máquinas virtuales críticas para el negocio de fallos en software, hardware de host y red. No se requiere configuración adicional en el dispositivo virtual para utilizar estas funciones; simplemente configúrelas mediante enfoques de vSphere estándar. Han sido probados y cuentan con soporte de NetApp.</block>
  <block id="ff43afff832597ff45e5abeab2826ccf" category="inline-link">Documentación de las herramientas de ONTAP para VMware vSphere (Configurar alta disponibilidad para herramientas de ONTAP)</block>
  <block id="d516ca4c9c18446a82d9fc9ee85bd955" category="paragraph">VSphere High Availability se puede configurar fácilmente para reiniciar un equipo virtual en otro host del clúster de hosts en caso de fallo. La tolerancia a fallos de vSphere proporciona una mayor disponibilidad al crear un equipo virtual secundario que se replica continuamente y que puede asumir el control en cualquier punto. La información adicional sobre estas funciones está disponible en la<block ref="b6d78cbf1d5afb52929c529b32a350ad" category="inline-link-rx"></block>, Además de la documentación de VMware vSphere (busque vSphere Availability en ESXi y vCenter Server).</block>
  <block id="97ba24d475ff6fdc7743099992cc301f" category="paragraph">Las herramientas de ONTAP VASA Provider realiza automáticamente backups de la configuración de vVols en tiempo real en sistemas ONTAP gestionados donde la información de vVols se almacena en metadatos de volumen de FlexVol. En el caso de que el dispositivo de herramientas de ONTAP deje de estar disponible por cualquier motivo, puede implementar uno nuevo de forma fácil y rápida e importar la configuración. Consulte este artículo de la base de conocimientos para obtener más información sobre los pasos de recuperación del proveedor VASA:</block>
  <block id="6799b6ec743f9159edf3b43790210a11" category="inline-link">Cómo realizar una recuperación de desastres de un proveedor VASA: Guía de resolución</block>
  <block id="9462790a7557a7eb2fe9daad4b875817" category="paragraph"><block ref="9462790a7557a7eb2fe9daad4b875817" category="inline-link-rx"></block></block>
  <block id="029a7740ecd792264454f9dbe194e980" category="section-title">Replicación de vVols</block>
  <block id="c7b26217fd0c9041b6f779a0f669de5c" category="paragraph">Muchos clientes de ONTAP replican sus almacenes de datos tradicionales en sistemas de almacenamiento secundario mediante SnapMirror de NetApp y, a continuación, utilizan el sistema secundario para recuperar máquinas virtuales individuales o todo un sitio en caso de desastre. En la mayoría de los casos, los clientes utilizan una herramienta de software para gestionarlo, por ejemplo, un producto de software de backup como el complemento de NetApp SnapCenter para VMware vSphere o una solución de recuperación ante desastres como Site Recovery Manager de VMware (junto con el adaptador de replicación de almacenamiento en herramientas de ONTAP).</block>
  <block id="bc6303e4538280b1b01d45a5f7d20039" category="paragraph">Este requisito de una herramienta de software es aún más importante para gestionar la replicación vVols. A pesar de que algunos aspectos pueden gestionarse mediante funcionalidades nativas (por ejemplo, las copias Snapshot de vVols gestionadas por VMware se descargan a ONTAP, que utiliza clones de archivos o LUN rápidos y eficientes), se necesita una orquestación general para gestionar la replicación y la recuperación. Los metadatos acerca de vVols están protegidos tanto por ONTAP como por el proveedor VASA, pero es necesario procesar más para usarlos en un sitio secundario.</block>
  <block id="c6a26835eb364bad22b16cb127b74135" category="paragraph">Las herramientas de ONTAP 9.7.1, junto con la versión VMware Site Recovery Manager (SRM) 8,3, añadieron compatibilidad para la recuperación ante desastres y la orquestación del flujo de trabajo de migración aprovechando la tecnología SnapMirror de NetApp.</block>
  <block id="2803a799fd66056eff404a17ba640c2b" category="paragraph">En la versión inicial de la compatibilidad de SRM con ONTAP Tools 9.7.1, era necesario crear previamente FlexVols y habilitar la protección de SnapMirror antes de usarlos como backup de volúmenes para un almacén de datos vVols. A partir de ONTAP TOOLS 9,10, ese proceso ya no es necesario. Ahora puede añadir protección de SnapMirror a los volúmenes de respaldo existentes y actualizar sus políticas de almacenamiento de máquinas virtuales para aprovechar la gestión basada en políticas con recuperación ante desastres y orquestación de migración, y automatización integrada con SRM.</block>
  <block id="8142fcf496d02a58ce02a17558db863e" category="paragraph">Actualmente, VMware SRM es la única solución de recuperación ante desastres y automatización de la migración para vVols compatible con NetApp, y las herramientas de ONTAP comprobarán la existencia de un servidor SRM 8,3 o posterior registrado en su vCenter antes de permitir habilitar la replicación de vVols. Aunque es posible aprovechar las API de REST DE herramientas de ONTAP para crear sus propios servicios.</block>
  <block id="7d8e8eced8d8b1a50f20640ffb5d363a" category="section-title">Replicación de vVols con SRM</block>
  <block id="c95aede1de7a41511c9d962deba49054" category="section-title">Soporte de MetroCluster</block>
  <block id="3f15bb720adb42bd521a2ce1cb3a2974" category="paragraph">Aunque las herramientas de ONTAP no pueden activar una conmutación por error de MetroCluster, sí son compatibles con los sistemas MetroCluster de NetApp para vVols que realizan el backup de volúmenes en una configuración uniforme de vSphere Metro Storage Cluster (VMSC). La conmutación de un sistema MetroCluster se efectúa de la forma normal.</block>
  <block id="cde16c5ee89c209c821e120caf65bb81" category="paragraph">Aunque SnapMirror Business Continuity (SM-BC) de NetApp también puede utilizarse como base para una configuración VMSC, actualmente no es compatible con vVols.</block>
  <block id="c859f5cd725cb2d1b163e4b066bede9a" category="paragraph">Consulte estas guías para obtener más información sobre MetroCluster de NetApp:</block>
  <block id="e5e0fb3ae5564674a6548ade7c601578" category="inline-link">_TR-4689 Arquitectura y diseño de la solución MetroCluster IP_</block>
  <block id="e64de4e49a37e62ff7f8c37e859bbeb9" category="paragraph"><block ref="e64de4e49a37e62ff7f8c37e859bbeb9" category="inline-link-rx"></block></block>
  <block id="0229efec9dc9b9a7fdf144b025157176" category="inline-link">_TR-4705 Arquitectura y diseño de la solución MetroCluster de NetApp_</block>
  <block id="6aee4b78ffdfaf193918978472d660a7" category="paragraph"><block ref="6aee4b78ffdfaf193918978472d660a7" category="inline-link-rx"></block></block>
  <block id="876341bac548f230eb390348e8b075ad" category="inline-link">_VMware KB 2031038 Soporte de VMware vSphere con NetApp MetroCluster_</block>
  <block id="5e68486fffeebad2ed145408dc250367" category="paragraph"><block ref="5e68486fffeebad2ed145408dc250367" category="inline-link-rx"></block></block>
  <block id="50c323f7050912164118ba47eab75888" category="section-title">Descripción general de vVols Backup</block>
  <block id="6751e706567f4773c4f3138b4de51a0f" category="paragraph">Existen varios enfoques para proteger las máquinas virtuales, como el uso de agentes de backup internos, la asociación de archivos de datos de máquinas virtuales a un proxy de backup o el uso de API definidas como VMware VADP. Es posible que vVols esté protegido usando los mismos mecanismos, y muchos partners de NetApp admiten backups de VM, incluidos vVols.</block>
  <block id="416d27c872769e934ac8a49ec98ccb53" category="paragraph">Como se ha mencionado anteriormente, las snapshots gestionadas por VMware vCenter se descargan en clones rápidos de archivos o LUN de ONTAP con gestión eficiente del espacio. Se pueden utilizar para realizar backups manuales rápidos, pero el vCenter limita a un máximo de 32 copias Snapshot. Puede utilizar vCenter para tomar Snapshot y revertir según sea necesario.</block>
  <block id="8f3d5ae5bd7d8922841975ccd84b8526" category="paragraph">Comenzando con el complemento SnapCenter para VMware vSphere (SCV) 4,6 cuando se usa junto con ONTAP Tools 9,10 y versiones posteriores añade soporte para el backup y la recuperación consistentes con los fallos de máquinas virtuales basadas en vVols aprovechando snapshots de volúmenes de ONTAP FlexVol con compatibilidad con replicación de SnapMirror y SnapVault. Se admiten hasta 1023 copias Snapshot por volumen. SCV también puede almacenar más copias Snapshot con una retención más prolongada en volúmenes secundarios mediante SnapMirror con una política de reflejo de almacén.</block>
  <block id="1429a9379faa8e82f8b198e93eebdf61" category="paragraph">Se introdujo la compatibilidad con vSphere 8,0 con SCV 4,7, que utilizó una arquitectura de complemento local aislada. Se agregó compatibilidad con vSphere 8.0U1 a SCV 4,8, que realizó la transición completa a la nueva arquitectura de complementos remotos.</block>
  <block id="de1d77d00dae616276b6ceb6296a18f2" category="section-title">VVols Backup con el complemento de SnapCenter para VMware vSphere</block>
  <block id="02f41838319aab980999b60967d7fd53" category="paragraph">Con NetApp SnapCenter, ahora puede crear grupos de recursos para vVols basados en etiquetas y/o carpetas para aprovechar automáticamente las snapshots basadas en FlexVol de ONTAP para máquinas virtuales basadas en vVols. De este modo, podrá definir servicios de backup y recuperación de datos que protegerán automáticamente las máquinas virtuales cuando se aprovisionen dinámicamente en su entorno.</block>
  <block id="4549a2943666c4815098331d30a872da" category="paragraph">El complemento de SnapCenter para VMware vSphere se pone en marcha como dispositivo independiente registrado como extensión de vCenter, gestionado a través de la interfaz de usuario de vCenter o a través de API de REST para la automatización de servicios de backup y recuperación de datos.</block>
  <block id="26e2418d177df1dddb008e455ce28752" category="section-title">Arquitectura SnapCenter</block>
  <block id="c32197281aa44f57ae568a9a42c7b3b6" category="paragraph">Como los otros complementos de SnapCenter aún no admiten vVols en el momento de escribir este documento, nos centraremos en el modelo de implementación independiente de este documento.</block>
  <block id="6750052f2c0fb06d80a8efd7cb871190" category="paragraph">Como SnapCenter utiliza copias Snapshot de ONTAP FlexVol, no se genera ninguna sobrecarga en vSphere ni el rendimiento se ve afectado por las máquinas virtuales tradicionales utilizando copias Snapshot gestionadas de vCenter. Además, dado que la funcionalidad de SCV se expone a través de las API DE REST, es más fácil crear flujos de trabajo automatizados mediante herramientas como Aria Automation de VMware, Ansible, Terraform y prácticamente cualquier otra herramienta de automatización capaz de usar API DE REST estándar.</block>
  <block id="0c889d77d71512ceb7241bd0f6d6ca23" category="inline-link">Información general de las API de REST</block>
  <block id="35eab4195b135718da016e20979f9031" category="paragraph">Para obtener más información sobre las API de REST de SnapCenter, consulte<block ref="33852d6f529e96c0b816da3945bcb1e5" category="inline-link-rx"></block></block>
  <block id="4ee2d383554981f4ea8eff4f35db6832" category="inline-link">API de REST del plugin de SnapCenter para VMware vSphere</block>
  <block id="63ae61e98eec102c39264a819a3c522e" category="paragraph">Para obtener información sobre las API de REST del plugin de SnapCenter para VMware vSphere, consulte<block ref="40a6c7462de67e21480b7a31e406f8f9" category="inline-link-rx"></block></block>
  <block id="bdf03d5c2a7086b6c916dc96d06a0a6c" category="paragraph">Las siguientes mejores prácticas pueden ayudarle a sacar el máximo partido de la puesta en marcha de SnapCenter.</block>
  <block id="60af6a4208b610da54a63a7e3658d5a5" category="list-text">SCV es compatible con el control de acceso basado en roles de vCenter Server y de ONTAP, e incluye roles predefinidos de vCenter que se crean automáticamente para usted cuando se registra el plugin. Es posible obtener más información sobre los tipos de RBAC admitidos<block ref="a8ef9d6a500bd8288101245a3828ddb1" category="inline-link-rx"></block></block>
  <block id="0ed0835259b5b8c4b0f0910e7bfe2b17" category="list-text">Use la interfaz de usuario de vCenter para asignar acceso a cuentas con menos privilegios mediante los roles predefinidos descritos<block ref="17b3487f3493b9c198e03f92348bfca0" category="inline-link-rx"></block>.</block>
  <block id="d53326766687d6bc7fa2e28ee177e809" category="list-text">Si utiliza SCV con SnapCenter Server, debe asignar el rol _SnapCenterAdmin_.</block>
  <block id="61ba6cb0b6021c205d41ed7f6fc1eb71" category="list-text">El control de acceso basado en roles de ONTAP hace referencia a la cuenta de usuario que se utiliza para añadir y gestionar los sistemas de almacenamiento que utiliza SCV. El control de acceso basado en roles de ONTAP no se aplica a los backups basados en vVols. Obtenga más información sobre el control de acceso basado en roles de ONTAP y SCV<block ref="e4e865178d3962f87ac5cef3d6d68942" category="inline-link-rx"></block>.</block>
  <block id="1c89ba258526186ea0ec98325b61371b" category="list-text">Replique sus conjuntos de datos de backups en un segundo sistema mediante SnapMirror para obtener réplicas completas de volúmenes de origen. Como ya se ha mencionado anteriormente, también puede utilizar políticas de mirror-vault para la retención a largo plazo de los datos de backup con independencia de la configuración de retención de copias Snapshot del volumen de origen. Ambos mecanismos son compatibles con vVols.</block>
  <block id="9792eeb3b91469abf77746b005d82d77" category="list-text">Dado que SCV también requiere las herramientas de ONTAP para la funcionalidad de VMware vSphere para vVols, compruebe siempre la compatibilidad de versiones específica de la Herramienta de Matriz de Interoperabilidad (IMT) de NetApp</block>
  <block id="71c989bd68059e2ddfa4200c60b736c7" category="list-text">Si usa la replicación de vVols con VMware SRM, tenga en cuenta el objetivo de punto de recuperación y la programación de backups de su política</block>
  <block id="604eb779cbb9af378f7bda71633b5b31" category="list-text">Diseñe sus políticas de backup con ajustes de retención que cumplan los objetivos de punto de recuperación (RPO) definidos de su organización</block>
  <block id="067ff91a08d3ff453b59d81993b96182" category="list-text">Configure los ajustes de notificación en los grupos de recursos para que se notifique el estado cuando se ejecuten los backups (consulte la figura 10 a continuación).</block>
  <block id="c3add00693172bbbb4dd864bf0ad9116" category="section-title">Opciones de notificación para el grupo de recursos</block>
  <block id="6eae9510711f8df8f55a15e1761875d9" category="section-title">Comience a usar SCV usando estos documentos</block>
  <block id="235a656535515ab3518937c09836e60d" category="inline-link">Obtenga información sobre el plugin de SnapCenter para VMware vSphere</block>
  <block id="79eb02d2a96cc634df87bec5bd511bbe" category="paragraph"><block ref="79eb02d2a96cc634df87bec5bd511bbe" category="inline-link-rx"></block></block>
  <block id="04e7bb0411c1c8f56ca4fc8000c62ad8" category="inline-link">Ponga en marcha el plugin de SnapCenter para VMware vSphere</block>
  <block id="d4ba0aa084ae1145248006481c881d29" category="paragraph"><block ref="d4ba0aa084ae1145248006481c881d29" category="inline-link-rx"></block></block>
  <block id="231cf4c70d866b616c21baddaeed0696" category="doc">Resolución de problemas</block>
  <block id="9d2169c1c2855b78a7aeaa4f42d27dc7" category="section-title">Sitio de soporte de NetApp</block>
  <block id="ed9018b2e8611a3d2c03bb6a205b9715" category="inline-link">Herramientas de ONTAP para VMware vSphere</block>
  <block id="890eb741924c425abbb11e4618560181" category="paragraph">Además de una gran variedad de artículos de la base de conocimientos para los productos de virtualización de NetApp, el sitio de soporte de NetApp también ofrece una página de inicio práctica para el<block ref="6e90053136fd326e5d581844ca21966d" category="inline-link-rx"></block> producto. Este portal proporciona enlaces a artículos, descargas, informes técnicos y debates sobre soluciones de VMware sobre la comunidad de NetApp. Está disponible en:</block>
  <block id="fff460b039580a1bd42725a397b4c8be" category="inline-link">_Sitio de soporte de NetApp_</block>
  <block id="897515b5a8a03f8d5cbed44fd47ef9f3" category="paragraph"><block ref="897515b5a8a03f8d5cbed44fd47ef9f3" category="inline-link-rx"></block></block>
  <block id="4020fd07f5ee2361dd23956e6a334ffd" category="paragraph">Aquí se encuentra disponible documentación adicional sobre la solución:</block>
  <block id="503a41e1e31e362793f7e86af9102c41" category="inline-link">_Soluciones de NetApp para la virtualización_</block>
  <block id="33d455bce1363bad4500664eb6208860" category="paragraph"><block ref="33d455bce1363bad4500664eb6208860" category="inline-link-rx"></block></block>
  <block id="baf17f6d2396be5fd3676baf863a331f" category="section-title">Solución de problemas del producto</block>
  <block id="9d6d7fa1a5253698556ac2b0cda2207d" category="paragraph">Los distintos componentes de las herramientas de ONTAP, como el complemento vCenter, el proveedor VASA y el adaptador de replicación de almacenamiento, se documentan juntos en el repositorio de documentos de NetApp. Sin embargo, cada uno tiene una subsección independiente de la base de conocimientos y puede tener procedimientos específicos de solución de problemas. Estos solucionan los problemas más comunes que se pueden encontrar con el proveedor VASA.</block>
  <block id="ae2a93a809929192ecc7b468f234af84" category="section-title">Problemas de interfaz de usuario del proveedor de VASA</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">artículo</block>
  <block id="69aecee18a55993c779487758eb051cc" category="paragraph">Ocasionalmente, vCenter vSphere Web Client encuentra problemas con los componentes de Serenity, lo que hace que no se muestren los elementos de menú VASA Provider for ONTAP. Consulte Resolver problemas de registro del proveedor VASA en la guía de puesta en marcha o esta base de conocimientos<block ref="c8979f1604396ce5570d07774ba255f0" category="inline-link-rx"></block>.</block>
  <block id="03cc611b90575ea37b55959adaa1c754" category="section-title">Error de aprovisionamiento del almacén de datos de vVols</block>
  <block id="281b890be0e8280eea1aebb82de90961" category="paragraph">En ocasiones, es posible que se agote el tiempo de espera de los servicios de vCenter al crear el almacén de datos vVols. Para corregirlo, reinicie el servicio vmware-sps y vuelva a montar el almacén de datos vVols mediante los menús de vCenter (Storage &gt; New Datastore). Esto se trata en el error del aprovisionamiento de almacenes de datos de vVols con vCenter Server 6,5 en la guía de administración.</block>
  <block id="3152add163cd8aaf116a259d85ebf8fb" category="section-title">La actualización de Unified Appliance no puede montar ISO</block>
  <block id="ffaa56a3f5a1157f2eb3955773bb41da" category="paragraph">Debido a un error en vCenter, es posible que el ISO utilizado para actualizar Unified Appliance de una versión a la siguiente no se pueda montar. Si la ISO se puede conectar al dispositivo en vCenter, siga el proceso en esta base de conocimientos<block ref="9839383ed04f777c0132b57ad0cb14ac" category="inline-link-rx"></block> para solucionar.</block>
  <block id="cacba1b456347ce8f32c7f5ed0d81e64" category="doc">Despliegue de vVols Storage</block>
  <block id="2a5f3dc8d46246216b293c9e41979269" category="paragraph">Puede que los dos primeros pasos no sean necesarios para un entorno vSphere existente que utilice ONTAP para almacenes de datos tradicionales. Es posible que ya utilice las herramientas de ONTAP para gestionar, automatizar y generar informes con su VMFS o almacenamiento basado en NFS tradicional. Estos pasos se tratan con más detalle en la siguiente sección.</block>
  <block id="841db3655338a0c3dc36cf2761bfdafd" category="list-text">Cree la Storage Virtual Machine (SVM) y su configuración de protocolos. Seleccionará NVMe/FC, NFSv3, NFSv4,1, iSCSI, FCP, o una mezcla de esas opciones. Puede usar los asistentes de ONTAP System Manager o la línea de comandos de shell de clúster.</block>
  <block id="10818a8ad4f650a48d78d728278d4cb3" category="list-text">Al menos un LIF por nodo para cada conexión de switch/estructura. Como práctica recomendada, cree dos o más por nodo para los protocolos basados en FCP, iSCSI o NVMe.</block>
  <block id="612705dd95888cdc6345d01c93c84c39" category="list-text">En este momento, se pueden crear los volúmenes, pero es más sencillo dejar que el asistente _Provision Datastore_ los cree. La única excepción a esta regla es si planea utilizar la replicación de vVols con VMware Site Recovery Manager. Esta configuración es más fácil con volúmenes FlexVol preexistentes con relaciones de SnapMirror existentes. Tenga en cuenta que no habilita la calidad de servicio en ningún volumen para que lo usen vVols, ya que esta se pretende que la gestionen las herramientas de SPBM y ONTAP.</block>
  <block id="16421df834af873175559b678c2b3cd9" category="list-text">Ponga en marcha herramientas de ONTAP para VMware vSphere mediante el OVA descargado del sitio de soporte de NetApp.</block>
  <block id="8bdb69b5934ff84bbaafd84585965a90" category="list-text">Configure las herramientas de ONTAP para su entorno.</block>
  <block id="dd07accb290c9c1e3900692630a70767" category="list-text">Añada el clúster ONTAP a las herramientas ONTAP en _Storage Systems_</block>
  <block id="869ce78032d85111f09ceb58bdb59a36" category="list-text">Si sus LIF de datos de ONTAP se encuentran en subredes diferentes a los de sus adaptadores de VMkernel, debe añadir las subredes del adaptador de VMkernel a la lista de subredes seleccionadas en el menú de configuración de herramientas de ONTAP. De forma predeterminada, las herramientas de ONTAP protegen el tráfico de almacenamiento al permitir solo el acceso a la subred local.</block>
  <block id="5a6d084090f063797fc6b863d2817d98" category="list-text">Las herramientas de ONTAP incluyen varias normativas predefinidas que pueden utilizarse o verse <block ref="434866eb159632a70c4db034544336ef" category="inline-xref-macro-rx"></block> Para obtener orientación sobre la creación de SCPs.</block>
  <block id="ef51190e4c839596248fc4173ed12a3c" category="list-text">Utilice el menú _ONTAP TOOLS_ de vCenter para iniciar el asistente _Provision datastore_.</block>
  <block id="66edaf6f622057aeadab950977c1f3e8" category="list-text">Proporcione un nombre significativo y seleccione el protocolo deseado. También puede proporcionar una descripción del almacén de datos.</block>
  <block id="d22d6de0c8f11375907a1c10d8d0f251" category="list-text">Seleccione uno o varios SCP que sea compatible con el almacén de datos vVols. Esto filtrará cualquier sistema ONTAP que no pueda coincidir con el perfil. En la lista que aparece, seleccione el clúster y la SVM que desee.</block>
  <block id="6a016a18a0c20e3b805cd9b8e713fb3e" category="list-text">Utilice el asistente para crear nuevos volúmenes FlexVol para cada uno de los SP especificados o utilice los volúmenes existentes seleccionando el botón de opción apropiado.</block>
  <block id="2527effe721902a77755b8d628fdad93" category="list-text">Cree políticas de VM para cada SCP que se utilizará en el almacén de datos desde el menú _Policies and Profiles_ de la interfaz de usuario de vCenter.</block>
  <block id="642dadaf5095b4c11730dca0ffcb0d27" category="list-text">Seleccione el conjunto de reglas de almacenamiento «NetApp.clustered.Data.ONTAP.VP.vvol». El conjunto de reglas de almacenamiento «NetApp.clustered.Data.ONTAP.VP.VASA10» es para la compatibilidad de SPBM con almacenes de datos que no sean vVols</block>
  <block id="c9565e0957e6e02cf12aef618bd30c3f" category="list-text">Especificará el perfil de capacidad de almacenamiento por nombre al crear una política de almacenamiento de VM. Durante este paso, también puede configurar la coincidencia de políticas de SnapMirror mediante la pestaña REPLICATION, así como la coincidencia basada en etiquetas mediante la ficha TAGS. Tenga en cuenta que las etiquetas ya deben crearse para poder seleccionarlas.</block>
  <block id="af70f7acdeed8e2a702372f9bc85d960" category="list-text">Cree las máquinas virtuales, seleccione la política de almacenamiento de las máquinas virtuales y el almacén de datos compatible en Select storage.</block>
  <block id="3db9849d9f30bfc6e05c4e0b36d28848" category="section-title">Migración de máquinas virtuales desde almacenes de datos tradicionales a vVols</block>
  <block id="7be42b7840cc093ce6d05a247df8e63d" category="paragraph">La migración de máquinas virtuales de almacenes de datos tradicionales a un almacén de datos vVols es tan sencilla como mover máquinas virtuales entre almacenes de datos tradicionales. Solo tiene que seleccionar las máquinas virtuales y, a continuación, seleccionar Migrate en la lista Actions y seleccionar un tipo de migración _change storage only_. Las operaciones de copia de migración se descargarán con vSphere 6,0 y versiones posteriores para las migraciones de SAN VMFS a vVols, pero no de VMDK de NAS a vVols.</block>
  <block id="58f2a764a13ec89d3c5ead5343e75637" category="section-title">Gestionar máquinas virtuales con políticas</block>
  <block id="4b746813f1085683be4f71c8affea233" category="paragraph">Para automatizar el aprovisionamiento de almacenamiento con gestión basada en políticas, necesitamos:</block>
  <block id="10b68fb9cbee818a044f91644423640c" category="list-text">Defina las capacidades del almacenamiento (nodo de ONTAP y volumen de FlexVol) con perfiles de capacidad de almacenamiento (SCP).</block>
  <block id="2e415dc7a6f21b4fd03f963858c9f680" category="list-text">Crear políticas de almacenamiento de equipos virtuales que se asignen a los SCPs definidos.</block>
  <block id="67c819108c4ef294ac28a51197046dfc" category="paragraph">NetApp ha simplificado las funcionalidades y la asignación desde VASA Provider 7,2, con mejoras continuas en las versiones posteriores. Esta sección se centra en este nuevo enfoque. En versiones anteriores se admitía un mayor número de funcionalidades y se podían asignar individualmente a normativas de almacenamiento, pero este método ya no es compatible.</block>
  <block id="0bd86c4955ab0bdce52b49644ce9396d" category="section-title">Funcionalidades de perfil de funcionalidades del almacenamiento publicadas por las herramientas de ONTAP</block>
  <block id="4a6af8a6e216dcc53a63f04143c13222" category="cell">*Capacidad SCP*</block>
  <block id="048424cc97a54b673c837ee7d4c19de0" category="cell">*Valores de capacidad*</block>
  <block id="098e77f7c5d9e0c2ad5454817edf0767" category="cell">*Lanzamiento soportado*</block>
  <block id="28f44037af103f0c930309365629f8ef" category="cell">*Notas*</block>
  <block id="d031377688b064b729a0cc60fb7fbbff" category="cell">*Compresión*</block>
  <block id="cc6aee5037bdc5b051433a266ec7d4a3" category="cell">Sí, No, Cualquiera</block>
  <block id="7778bddb1c205e9f74d08bd30be0aca3" category="cell">Obligatorio para AFF en 7,2 y posteriores.</block>
  <block id="221baf8ad30299306e725e4fb395bf34" category="cell">*Deduplicación*</block>
  <block id="6868f879256c802b106616a006671848" category="cell">M andatorio de AFF en 7,2 y versiones posteriores.</block>
  <block id="504897d4a6b59afadffd3cf9e5d3ea85" category="cell">*Cifrado*</block>
  <block id="95fddd53c531d6efe15e3ac7ace1d9eb" category="cell">7,2 y posterior</block>
  <block id="b3870ec121aeafa2e7ca8cb3894c0e3a" category="cell">Selecciona/crea un volumen FlexVol cifrado. Se requiere una licencia de ONTAP.</block>
  <block id="e2dcc78cf70dac34550234c95443ac37" category="cell">*Max IOPS*</block>
  <block id="b78a981cc40fc4e66208bf5ee6d1a1eb" category="cell">&lt;number&gt;</block>
  <block id="130b32bc15d3fbe6d2e80ecda94135cc" category="cell">7,1 y más tarde, pero diferencias</block>
  <block id="c0f84018aff4ff4a1cf4012a8b82e509" category="cell">Aparece en QoS Policy Group para 7,2 y versiones posteriores. Consulte <block ref="8fdd8868d80d04eecf1b4189862f536c" category="inline-xref-macro-rx"></block> si quiere más información.</block>
  <block id="993c56850c1da5de36e798b0c5a72513" category="cell">*Personalidad*</block>
  <block id="8485fa08bf8c556b7b2275349d11eb05" category="cell">A FF, FAS</block>
  <block id="c0acd03e8ba6b951b8c6dff3e95b9560" category="cell">FAS también incluye otros sistemas que no son AFF, como ONTAP Select. AFF incluye a ASA.</block>
  <block id="dce365633ffb688b7532470dfaf4e118" category="cell">*Protocolo*</block>
  <block id="7cff0b96b4a6467ea880f49dd365a81f" category="cell">NFS, NFS 4,1, iSCSI, FCP, NVMe/FC, Cualquiera</block>
  <block id="be18de5e88c84ba55eeb5bc42cca4c0d" category="cell">7,1 y anteriores, 9,10 y posteriores</block>
  <block id="cfca0bc0c0b481555ba52be1f4e21da6" category="cell">7,2-9,8 es efectivamente “cualquiera”. A partir de 9,10, donde se añadieron 4,1 y NVMe/FC a la lista original.</block>
  <block id="3dd301ae5682df79e8687ead5b6a3ddf" category="cell">*Reserva de espacio (Thin Provisioning)*</block>
  <block id="03868a080fbf4cdbc006da45e13cfad7" category="cell">Fino, grueso, (cualquiera)</block>
  <block id="0a74dc1caf6ce891d5cbd3878cae2221" category="cell">Todo, pero diferencias</block>
  <block id="4b370bcc260aa96e343bbb24d3af2cc5" category="cell">Se llamaba Thin Provisioning en la versión 7,1 y versiones anteriores, lo que también permitía el valor de cualquier. Llamado Reserva Espacial en 7,2. Todas las versiones se establecen de forma predeterminada en Delgado.</block>
  <block id="40e2e283d064264dd51846580adb367d" category="cell">*Política de organización en niveles*</block>
  <block id="06b815f81a7e7aceb1489e3888fb9534" category="cell">Cualquiera, Ninguna, Instantánea, Automático</block>
  <block id="00917abc35f0d57db6562a886997c4e8" category="cell">Utilizado para FabricPool: Se requiere AFF o ASA con ONTAP 9,4 o posterior. Solo se recomienda Snapshot a menos que se utilice una solución S3 en sus instalaciones como StorageGRID de NetApp.</block>
  <block id="ffb0d092d584c15937dfacd5be3c684a" category="section-title">Crear perfiles de capacidad de almacenamiento</block>
  <block id="ad0b6bb809400347fc4806f18385015c" category="paragraph">El proveedor de VASA de NetApp se incluye con varios SCPs predefinidos. Es posible crear nuevos SCP manualmente mediante la interfaz de usuario de vCenter o a través de automatización mediante las API de REST. Especificando capacidades en un nuevo perfil, clonando un perfil existente o generando perfiles automáticamente a partir de almacenes de datos tradicionales existentes. Esto se realiza utilizando los menús de las herramientas de ONTAP. Utilice _Storage Capability Profiles_ para crear o clonar un perfil y _Storage Mapping_ para generar automáticamente un perfil.</block>
  <block id="62351556db3b0f6f13da226ca3e2df24" category="section-title">Funcionalidades de almacenamiento para las herramientas de ONTAP 9,10 y posteriores</block>
  <block id="14b49e2a6b56b1177a77be03a29dfc83" category="inline-image-macro">«Funciones de almacenamiento de las herramientas de ONTAP 9,10 y posteriores»,300</block>
  <block id="2a53cbcd07a15d9f13f0cc630c7cc44d" category="paragraph"><block ref="2a53cbcd07a15d9f13f0cc630c7cc44d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12bb128f53dfaac0a251798e4b4e6954" category="paragraph"><block ref="12bb128f53dfaac0a251798e4b4e6954" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e6d46028a015a7f3860fc8fdf214b3c" category="paragraph"><block ref="4e6d46028a015a7f3860fc8fdf214b3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64ca5ade59a3a7351134cf0db3a8e06a" category="paragraph"><block ref="64ca5ade59a3a7351134cf0db3a8e06a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c8f597441425c22b4ae09f872f8bcc4" category="paragraph"><block ref="2c8f597441425c22b4ae09f872f8bcc4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd59d4e26c472ef1e14cadb688283604" category="paragraph"><block ref="fd59d4e26c472ef1e14cadb688283604" category="inline-image-macro-rx" type="image"></block></block>
  <block id="049b6d7b78dd8ffebadb5a0be2261637" category="paragraph">*Creando vVols datastores*
Una vez creados los SCPs necesarios, pueden utilizarse para crear el almacén de datos vVols (y, opcionalmente, volúmenes FlexVol para el almacén de datos). Haga clic con el botón derecho en el host, clúster o centro de datos en el que desea crear el almacén de datos vVols y, a continuación, seleccione _ONTAP tools_ &gt; _Provision Datastore_. Seleccione uno o varios FlexVol para que el almacén de datos sea compatible y, a continuación, seleccione de los volúmenes de FlexVol existentes o aprovisione los volúmenes de nuevos para el almacén de datos. Por último, especifique el SCP predeterminado para el almacén de datos, que se utilizará para las VM que no tienen un SCP especificado por política, así como para vVols de intercambio (estos no requieren almacenamiento de alto rendimiento).</block>
  <block id="a4332a81dbc3a9888be608dea640cd3d" category="section-title">Creación de políticas de almacenamiento de equipos virtuales</block>
  <block id="b4f6f65777757af7630fae901718e51e" category="paragraph">Las versiones anteriores son similares, pero como se menciona en <block ref="68072d20e775e4558feadbec7ba8f768" category="inline-xref-macro-rx"></block>, sus opciones variarán.</block>
  <block id="52896487a6472798e1d6cbc9a95ec51e" category="section-title">Creación de políticas de almacenamiento de máquinas virtuales con herramientas de ONTAP VASA Provider 9,10</block>
  <block id="c0c5e719ad5439106e5a00588402f206" category="inline-image-macro">«VM Storage Policy Creation with ONTAP tools VASA Provider 9,10»,300</block>
  <block id="378e30f2a60dc28c4afc9ae4f11a39e1" category="paragraph"><block ref="378e30f2a60dc28c4afc9ae4f11a39e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95ac22478e141fde0d2878c71530a13a" category="section-title">Gestión del rendimiento con las herramientas de ONTAP 9,10 y posteriores</block>
  <block id="c153012a9aa13e8ed8ce3f3e471a70b4" category="list-text">ONTAP TOOLS 9,10 utiliza su propio algoritmo de ubicación equilibrada para colocar un nuevo VVOL en el mejor volumen FlexVol dentro de un almacén de datos vVols. La colocación se basa en el SCP especificado y los volúmenes FlexVol correspondientes. Esto garantiza que el almacén de datos y el almacenamiento de respaldo puedan cumplir con los requisitos de rendimiento especificados.</block>
  <block id="e65bde48b0a84fcc60d957de90c3a128" category="list-text">Cambiar las funcionalidades de rendimiento como IOPS mín. Y máx. Requiere cierta atención a la configuración específica.</block>
  <block id="c43f1c590aab42b849ee038e863a567d" category="list-text">*IOPS mín. Y máx.* se pueden especificar en un SCP y utilizarse en una Política de VM.</block>
  <block id="404e0fefd61512a9f144586382a62641" category="list-text">Cambiar las IOPS en el SCP no cambiará la QoS en los vVols hasta que se edite la Política de VM y, a continuación, se volverá a aplicar a las VM que la utilizan (consulte <block ref="2358041c73953300d39d98366deee80d" category="inline-xref-macro-rx"></block>). También puede crear un SCP nuevo con las IOPS deseadas y cambiar la política para usarlo (y volver a aplicarlo a las VM). Generalmente, se recomienda simplemente definir SCPs independientes y políticas de almacenamiento de equipos virtuales para diferentes niveles de servicio y simplemente cambiar la política de almacenamiento de equipos virtuales en el equipo virtual.</block>
  <block id="0e05d638b7a9c7a5c32e6c22679eeb82" category="list-text">Las personalidades de AFF y FAS tienen diferentes configuraciones de IOPS. Los valores Mín y Máx están disponibles en AFF. Sin embargo, los sistemas que no sean AFF solo pueden usar la configuración de Max IOPS.</block>
  <block id="97659fa3c3a5aaf088f6020a38faf086" category="list-text">En algunos casos, es posible que un VVol deba migrarse después de un cambio de política (ya sea manualmente o automáticamente mediante el proveedor VASA y ONTAP):</block>
  <block id="81c975fc79a19102fa04ad9c49f7538b" category="list-text">Algunos cambios no requieren ninguna migración (como el cambio de Max IOPS, que se puede aplicar inmediatamente al VM tal como se ha descrito anteriormente).</block>
  <block id="a426b56f86a12c200f3484efb990e81f" category="list-text">Si el cambio de política no puede ser compatible con el volumen FlexVol actual que almacena el VVol (por ejemplo, la plataforma no admite la política de cifrado o organización en niveles solicitada), deberá migrar manualmente la máquina virtual a vCenter.</block>
  <block id="7de504873f20af5c8ce6dadd2f79b29a" category="list-text">Las herramientas de ONTAP crean políticas de calidad de servicio individuales no compartidas con las versiones actuales compatibles de ONTAP. Por lo tanto, cada VMDK individual recibirá su propia asignación de IOPS.</block>
  <block id="63a33ddbd2c3ccd2daac06020248049f" category="section-title">Nueva aplicación de la normativa de almacenamiento de equipos virtuales</block>
  <block id="d0f5986c3378364e5cb0eda0e98fd0fd" category="inline-image-macro">«Reapplying VM Storage Policy»,300</block>
  <block id="2a8c2026166e178134c7e19c2f4a2c15" category="paragraph"><block ref="2a8c2026166e178134c7e19c2f4a2c15" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50b6e1c7f2e81842d993d8ce88acc979" category="summary">ONTAP admite los principales protocolos de almacenamiento utilizados para la virtualización, como iSCSI, Fibre Channel (FC), Fibre Channel sobre Ethernet (FCoE) o memoria no volátil exprés sobre Fibre Channel (NVMe/FC) para entornos SAN, así como NFS (v3 y v4.1) y SMB o S3 para conexiones «guest». Los clientes pueden elegir qué funciona mejor para su entorno y pueden combinar los protocolos que necesiten en un único sistema.</block>
  <block id="ee8cc65cae83009c275cd4748f4c58ae" category="doc">Herramientas de virtualización para ONTAP</block>
  <block id="0894f8dfb7dd501a78dc2416b7b90c2a" category="paragraph">NetApp ofrece varias herramientas de software independientes que se pueden utilizar junto con ONTAP y vSphere para gestionar su entorno virtualizado.</block>
  <block id="236e1a1bf6abf86968baf738af47b78c" category="paragraph">Las siguientes herramientas se incluyen con la licencia de ONTAP sin coste adicional. Consulte la figura 1 para obtener una descripción de cómo funcionan estas herramientas juntas en su entorno vSphere.</block>
  <block id="f364e3337f5237c93d7b5439c82d444b" category="paragraph">Las herramientas de ONTAP para VMware vSphere son un conjunto de herramientas para usar el almacenamiento de ONTAP junto con vSphere. El complemento de vCenter, anteriormente conocido como Virtual Storage Console (VSC), simplifica las funciones de gestión y eficiencia del almacenamiento, mejora la disponibilidad y reduce los costes de almacenamiento y la sobrecarga operativa, tanto si usa SAN como NAS. Utiliza prácticas recomendadas para aprovisionar almacenes de datos y optimiza la configuración de host ESXi para entornos de almacenamiento en bloques y NFS. Para todas estas ventajas, NetApp recomienda usar estas herramientas de ONTAP como práctica recomendada cuando se usa vSphere con sistemas que ejecutan el software ONTAP. Incluye un dispositivo de servidor, extensiones de interfaz de usuario para vCenter, proveedor VASA y Storage Replication Adapter. Casi todo lo que incluye las herramientas de ONTAP se puede automatizar mediante API de REST sencillas, consumibles gracias a las herramientas de automatización más modernas.</block>
  <block id="0b266371a133b176a2ee883ccf72b46c" category="list-text">*Extensiones de la interfaz de usuario de vCenter.* las extensiones de la interfaz de usuario de las herramientas de ONTAP simplifican el trabajo de los equipos de operaciones y los administradores de vCenter al incorporar menús contextuales fáciles de usar para gestionar hosts y almacenamiento, portlets informativos y capacidades de alerta nativas directamente en la interfaz de usuario de vCenter para optimizar los flujos de trabajo.</block>
  <block id="e08c666b5127e745f8aacbacfce37dcf" category="list-text">*Proveedor VASA para ONTAP.* el Proveedor VASA para ONTAP es compatible con el marco de trabajo VMware vStorage APIs for Storage Awareness (VASA). Se suministra como parte de las herramientas de ONTAP para VMware vSphere como un dispositivo virtual único para facilitar la puesta en marcha. EL proveedor DE VASA conecta vCenter Server con ONTAP para ayudar en el aprovisionamiento y la supervisión del almacenamiento de máquinas virtuales. Permite el soporte de VMware Virtual Volumes (vVols), la gestión de los perfiles de las funcionalidades del almacenamiento y el rendimiento vVols individual, y las alarmas para supervisar la capacidad y el cumplimiento de los perfiles.</block>
  <block id="1c7bb8764fc089dda8481678ad1ea0b5" category="list-text">*Storage Replication Adapter.* el SRA se utiliza junto con VMware Site Recovery Manager (SRM) para gestionar la replicación de datos entre sitios de producción y de recuperación ante desastres y probar las réplicas de recuperación ante desastres de forma no disruptiva. Ayuda a automatizar las tareas de identificación, recuperación y protección. Incluye tanto un dispositivo de servidor SRA como adaptadores SRA para el servidor SRM de Windows y el dispositivo SRM.</block>
  <block id="a1c13ec555198266776a3a7b904810dd" category="paragraph">La figura siguiente muestra las herramientas de ONTAP para vSphere.</block>
  <block id="dd55e255500b9ec15305dc69dfa0e15b" category="section-title">Plugin NFS para VAAI de VMware</block>
  <block id="4fbfd4c228f22ff3f2841908e853d895" category="paragraph">El plugin de NetApp NFS para VMware VAAI es un plugin para hosts ESXi que permite usar funciones VAAI con almacenes de datos NFS en ONTAP. Es compatible con copias de descarga para operaciones de clonado, reserva de espacio para archivos de disco virtual gruesos y descarga de copias Snapshot. La descarga de operaciones de copia en el almacenamiento no es necesariamente más rápida de completarse, pero reduce los requisitos de ancho de banda de red y libera a recursos del host, como ciclos de CPU, búferes y colas. Puede usar las herramientas de ONTAP para VMware vSphere para instalar el plugin en hosts ESXi o, si es compatible, vSphere Lifecycle Manager (VLCM).</block>
  <block id="00cdd3f66e02711548cf72d579ec0df8" category="summary">SnapCenter permite crear políticas de backup que se pueden aplicar a varias tareas. Estas políticas pueden definir programaciones, retención, replicación y otras funcionalidades. Continúan permitiendo la selección opcional de snapshots consistentes con las máquinas virtuales, lo que aprovecha la capacidad del hipervisor para desactivar la I/O antes de tomar una snapshot de VMware.</block>
  <block id="f1d1eddd608fe98b6fa2bc3436ce81d0" category="doc">Gestión basada en políticas de almacenamiento y vVols</block>
  <block id="2bdce8d6813e7a3d93783119529cf146" category="paragraph">Las API de VMware vSphere para la conciencia de almacenamiento (VASA) facilitan que el administrador de almacenamiento pueda configurar almacenes de datos con funcionalidades bien definidas y permiten que el administrador de equipos virtuales las utilice siempre que lo necesite para aprovisionar equipos virtuales sin tener que interactuar entre sí.</block>
  <block id="871db14a81b3510676400538c6f07073" category="paragraph">Merece la pena echar un vistazo a este enfoque para ver cómo puede optimizar sus operaciones de almacenamiento de virtualización y evitar un gran trabajo trivial.</block>
  <block id="ad0bd815b4fb6f01acc94f160af3dca7" category="paragraph">Antes de VASA, los administradores de máquinas virtuales podían definir políticas de almacenamiento de máquinas virtuales, pero tenían que trabajar con el administrador de almacenamiento para identificar los almacenes de datos adecuados, a menudo utilizando documentación o convenciones de nomenclatura. Con VASA, el administrador de almacenamiento puede definir una serie de capacidades de almacenamiento, como el rendimiento, la clasificación por niveles, el cifrado y la replicación. Un conjunto de funcionalidades para un volumen o un conjunto de volúmenes se denomina perfil de capacidad de almacenamiento (SCP).</block>
  <block id="44d75bdf4feecabe2de10427870ae623" category="paragraph">El SCP admite QoS mínimo y/o máximo para los vVols de datos de una VM. La calidad de servicio mínima solo se admite en los sistemas AFF. Las herramientas de ONTAP para VMware vSphere incluyen una consola donde se muestra el rendimiento granular de máquinas virtuales y la capacidad lógica para vVols en sistemas ONTAP.</block>
  <block id="4240fa68f6d9919e6d039c4038175025" category="paragraph">La siguiente figura muestra las herramientas de ONTAP para el panel de vVols de VMware vSphere 9.8.</block>
  <block id="50e0e66922b3b12510a128829d1fdc70" category="paragraph">Una vez definido el perfil de funcionalidad de almacenamiento, puede utilizarse para aprovisionar equipos virtuales mediante la normativa de almacenamiento que identifique sus requisitos. La asignación entre la política de almacenamiento de máquinas virtuales y el perfil de capacidad de almacenamiento de almacenes de datos permite que vCenter muestre una lista de almacenes de datos compatibles que podrá seleccionar. Este enfoque se conoce como gestión basada en políticas de almacenamiento.</block>
  <block id="794b6e2fc393d40a552fc58975920cb0" category="paragraph">VASA proporciona la tecnología para consultar el almacenamiento y devolver un conjunto de funcionalidades de almacenamiento a vCenter. Los proveedores de VASA proporcionan la traducción entre las API y construcciones del sistema de almacenamiento y las API de VMware que comprende vCenter. VASA Provider de NetApp para ONTAP se ofrece como parte de las herramientas de ONTAP para VM del dispositivo VMware vSphere. El complemento de vCenter proporciona la interfaz para aprovisionar y gestionar almacenes de datos VVOL, así como la capacidad para definir perfiles de capacidades de almacenamiento (SCPs).</block>
  <block id="dad160104969c39365dd2cd4c98dd300" category="inline-link">CONSULTE TR-4400</block>
  <block id="bd490c925219bcb312338a370589bf70" category="list-text">Un almacén de datos de VVol puede consistir en varios volúmenes de FlexVol en varios nodos de clúster. El método más sencillo es un único almacén de datos, incluso cuando los volúmenes tienen diferentes funcionalidades. SPBM garantiza que se utiliza un volumen compatible para la máquina virtual. Sin embargo, todos los volúmenes deben formar parte de una única SVM de ONTAP y se debe acceder a ellos mediante un único protocolo. Un LIF por nodo para cada protocolo es suficiente. Evite el uso de varias versiones de ONTAP en un único almacén de datos de VVol, ya que las funcionalidades de almacenamiento pueden variar entre las versiones.</block>
  <block id="0cc956d6da91fefae9dad9b2c8c9519b" category="list-text">Utilice las herramientas de ONTAP para el plugin de VMware vSphere para crear y gestionar almacenes de datos de VVol. Además de gestionar el almacén de datos y su perfil, crea automáticamente un extremo de protocolo para acceder a vVols, si es necesario. Si se utilizan LUN, tenga en cuenta que los extremos de protocolo de LUN se asignan mediante los ID de LUN 300 y posteriores. Compruebe que la opción de configuración del sistema avanzado del host ESXi<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> Permite un número de ID de LUN que sea mayor que 300 (el valor predeterminado es 1,024). Para realizar este paso, seleccione el host ESXi en vCenter, después la pestaña Configure y busque<block ref="ce913b4e625461a33f54f9e4ac38c2d7" prefix=" " category="inline-code"></block> En la lista Advanced System Settings.</block>
  <block id="fac85f355a1eb47127ef1b94e7603924" category="list-text">No instale ni migre VASA Provider, vCenter Server (basado en dispositivos o Windows) ni las herramientas de ONTAP para VMware vSphere en un almacén de datos vVols, ya que estos dependen mutuamente, lo cual limita la capacidad de gestionarlos en caso de una interrupción del suministro eléctrico u otra interrupción del centro de datos.</block>
  <block id="dd76252ea7a50def2a98f218cb1505b4" category="inline-link">Artículo de base de conocimientos</block>
  <block id="15ef75dd3d20b8278c16cd01a708e13e" category="list-text">Realice un backup regular de la máquina virtual del proveedor de VASA. Como mínimo, cree copias Snapshot por hora del almacén de datos tradicional que contenga VASA Provider. Para obtener más información sobre la protección y recuperación del proveedor de VASA, consulte este tema<block ref="9d642870dca1748c69f7aa0b6fb95a89" category="inline-link-rx"></block>.</block>
  <block id="2d2d2e356f9ab117b7d2a58d42cc5988" category="paragraph">La siguiente figura muestra los componentes de vVols.</block>
  <block id="d3ba101543fc97ba1dd9272c87bf65da" category="doc">Volúmenes virtuales (vVols) y gestión basada en políticas de almacenamiento (SPBM)</block>
  <block id="a42f13867ea459821488608dc4d1b7c4" category="paragraph">NetApp fue un partner de diseño inicial de VMware en el desarrollo de vSphere Virtual Volumes (vVols), que ofrecía información sobre la arquitectura y compatibilidad temprana con vVols y VMware vSphere APIs for Storage Awareness (VASA). Este enfoque no solo llevó la gestión de almacenamiento granular de la máquina virtual a VMFS, sino que también admitió la automatización del aprovisionamiento de almacenamiento a través de la gestión basada en políticas de almacenamiento (SPBM).</block>
  <block id="ce09fc365ce48a9d89c0fdb5222c3909" category="paragraph">La SPBM proporciona un marco que funciona como capa de abstracción entre los servicios de almacenamiento disponibles para su entorno de virtualización y los elementos de almacenamiento aprovisionados mediante políticas. Este enfoque permite a los arquitectos de almacenamiento diseñar pools de almacenamiento con distintas funcionalidades que pueden consumir fácilmente los administradores de máquinas virtuales. A continuación, los administradores pueden igualar los requisitos de carga de trabajo de las máquinas virtuales con los pools de almacenamiento aprovisionados, lo que permite controlar de forma granular diversos ajustes a nivel de máquinas virtuales o discos virtuales.</block>
  <block id="2902acda09b9786460c2dd928a2d8f1a" category="paragraph">ONTAP es líder en el sector del almacenamiento a escala de vVols, ya que admite cientos de miles de vVols en un único cluster, mientras que las cabinas empresariales y los proveedores de cabinas flash más pequeños admiten hasta varios miles de vVols por cabina. NetApp también impulsa la evolución de la gestión granular de máquinas virtuales con próximas funcionalidades para admitir vVols 3.0.</block>
  <block id="fda9c21a4aefd4a1f42ad0b195e6ef0a" category="inline-link">TR-4400: VMware vSphere Virtual Volumes con ONTAP</block>
  <block id="61823c0f572643e0ce2e4edcb74cae51" category="paragraph">Use copias Snapshot para realizar copias rápidas de sus máquinas virtuales o almacenes de datos sin afectar al rendimiento y, a continuación, envíelas a un sistema secundario usando SnapMirror para la protección de datos fuera del sitio a largo plazo. Este método minimiza el espacio de almacenamiento y el ancho de banda de red porque solo almacena la información modificada.</block>
  <block id="0aef2da721f0ab14676f8d6ffb9e7e8c" category="inline-link">recomendado</block>
  <block id="022e604112aa3d1870f0da5e7806f48b" category="paragraph">SnapCenter permite crear políticas de backup que se pueden aplicar a varias tareas. Estas políticas pueden definir programaciones, retención, replicación y otras funcionalidades. Continúan permitiendo la selección opcional de snapshots consistentes con las máquinas virtuales, lo que aprovecha la capacidad del hipervisor para desactivar la I/O antes de tomar una snapshot de VMware. Sin embargo, debido al efecto sobre el rendimiento de las snapshots de VMware, generalmente no se recomiendan a menos que necesite que el sistema de archivos invitados se coloque en modo inactivo. En su lugar, utilice los snapshots para protección general y use herramientas de aplicaciones como los complementos de SnapCenter para proteger los datos transaccionales, como SQL Server u Oracle. Estas copias Snapshot son diferentes de las copias snapshot de VMware (consistencia) y son adecuadas para la protección a largo plazo.  Las copias Snapshot de VMware son solo<block ref="75f5ad475d959e2ecb55267e1a9a54f1" category="inline-link-rx"></block> para uso a corto plazo debido al rendimiento y otros efectos.</block>
  <block id="26aae91a7d92b32a60b1fbc86c29ee81" category="paragraph">Estos complementos ofrecen funcionalidades ampliadas para proteger las bases de datos tanto en entornos físicos como virtuales. Con vSphere, puede usarlos para proteger bases de datos de SQL Server o Oracle donde los datos se almacenan en LUN de RDM, LUN iSCSI conectados directamente al sistema operativo invitado o archivos VMDK en almacenes de datos VMFS o NFS. Los plugins permiten especificar diferentes tipos de backups de bases de datos, admiten backup en línea o sin conexión y protegen los archivos de base de datos junto con los archivos de registros. Además del backup y recuperación, los plugins también admiten la clonado de bases de datos para fines de desarrollo o pruebas.</block>
  <block id="1556ba0bf6ea4783cda0ff40e96f0265" category="paragraph">En la siguiente figura se muestra un ejemplo de la instalación de SnapCenter.</block>
  <block id="6c1bef29e8dc34a00e17b06c221d5efe" category="paragraph">Para obtener mejores funcionalidades de recuperación ante desastres, considere el uso del SRA de NetApp para ONTAP con el administrador de recuperación del sitio de VMware. Además de admitir la replicación de almacenes de datos en un sitio de recuperación ante desastres, también permite realizar pruebas no disruptivas en el entorno de recuperación ante desastres mediante la clonación de los almacenes de datos replicados. La recuperación de un desastre y la reprotección de la producción después de resolver la interrupción del servicio también son fáciles mediante la automatización incorporada en el SRA.</block>
  <block id="650062685b0df8284f1b87f62fa3f9f3" category="inline-link">CONSULTE TR-4128</block>
  <block id="886a3fd32ec402d87ea2b090f8f701b2" category="paragraph">Finalmente, para obtener el máximo nivel de protección de datos, considere una configuración de VMware vSphere Metro Storage Cluster (VMSC) con MetroCluster de NetApp. VMSC es una solución certificada por VMware que combina la replicación síncrona con la agrupación en clusters basada en arreglos, con los mismos beneficios de un cluster de alta disponibilidad que la distribución en sitios independientes para proteger contra los desastres del sitio. MetroCluster de NetApp ofrece configuraciones rentables para la replicación síncrona con recuperación transparente de fallos de cualquier componente de almacenamiento, así como recuperación con un único comando en caso de desastre en el sitio. El VMSC se describe con mayor detalle en la<block ref="737e6eedc4568d5bb72c6a6cf1fe681a" category="inline-link-rx"></block>.</block>
  <block id="92515b597b8c0784d6000b89ee47c5fd" category="doc">Almacenamiento unificado</block>
  <block id="d6154a0901f9ca6bb5d8fb15c113581e" category="paragraph"><block ref="d6154a0901f9ca6bb5d8fb15c113581e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c46d272642e0999c025f67e9de315c9" category="paragraph">En el mundo de vSphere, este enfoque también podría significar un sistema unificado para una infraestructura de puestos de trabajo virtuales (VDI) junto con una infraestructura de servidores virtuales (VSI). Los sistemas que ejecutan el software ONTAP suelen ser menos caros para VSI que las cabinas empresariales tradicionales y, al mismo tiempo, cuentan con funcionalidades avanzadas de eficiencia del almacenamiento para manejar VDI en el mismo sistema. ONTAP también unifica varios medios de almacenamiento, desde SSD a SATA, y puede ampliarlos fácilmente al cloud. No es necesario comprar una cabina flash para el rendimiento, una cabina SATA para archivos y sistemas independientes para la nube. ONTAP los une a todos.</block>
  <block id="e9e0f5f2c513c7138ea70b4c929d6fef" category="inline-link">Virtualización del almacenamiento</block>
  <block id="400cc516a4a40acd605aef2cfd4ba4c0" category="doc">Planificador de recursos distribuidos de almacenamiento de VMware</block>
  <block id="6e210af5c49ef2b81c06b57f989ed5c6" category="paragraph">El planificador de recursos distribuidos de almacenamiento (SDRS) de VMware es una función de vSphere que coloca los equipos virtuales en el almacenamiento en función de la latencia de I/o actual y el uso del espacio.</block>
  <block id="e7649bfbacc438bf8e20ba3564db4bdd" category="paragraph">A continuación, mueve la máquina virtual o los VMDK de forma no disruptiva entre los almacenes de datos de un clúster de almacenes de datos (también conocido como "pod"), seleccionando el mejor almacén de datos en el que colocar la máquina virtual o los VMDK en el clúster de almacenes de datos. Un clúster de almacenes de datos es una colección de almacenes de datos similares que se agregan en una única unidad de consumo desde la perspectiva del administrador de vSphere.</block>
  <block id="b028cce2007c32457c41f20d2954c0c2" category="paragraph">Otras prácticas recomendadas de ONTAP para SDRS incluyen lo siguiente:</block>
  <block id="d11eff5be5178b7ba95b06270611ffc8" category="list-text">Todos los almacenes de datos del clúster deben usar el mismo tipo de almacenamiento (como SAS, SATA o SSD), ser todos los almacenes de datos VMFS o NFS y tener la misma configuración de replicación y protección.</block>
  <block id="76db7ce67615bbc16da685df79ed0aa9" category="list-text">Considere el uso de SDR en modo predeterminado (manual). Este enfoque permite revisar las recomendaciones y decidir si se aplican o no. Tenga en cuenta los siguientes efectos de las migraciones de VMDK:</block>
  <block id="97f4ed95cb52bb29629002a25cb5039f" category="list-text">Cuando SDRS mueve VMDK entre almacenes de datos, se pierde cualquier ahorro de espacio con la clonado o deduplicación de ONTAP. Puede volver a ejecutar la deduplicación para recuperar este ahorro.</block>
  <block id="38f492286c3edf236c76e993ce0f0bf2" category="list-text">Después de que SDRS mueva los VMDK, NetApp recomienda volver a crear las snapshots en el almacén de datos de origen porque el espacio se bloqueará por la máquina virtual que se movió.</block>
  <block id="09a99cbc4fb85d10c7af970e79032a05" category="list-text">Mover VMDK entre almacenes de datos en el mismo agregado tiene pocas ventajas y LOS SDRS no tienen visibilidad en otras cargas de trabajo que puedan compartir el agregado.</block>
  <block id="09b616c445ab7efa8240062532e526e4" category="doc">VMware vSphere con ONTAP</block>
  <block id="48e29772cebbf1133d022577e278d5c1" category="admonition">Esta documentación sustituye a los informes técnicos publicados anteriormente _TR-4597: VMware vSphere para ONTAP_</block>
  <block id="bfa7e7fc7c6bf4cc4e4c5c74b09763eb" category="paragraph">Las prácticas recomendadas complementan otros documentos, como guías y listas de compatibilidad. Se desarrollan según pruebas de laboratorio y una amplia experiencia de campo por parte de ingenieros y clientes de NetApp. Puede que no sean las únicas prácticas compatibles que funcionan en todos los entornos, pero suelen ser las soluciones más sencillas que satisfacen las necesidades de la mayoría de los clientes.</block>
  <block id="9ed4a475dd3705157a9fed8811f63ce2" category="inline-link">Herramienta de matriz de interoperabilidad de NetApp</block>
  <block id="e08175c6fa64cba68719dea85ebd9d34" category="inline-link">Guía de compatibilidad de VMware</block>
  <block id="c7e9d53e7f1a53451fa25cb6340fbf6f" category="paragraph">Este documento se centra en las funcionalidades de los lanzamientos recientes de ONTAP (9.x) ejecutados en vSphere 7,0 o posterior. Consulte<block ref="37aa2814221d042697a27bc81e148f64" category="inline-link-rx"></block> y..<block ref="e1593898142109fc8cd8025356d3f312" category="inline-link-rx"></block> para obtener detalles relacionados con versiones específicas.</block>
  <block id="74587fa4ad90f8713c0446529a3670e0" category="section-title">¿Por qué elegir ONTAP para vSphere?</block>
  <block id="a110ecc6d4ce7014019c560e5fedf572" category="paragraph">Hay muchas razones por las que decenas de miles de clientes han seleccionado ONTAP como solución de almacenamiento para vSphere, como un sistema de almacenamiento unificado que admite los protocolos SAN y NAS, sólidas funcionalidades de protección de datos mediante copias Snapshot con gestión eficiente del espacio y una gran cantidad de herramientas para ayudarle a gestionar los datos de aplicaciones. El uso de un sistema de almacenamiento independiente del hipervisor permite descargar numerosas funciones y maximizar su inversión en sistemas de host vSphere. Este método no solo garantiza que los recursos del host se centren en las cargas de trabajo de las aplicaciones, sino que también evita efectos de rendimiento aleatorios en las aplicaciones de operaciones de almacenamiento.</block>
  <block id="0f50acddbdbb9aa9712a471f2276e655" category="paragraph">El uso de ONTAP junto con vSphere es una excelente combinación que le permite reducir los gastos en hardware del host y software de VMware. También puede proteger sus datos con un coste menor y un alto rendimiento constante. Dado que las cargas de trabajo virtualizadas son móviles, puede explorar distintos enfoques mediante Storage vMotion para mover equipos virtuales entre almacenes de datos de VMFS, NFS o vVols, todo ello en el mismo sistema de almacenamiento.</block>
  <block id="90977175b761542615a11f2b96cc4cbd" category="paragraph">Estos son algunos de los factores clave que valoran los clientes en la actualidad:</block>
  <block id="442c1f0ac31c3d71b638125e0a8b51da" category="list-text">*Almacenamiento unificado.* los sistemas que ejecutan el software ONTAP están unificados de varias maneras significativas. En un principio, este enfoque hacía referencia a los protocolos NAS y SAN, y ONTAP sigue siendo la plataforma líder para SAN junto con su fortaleza original en NAS. En el mundo de vSphere, este enfoque también podría significar un sistema unificado para una infraestructura de puestos de trabajo virtuales (VDI) junto con una infraestructura de servidores virtuales (VSI). Los sistemas que ejecutan el software ONTAP suelen ser menos caros para VSI que las cabinas empresariales tradicionales y, al mismo tiempo, cuentan con funcionalidades avanzadas de eficiencia del almacenamiento para manejar VDI en el mismo sistema. ONTAP también unifica varios medios de almacenamiento, desde SSD a SATA, y puede ampliarlos fácilmente al cloud. No es necesario comprar una cabina flash para el rendimiento, una cabina SATA para archivos y sistemas independientes para la nube. ONTAP los une a todos.</block>
  <block id="0ce37df1cd9b66a2abde8244f17fc051" category="list-text">*Gestión basada en políticas de almacenamiento y volúmenes virtuales* NetApp fue un socio de diseño temprano con VMware en el desarrollo de vSphere Virtual Volumes (vVols), proporcionando información arquitectónica y soporte temprano para vVols y VMware vSphere APIs for Storage Awareness (Vasa). Este enfoque no solo integró la gestión granular de almacenamiento de máquinas virtuales en VMFS, sino que también admitió la automatización del aprovisionamiento de almacenamiento a través de la gestión basada en políticas de almacenamiento. Este enfoque permite a los arquitectos de almacenamiento diseñar pools de almacenamiento con distintas funcionalidades que pueden consumir fácilmente los administradores de máquinas virtuales. ONTAP es líder en el sector del almacenamiento a escala VVol, por lo que admite cientos de miles de vVols en un único clúster, mientras que las cabinas empresariales y los proveedores de cabinas flash más pequeños admiten hasta varios miles de vVols por cabina. NetApp también está impulsando la evolución de la gestión granular de equipos virtuales con próximas funcionalidades para admitir vVols 3.0.</block>
  <block id="9eeea06a6a7f860f801343c04af5d7d2" category="list-text">*Eficiencia del almacenamiento*. Aunque NetApp fue el primero en ofrecer deduplicación para las cargas de trabajo de producción, esta innovación no fue la primera ni la última en esta área. Comenzó con copias Snapshot, un mecanismo de protección de datos con gestión eficiente del espacio sin efecto en el rendimiento, junto con la tecnología FlexClone para realizar de forma instantánea copias de lectura y escritura de equipos virtuales para producción y uso del backup. NetApp siguió ofreciendo funcionalidades inline, que incluían deduplicación, compresión y deduplicación de bloque cero, para sacar el máximo partido de almacenamiento de SSD de elevado coste. Más recientemente, ONTAP añadió la capacidad de empaquetar las operaciones de I/o y archivos más pequeños en un bloque de discos mediante la compactación. La combinación de estas funcionalidades ha dado como resultado que los clientes observan un ahorro de hasta 5:1 para VSI y de hasta 30:1 para la infraestructura de puestos de trabajo virtuales.</block>
  <block id="bb73602f3344c326a7b63c94db24362a" category="list-text">*Cloud híbrido.* tanto si se utiliza para un cloud privado en las instalaciones, una infraestructura de cloud público o un cloud híbrido que combina lo mejor de ambos, las soluciones ONTAP le ayudan a crear su Data Fabric para optimizar y optimizar la gestión de datos. Empiece con sistemas all-flash de alto rendimiento y, a continuación, apítelos con sistemas de disco o de almacenamiento en cloud para protección de datos y cloud computing. Elija entre clouds de Azure, AWS, IBM o Google para optimizar costes y evitar la restricción. Aproveche el soporte avanzado para OpenStack y las tecnologías de contenedor según sea necesario. NetApp también ofrece backup basado en cloud (SnapMirror Cloud, Cloud Backup Service y Cloud Sync) y herramientas de organización en niveles del almacenamiento y archivado (FabricPool) para ONTAP para ayudar a reducir los gastos operativos y aprovechar el amplio alcance del cloud.</block>
  <block id="7a61ec7965eebc0b5486cb78f096c770" category="list-text">*Y mucho más.* saque partido del rendimiento extremo de las cabinas AFF A-Series de NetApp para acelerar su infraestructura virtualizada a la vez que gestiona los costes. Disfrute de operaciones no disruptivas, desde el mantenimiento hasta las actualizaciones, pasando por la sustitución completa de su sistema de almacenamiento, mediante clústeres ONTAP de escalado horizontal. Proteja los datos en reposo con funcionalidades de cifrado de NetApp sin coste adicional. Asegúrese de que el rendimiento cumple los niveles de servicio empresarial a través de funcionalidades de calidad de servicio de gran precisión. Todos ellos forman parte de la amplia gama de funcionalidades que incluyen ONTAP, el software para la gestión de datos empresariales líder del sector.</block>
  <block id="6104c8ef7be4222a76596ab6a22bb422" category="doc">Host ESXi recomendado y otra configuración de ONTAP</block>
  <block id="678582eb0cbbe0e063e618d230b63223" category="cell">*Configuración del host*</block>
  <block id="dfe49b73bd7e747701b49f9ed21ea2d6" category="cell">*Valor recomendado por NetApp*</block>
  <block id="edceae57d92287f4f6200f94d3259cd0" category="cell">*Se requiere reinicio*</block>
  <block id="dc3a6955a23583876d020db0f6b80d4d" category="cell">*Configuración avanzada de ESXi*</block>
  <block id="73663d0d00956f0632e4ae75d811d53f" category="cell">VMFS3.HardwareAccelerated Locking</block>
  <block id="59b1aceaef0203fdc32e11df232b16e6" category="cell">Mantener predeterminado (1)</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">No</block>
  <block id="1b50110aedae4d8d2043a4eb9beb20af" category="cell">VMFS3.EnableBlockDelete</block>
  <block id="5d1b81f1885499e392018ebd7124ad37" category="inline-link-macro">2007427 de la base de conocimientos de VMware</block>
  <block id="316084648bbafe451240702bd19c6ee9" category="cell">VMFS3.EnableVMFS6Unmap</block>
  <block id="befd90cd01403237f6fdf296822efbee" category="inline-link-macro">API de VMware vSphere: Integración de cabinas (VAAI)</block>
  <block id="e385d2442208cc1e23ca841b1f217380" category="cell">Mantener predeterminado (1)
Para obtener más información, consulte <block ref="d124e203790e5f214a195f69cd068c6d" category="inline-link-macro-rx"></block></block>
  <block id="571cc1d48c6d1ff3cf7e3a54cb035753" category="cell">*Ajustes NFS*</block>
  <block id="c3b49a515dd0046685e06092642aa139" category="cell">NET.TcpipHeapSize</block>
  <block id="875f6b98e20edfecb56f9013d00987f6" category="cell">VSphere 6.0 o posterior; establezca esta opción en 32.
El resto de configuraciones de NFS se establecen en 30</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">Sí</block>
  <block id="504e96cc79e7efe30a8271cea152d9d1" category="cell">NET.TcpipHeapMax</block>
  <block id="a8af33a99dd728969fd947da27a2f69f" category="cell">Configure 512 MB para la mayoría de las versiones de vSphere 6.X.
Establezca 1024 MB para 6.5U3, 6.7U3 y 7.0 o superior.</block>
  <block id="5f1e7b6431061565550e292d05c73588" category="cell">NFS.MaxVolumes</block>
  <block id="3058676a1cf088aa4a73312ac36f2a58" category="cell">NFS41.MaxVolumes</block>
  <block id="62c07f94c64184ee5d530e4c0917093f" category="cell">VSphere 6,0 o posterior, configurado en 256.</block>
  <block id="e18600af98c17fae10fdba0dc89979ed" category="cell">NFS.MaxQueueDepth</block>
  <block id="be7707fa525d0124489c9fe3072f78de" category="cell">VSphere 6.0 o posterior; establezca esta opción en 128</block>
  <block id="18e1fb6924459470760771b20ab0c379" category="cell">NFS.HeartbeatMaxFailures</block>
  <block id="138989cbe5dd3a4997662e0f65c17878" category="cell">Establezca en 10 para todas las configuraciones NFS</block>
  <block id="1aa26eb281359ba3b9a9a4b83a09ed46" category="cell">NFS.HeartbeatFrequency</block>
  <block id="7ea6e8664542e3beb1aea10425efb4db" category="cell">Establezca en 12 para todas las configuraciones NFS</block>
  <block id="eb4182715f8cde98563dc59ea36461d3" category="cell">NFS.HeartbeatTimeout</block>
  <block id="45aa5481fa55802a29a96aefd2f5dab1" category="cell">Establezca en 5 para todas las configuraciones NFS.</block>
  <block id="54a08b15243d9078d3b5a47f8242da6f" category="cell">SunRPC.MaxConnPerIP</block>
  <block id="9a9ccbecb3f315797ff8e709d85a0e18" category="cell">VSphere 7,0 o posterior, configurado en 128.</block>
  <block id="c0b3fd5512c2093847f753f398290f30" category="cell">*Configuración de FC/FCoE*</block>
  <block id="2e556ad678160413b32dcca55c7d1f5f" category="cell">Política de selección de rutas</block>
  <block id="fb62337a3ef32f4701b639339a4ceb33" category="cell">Establezca el valor RR (round robin) cuando se utilicen rutas FC con ALUA. Establezca COMO FIJO para todas las demás configuraciones.
Al establecer este valor en RR, se ayuda a proporcionar un equilibrio de carga en todas las rutas activas/optimizadas.
El valor FIJO es para configuraciones antiguas que no pertenecen a ALUA y ayuda a evitar las operaciones de I/o del proxy En otras palabras, ayuda a evitar que las operaciones de I/o vayan al otro nodo de una pareja de alta disponibilidad (ha) en un entorno con Data ONTAP en 7-Mode</block>
  <block id="117704664d6cada78ac3107380f63d23" category="cell">Disk.QFullSampleSize</block>
  <block id="0e82e1f81de2159b0e9bee0b7be00dc9" category="cell">Establezca en 32 para todas las configuraciones.
Si configura este valor, se evitan los errores de I/O.</block>
  <block id="f66a3c183f0e736240b77f8b755c880e" category="cell">Disk.QFullThreshold</block>
  <block id="bdd8c1d08eabb5e1923ed8f0c4b10ba4" category="cell">Establecer en 8 para todas las configuraciones.
Si configura este valor, se evitan los errores de I/O.</block>
  <block id="19c08de7404551288e1274186e039ef4" category="cell">Tiempos de espera de FC HBA de Emulex</block>
  <block id="b4dbfc2d52627e923cbb563a31ff756d" category="cell">Se utiliza el valor predeterminado.</block>
  <block id="d46cddda4da7ec11f17472d11df95b68" category="cell">Tiempos de espera de HBA FC de QLogic</block>
  <block id="19b5aaf3e2cb86809996ca63a2a416b0" category="cell">*Configuración iSCSI*</block>
  <block id="2aa077454308383f1e82025427cd7362" category="cell">Establezca el valor RR (round robin) para todas las rutas iSCSI.
Al establecer este valor en RR, se ayuda a proporcionar un equilibrio de carga en todas las rutas activas/optimizadas.</block>
  <block id="0340eb1bcbfc6cd3c62b8a878d8d643b" category="cell">Establezca en 32 para todas las configuraciones.
Si configura este valor, se evitan los errores de I/O.</block>
  <block id="891c10448731ad57490b9a932dabfff8" category="inline-link-macro">86331 de la base de conocimientos de VMware</block>
  <block id="2c572e3c397fe100b075a09359c9cc23" category="admonition">1: Es posible que la opción de configuración avanzada de NFS MaxQueueDepth no funcione según lo previsto al usar VMware vSphere ESXi 7.0.1 y VMware vSphere ESXi 7.0.2. Consulte <block ref="861055760f3cd527823fd34a49459992" category="inline-link-macro-rx"></block> si quiere más información.</block>
  <block id="fb55ee99c04280ac638757869929785d" category="paragraph">Las herramientas de ONTAP también especifican determinada configuración predeterminada al crear volúmenes de ONTAP FlexVol y LUN:</block>
  <block id="3f7502a5f109d7a73706aba1c0741a4b" category="cell">*Herramienta ONTAP*</block>
  <block id="485577e97e8efcd504fc8e8b13e613f1" category="cell">*Ajuste predeterminado*</block>
  <block id="5938fe448c8661febcef3f4e779e3adb" category="cell">Reserva de Snapshot (-Porcentaje-espacio de instantáneas)</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="7218aec62575561a6de1cae8d5658390" category="cell">Reserva fraccionaria (-reserva fraccionaria)</block>
  <block id="3a7e09ff0fa38663ffe6d91324ea75d9" category="cell">Actualización del tiempo de acceso (-atime-update)</block>
  <block id="f8320b26d30ab433c5a54546d21f414c" category="cell">Falso</block>
  <block id="e93200d5b0d16915bf04236790544b2f" category="cell">Lectura mínima (lectura mínima)</block>
  <block id="c877d89702fdd14e51b02028a20c7d07" category="cell">Snapshots programadas</block>
  <block id="fd18465573ec21a6218982055981f6b1" category="cell">Eficiencia del almacenamiento</block>
  <block id="00d23a76e43b46dae9ec7aa9dcbebb32" category="cell">Activado</block>
  <block id="f65fd63b63c9e9f25bf6bc141e83de34" category="cell">Garantía de volumen</block>
  <block id="c2410aebdf425dabcc65e546e506b03e" category="cell">Ninguno (con thin provisioning)</block>
  <block id="f97c03bf3e9580446d70d479f5aad1e0" category="cell">Tamaño automático del volumen</block>
  <block id="d89f4f8b1d7c18847b88b46142f61535" category="cell">aumentar_reducción</block>
  <block id="ace72ec54e17777d27eb8bdb9d57e782" category="cell">Reserva de espacio de LUN</block>
  <block id="b9f5c797ebbf55adccdd8539a65a0241" category="cell">Deshabilitado</block>
  <block id="514aa7792a71ab4ab677eb2385131aae" category="cell">Asignación de espacio de LUN</block>
  <block id="dbe1e98b00264bd496095ed5c95f9350" category="section-title">Configuración de multivía para el rendimiento</block>
  <block id="de9f44b08eec22d6b405acff2c925d56" category="paragraph">Aunque no está configurado actualmente por las herramientas de ONTAP disponibles, NetApp sugiere estas opciones de configuración:</block>
  <block id="840731ae1cb9e4b23e19f645ab018b6f" category="inline-link">2069356</block>
  <block id="5073fc9da327263a7db04fd449991e6a" category="list-text">En entornos de alto rendimiento o al probar el rendimiento con un único almacén de datos LUN, considere la posibilidad de cambiar la configuración del equilibrio de carga de la normativa de selección de rutas (PSP_RR_VMW) por turnos desde la configuración predeterminada de IOPS de 1000 a un valor de 1. Consulte la base de conocimientos de VMware<block ref="f3f4762788a6845119bdb5b9c9179bda" category="inline-link-rx"></block> para obtener más información.</block>
  <block id="1ea3eb55b985cf75e100607ee8bd935d" category="inline-link">Complementos y políticas de selección de rutas</block>
  <block id="01d954fb2edbf283d121f0651b04de83" category="section-title">Documentación adicional</block>
  <block id="40db5019ed68654f4eb2cf21ec5021db" category="inline-link">Utilice VMware vSphere 7.x con ONTAP</block>
  <block id="30d85838b9488ee908d075559c8978cd" category="inline-link">Utilice VMware vSphere 8.x con ONTAP</block>
  <block id="000c9205416c1ea85f6841a7ca379c17" category="inline-link">Para NVMe-oF, puede encontrar más información en NVMe-oF Configuración del host para ESXi 7.x con ONTAP</block>
  <block id="5a27e6dbe6279e323aec51d205b2b455" category="inline-link">Para NVMe-oF, puede encontrar más información en NVMe-oF Configuración del host para ESXi 8.x con ONTAP</block>
  <block id="842acd8b4932f6c9329df8e0fefe8b9b" category="paragraph">Para FCP e iSCSI con vSphere 7, encontrará más información en<block ref="f3eae508de4d3c1748a9c65337197b21" category="inline-link-rx"></block>
Para FCP e iSCSI con vSphere 8, encontrará más información en<block ref="3f8db75ee0177b85df9cdf31ddb51abe" category="inline-link-rx"></block>
Para NVMe-oF con vSphere 7, encontrará más información en<block ref="6c040a6e611e78bb9d0ad92946e613ea" category="inline-link-rx"></block>
Para NVMe-oF con vSphere 8, encontrará más información en<block ref="030788e4c7bbe3137759b534ea62d7d9" category="inline-link-rx"></block></block>
  <block id="99a66df20e19a8e18fae37a7f714750a" category="doc">Clonado de máquinas virtuales y almacenes de datos</block>
  <block id="fe12a277656562082ad50b980c227a84" category="paragraph">En vSphere, es posible clonar una máquina virtual, un disco virtual, VVol o un almacén de datos. Después de que se clona, el objeto se puede personalizar aún más, a menudo mediante un proceso automatizado. VSphere es compatible con ambos clones de copias completas, así como clones enlazados, donde sigue los cambios de forma independiente del objeto original.</block>
  <block id="883a97a36ab0c59ec785b03161a1cc32" category="paragraph">Los clones enlazados son excelentes para ahorrar espacio, pero aumentan la cantidad de I/o que vSphere gestiona para el equipo virtual, lo que afecta al rendimiento de ese equipo virtual y, quizás, al host en general. Por eso los clientes de NetApp suelen usar clones basados en sistemas de almacenamiento para obtener lo mejor de ambos mundos: Un uso eficiente del almacenamiento y un mayor rendimiento.</block>
  <block id="17e1a153b5d05c5a642c93ba9ce3c6de" category="paragraph">La siguiente figura muestra la clonación de ONTAP.</block>
  <block id="76ee7355875ad5e9f56186ff7da961f6" category="paragraph">Es posible descargar la clonado en sistemas que ejecutan software ONTAP mediante varios mecanismos, normalmente a nivel de máquina virtual, VVol o almacén de datos. Entre ellos se incluyen los siguientes:</block>
  <block id="d957242cd67db8ffccec78d93c14449d" category="list-text">VVols utiliza el proveedor de API de vSphere para el reconocimiento del almacenamiento (VASA) de NetApp.  Los clones de ONTAP se utilizan para admitir copias Snapshot VVOL gestionadas por vCenter, que gestionan el espacio de forma eficiente y tienen un efecto de I/O mínimo para crearlas y eliminarlas.  Las máquinas virtuales también pueden clonarse mediante vCenter y también se descargan en ONTAP, ya sea en un único almacén de datos/volumen o entre almacenes de datos/volúmenes.</block>
  <block id="059e5a6b7f963e9876ba0129dc1b667d" category="list-text">Clonado y migración de vSphere mediante API de vSphere: Integración de cabina (VAAI). Es posible descargar las operaciones de clonado de máquinas virtuales en ONTAP tanto en entornos SAN como NAS (NetApp suministra un complemento ESXi para habilitar VAAI para NFS).  VSphere solo descarga las operaciones en máquinas virtuales frías (apagadas) en un almacén de datos NAS, mientras que las operaciones en máquinas virtuales activas (clonado y vMotion de almacenamiento) también se descargan para SAN. ONTAP usa el método más eficaz basado en el origen, el destino y las licencias de productos instaladas. Esta funcionalidad también la utiliza VMware Horizon View.</block>
  <block id="a603c207c7b5801942ff108502676c12" category="list-text">SRA (usado con VMware Site Recovery Manager). Aquí, se utilizan clones para probar la recuperación de la réplica de recuperación ante desastres de forma no disruptiva.</block>
  <block id="bb300d356d258c084dbe5da2ca367e08" category="list-text">Backup y recuperación de datos con herramientas de NetApp como SnapCenter. Los clones de equipos virtuales se utilizan para verificar las operaciones de backup y montar un backup de equipo virtual para que se puedan copiar archivos individuales.</block>
  <block id="524b5b8bc03312baeafbea86df667c4b" category="paragraph">El clonado descargado de ONTAP puede invocarse con VMware, NetApp y herramientas de terceros. Los clones que se descargan en ONTAP tienen varias ventajas. Ofrecen una gestión eficiente del espacio en la mayoría de los casos, y necesitan almacenamiento solo para los cambios en el objeto; no hay ningún efecto adicional en el rendimiento para leerlos y escribirlos; en algunos casos, el rendimiento mejora si se comparten los bloques en las cachés de alta velocidad. También descargan los ciclos de CPU y las operaciones de I/o de red del servidor ESXi. La descarga de copias en un almacén de datos tradicional mediante un volumen FlexVol puede ser rápida y eficiente con la licencia de FlexClone, pero las copias entre volúmenes FlexVol pueden ser más lentas. Si mantiene las plantillas de equipos virtuales como origen de los clones, considere colocarlas en el volumen del almacén de datos (utilice carpetas o bibliotecas de contenido para organizarlas) para lograr clones rápidos con un uso eficiente del espacio.</block>
  <block id="f3968368501d882b3969da59138db6e2" category="paragraph">También es posible clonar un volumen o LUN directamente en ONTAP para clonar un almacén de datos. Con almacenes de datos NFS, la tecnología FlexClone puede clonar un volumen completo, y el clon se puede exportar desde ONTAP y montar en ESXi como otro almacén de datos. En almacenes de datos VMFS, ONTAP puede clonar una LUN dentro de un volumen o un volumen entero, incluida una o varias LUN dentro de él. Una LUN que contiene un VMFS debe asignarse a un iGroup de ESXi y, a continuación, volver a firmar la bandeja de ESXi para que se monte y utilice como almacén de datos normal. Para algunos casos de uso temporales, se puede montar un VMFS clonado sin renuncias. Una vez que se ha clonado un almacén de datos, los equipos virtuales del interior se pueden registrar, volver a configurar y personalizar como si se clonaran individualmente.</block>
  <block id="2d506b6088a383ccf08479b0f80c0ff4" category="paragraph">En algunos casos, se pueden utilizar otras funciones con licencia para mejorar la clonación, como SnapRestore para backup o FlexClone. Estas licencias se incluyen a menudo en los paquetes de licencias sin coste adicional. Se necesita una licencia de FlexClone para las operaciones de clonado de VVol, así como para admitir Snapshot gestionadas de un VVol (que se descargan del hipervisor a ONTAP). Una licencia de FlexClone también puede mejorar ciertos clones basados en VAAI cuando se usan en un almacén de datos/volumen (crea copias instantáneas con gestión eficiente del espacio en lugar de copias de bloques).  El SRA también usa para probar la recuperación de una réplica de DR, y el SnapCenter para las operaciones de clonado y para buscar copias de backup para restaurar archivos individuales.</block>
  <block id="5dd57c2a315d3af44c2eb40eefc47111" category="doc">Configuración de red</block>
  <block id="66507f357c74ee12194270cfe053b98d" category="paragraph">Estas son algunas cosas a tener en cuenta:</block>
  <block id="7c4904daaa282388097ad83bf382e1a5" category="list-text">Las tramas gigantes se pueden utilizar si se desean y admiten en la red, especialmente si se utiliza iSCSI. Si se usan, asegúrese de que estén configurados de la misma forma en todos los dispositivos de red, VLAN, etc., en la ruta entre el almacenamiento y el host ESXi. De lo contrario, puede que observe problemas de rendimiento o conexión. La MTU también debe establecerse de forma idéntica en el switch virtual ESXi, el puerto de VMkernel y, además, en los puertos físicos o los grupos de interfaces de cada nodo ONTAP.</block>
  <block id="8b6e7f43d1d697e8f99164f0aa2ab1b6" category="inline-link">CONSULTE TR-4182</block>
  <block id="3745abd352adaa2cdec42c798060eef6" category="list-text">NetApp solo recomienda deshabilitar el control de flujo de red en los puertos de red de clúster dentro de un clúster de ONTAP. NetApp no ofrece otras recomendaciones para seguir las prácticas recomendadas para los puertos de red restantes que se usan para el tráfico de datos. Debe activar o desactivar según sea necesario. Consulte<block ref="bdfb81665a0ef86d871a52c0e6ebc591" category="inline-link-rx"></block> para obtener más fondo sobre el control de flujo.</block>
  <block id="730a8287f758961d602b1b050bbe2751" category="list-text">Cuando las cabinas de almacenamiento ESXi y ONTAP están conectadas a redes de almacenamiento Ethernet, NetApp recomienda configurar los puertos Ethernet a los que se conectan estos sistemas como puertos periféricos del protocolo de árbol de expansión rápido (RSTP) o mediante la función PortFast de Cisco. NetApp recomienda habilitar la función de enlace troncal Spanning-Tree PortFast en entornos que utilizan la función Cisco PortFast y que tienen la conexión de enlaces VLAN 802.1Q habilitada tanto para el servidor ESXi como para las cabinas de almacenamiento ONTAP.</block>
  <block id="ac4976538e1fc8726f77afc202561afc" category="list-text">NetApp recomienda las siguientes prácticas recomendadas para la agregación de enlaces:</block>
  <block id="19d137845c7f6687c99b386dfad0aa97" category="list-text">Deshabilite LACP para los puertos del switch conectados a ESXi a menos que utilice dvSwitch 5.1 o una versión posterior con LACP configurado.</block>
  <block id="30254a2bb3e4b3b958b06d08c724e7db" category="list-text">LACP se utiliza para crear agregados de enlaces para sistemas de almacenamiento ONTAP con grupos de interfaces dinámicas multimodo con hash IP.</block>
  <block id="d608421cceb8e4c584a2a32d9127879e" category="list-text">Use una política de agrupación de hash IP en ESXi.</block>
  <block id="2432030fc6183a1a6c52cf5e93f3e9ae" category="paragraph">En la siguiente tabla se ofrece un resumen de los elementos de configuración de red e indica dónde se aplican los ajustes.</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">Elemento</block>
  <block id="1aa66ef3a8e34a7a538960a80d2e1e31" category="cell">ESXi</block>
  <block id="bbc155fb2b111bf61c4f5ff892915e6b" category="cell">Conmutador</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">Nodo</block>
  <block id="0b7e67b6cdcf0432b624d53588d520fb" category="cell">SVM</block>
  <block id="75ba8d70e3692ba200f0e0df37b4d2ae" category="cell">Dirección IP</block>
  <block id="ee6c0f25c2881cc69947a2ef23be5b8c" category="cell">VMkernel</block>
  <block id="e11f298a5bd5344d2d975b5157c27b69" category="cell">No**</block>
  <block id="d6f0876f76c273b8962b749c36153157" category="cell">Agregación de enlaces</block>
  <block id="fabd320b3b2249377e53e93099e27657" category="cell">Switch virtual</block>
  <block id="b1b40427c8eb8d0a083ddb16e250325b" category="cell">No*</block>
  <block id="9881f82f0dd89588831f9d1682bd5492" category="cell">VLAN</block>
  <block id="5fc0d231160fa9650ea5c877f146bbe6" category="cell">VMkernel y grupos de puertos de máquina virtual</block>
  <block id="39a3e05f380e583ae2887c79c7443f11" category="cell">Control de flujo</block>
  <block id="220071ab44b426f80ef21f1c552c363c" category="cell">NIC</block>
  <block id="6f2c08412f489e52a17a30217f50b3c1" category="cell">Árbol expansivo</block>
  <block id="4b1c0df98ba3f3d1681c3c3dbdc97746" category="cell">MTU (para tramas gigantes)</block>
  <block id="7d6feaf896df4a937157d4ee5b91f4e1" category="cell">Conmutador virtual y puerto de VMkernel (9000)</block>
  <block id="0110e50bd8629573701e73a4ba8b056f" category="cell">Sí (configurado como máx.)</block>
  <block id="061ff5255adf00e4ae68469f43a7bf55" category="cell">Sí (9000)</block>
  <block id="bcc0e5a3e08cd34e80692195d056b06d" category="cell">Grupos de conmutación por error</block>
  <block id="a4d1a66a448e327c12d3e287098a31d5" category="cell">Sí (crear)</block>
  <block id="465d5674eb6808b997037470f4dace73" category="cell">Sí (seleccione)</block>
  <block id="ba78d695573c8d4f1205452c675fa539" category="paragraph">*Las LIF de SVM se conectan a puertos, grupos de interfaces o interfaces VLAN que tienen VLAN, MTU y otras configuraciones. Sin embargo, la configuración no se gestiona a nivel de SVM.</block>
  <block id="50ecdab93bf5a2f1bfb4cd8f81b9bd3d" category="paragraph">**Estos dispositivos tienen direcciones IP propias para la administración, pero estas direcciones no se utilizan en el contexto de las redes de almacenamiento ESXi.</block>
  <block id="efd0bde36323238fec688b9cdf0c75a3" category="section-title">SAN (FC, FCoE, NVMe/FC, iSCSI), RDM</block>
  <block id="29cdd488736a6111699f7348320bbed7" category="paragraph">En vSphere hay tres formas de usar LUN de almacenamiento basado en bloques:</block>
  <block id="8982d243303f9d1a8c2470b7d55278e6" category="list-text">Con almacenes de datos VMFS</block>
  <block id="9a0098c8c1be287e8d1da1aaf3bd2e59" category="list-text">Con asignación de dispositivos sin formato (RDM)</block>
  <block id="93e209176746ac6f25c618631a02643b" category="list-text">A medida que una LUN accede y está controlada por un iniciador de software desde un SO invitado de máquina virtual</block>
  <block id="c25dc676ca39a05ee6067ac9a50dbce0" category="paragraph">VMFS es un sistema de archivos en clúster de alto rendimiento que proporciona almacenes de datos que son pools de almacenamiento compartido. Los almacenes de datos VMFS pueden configurarse con LUN a las que se accede mediante espacios de nombres FC, iSCSI, FCoE o NVMe a los que se accede mediante el protocolo NVMe/FC. VMFS permite que cada servidor ESX acceda a las LUN tradicionales de forma simultánea en un clúster. El tamaño máximo de LUN de ONTAP suele ser de 16 TB; por tanto, se crea un almacén de datos VMFS 5 de tamaño máximo de 64 TB (consulte la primera tabla de esta sección) mediante cuatro LUN de 16 TB (los sistemas de cabinas SAN admiten el tamaño máximo de LUN de VMFS de 64 TB). Como la arquitectura de LUN de ONTAP no cuenta con pequeñas profundidades de cola individuales, los almacenes de datos VMFS en ONTAP pueden escalarse a un mayor grado que con las arquitecturas de cabinas tradicionales de forma relativamente sencilla.</block>
  <block id="43f67f108e50dab0978a343603cbfec9" category="paragraph">VSphere incluye compatibilidad incorporada para múltiples rutas a los dispositivos de almacenamiento, conocida como multivía nativa (NMP). NMP puede detectar el tipo de almacenamiento para los sistemas de almacenamiento compatibles y configura automáticamente la pila NMP para admitir las funcionalidades del sistema de almacenamiento en uso.</block>
  <block id="b284ee628d89c3e804c4def2a90f0520" category="paragraph">ESXi 6 admite hasta 256 LUN y hasta 1,024 rutas totales a LUN. ESXi no ve ningún LUN o ruta que supere estos límites. Suponiendo el número máximo de LUN, el límite de rutas permite cuatro rutas por LUN. En un clúster de ONTAP mayor, es posible alcanzar el límite de ruta antes del límite de LUN. Para solucionar esta limitación, ONTAP admite una asignación de LUN selectiva (SLM) en la versión 8.3 y posteriores.</block>
  <block id="8466b1e5abb4751e931c5feb1af4e469" category="inline-link">CONSULTE TR-4080</block>
  <block id="e9e7de5d01d51034d9114fd8f16c9144" category="paragraph">SLM limita los nodos que anuncian rutas a un LUN determinado. NetApp es una práctica recomendada tener al menos un LIF por nodo por SVM y usar SLM para limitar las rutas anunciadas al nodo que aloja la LUN y su partner de alta disponibilidad. Aunque existen otras rutas, no se anuncian por defecto. Es posible modificar las rutas anunciadas con los argumentos de nodo de informes Agregar y quitar dentro de SLM. Tenga en cuenta que las LUN creadas en versiones anteriores a la 8.3 anuncian todas las rutas y necesitan modificarse para anunciar únicamente las rutas a la pareja de alta disponibilidad del host. Para obtener más información sobre SLM, consulte la sección 5.9 de<block ref="c6b12416d518b4689065ffe16afe88db" category="inline-link-rx"></block>. El método anterior de conjuntos de puertos también puede utilizarse para reducir aún más las rutas disponibles para una LUN. Los conjuntos de puertos ayudan a reducir el número de rutas visibles a través de las cuales los iniciadores de un igroup pueden ver LUN.</block>
  <block id="4157f0c23fc104508f492dc846f187f3" category="list-text">SLM está habilitado de forma predeterminada. A menos que utilice conjuntos de puertos, no se requiere ninguna configuración adicional.</block>
  <block id="597f1433ad810b3b86c7ae0f8f95afa8" category="list-text">Para LUN creados antes de Data ONTAP 8.3, ejecute manualmente la ejecución de SLM<block ref="886fd385b633a0746a8a08f8f00c67cd" prefix=" " category="inline-code"></block> Comando para quitar los nodos de generación de informes de LUN y restringir el acceso de las LUN al nodo de propiedad de LUN y a su partner de alta disponibilidad.</block>
  <block id="43919b4d4d6d446ed498e26bff62db84" category="paragraph">Los protocolos de bloque (iSCSI, FC y FCoE) acceden a las LUN utilizando los ID de LUN y los números de serie, junto con nombres únicos. FC y FCoE utilizan nombres globales (WWN y WWPN); iSCSI utiliza nombres completos de iSCSI (IQN). La ruta a las LUN del interior del almacenamiento no tiene sentido para los protocolos de bloque y no se presenta en ningún lugar del protocolo. Por lo tanto, no es necesario montar de forma interna un volumen que solo contiene LUN; por lo tanto, no es necesaria una ruta de unión para los volúmenes que contengan LUN usadas en los almacenes de datos. El subsistema NVMe en ONTAP funciona de manera similar.</block>
  <block id="ed0e76ed86e852bd7317a09d856ec4e8" category="paragraph">Otras prácticas recomendadas a tener en cuenta:</block>
  <block id="93586ad57931e0f16fff61cdba9d77df" category="list-text">Asegúrese de que se crea una interfaz lógica (LIF) para cada SVM en cada nodo del clúster de ONTAP para garantizar la máxima disponibilidad y movilidad. La práctica recomendada para SAN de ONTAP es usar dos puertos físicos y LIF por nodo, uno para cada estructura. ALUA se utiliza para analizar las rutas e identificar las rutas activas optimizadas (directas) en comparación con las rutas activas no optimizadas. ALUA se utiliza para FC, FCoE e iSCSI.</block>
  <block id="b3cebb7381bddbabb1e950a46d264190" category="list-text">En el caso de las redes iSCSI, utilice varias interfaces de red de VMkernel en distintas subredes de la red con la agrupación de NIC cuando haya varios switches virtuales. También puede utilizar varias NIC físicas conectadas a varios switches físicos para proporcionar alta disponibilidad y mayor rendimiento. En la figura siguiente se proporciona un ejemplo de conectividad multivía. En ONTAP, configure un grupo de interfaces de un único modo para realizar la conmutación al nodo de respaldo con dos o más enlaces conectados a dos o más switches, o bien utilice LACP u otra tecnología de agregación de enlaces con grupos de interfaces multimodo para proporcionar alta disponibilidad y las ventajas de la agregación de enlaces.</block>
  <block id="2968b9f3c141bf23bc73d0e6e15a174a" category="list-text">Si el protocolo de autenticación por desafío mutuo (CHAP) se utiliza en ESXi para la autenticación de destino, también debe configurarse en ONTAP mediante la CLI <block ref="199c9b970eacf1c35d84a383b7ceb210" prefix="(" category="inline-code"></block>) O con System Manager (edite Initiator Security en almacenamiento &gt; SVM &gt; SVM Settings &gt; Protocols &gt; iSCSI).</block>
  <block id="d31f2e075df4ca75ca0874fa08f74b12" category="list-text">Utilice las herramientas de ONTAP para VMware vSphere para crear y gestionar LUN y iGroups. El plugin determina automáticamente los WWPN de los servidores y crea iGroups adecuados. También configura las LUN de acuerdo con las prácticas recomendadas y las asigna a los iGroups correctos.</block>
  <block id="de78559e8aed2cd62fbf852f73dc58c2" category="inline-link">modo de compatibilidad físico y virtual</block>
  <block id="905221150fdd103b5241870a0a1f2c42" category="list-text">Use los DMR con cuidado porque pueden ser más difíciles de manejar, y también usan rutas, que son limitadas como se describió anteriormente. Las LUN de ONTAP son compatibles con ambos<block ref="27e1f8e5a88cfbb2836b083145b004c9" category="inline-link-rx"></block> RDM.</block>
  <block id="636da39a2033c6179a718983c5ce1222" category="inline-link">Guía de configuración de hosts ONTAP NVMe/FC</block>
  <block id="81ef6507a13da5635951bc5b533deb59" category="inline-link">CONSULTE TR-4684</block>
  <block id="15483b0826bb9a4b11d1c89af2029c5c" category="list-text">Para obtener más información sobre cómo usar NVMe/FC con vSphere 7.0, consulte este tema<block ref="6b4ed262d14e47ef641cd57b65c32c38" category="inline-link-rx"></block> y..<block ref="7a29b2f31035a451d5b068728d2b79a7" category="inline-link-rx"></block>.En la siguiente figura, se muestra la conectividad multivía de un host de vSphere a un LUN de ONTAP.</block>
  <block id="f9fd9ea22ea7a2e8ec9e95254a449831" category="paragraph"><block ref="f9fd9ea22ea7a2e8ec9e95254a449831" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a693e1f056b96566c4551fcab418f2" category="paragraph">VSphere permite a los clientes utilizar cabinas NFS de nivel empresarial para proporcionar acceso simultáneo a los almacenes de datos en todos los nodos de un clúster ESXi. Como hemos mencionado en la sección de almacenes de datos, existen algunas ventajas de facilidad de uso y visibilidad de la eficiencia del almacenamiento al usar NFS con vSphere.</block>
  <block id="743fa5a7bc7d4ba215b096e34779d298" category="paragraph">Las siguientes prácticas recomendadas se recomiendan al usar NFS de ONTAP con vSphere:</block>
  <block id="c05061b6d3055b83136fa96cb38f0f9a" category="list-text">Utilice una sola interfaz lógica (LIF) para cada SVM en cada nodo del clúster de ONTAP. Ya no son necesarias las recomendaciones anteriores de una LIF por almacén de datos. Aunque el acceso directo (LIF y almacén de datos en el mismo nodo) es el mejor, no se preocupe por el acceso indirecto, ya que el efecto sobre el rendimiento suele ser mínimo (microsegundos).</block>
  <block id="7b997b3be9c993d49799dd9d71d8c3f6" category="list-text">VMware ha sido compatible con NFSv3 desde VMware Infrastructure 3. VSphere 6.0 ha añadido compatibilidad con NFSv4.1, lo cual permite algunas funcionalidades avanzadas, como la seguridad de Kerberos. Donde NFSv3 utiliza el bloqueo del lado del cliente, NFSv4.1 utiliza el bloqueo del lado del servidor. Aunque un volumen ONTAP se puede exportar mediante ambos protocolos, ESXi solo se puede montar a través de un único protocolo. Este montaje de protocolo único no excluye que otros hosts ESXi monten el mismo almacén de datos a través de una versión diferente. Asegúrese de especificar la versión del protocolo que se va a utilizar al montar para que todos los hosts utilicen la misma versión y, por lo tanto, el mismo estilo de bloqueo. No mezcle versiones de NFS entre hosts. Si es posible, utilice perfiles de host para comprobar el cumplimiento.</block>
  <block id="ae4c5baa79e370d8f601cc7082f8123e" category="list-text">Dado que no existe ninguna conversión automática de almacenes de datos entre NFSv3 y NFSv4.1, cree un nuevo almacén de datos NFSv4.1 y utilice Storage vMotion para migrar las máquinas virtuales al nuevo almacén de datos.</block>
  <block id="8065bff4940ae8d7161f926b0df47ac4" category="inline-link">Herramienta de matriz de interoperabilidad de NetApp</block>
  <block id="24aaa4a688e881fa13d31656a85d40a9" category="list-text">Los hosts de vSphere utilizan políticas de exportación de NFS para controlar el acceso. Puede usar una política con varios volúmenes (almacenes de datos). Con NFSv3, ESXi utiliza el estilo de seguridad sys (UNIX) y requiere la opción de montaje raíz para ejecutar las máquinas virtuales. En ONTAP, esta opción se denomina superusuario y cuando se utiliza la opción superusuario, no es necesario especificar el ID de usuario anónimo. Tenga en cuenta que las reglas de política de exportación con valores diferentes para<block ref="ea72d12ecaa06afdb0c8a3b15e485e95" prefix=" " category="inline-code"></block> y..<block ref="df809a941c1287d18c08bb5927b639dc" prefix=" " category="inline-code"></block> Puede causar problemas de detección de SVM con las herramientas de ONTAP. He aquí una política de ejemplo:</block>
  <block id="69abbd5c7cd9c1b3828b9aa5a894ff47" category="list-text">Especificación de coincidencia de cliente: 192.168.42.21</block>
  <block id="bd6cc42f9cd65cca72cbd56d2f4bf43d" category="list-text">Regla DE ACCESO DE RO: Sys</block>
  <block id="581c470a5099548fc9865a4bab8761f8" category="list-text">Regla de acceso RW: Sys</block>
  <block id="0bbc71e6a4ea49af70dd616d3807e524" category="list-text">UID anónimo</block>
  <block id="59d5d8c898df18115bd4ced36c6bc0de" category="list-text">Superusuario: Sys</block>
  <block id="6670a317619282ec228a9ef492af0a76" category="list-text">Los volúmenes de almacenes de datos NFS se unen desde el volumen raíz de la SVM; por lo tanto, ESXi también debe tener acceso al volumen raíz para navegar y montar volúmenes de almacenes de datos. La política de exportación del volumen raíz y para cualquier otro volumen en el que esté anidada la unión del volumen de almacenes de datos, debe incluir una regla o reglas para los servidores ESXi que les otorgan acceso de solo lectura. A continuación, se muestra una política de ejemplo para el volumen raíz, que también utiliza el complemento VAAI:</block>
  <block id="8c93fb3ff528165613797962f5a0ed9c" category="list-text">Protocolo de acceso: nfs (que incluye nfs3 y nfs4)</block>
  <block id="80e6a4f964e826c69c1c62bd5ea67590" category="list-text">Regla de acceso RW: Nunca (mejor seguridad para el volumen raíz)</block>
  <block id="f96625174b4a06d13267f9b0a5a96d59" category="list-text">Superusuario: Sys (también necesario para el volumen raíz con VAAI)</block>
  <block id="4c571520a8128d1692fc709ffbfb2b1e" category="list-text">Use las herramientas de ONTAP para VMware vSphere (las mejores prácticas más importantes):</block>
  <block id="b8d278c6184cb65727ca5ae729db92d7" category="list-text">Utilice herramientas de ONTAP para VMware vSphere para aprovisionar almacenes de datos, ya que simplifica la gestión de políticas de exportación de forma automática.</block>
  <block id="23aa7b9aeed3fba2a1ec43e630313af7" category="list-text">Cuando se crean almacenes de datos para clústeres de VMware con el plugin, seleccione el clúster en lugar de un único servidor ESX. Esta opción la activa para montar automáticamente el almacén de datos en todos los hosts del clúster.</block>
  <block id="e4e62770daaf9887c7868fbc8e248a4b" category="list-text">Utilice la función de montaje de plugins para aplicar almacenes de datos existentes a servidores nuevos.</block>
  <block id="928562eb576ed6ae31cb1a149d3e751a" category="list-text">Si no se utilizan las herramientas de ONTAP para VMware vSphere, utilice una única política de exportación para todos los servidores o para cada cluster de servidores donde se necesite un control de acceso adicional.</block>
  <block id="7bccab0fa4c0864835c645c9fde7ebf6" category="list-text">Aunque ONTAP ofrece una estructura de espacio de nombres de volúmenes flexibles para organizar los volúmenes en un árbol mediante uniones, este enfoque no tiene valor para vSphere. Crea un directorio para cada equipo virtual en la raíz del almacén de datos, independientemente de la jerarquía de espacio de nombres del almacenamiento. Por lo tanto, la práctica recomendada es simplemente montar la ruta de unión para volúmenes para vSphere en el volumen raíz de la SVM, que es la forma en que las herramientas de ONTAP para VMware vSphere aprovisiona almacenes de datos. No tener rutas de unión anidadas también significa que ningún volumen depende de ningún otro volumen que no sea el volumen raíz y que el hecho de desconectar un volumen o destruirlo, incluso intencionalmente, no afecta la ruta a otros volúmenes.</block>
  <block id="ea6fc1288f1d3b21238d29ff28cb867a" category="list-text">El tamaño de bloque de 4K se ajusta a las particiones NTFS en almacenes de datos NFS. En la siguiente figura, se muestra la conectividad de un host vSphere a un almacén de datos NFS de ONTAP.</block>
  <block id="16c864cb4f3b00c59e1124932e49f342" category="paragraph"><block ref="16c864cb4f3b00c59e1124932e49f342" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e54433644e830ed1503561b778e9ded4" category="paragraph">En la siguiente tabla, se enumeran las versiones de NFS y las funciones compatibles.</block>
  <block id="9fb9dac7513c7ef8452aade8a52ad40d" category="cell">Funciones de vSphere</block>
  <block id="5b12ee0369243579651edca43ff65c85" category="cell">NFSv3</block>
  <block id="de841868c2911da76b8ae2da9fa3166d" category="cell">NFSv4,1</block>
  <block id="64e3cc476958b05086721cd6070004cf" category="cell">VMotion y Storage vMotion</block>
  <block id="05807e454c19f244770adae059b3c330" category="cell">Alta disponibilidad</block>
  <block id="45a75e44a713fdf94dbf1dbaa0749188" category="cell">Tolerancia a fallos</block>
  <block id="f1e3446c69e4d87279ff7863482f9dcb" category="cell">DRS</block>
  <block id="6ca09f98e8925b2cb78bbf24eccc0186" category="cell">Perfiles de host</block>
  <block id="ec8420797e3b089812499cce4047ded8" category="cell">DRS de almacenamiento</block>
  <block id="7c19bf1cbe62a87a42857ef0b4fe22ae" category="cell">Control de la actividad de I/o de almacenamiento</block>
  <block id="56d43ad1a280ada5e16fd2960ae44b32" category="cell">SRM</block>
  <block id="d595c8f30866b71ea121ced5cde66b1d" category="cell">Volúmenes virtuales</block>
  <block id="6ad5114acf73f68a85c72f11646920cb" category="cell">Aceleración de hardware (VAAI)</block>
  <block id="ad37ded9046268d8e5ea7cb253bb5dda" category="cell">Autenticación Kerberos</block>
  <block id="45701e6ef9bc09dca07f8f4abe661dc6" category="cell">Sí (mejorada con vSphere 6.5 y versiones posteriores para ser compatible con AES, krb5i)</block>
  <block id="76969a36155d2f41fc6cc3bd3faff244" category="cell">Compatibilidad con accesos múltiples</block>
  <block id="be0ec3d9251292dd856ea0924ecc6873" category="doc">Calidad de servicio (QoS)</block>
  <block id="8fdd6138f63aa45f1c51b48d9a01b19d" category="paragraph">Los límites de rendimiento son útiles para controlar las cargas de trabajo desconocidas o de prueba antes de la implementación para asegurarse de que no afecten a otras cargas de trabajo. También se pueden utilizar para limitar una carga de trabajo abusivas una vez que se identifica. También admite niveles mínimos de servicio basados en IOPS para proporcionar un rendimiento constante para los objetos SAN en ONTAP 9.2 y para los objetos NAS en ONTAP 9.3.</block>
  <block id="3e4a2dc31acddb628ba286d25b1bd36e" category="paragraph">Con un almacén de datos NFS, se puede aplicar una política de calidad de servicio a todo el volumen FlexVol o a archivos VMDK individuales en el mismo. Con almacenes de datos VMFS que utilizan LUN de ONTAP, las políticas de calidad de servicio se pueden aplicar al volumen de FlexVol que contiene los LUN o LUN individuales, pero no archivos VMDK individuales porque ONTAP no reconoce el sistema de archivos VMFS. Al utilizar vVols, se puede establecer una calidad de servicio mínima o máxima en equipos virtuales individuales usando el perfil de capacidad de almacenamiento y la política de almacenamiento de equipos virtuales.</block>
  <block id="534ecd446aac2f9c809eef9064f44aab" category="paragraph">El límite máximo de rendimiento de calidad de servicio en un objeto se puede establecer en Mbps o IOPS. Si se utilizan ambos, ONTAP aplica el primer límite alcanzado. Una carga de trabajo puede contener varios objetos y una política de calidad de servicio se puede aplicar a una o más cargas de trabajo. Cuando se aplica una política a varias cargas de trabajo, las cargas de trabajo comparten el límite total de la política. No se admiten los objetos anidados (por ejemplo, los archivos de un volumen no pueden tener cada uno su propia política). Los valores mínimos de calidad de servicio solo se pueden establecer en IOPS.</block>
  <block id="040f184b126879657b253b6d258661d9" category="paragraph">Las siguientes herramientas están disponibles en este momento para gestionar las políticas de calidad de servicio de ONTAP y aplicarlas a los objetos:</block>
  <block id="de134183bea5df515a6756a539ce6f18" category="list-text">CLI de ONTAP</block>
  <block id="6ad5e0a20f49ad6a370454bb3afc9a9e" category="list-text">System Manager de ONTAP</block>
  <block id="8e23e05fc0865e950d6a3581e0dd8ce9" category="list-text">OnCommand Workflow Automation</block>
  <block id="5ecb6b24c169667ff1a176768115659e" category="list-text">Active IQ Unified Manager</block>
  <block id="8cc4e713850f67a131e9dbf8b997f61e" category="list-text">Kit de herramientas NetApp PowerShell para ONTAP</block>
  <block id="fcdb48d0d22627e4910a8352c80bd87a" category="list-text">Herramientas de ONTAP para VASA Provider de VMware vSphere</block>
  <block id="e6defd03e0f49585b6d47614713e97f7" category="paragraph">Para asignar una política de calidad de servicio a un VMDK en NFS, tenga en cuenta las siguientes directrices:</block>
  <block id="10509998e8d4c4d7be30fc1d0b6b2a1e" category="list-text">La política debe aplicarse a la<block ref="a1bb63c284b58c32f1afb554a12e3e9a" prefix=" " category="inline-code"></block> que contiene la imagen del disco virtual real, no la<block ref="aa26c73336ecfd98ed727b3e249c7f90" prefix=" " category="inline-code"></block> (archivo de descriptor de disco virtual) o.<block ref="092eb4dd2ca488962f4c22b3e8cc4ca0" prefix=" " category="inline-code"></block> (Archivo descriptor de máquina virtual).</block>
  <block id="2175e0e29bc4b213fa8b9c7afd591b6b" category="list-text">No aplique políticas a otros archivos del equipo virtual, como archivos de intercambio virtual <block ref="aa33c3c1850a3f99cec7426e2c411d08" prefix="(" category="inline-code"></block>).</block>
  <block id="8230e9b5c1e9862fedb2c69f7cc5d3d1" category="list-text">Cuando utilice el cliente web de vSphere para buscar rutas de archivos (Datastore &gt; Files), tenga en cuenta que combina la información del<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block> y..<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> y simplemente muestra un archivo con el nombre del<block ref="4a78be158c13cd6b2dc2100a80bb7070" prefix=" " category="inline-code"></block> pero el tamaño del<block ref="f149d7424e10a266ec998ca5b32b81bb" prefix=" " category="inline-code"></block>. Agregar<block ref="4fc4e556dbb9dcede037ccd80fabd784" prefix=" " category="inline-code"></block> en el nombre del archivo para obtener la ruta correcta.</block>
  <block id="1d4614aca13104c98d5d8cc2d415b941" category="paragraph">Para asignar una normativa de calidad de servicio a un LUN, incluidos VMFS y RDM, la SVM de ONTAP (mostrada como Vserver), la ruta de LUN y el número de serie pueden obtenerse en el menú sistemas de almacenamiento de la página de inicio de ONTAP Tools para VMware vSphere. Seleccione el sistema de almacenamiento (SVM) y, a continuación, Related Objects &gt; SAN.  Use este enfoque cuando especifique la calidad de servicio mediante una de las herramientas de ONTAP.</block>
  <block id="cc97a1a52adc0bd6f188de1545eea887" category="paragraph">La calidad de servicio máxima y mínima se puede asignar fácilmente a una máquina virtual basada en VVol con las herramientas de ONTAP para VMware vSphere o Virtual Storage Console 7.1 y versiones posteriores. Al crear el perfil de funcionalidad de almacenamiento para el contenedor de VVol, especifique un valor de IOPS máximo y/o mínimo con la funcionalidad de rendimiento y, a continuación, haga referencia a este SCP con la política de almacenamiento de la máquina virtual. Use esta política cuando cree la máquina virtual o aplique la política a una máquina virtual existente.</block>
  <block id="421c9efa4ff1b039a5378be7bc1e2e49" category="paragraph">Los almacenes de datos de FlexGroup ofrecen funcionalidades de calidad de servicio mejoradas al usar las herramientas de ONTAP para VMware vSphere 9.8 y versiones posteriores. Puede establecer fácilmente la calidad de servicio en todas las máquinas virtuales de un almacén de datos o en máquinas virtuales específicas. Consulte la sección FlexGroup de este informe para obtener más información.</block>
  <block id="77bb2ba950959bd3f1c55da523ace0be" category="section-title">ONTAP QoS y VMware SIOC</block>
  <block id="b2e21dac6070ea83831ff6521a66a447" category="paragraph">QoS de ONTAP y VMware vSphere Storage I/o Control (SIOC) son tecnologías complementarias que los administradores de vSphere y almacenamiento pueden utilizar juntos para gestionar el rendimiento de máquinas virtuales vSphere alojadas en sistemas que ejecutan el software ONTAP. Cada herramienta tiene sus propias fuerzas, como se muestra en la siguiente tabla. Debido a los distintos ámbitos de VMware vCenter y ONTAP, algunos objetos pueden verse y gestionarse mediante un sistema, no el otro.</block>
  <block id="5ad234cb2cde4266195252a23ca7d84e" category="cell">Propiedad</block>
  <block id="b8b8d1ba8fa345f03438a90f29af5784" category="cell">Calidad de servicio de ONTAP</block>
  <block id="c2a4cb962db2a4a6782b69864f0e411c" category="cell">VMware SIOC</block>
  <block id="aa628d5a66888444926b4dc042458200" category="cell">Cuando está activo</block>
  <block id="688b10fcfff927dee65634e3b3636064" category="cell">La directiva está siempre activa</block>
  <block id="a981c4aa67c29ff2d36fc614d8b28808" category="cell">Activo cuando existe una contención (latencia por encima del umbral de los almacenes de datos)</block>
  <block id="f46e64a82c96db56f3d6657d4fb53f00" category="cell">Tipo de unidades</block>
  <block id="878b4223bb85b95d8caf0429d9406cd5" category="cell">IOPS, Mbps</block>
  <block id="3e189a34f422a141311dad231f9ad5b5" category="cell">IOPS, recursos compartidos</block>
  <block id="7367a0ec46339213625cbc77d56a9572" category="cell">Alcance de vCenter o aplicaciones</block>
  <block id="1faff19290bb64ce8ff6bc1220496881" category="cell">Varios entornos de vCenter, otros hipervisores y aplicaciones</block>
  <block id="1e664a3cc0ab109fcabcc81b488cebb1" category="cell">Un único servidor vCenter</block>
  <block id="ebccc9f5c939841d86e5382988dfcc47" category="cell">¿Establecer QoS en la máquina virtual?</block>
  <block id="cddd0980ce99890d2ea90288f6b03117" category="cell">VMDK solo en NFS</block>
  <block id="928629d8a2a889f5274cad9940a06da0" category="cell">VMDK en NFS o VMFS</block>
  <block id="305e85b992089534091855224f60cf75" category="cell">¿Establecer QoS en el LUN (RDM)?</block>
  <block id="e798014243cf5682e7fb3aaf4ee7cecf" category="cell">¿Configurar QoS en LUN (VMFS)?</block>
  <block id="9cd021ea9d3c88de723fe9a2e50a2380" category="cell">¿Configurar calidad de servicio en el volumen (almacén de datos NFS)?</block>
  <block id="c352b53c32380efcf4436926da6d0414" category="cell">¿Configurar la calidad de servicio en SVM (inquilino)?</block>
  <block id="5dad340ee8f9e8fa9b65bf86a9fd5341" category="cell">¿Enfoque basado en políticas?</block>
  <block id="b31c76176f26196c6379a9bcce212d99" category="cell">Sí, pueden compartirse todas las cargas de trabajo de la política o aplicarse por completo a cada carga de trabajo de la política.</block>
  <block id="1ff33557bad923d68973872cacf2e43a" category="cell">Sí, con vSphere 6.5 y posterior.</block>
  <block id="d5f1465492190ee9d30a09b36f64f4b7" category="cell">Se requiere licencia</block>
  <block id="4cec76d82991abd453484c23f7e3788a" category="cell">Incluido con ONTAP</block>
  <block id="6bb36803f4670824ff9ebdf665654829" category="cell">Enterprise Plus</block>
  <block id="d4d4b5b65bebf236590d70c702a6ba6b" category="paragraph">El planificador de recursos distribuidos de almacenamiento (SDRS) de VMware es una función de vSphere que coloca los equipos virtuales en el almacenamiento en función de la latencia de I/o actual y el uso del espacio. A continuación, mueve la máquina virtual o los VMDK de forma no disruptiva entre los almacenes de datos de un clúster de almacenes de datos (también conocido como "pod"), seleccionando el mejor almacén de datos en el que colocar la máquina virtual o los VMDK en el clúster de almacenes de datos. Un clúster de almacenes de datos es una colección de almacenes de datos similares que se agregan en una única unidad de consumo desde la perspectiva del administrador de vSphere.</block>
  <block id="01e838e1c124042f75adb374a81f72a6" category="paragraph">Las API de VMware vSphere para la conciencia de almacenamiento (VASA) facilitan que el administrador de almacenamiento pueda configurar almacenes de datos con funcionalidades bien definidas y permiten que el administrador de equipos virtuales las utilice siempre que lo necesite para aprovisionar equipos virtuales sin tener que interactuar entre sí. Merece la pena echar un vistazo a este enfoque para ver cómo puede optimizar sus operaciones de almacenamiento de virtualización y evitar un gran trabajo trivial.</block>
  <block id="0ce8b0e3e0d7dc7f39c62fb74a28b3bf" category="section-title">Migración al cloud y backup</block>
  <block id="4fe11b4a91ff38ec9933009a15dd5b0b" category="paragraph">Otra ventaja de ONTAP es la amplia compatibilidad con el cloud híbrido, al fusionar sistemas en el cloud privado local con funcionalidades de cloud público. Estas son algunas de las soluciones cloud de NetApp que se pueden usar junto con vSphere:</block>
  <block id="e18ab5f123ad4ce169202479f07f3f0f" category="list-text">* Cloud Volumes.* NetApp Cloud Volumes Service para Amazon Web Services o Google Cloud Platform y Azure NetApp Files para ANF proporcionan servicios de almacenamiento gestionados multiprotocolo y de alto rendimiento en los principales entornos de cloud público. Los pueden utilizar directamente los invitados de VMware Cloud VM.</block>
  <block id="2a11701c0c01affc0ce96eb0d0c16ed9" category="list-text">*Servicios en la nube.* Utilice Cloud Backup Service o SnapMirror Cloud para proteger los datos de sistemas en las instalaciones mediante almacenamiento en cloud público. Cloud Sync le ayuda a migrar y mantener sus datos sincronizados a través de NAS, almacenes de objetos y almacenamiento Cloud Volumes Service.</block>
  <block id="99c6c4d349151c1f4a6694e424aef741" category="inline-link">Almacenar más snapshots de sus máquinas virtuales</block>
  <block id="01fa297dbdab5aceb83a45a98161efe0" category="list-text">*FabricPool.* FabricPool ofrece una organización en niveles rápida y fácil para los datos de ONTAP. Los bloques inactivos se pueden migrar a un almacén de objetos en clouds públicos o en un almacén de objetos de StorageGRID privado y se recuerdan automáticamente cuando se vuelve a acceder a los datos de ONTAP. También puede usar el nivel de objeto como un tercer nivel de protección para los datos que ya está gestionado por SnapVault. Este enfoque le permite<block ref="60d027dbb3c3f076cbb70c6b246eb433" category="inline-link-rx"></block> En sistemas de almacenamiento ONTAP principales o secundarios</block>
  <block id="1a7072854c9dd945a98f4314b3f77408" category="list-text">*ONTAP Select.* Utilice el almacenamiento definido por software de NetApp para ampliar su cloud privado a través de Internet a instalaciones y oficinas remotas, donde puede utilizar ONTAP Select para ofrecer compatibilidad con servicios de bloques y archivos, así como las mismas funcionalidades de gestión de datos vSphere que tiene en su centro de datos empresarial.</block>
  <block id="79aec220098057ef8c0e46281a45d6c2" category="paragraph">A la hora de diseñar sus aplicaciones basadas en máquinas virtuales, tenga en cuenta la movilidad del cloud futura. Por ejemplo, en lugar de colocar los archivos de datos y aplicaciones en conjunto, utilizan una exportación de NFS o LUN independiente para los datos. Esto permite migrar la máquina virtual y los datos por separado a los servicios de cloud.</block>
  <block id="af63597853dc0983258c8f86a12aae0b" category="section-title">Cifrado para datos de vSphere</block>
  <block id="63a07ab9352c9297cea3894d6cd41c3f" category="paragraph">Hoy en día, hay cada vez más demandas de protección de los datos en reposo mediante el cifrado. Aunque el foco inicial era la información financiera y de atención sanitaria, existe un creciente interés en proteger toda la información, ya sea en archivos, bases de datos u otros tipos de datos.</block>
  <block id="f131c8f285a9ebc44140235877aecbe5" category="paragraph">Los sistemas que ejecutan el software ONTAP facilitan la protección de cualquier dato con el cifrado en reposo. El cifrado de almacenamiento de NetApp (NSE) utiliza unidades de disco de cifrado automático con ONTAP para proteger datos SAN y NAS. NetApp también ofrece el cifrado de volúmenes de NetApp y el cifrado de agregados de NetApp como un método sencillo basado en software para cifrar volúmenes en cualquier unidad de disco. Este cifrado de software no requiere unidades de disco especiales ni gestores de claves externos y está disponible para los clientes de ONTAP sin coste adicional. Puede realizar una actualización y empezar a utilizarla sin interrupciones en los clientes o las aplicaciones, y ha sido validada según el estándar de nivel 1 de FIPS 140-2-2, incluido el gestor de claves incorporado.</block>
  <block id="937a352e0f824ff55e4cd50c8e3b051e" category="paragraph">Existen varios métodos para proteger los datos de las aplicaciones virtualizadas que se ejecutan en VMware vSphere. Uno de los métodos consiste en proteger los datos con software dentro de los equipos virtuales a nivel de SO «guest». Los hipervisores más recientes, como vSphere 6.5, ahora admiten el cifrado a nivel de equipo virtual como otra alternativa. Sin embargo, el cifrado del software de NetApp es simple y fácil y tiene estas ventajas:</block>
  <block id="6eda79cc710edc32583cf567b00e7672" category="list-text">*Sin efecto sobre la CPU del servidor virtual.* algunos entornos de servidor virtual necesitan todos los ciclos de CPU disponibles para sus aplicaciones, aunque las pruebas han demostrado que se necesitan hasta 5 veces los recursos de CPU con cifrado a nivel de hipervisor. Incluso si el software de cifrado admite el conjunto de instrucciones AES-NI de Intel para descargar la carga de trabajo de cifrado (como lo hace el cifrado de software NetApp), este enfoque podría no ser factible debido a la necesidad de nuevas CPU que no son compatibles con servidores antiguos.</block>
  <block id="6abee98aea26f85e6f0fe8d4db70f998" category="list-text">*Incluye el gestor de claves incorporado.* el cifrado de software de NetApp incluye un gestor de claves incorporado sin coste adicional, lo que facilita su introducción sin servidores de gestión de claves de alta disponibilidad complejos de adquirir y usar.</block>
  <block id="c216121021de8554d33503ef6616b256" category="list-text">*No afecta a la eficiencia del almacenamiento.* las técnicas de eficiencia del almacenamiento como la deduplicación y la compresión se utilizan ampliamente hoy en día y son clave para utilizar medios de disco flash de forma rentable. Sin embargo, por lo general, los datos cifrados no se pueden deduplicar o comprimir. El cifrado de almacenamiento y hardware de NetApp funciona a un nivel inferior y permite el uso completo de funciones de eficiencia del almacenamiento de NetApp, líderes del sector, a diferencia de otros métodos.</block>
  <block id="5f9aa8333f218d1c21e67c8608a48672" category="list-text">*Cifrado granular sencillo del almacén de datos.* con el cifrado de volúmenes de NetApp, cada volumen obtiene su propia clave AES de 256 bits. Si necesita cambiarlo, puede hacerlo con un solo comando. Este método es genial si tiene varios clientes o necesita probar el cifrado independiente para diferentes departamentos o aplicaciones. Este cifrado se gestiona a nivel de almacén de datos, lo cual es mucho más fácil que gestionar equipos virtuales individuales.</block>
  <block id="de2b3baa1cd4980c36e8bbf7c827ae0c" category="paragraph">Es fácil empezar a utilizar el cifrado de software. Después de instalar la licencia, solo tiene que configurar el gestor de claves incorporado especificando una frase de acceso y luego crear un volumen nuevo o mover un volumen en el almacenamiento para habilitar el cifrado. NetApp está trabajando para añadir compatibilidad más integrada con funcionalidades de cifrado en futuros lanzamientos de sus herramientas de VMware.</block>
  <block id="c95fa5b56a01e5c1a80c540c1ab1a750" category="paragraph">Active IQ Unified Manager proporciona visibilidad de los VM en su infraestructura virtual y permite supervisar y solucionar los problemas de almacenamiento y rendimiento en su entorno virtual.</block>
  <block id="be75250c2f30870dc1e359b4ade2a767" category="paragraph">Una infraestructura virtual típica puesta en marcha en ONTAP tiene diversos componentes que se distribuyen en las capas informática, de red y de almacenamiento. Cualquier retraso en el rendimiento de una aplicación de equipo virtual puede producirse debido a una combinación de latencias que deben afrontar los distintos componentes de las capas respectivas.</block>
  <block id="d1734f6f2e65a1488896f74695db5254" category="paragraph">La siguiente captura de pantalla muestra la vista Máquinas virtuales de Active IQ Unified Manager.</block>
  <block id="2118336fa447fcc0f213cb8c40c516af" category="paragraph">Unified Manager presenta el subsistema subyacente de un entorno virtual en una vista topológica para determinar si se ha producido un problema de latencia en el nodo de computación, la red o el almacenamiento. La vista también destaca el objeto específico que provoca el desfase en el rendimiento a la hora de dar pasos correctivas y solucionar el problema subyacente.</block>
  <block id="d8a78b994fcd4e04901203a2e7bc6414" category="paragraph">La siguiente captura de pantalla muestra la topología ampliada de AIUM.</block>
  <block id="f02207fb26160d7e47cf5ea35d07df03" category="doc">Almacenes de datos y protocolos</block>
  <block id="af8dcb8c7a1e8b7e614e570806d8dcee" category="paragraph">Se utilizan siete protocolos para conectar VMware vSphere a almacenes de datos en un sistema que ejecuta el software ONTAP:</block>
  <block id="a7c815fafe60ae637d38216fa6300395" category="list-text">FCP</block>
  <block id="14eae6ee278098bfad4f8a10fd6c1195" category="list-text">FCoE</block>
  <block id="26bcb9f1cb6f391f4b2c18e676bb458d" category="list-text">NVMe/FC</block>
  <block id="8b7c42123642e2e4ea7dd426aeb2de58" category="list-text">NVMe/TCP</block>
  <block id="e4e1c13bb0b14f6cb7608cbecea948ef" category="list-text">ISCSI</block>
  <block id="f7d773fd2896401c143676940bc001fc" category="list-text">NFS v3</block>
  <block id="0b99b245267ef194ca3b9f6e694b0983" category="list-text">NFS v4,1</block>
  <block id="cfa070ed8af17c3125cfd1530fbd387a" category="paragraph">FCP, FCoE, NVMe/FC, NVMe/TCP e iSCSI son protocolos de bloque que usan el sistema de archivos de máquina virtual de vSphere (VMFS) para almacenar máquinas virtuales en LUN de ONTAP o espacios de nombres NVMe que se encuentran en un volumen ONTAP FlexVol. Tenga en cuenta que, a partir de vSphere 7.0, VMware ya no es compatible con el software FCoE en entornos de producción. NFS es un protocolo de archivos que coloca equipos virtuales en almacenes de datos (que son simplemente volúmenes de ONTAP) sin necesidad de VMFS. SMB (CIFS), iSCSI, NVMe/TCP o NFS también se puede utilizar directamente de un sistema operativo invitado a ONTAP.</block>
  <block id="2b19cb432f68f1ba3dc7b0f175a14778" category="inline-link">Máximos de configuración de VMware</block>
  <block id="f8ca1b19553d4c965e40e9eeb1eb5aca" category="paragraph">Las siguientes tablas presentan funciones de almacén de datos tradicionales compatibles con vSphere con ONTAP. Esta información no se aplica a almacenes de datos vVols, pero, generalmente, se aplica a vSphere 6.x y versiones posteriores mediante versiones ONTAP compatibles. También puede consultar<block ref="61b579b455015dfa2bbf16bf62f07f93" category="inline-link-rx"></block> En versiones específicas de vSphere para confirmar límites específicos.</block>
  <block id="9da73946f1bc3be4a41898d06c9d2e8b" category="cell">Característica/función</block>
  <block id="c982f804d02e2d7e937f125d2cac1024" category="cell">FC/FCoE</block>
  <block id="6151632541dcd80356c6c76b34d69d0c" category="cell">NVMe-of</block>
  <block id="520d0db389f362bf79ef56ca0af3dcab" category="cell">Formato</block>
  <block id="99a3142584ca8ad0a3afadeaa6f2ef69" category="cell">Asignación de dispositivo sin formato (RDM) o VMFS</block>
  <block id="26aae26f61844ac20ab7b04ba6f5c515" category="cell">VMFS o RDM</block>
  <block id="18263a30df8afc60a733e59c60676ac0" category="cell">VMFS</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">N.A.</block>
  <block id="8dc6d0c66219ddb809322c0d248e55e6" category="cell">Número máximo de almacenes de datos o LUN</block>
  <block id="aa23f9914ce1939ea7a4d479edfdc915" category="cell">1024 LUN por host</block>
  <block id="1af3b27207afc48a363629a315d76b59" category="cell">1024 LUN por servidor</block>
  <block id="0705fd627c25b5fba17cd9a022ed7d72" category="cell">256 nombres por servidor</block>
  <block id="2774ddb6f193789c5d9a480b9e53a38d" category="cell">256 montajes
NFS predeterminado. MaxVolumes tiene 8 años. Utilice las herramientas de ONTAP para VMware vSphere para aumentar a 256.</block>
  <block id="51c0dc217976e27de06e262947947a62" category="cell">Tamaño máximo de almacén de datos</block>
  <block id="856c997f909830b8249756c07dc9452b" category="cell">64 TB</block>
  <block id="8e5d3a4b085389c59a1a7af7c4067a9b" category="cell">100 TB de volumen FlexVol o superior con volumen FlexGroup</block>
  <block id="b4fb1d41fedaec79072964cbb4d16e3d" category="cell">Tamaño máximo de archivo del almacén de datos</block>
  <block id="d10549beb2f7bd1e91e5ef8965edd84a" category="cell">62 TB</block>
  <block id="18301e675ce7d51c23071d7b135edbdc" category="cell">62TB con ONTAP 9.12.1P2 y posterior</block>
  <block id="9aa56a79640231adaec83bc53e59c929" category="cell">Profundidad de cola óptima por LUN o sistema de archivos</block>
  <block id="c7dfde106afbb4e1d55096403af252e0" category="cell">64-256</block>
  <block id="ca6e77250a239af7b4aed9a1ac058825" category="cell">Autonegociar</block>
  <block id="edc5121cb9b42a76b718b8ece9d67437" category="paragraph">En la siguiente tabla se enumeran las funcionalidades relacionadas con el almacenamiento de VMware admitidas.</block>
  <block id="6c1a84b789b54fd42511ce582be94d21" category="cell">VMotion</block>
  <block id="e95b58d02782c970bb339c6cc587ff39" category="cell">VMotion de almacenamiento</block>
  <block id="0486e0e3dc3e86859f43b6d8e32b8071" category="cell">Ha de VMware</block>
  <block id="8be6bd7f20474cbefdd496cb9fd495ca" category="cell">Planificador de recursos distribuidos de almacenamiento (SDRS)</block>
  <block id="4244919a64848265426dfd82a14f8248" category="cell">Software de backup compatible con VMware vStorage APIs for Data Protection (VADP)</block>
  <block id="28c2f8ab9cdbf296aa4261bc3c58ba0d" category="cell">Microsoft Cluster Service (MSCS) o clustering de recuperación tras fallos en un equipo virtual</block>
  <block id="01a9a3b8d0fcae3055dc91935e8ec6c6" category="cell">Sí*</block>
  <block id="aa7f77e663b832d5b0e544c5511e680c" category="cell">No admitido</block>
  <block id="aa18abedec09bd4f85e612c307e2eaa6" category="cell">Tolerancia a fallos</block>
  <block id="bfd52522de4ac6efd6f680e0e754eeb5" category="cell">Gestor de recuperación de sitios</block>
  <block id="d6407966cf588d8d78d4f7e65f1ea6fd" category="cell">Sólo v3**</block>
  <block id="17d495427086fa21259b9df40b27e00a" category="cell">Equipos virtuales con thin provisioning (discos virtuales)</block>
  <block id="4ee7af004efef335d6a14c60ee758f5e" category="cell">Sí
Esta configuración es la predeterminada para todas las máquinas virtuales de NFS cuando no se utiliza VAAI.</block>
  <block id="13bc264ff420559de4156ec40980a4b9" category="cell">Accesos múltiples nativos de VMware</block>
  <block id="50ed43e1a7a22335069a344bc706b600" category="cell">Sí, utilizando el nuevo complemento de alto rendimiento (HPP)</block>
  <block id="a06819d91a165d0491c5816c54b41234" category="paragraph">En la siguiente tabla se enumeran las funciones de gestión de almacenamiento de ONTAP admitidas.</block>
  <block id="f8d61013f1a3bbf1342f4ced3279c7cf" category="cell">Deduplicación de datos</block>
  <block id="72167540968147afed9deb59f0e9fe00" category="cell">Ahorro en la cabina</block>
  <block id="9a5473a6abaea16b736f096913a749be" category="cell">De ahorro en el almacén de datos</block>
  <block id="6cd880eabbec3488232c6cba3fbcf998" category="cell">Aprovisionamiento ligero</block>
  <block id="5caeb11c4ed379b808d7f7cdca7cfbf0" category="cell">Almacén de datos o RDM</block>
  <block id="8a5227cc82d14862956938caffc1acf2" category="cell">Almacén de datos</block>
  <block id="b71ba22dcd42deceac87150206f7bd12" category="cell">Redimensión de almacén de datos</block>
  <block id="c6b792bfd7aac8067d36337e67d11545" category="cell">Crezca solo</block>
  <block id="29e23534878bb63341e0b689426b7fb0" category="cell">Crecer, crecimiento automático y reducción</block>
  <block id="76021405cc62a4b8c542e7f65e3d24ed" category="cell">Complementos de SnapCenter para aplicaciones Windows y Linux (en invitado)</block>
  <block id="c0b3c629432c82a9e8500242abb35eaf" category="cell">Supervisión y configuración del host mediante herramientas de ONTAP para VMware vSphere</block>
  <block id="5a915a8215e9a66bcff0f034e8adff18" category="cell">Aprovisionar mediante las herramientas de ONTAP para VMware vSphere</block>
  <block id="6495c7cda42bf1b80bc1c2af6166ef58" category="paragraph">En la siguiente tabla se enumeran las funciones de backup admitidas.</block>
  <block id="ad336d1fccea3e918d07055edac855a3" category="cell">Snapshots de ONTAP</block>
  <block id="bf22a1b5bc2b72a75825094826a942de" category="cell">SRM compatible con backups replicados</block>
  <block id="60d3f7d9f265eb34e826da352cb545be" category="cell">SnapMirror para volúmenes</block>
  <block id="fabf31a57c142c986c5d88cb089b3d7b" category="cell">Acceso a imagen VMDK</block>
  <block id="40b655e79545b3922b8095be28d59428" category="cell">Software de backup compatible con VADP</block>
  <block id="8215e73d220182794dfbd75ad494c727" category="cell">Explorador del software de backup habilitado para VADP, vSphere Client y almacén de datos de vSphere Web Client</block>
  <block id="d7605580ecad0fcb4528789d74cdcad5" category="cell">Acceso de nivel de ficheros VMDK</block>
  <block id="906ece32da286d6c4b323bc0d6443b7c" category="cell">Software de backup compatible con VADP, solo Windows</block>
  <block id="d17e2fa63a62622f88bf170612132383" category="cell">Software de backup compatible con VADP y aplicaciones de terceros</block>
  <block id="4e3d259d82a536e12c5c9c948b62e26a" category="cell">Granularidad de NDMP</block>
  <block id="90d45e02e50c81603c36a4e4ad3649d9" category="cell">Almacén de datos o máquina virtual</block>
  <block id="8339c514e73f5cced3b83d504d60441b" category="inline-link">Configuración de clústeres de conmutación por error de Windows Server</block>
  <block id="45f7e6f7f6f0f4093754d7d48810e17f" category="paragraph">*NetApp recomienda utilizar iSCSI en sistemas invitados para clústeres de Microsoft en lugar de VMDK habilitados para varios escritores en un almacén de datos VMFS. Este enfoque es totalmente compatible con Microsoft y VMware, ofrece una gran flexibilidad con ONTAP (sistemas de SnapMirror a ONTAP en las instalaciones o en el cloud), es fácil de configurar y automatizar y puede protegerse con SnapCenter. VSphere 7 añade una nueva opción de VMDK en clúster. Esto es diferente de los VMDK habilitados para varias ediciones, que requieren un almacén de datos presentado a través del protocolo FC que tiene habilitada la compatibilidad con VMDK en cluster. Se aplican otras restricciones. Consulte la lista de VMware<block ref="b158594c147457b5b6417413cb30f800" category="inline-link-rx"></block> documentación para directrices de configuración.</block>
  <block id="e2bd40041a6472b580305ce9017b0b2e" category="paragraph">**Los almacenes de datos que usan NVMe-of y NFS v4.1 requieren la replicación de vSphere. SRM no admite la replicación basada en cabinas.</block>
  <block id="54b3e11ce37eaaa9884f4086e72dd2be" category="section-title">Seleccionar un protocolo de almacenamiento</block>
  <block id="4bbd62e7748dbf2416c644698342b5f9" category="paragraph">Los sistemas que ejecutan el software ONTAP admiten todos los protocolos de almacenamiento más importantes, por lo que los clientes pueden elegir cuál es la mejor opción para su entorno, en función de la infraestructura de red y la capacidad del personal actuales y planificadas. Por lo general, las pruebas de NetApp han mostrado poca diferencia entre protocolos que se ejecutan a velocidades de línea similares, por lo que es mejor centrarse en su infraestructura de red y en las capacidades del personal sobre el rendimiento del protocolo bruto.</block>
  <block id="0212b4e8bc965dcd8a7ff771dd96bf21" category="paragraph">Los siguientes factores pueden ser útiles a la hora de considerar una opción de protocolo:</block>
  <block id="0425ddb6dbbe7f13280e19e1f925b0a8" category="list-text">*Entorno actual del cliente.* aunque los equipos DE TI generalmente tienen experiencia en la gestión de la infraestructura IP Ethernet, no todos son expertos en la administración de una estructura SAN FC. Sin embargo, es posible que el uso de una red IP de uso general que no está diseñada para el tráfico de almacenamiento no funcione bien. Considere la infraestructura de red de que dispone, las mejoras planificadas y las capacidades y la disponibilidad del personal para gestionarlos.</block>
  <block id="774f1348caf3e145710073eb634c4fa1" category="list-text">*Facilidad de configuración.* más allá de la configuración inicial de la estructura FC (conmutadores y cableado adicionales, zonificación y verificación de interoperabilidad de HBA y firmware), los protocolos de bloque también requieren la creación y asignación de LUN y descubrimiento y formato por parte del SO invitado. Una vez creados y exportados los volúmenes de NFS, el host ESXi los monta y está listo para usarse. NFS no tiene ninguna cualificación de hardware o firmware especial que gestionar.</block>
  <block id="bf5169ce5bb544313eaf17435f756da2" category="list-text">*Facilidad de administración.* con los protocolos SAN, si se necesita más espacio, se necesitan varios pasos, incluyendo el crecimiento de una LUN, el reexamen para descubrir el nuevo tamaño, y luego el crecimiento del sistema de archivos). A pesar de que es posible aumentar una LUN, reducir el tamaño de una LUN no es así, y recuperar el espacio no utilizado puede requerir esfuerzo adicional. NFS permite ajustar fácilmente el tamaño, y el sistema de almacenamiento puede automatizar este ajuste de tamaño. SAN ofrece una reclamación de espacio mediante comandos TRIM/UNMAP del sistema operativo invitado, lo que permite que el espacio de los archivos eliminados se devuelva a la matriz. Este tipo de recuperación de espacio es más difícil con los almacenes de datos NFS.</block>
  <block id="530c759326761c6ac026b313985b255f" category="list-text">*Transparencia del espacio de almacenamiento.* la utilización del almacenamiento suele ser más fácil de ver en entornos NFS, ya que Thin Provisioning devuelve ahorros inmediatamente. Del mismo modo, los ahorros en deduplicación y clonado están disponibles inmediatamente para otras máquinas virtuales en el mismo almacén de datos o para otros volúmenes del sistema de almacenamiento. La densidad de las máquinas virtuales también es superior en un almacén de datos NFS, que puede mejorar el ahorro de la deduplicación y reducir los costes de gestión al tener menos almacenes de datos que gestionar.</block>
  <block id="16ee928b12bc598bf52b0f312879ec95" category="section-title">Distribución de almacenes de datos</block>
  <block id="b8c499c7b537f5bd4e51b0a6d6a1e9d0" category="list-text">La puesta en marcha de vSphere con almacenes de datos NFS de ONTAP da como resultado una implementación de alto rendimiento y fácil de gestionar que proporciona ratios de máquina virtual a almacén de datos que no pueden obtenerse con protocolos de almacenamiento basados en bloques. Esta arquitectura puede provocar un aumento diez veces en la densidad de los almacenes de datos con una reducción correlacionada en el número de almacenes de datos. Aunque un almacén de datos de mayor tamaño puede beneficiar la eficiencia de almacenamiento y proporcionar beneficios operativos, considere el uso de al menos cuatro almacenes de datos (volúmenes de FlexVol) para almacenar las máquinas virtuales en una sola controladora de ONTAP a fin de obtener el máximo rendimiento de los recursos de hardware. Este enfoque también permite establecer almacenes de datos con diferentes políticas de recuperación. Algunas se pueden hacer backups o replicarse con una frecuencia mayor que otras en función de las necesidades de las empresas. No se necesitan varios almacenes de datos en los volúmenes de FlexGroup para mejorar el rendimiento, ya que se escalan por diseño.</block>
  <block id="e15ed0ec7af4278259b7618024b3e7ce" category="list-text">NetApp recomienda el uso de volúmenes de FlexVol para la mayoría de almacenes de datos NFS. A partir de la versión ONTAP 9,8, se admiten los volúmenes FlexGroup también para su uso como almacenes de datos y, por lo general, se recomienda en determinados casos de uso. No se recomiendan normalmente otros contenedores de almacenamiento de ONTAP, como qtrees, porque actualmente no son compatibles con las herramientas de ONTAP para VMware vSphere o con el complemento de NetApp SnapCenter para VMware vSphere. Dicho esto, la puesta en marcha de almacenes de datos como varios qtrees en un único volumen puede ser útil para entornos muy automatizados que pueden beneficiarse de cuotas a nivel de almacenes de datos o clones de archivos de máquinas virtuales.</block>
  <block id="dc4d78be836807b32c7ef7f42028b1ef" category="list-text">Un buen tamaño para un almacén de datos con volúmenes FlexVol es de entre 4 y 8 TB. Este tamaño es un buen punto de equilibrio entre rendimiento, facilidad de gestión y protección de datos. Empiece con poco (digamos, 4 TB) y crezca el almacén de datos según sea necesario (hasta el máximo de 100 TB). Los almacenes de datos más pequeños son más rápidos de recuperar desde un backup o después de un desastre y se pueden mover rápidamente en el clúster. Considere la posibilidad de utilizar el ajuste de tamaño automático de ONTAP para aumentar y reducir automáticamente el volumen a medida que se modifique el espacio utilizado. Las herramientas de ONTAP para el Asistente de aprovisionamiento de almacenes de datos de VMware vSphere utilizan autosize de forma predeterminada para los nuevos almacenes de datos. System Manager o la línea de comandos pueden personalizarse los umbrales de crecimiento y reducción, y el tamaño máximo y mínimo.</block>
  <block id="964a81e46088ae1cc6306072464a9d73" category="list-text">De forma alternativa, los almacenes de datos VMFS se pueden configurar con LUN a las que se accede mediante FC, iSCSI o FCoE. VMFS permite que cada servidor ESX acceda a las LUN tradicionales de forma simultánea en un clúster. Los almacenes de datos VMFS pueden tener un tamaño de hasta 64 TB y constan de hasta 32 LUN de 2 TB (VMFS 3) o una única LUN de 64 TB (VMFS 5). El tamaño máximo de LUN de ONTAP es de 16 TB en la mayoría de los sistemas y de 128 TB en los sistemas de cabinas All-SAN. Por lo tanto, es posible crear un almacén de datos VMFS 5 de tamaño máximo en la mayoría de los sistemas ONTAP utilizando cuatro LUN de 16 TB. Aunque es posible obtener un beneficio en el rendimiento de las cargas de trabajo con un gran volumen de I/o con varias LUN (con sistemas FAS o AFF de gama alta), esta ventaja se ve compensada por la mayor complejidad de gestión para crear, gestionar y proteger las LUN de almacenes de datos y un mayor riesgo para la disponibilidad. NetApp suele recomendar el uso de una única LUN de gran tamaño para cada almacén de datos y únicamente span si hay una necesidad especial de ir más allá de un almacén de datos de 16 TB. Como sucede con NFS, considere el uso de varios almacenes de datos (volúmenes) para maximizar el rendimiento en una única controladora de ONTAP.</block>
  <block id="c74cab014e402128efd8102b941c0b0c" category="list-text">Los sistemas operativos invitados (SO) antiguos necesitaban alineación con el sistema de almacenamiento para obtener el mejor rendimiento y eficiencia del almacenamiento. Sin embargo, los sistemas operativos modernos admitidos por el proveedor de distribuidores de Microsoft y Linux como Red Hat ya no requieren ajustes para alinear la partición del sistema de archivos con los bloques del sistema de almacenamiento subyacente en un entorno virtual. Si utiliza un sistema operativo antiguo que puede requerir alineación, busque artículos en la base de conocimientos de soporte de NetApp usando "alineación de máquinas virtuales" o solicite una copia de TR-3747 a través de un contacto de partners o de ventas de NetApp.</block>
  <block id="8c761039ef4dd69451490b849ace1f82" category="list-text">Evite el uso de utilidades de desfragmentación en el sistema operativo invitado, ya que no ofrece beneficios de rendimiento y afecta a la eficiencia del almacenamiento y al uso del espacio de instantáneas. Considere también desactivar la indización de búsquedas en el sistema operativo invitado para escritorios virtuales.</block>
  <block id="14abb814748566a24367c4459a54840b" category="list-text">ONTAP ha dirigido el sector mediante funciones innovadoras de eficiencia del almacenamiento, que le permiten sacar el máximo partido a su espacio en disco utilizable. Los sistemas AFF llevan esta eficiencia aún más allá gracias a la compresión y la deduplicación inline predeterminadas. Los datos se deduplican en todos los volúmenes de un agregado, por lo que ya no necesita agrupar sistemas operativos similares y aplicaciones similares en un único almacén de datos para optimizar el ahorro.</block>
  <block id="446548f2b1301893641e29657fc7fe53" category="inline-link-macro">Bases de datos de Oracle en ONTAP</block>
  <block id="6cda576d2fd323c1a728b7ac67d6034f" category="list-text">Los discos de primera clase (o discos virtuales mejorados) permiten discos gestionados por vCenter independientemente de una máquina virtual con vSphere 6.5 y versiones posteriores. Aunque son gestionados principalmente por la API, pueden ser útiles con vVols, sobre todo cuando las herramientas de OpenStack o Kubernetes las gestionan. Son compatibles tanto con ONTAP como con herramientas de ONTAP para VMware vSphere.</block>
  <block id="71318121439b39fdf872bb0bd57494f2" category="section-title">Migración de almacenes de datos y máquinas virtuales</block>
  <block id="e8824ce2062c6d1fc536163f7b8940bd" category="paragraph">Al migrar las máquinas virtuales desde un almacén de datos existente en otro sistema de almacenamiento a ONTAP, estas son algunas prácticas que deben tenerse en cuenta:</block>
  <block id="73b729fbc964c7d78dd90b64aaaeb785" category="list-text">Use Storage vMotion para mover la mayoría de los equipos virtuales a ONTAP. Este método no solo no es disruptivo para la ejecución de equipos virtuales, sino que también permite funciones de eficiencia del almacenamiento de ONTAP como deduplicación y compresión inline para procesar los datos a medida que migran. Considere usar funcionalidades de vCenter para seleccionar varias máquinas virtuales de la lista de inventario y programar la migración (utilice la tecla Ctrl mientras hace clic en acciones) en un momento adecuado.</block>
  <block id="e512c890754c686d8deccac97d84a290" category="list-text">Aunque podría planificar con cuidado la migración a los almacenes de datos de destino adecuados, a menudo es más sencillo migrar de forma masiva y luego organizarse más tarde, según sea necesario. Puede que desee utilizar este enfoque para guiar la migración a diferentes almacenes de datos si tiene necesidades específicas de protección de datos, como distintas programaciones de Snapshot.</block>
  <block id="616b2180a0659911fed5aa758dba722c" category="list-text">La mayoría de los equipos virtuales y su almacenamiento pueden migrarse mientras se están ejecutando (en caliente), pero es posible que la migración de almacenamiento conectado (no en el almacén de datos), como ISO, LUN o volúmenes NFS desde otro sistema de almacenamiento requiera una migración de datos fría.</block>
  <block id="fbb88da5639930a05f510729e473a216" category="inline-link">CONSULTE TR-4534</block>
  <block id="096f2185af16e07c387a7fbe50df957a" category="list-text">Los equipos virtuales que necesitan una migración más cuidadosa incluyen las bases de datos y las aplicaciones que utilizan almacenamiento conectado. En general, considere el uso de las herramientas de la aplicación para gestionar la migración. Para Oracle, considere la posibilidad de utilizar herramientas de Oracle como RMAN o ASM para migrar los archivos de base de datos. Consulte<block ref="6b3f565e7a7ce633fa62f4114c295216" category="inline-link-rx"></block> si quiere más información. Del mismo modo, para SQL Server, plantéese utilizar SQL Server Management Studio o herramientas de NetApp, como SnapManager para SQL Server o SnapCenter.</block>
  <block id="09485b54473eee31422696bf0217d714" category="paragraph">Las mejores prácticas más importantes cuando se usa vSphere con sistemas que ejecutan el software ONTAP son instalar y utilizar las herramientas de ONTAP para el complemento VMware vSphere (antes llamado Virtual Storage Console). Este complemento de vCenter simplifica la gestión del almacenamiento, mejora la disponibilidad y reduce los costes de almacenamiento y la sobrecarga operativa, ya sea mediante SAN o NAS. Utiliza prácticas recomendadas para el aprovisionamiento de almacenes de datos y optimiza la configuración del host ESXi para los tiempos de espera de multivía y HBA (que se describen en el apéndice B). Dado que es un complemento de vCenter, está disponible para todos los clientes web de vSphere que se conectan al servidor vCenter.</block>
  <block id="9fb2cc2ced88ce872ef16c37d8284360" category="paragraph">El plugin también le ayuda a utilizar otras herramientas ONTAP en entornos de vSphere. Le permite instalar el complemento de NFS para VMware VAAI, que permite realizar copias de datos descargados en ONTAP para las operaciones de clonado de equipos virtuales, reservar espacio para archivos de disco virtual gruesos y descargar la copia Snapshot de ONTAP.</block>
  <block id="9baea886f208a41896164d4ade5b3fde" category="paragraph">En general, NetApp recomienda el uso de las herramientas de ONTAP para la interfaz de VMware vSphere en vCenter con el fin de aprovisionar almacenes de datos tradicionales y vVols, para garantizar que se sigan las prácticas recomendadas.</block>
  <block id="6161d374e9022f89382fd63b4be15aa1" category="section-title">Redes generales</block>
  <block id="f0cd6847f2a7a0773ad0b58d0f9dc67d" category="paragraph">La configuración de ajustes de red cuando se usa vSphere con sistemas que ejecutan el software ONTAP es sencilla y similar a la de otra configuración de red. Estas son algunas cosas a tener en cuenta:</block>
  <block id="c7949782ad094d3ffc126bee722642a3" category="list-text">Utilice switches que admitan la agregación de enlaces de puertos en dos chasis de switch separados mediante un enfoque de grupo de agregación de enlaces de varios chasis, como Virtual PortChannel (VPC) de Cisco.</block>
  <block id="9dc1904e0c3ace141704b477cd9b345d" category="inline-link">Gestión de redes</block>
  <block id="68ecdb0d7a96e68318a53d12e9fab5b5" category="list-text">Utilice LACP para crear agregados de enlaces para sistemas de almacenamiento de ONTAP con grupos de interfaces dinámicas multimodo con puerto o hash IP. Consulte<block ref="b87480ad0ff34784c4be1445a72a3aaf" category="inline-link-rx"></block> para obtener más orientación.</block>
  <block id="3b407fe7c9654197902b1dd26af6dc81" category="list-text">Utilice una política de agrupación de hash IP en ESXi cuando utilice la agregación de enlaces estáticos (por ejemplo, EtherChannel) y vSwitch estándar, o la agregación de enlaces basada en LACP con switches distribuidos de vSphere. Si no se utiliza la agregación de enlaces, utilice en su lugar «Ruta basada en el identificador de puerto virtual de origen».</block>
  <block id="ee1ef6cf0f3971b44eb2abcac958fb8d" category="section-title">Volúmenes de FlexGroup</block>
  <block id="dd9bd4a686bdeb1c7f11dc3cd0cda75f" category="paragraph">Considere el siguiente escenario:</block>
  <block id="6b277580cb59b13790b36344e827e22f" category="list-text">Ha creado un nuevo FlexGroup con 8 componentes</block>
  <block id="32efd8b10cc3b73c344f4c7e6c4b741e" category="list-text">El tiempo de espera de caché para el nuevo FlexGroup se establece en 160 minutos</block>
  <block id="879f959734466d50681eae9b95e7e591" category="paragraph">En esta situación, los primeros 8 clones que se realizarán serán copias completas, no clones de archivos locales. Cualquier clonación adicional de ese equipo virtual antes de que caduque el tiempo de espera de 160 segundos utilizará el motor de clonado de archivos dentro de cada componente en turno rotatorio para crear copias casi inmediatas distribuidas uniformemente en los volúmenes constituyentes.</block>
  <block id="0f98175ace2dd0d56e47961b22b2544b" category="paragraph">En entornos donde no es posible aprovechar al máximo la caché FlexGroup, pero aún así requerir un clonado rápido entre volúmenes, considere el uso de vVols. La clonación entre volúmenes con vVols es mucho más rápida que el uso de almacenes de datos tradicionales y no utiliza una caché.</block>
  <block id="189aae773e13462525f07e99fcd9e90f" category="inline-link">VAAI: ¿Cómo funciona el almacenamiento en caché con volúmenes FlexGroup?</block>
  <block id="718103d957da7fb9e8210a49a85aedab" category="paragraph">Para obtener más información sobre el uso de FlexGroups con VAAI, consulte este artículo de la base de conocimientos:<block ref="23db52497ce446299e31ecc0b7572649" category="inline-link-rx"></block></block>
  <block id="ce4df831657d2621e80bbef9271c33cd" category="summary">Con la transición del dispositivo virtual anterior, las herramientas de ONTAP incorporan una gran cantidad de nuevas funciones, límites más altos y nueva compatibilidad con vVols.</block>
  <block id="45b1565c472fff4046d0f7ddbe1342f2" category="doc">Nuevas funcionalidades con SRM y las herramientas de ONTAP</block>
  <block id="116d20fc387d73c8e4a86e7998913947" category="section-title">Versiones más recientes de vSphere y Site Recovery Manager</block>
  <block id="57359b8d2b77ce83f2e854fdd323377f" category="paragraph">Gracias al lanzamiento de SRM 8,7 y versiones posteriores, así como a las versiones 9,12 y posteriores de las herramientas de ONTAP, ahora puede proteger equipos virtuales que se ejecuten en la actualización 1 de VMware vSphere 8.</block>
  <block id="96ca6fcc2ffdab3c06d0875be8d4fe29" category="paragraph">NetApp ha compartido una estrecha colaboración con VMware durante casi dos décadas y se esfuerza por ofrecer soporte para las últimas versiones de Lo antes posible.. Consulte siempre la herramienta de matriz de interoperabilidad (IMT) de NetApp para ver las combinaciones de software más recientes cualificadas.</block>
  <block id="4ada3eb5b908caaedb757052562dfcf5" category="inline-link-macro"><block ref="4ada3eb5b908caaedb757052562dfcf5" category="inline-link-rx"></block></block>
  <block id="0a0a2a299629bed81a283fcd3b7833e9" category="paragraph">Puede encontrar el NetApp IMT en <block ref="83e08b5e992bc41d59feec38bb24f26d" category="inline-link-macro-rx"></block>.</block>
  <block id="9d6e1631f68d52fd0f82222bf276cdc4" category="section-title">Compatibilidad con vVols (y por qué es importante la gestión basada en políticas de almacenamiento (SPBM), incluso con SRM)</block>
  <block id="b0b7bc3c901f340c708b7560d1f2b7e1" category="paragraph">A partir de la versión 8,3, SRM ahora admite la gestión basada en políticas de almacenamiento (SPBM) de replicación que aprovecha vVols y la replicación basada en cabinas para almacenes de datos que usan iSCSI, FCP y NFS v3. Para ello, el servidor SRM se actualizó para incluir un nuevo servicio de proveedor vVols de SRM, que se comunica con el servicio SMS del servidor vCenter para tareas relacionadas con VASA.</block>
  <block id="4567f5576b4577c63b126cac3f6aa5fa" category="paragraph">Una ventaja de esta arquitectura es que el SRA ya no es necesario porque todo se gestiona con VASA.</block>
  <block id="e04031e1cecdb6732f91d44b204dbcf3" category="paragraph">La SPBM es una potente herramienta en el cuadro de herramientas de vSphere que permite servicios de almacenamiento simplificados, predecibles y constantes para el consumo mediante marcos de automatización en entornos de cloud privado e híbrido. Básicamente, SPBM permite definir clases de servicio que satisfacen las necesidades de su diversa base de clientes. SRM ahora le permite exponer capacidades de replicación a sus clientes para cargas de trabajo críticas que requieren una orquestación y automatización sólidas para la recuperación ante desastres estándares del sector.</block>
  <block id="1b6204fa76bd422416757c4e2d6187bd" category="paragraph">Ejemplo de arquitectura de vVols con FCP o iSCSI:</block>
  <block id="6f1ad7cac2af0e3b92a3936efc393a0e" category="paragraph"><block ref="6f1ad7cac2af0e3b92a3936efc393a0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9abbd7aed7e9791d9c52e8e17f34a756" category="section-title">Soporte para servidores SRM basados en dispositivos</block>
  <block id="925c477f139cce0692e13946a7f75eac" category="paragraph">Ahora, los servidores de SRM basados en el SO fotones son compatibles, además de las plataformas basadas en Windows heredadas.</block>
  <block id="62c2c4203aebe081ddbc6cdd489f8ad7" category="paragraph">Ahora puede instalar adaptadores SRA independientemente del tipo de servidor SRM preferido.</block>
  <block id="7cb1700928c008eb817bc79250cc9002" category="section-title">Compatibilidad con IPv6</block>
  <block id="ea9aacd1495949730de8eeab11e66459" category="paragraph">IPv6 ahora es compatible con las siguientes limitaciones:</block>
  <block id="d6d7f3d43de975c07655ebba1936867a" category="list-text">VCenter 6.7 o posterior</block>
  <block id="eb26ee1a20fe3dbde98204ec8b3ab838" category="list-text">No es compatible con SRM 8.2 (8.1, 8.3 y 8. 4 son compatibles)</block>
  <block id="918d32b75f0ab883abba3a8dc0c3ae8d" category="inline-link">Herramienta de matriz de interoperabilidad</block>
  <block id="02e7e71042609d3158020ab7befe45c6" category="list-text">Compruebe la<block ref="218f4ad7153f69cdc5467065434cd2f0" category="inline-link-rx"></block> para las versiones cualificadas más recientes.</block>
  <block id="e887aed8f9c3dbecd37e8896d96b6637" category="section-title">Mejor rendimiento</block>
  <block id="2a71574e89a69c8218fbac3f604b5728" category="paragraph">El rendimiento operativo es un requisito clave para la ejecución de tareas del SRM. Para satisfacer los requisitos de los objetivos de tiempo de recuperación y de punto de recuperación modernos, el SRA con las herramientas de ONTAP ha añadido tres nuevas mejoras.</block>
  <block id="bd403c539a0c414afacd7477bf3d311f" category="list-text">*Soporte para operaciones de reprotección simultáneas.* primero introducido en SRA 9.7.1, habilitar esta función permite ejecutar reprotección en dos o más planes de recuperación simultáneamente, reduciendo así el tiempo necesario para volver a proteger los almacenes de datos después de una migración por error y permanecer dentro de los parámetros RTO y RPO.</block>
  <block id="f63b947f655a5aee2cf69d4f30d7f96b" category="list-text">*Herramientas de ONTAP 9.8 agrega un nuevo modo optimizado sólo para NAS.* cuando utiliza cuentas y conexiones de ámbito SVM a clústeres de ONTAP con sólo almacenes de datos basados en NFS, puede habilitar el modo optimizado sólo para NAS para obtener el máximo rendimiento en entornos compatibles.</block>
  <block id="c82379d922d9cdc55fa21affe9f9b8bf" category="list-text">*Herramientas de ONTAP 9,12 añadió soporte para la función de resincronización rápida de SnapMirror de ONTAP*. Esto permite volver a sincronizar los duplicados con la vista de tener que volver a calcular el ahorro de eficiencia del almacenamiento después del proceso. Esta función no se utiliza de forma predeterminada, pero puede habilitarse en entornos a gran escala en los que la resincronización tradicional demora demasiado tiempo o se agota el tiempo de espera.</block>
  <block id="4a4842d7448ef71eb69b013e560b18bb" category="section-title">Mayor escala</block>
  <block id="26738e8d40ae8035805f13bdbf185c30" category="paragraph">Las herramientas de ONTAP SRA ahora pueden admitir hasta 500 grupos de protección (PGS) cuando se usa con SRM 8.3 y versiones posteriores.</block>
  <block id="96cb4d41ca97bd9d3d446984d3170a57" category="paragraph">Una nueva función que se espera tanto y que se prevé que será SnapMirror Synchronous (SM-S) con ONTAP 9.5 y posterior, que ofrece una solución de replicación de datos de RPO cero para sus aplicaciones críticas. SM-S requiere las herramientas ONTAP 9.8 o posterior.</block>
  <block id="b9832b10a87d0c3793ed3b413ee1d839" category="section-title">Soporte para API de REST</block>
  <block id="0065ce57adc813187a8e9c640ba6223a" category="paragraph">La configuración del servidor SRA ahora puede gestionarse mediante API DE REST. Se ha añadido una interfaz de usuario de Swagger para ayudar a crear sus flujos de trabajo de automatización y se puede encontrar en el dispositivo de herramientas de ONTAP en<block ref="579ce3ee0a7c1521f3dce6a507ea64a0" prefix=" " category="inline-code"></block>.</block>
  <block id="5bdb12cbb14efa98a61e7c5e3b4de108" category="admonition">Esta documentación sustituye al informe técnico _TR-4900 publicado anteriormente: VMware Site Recovery Manager por ONTAP_</block>
  <block id="e3445c3aa798f5ad98665e33d34dd952" category="paragraph">Las prácticas recomendadas complementan otros documentos como guías y herramientas de compatibilidad. Se desarrollan según pruebas de laboratorio y una amplia experiencia de campo por parte de ingenieros y clientes de NetApp. En algunos casos, las prácticas recomendadas pueden no ser la opción adecuada para su entorno; sin embargo, generalmente son las soluciones más sencillas que satisfacen las necesidades del mayor número de clientes.</block>
  <block id="10b8f80c23f8a44dfa6b10ae56d7dbe9" category="paragraph">Este documento se centra en las funcionalidades de las versiones recientes de ONTAP 9 cuando se utiliza junto con las herramientas de ONTAP para VMware vSphere 9,12 (que incluye el adaptador de replicación del almacenamiento de NetApp [SRA] y el proveedor VASA [VP]), así como VMware Site Recovery Manager 8,7.</block>
  <block id="c40f8c2af56356193284f6b46865d954" category="section-title">¿Por qué usar ONTAP con SRM?</block>
  <block id="36c28121fc6c9b02a38c0b6c92654e9a" category="paragraph">Las plataformas de gestión de datos de NetApp que incorpora el software ONTAP son algunas de las soluciones de almacenamiento más ampliamente adoptadas para SRM. Las razones están en abundancia: Una plataforma de gestión de datos de protocolo unificado seguro y de alto rendimiento (NAS y SAN juntos) que proporcione eficiencia del almacenamiento que defina el sector, multi-tenancy, controles de calidad de servicio, protección de datos con copias Snapshot con gestión eficiente del espacio y replicación con SnapMirror. Todos ellos aprovechan la integración nativa en el multicloud híbrido para la protección de las cargas de trabajo de VMware y una gran cantidad de herramientas de automatización y orquestación a su alcance.</block>
  <block id="2242b80f4627736a48c4c9a36b7428f6" category="paragraph">Al utilizar SnapMirror para la replicación basada en cabina, aprovecha una de las tecnologías más contrastadas y maduras de ONTAP. SnapMirror le ofrece la ventaja de las transferencias de datos seguras y altamente eficientes, con la copia solo de los bloques del sistema de archivos modificados, no de máquinas virtuales completas ni de almacenes de datos. Incluso esos bloques aprovechan el ahorro de espacio, como la deduplicación, la compresión y la compactación. Los sistemas ONTAP modernos ahora utilizan SnapMirror sin versiones, lo que le ofrece la flexibilidad de seleccionar sus clústeres de origen y destino. SnapMirror se ha convertido en una de las herramientas más potentes disponibles para la recuperación ante desastres.</block>
  <block id="36b04390d6103d8075862e4b825a485e" category="paragraph">Tanto si se utilizan almacenes de datos tradicionales NFS, iSCSI o conectados a Fibre Channel (ahora con compatibilidad con almacenes de datos vVols), SRM ofrece una sólida oferta de primera parte que aprovecha las mejores funcionalidades de ONTAP para la planificación y orquestación de la recuperación ante desastres o de la migración al centro de datos.</block>
  <block id="5d111e8a6885460b43ecf1f7abb6377e" category="section-title">Aprovechamiento de SRM ONTAP 9</block>
  <block id="16d4ec242c9f020f3a1fade311c776ed" category="paragraph">SRM aprovecha las tecnologías avanzadas de gestión de datos de los sistemas de ONTAP al integrarse con herramientas de ONTAP para VMware vSphere, un dispositivo virtual que incluye tres componentes principales:</block>
  <block id="d54038ba1f2a04a5b5f26c96627ae3e7" category="list-text">El complemento de vCenter, anteriormente conocido como Virtual Storage Console (VSC), simplifica las funciones de gestión y eficiencia del almacenamiento, mejora la disponibilidad y reduce los costes de almacenamiento y la sobrecarga operativa, tanto si usa SAN como NAS. Utiliza prácticas recomendadas para aprovisionar almacenes de datos y optimiza la configuración de host ESXi para entornos de almacenamiento en bloques y NFS. Para todas estas ventajas, NetApp recomienda este plugin cuando se usa vSphere en sistemas que ejecutan el software ONTAP.</block>
  <block id="a106bb15d6dc2b11535ed4fefc81fbf4" category="list-text">El proveedor VASA para ONTAP admite el marco de trabajo VMware vStorage APIs for Storage Awareness (VASA). EL proveedor DE VASA conecta vCenter Server con ONTAP para ayudar en el aprovisionamiento y la supervisión del almacenamiento de máquinas virtuales. Permite admitir volúmenes virtuales de VMware (vVols) y gestionar perfiles de funcionalidad del almacenamiento (incluidas funcionalidades de replicación vVols) y rendimiento vVols individual. También proporciona alarmas para controlar la capacidad y el cumplimiento de los perfiles. Si se utiliza junto con SRM, el proveedor VASA para ONTAP permite el soporte para máquinas virtuales basadas en vVols sin necesidad de instalar un adaptador de SRA en el servidor SRM.</block>
  <block id="f2007951062862f5f0d593acbb23bcb4" category="list-text">El SRA se usa junto con el SRM para gestionar la replicación de datos de máquinas virtuales entre sitios de producción y recuperación ante desastres para almacenes de datos VMFS tradicionales y NFS, y también para las pruebas no disruptivas de réplicas de recuperación ante desastres. Ayuda a automatizar las tareas de identificación, recuperación y protección. Incluye tanto un dispositivo de servidor SRA como adaptadores SRA para el servidor SRM de Windows y el dispositivo SRM.</block>
  <block id="8ccaa60ee78ecc93c4870b3b2ad15284" category="paragraph">Después de instalar y configurar los adaptadores SRA en el servidor SRM para proteger almacenes de datos que no son vVols y/o habilitar la replicación vVols en la configuración del proveedor VASA, puede iniciar la tarea de configurar el entorno de vSphere para la recuperación ante desastres.</block>
  <block id="0a1e25166326359cd5f50d0ab83e6a37" category="paragraph">El SRA y el proveedor VASA ofrece una interfaz de comandos y control para que el servidor SRM gestione los FlexVols de ONTAP que contienen las máquinas virtuales de VMware, así como la replicación de SnapMirror que las protege.</block>
  <block id="38db855935949f86c5db7bfe7d49873e" category="paragraph">A partir del SRM 8.3, se introdujo una nueva ruta de control del proveedor vVols de SRM, que permite comunicarse con el servidor vCenter y, a través del mismo, con el proveedor VASA sin necesidad de un SRA. Esto permitió que el servidor SRM aprovechara un control mucho más profundo sobre el clúster de ONTAP del que era posible antes, ya que VASA ofrece una API completa para la integración estrechamente vinculada.</block>
  <block id="1c27364cc3705aff403c6ef131c347ff" category="paragraph">SRM puede probar su plan de recuperación ante desastres sin interrupciones con la tecnología FlexClone de NetApp para crear clones casi instantáneos de los almacenes de datos protegidos del centro de recuperación ante desastres. SRM crea una zona aislada para probar con seguridad de modo que su organización y sus clientes estén protegidos en caso de un verdadero desastre, lo que le da confianza en que sus organizaciones pueden ejecutar una conmutación por error durante un desastre.</block>
  <block id="04a8f82007ed4bec45053912a49b6f85" category="paragraph">En caso de verdadero desastre o incluso de una migración planificada, SRM permite enviar cualquier cambio de última hora al conjunto de datos mediante una actualización final de SnapMirror (si lo decide). A continuación, interrumpe el reflejo y monta el almacén de datos en los hosts de recuperación ante desastres. En ese momento, las máquinas virtuales pueden encenderse automáticamente en cualquier orden de acuerdo con la estrategia planificada previamente.</block>
  <block id="b2560426a08ae6ceb167dad2bfb5e8ae" category="section-title">SRM con ONTAP y otros casos de uso: Cloud híbrido y migración</block>
  <block id="ed4c730bd8636c27d3eaa876c63b3d45" category="inline-link">Almacenamiento privado de NetApp en Equinix</block>
  <block id="b422e05bc5c6f52208b66ff51d718b9d" category="paragraph">La integración de su puesta en marcha de SRM con las capacidades de gestión de datos avanzadas de ONTAP posibilita una ampliación y un rendimiento mucho mejores en comparación con las opciones de almacenamiento local. Mucho más que eso, aporta la flexibilidad del cloud híbrido. El cloud híbrido le permite ahorrar dinero al organizar en niveles los bloques de datos no utilizados de su cabina de alto rendimiento en su proveedor a hiperescala preferido mediante FabricPool, que podría ser un almacén de S3 en las instalaciones, como StorageGRID de NetApp. También puede utilizar SnapMirror para sistemas basados en el perímetro con ONTAP Select definido por software o recuperación ante desastres basada en cloud usando Cloud Volumes ONTAP (CVO) o.<block ref="37a666d3a37f1c4a8c4c8dba379664a4" category="inline-link-rx"></block> Para Amazon Web Services (AWS), Microsoft Azure y Google Cloud Platform (GCP) para crear una pila de servicios de computación, redes y almacenamiento totalmente integrada en el cloud.</block>
  <block id="87a7b114355b836acefe833c497611bb" category="paragraph">Podría entonces hacer una conmutación por error de prueba dentro del centro de datos de un proveedor de servicios en cloud con un espacio de almacenamiento prácticamente nulo gracias a FlexClone. La protección de su empresa ahora puede costar menos que nunca.</block>
  <block id="12d0cbcf61df7df30bf9b020f6fbb051" category="paragraph">SRM también puede utilizarse para ejecutar migraciones planificadas aprovechando SnapMirror para transferir de forma eficiente sus máquinas virtuales desde un centro de datos a otro o incluso dentro del mismo centro de datos, ya sea el suyo o mediante cualquier otro proveedor de servicios para partners de NetApp.</block>
  <block id="89fafdb11a7e8cd8abebb1d4df053dad" category="doc">Topologías de replicación</block>
  <block id="be01acd2f018d38f9446f06b99ee4a2a" category="paragraph">En ONTAP 9, los componentes físicos de un clúster son visibles para los administradores del clúster, pero no pueden ver directamente las aplicaciones y los hosts que utilizan el clúster. Los componentes físicos proporcionan un conjunto de recursos compartidos desde los cuales se construyen los recursos del clúster lógicos. Las aplicaciones y los hosts solo acceden a los datos a través de SVM que contienen volúmenes y LIF.</block>
  <block id="7758fc02779ee5917b0a09ee22b52221" category="paragraph">Cada SVM de NetApp se trata como una cabina en VMware vCenter Site Recovery Manager. SRM admite ciertas distribuciones de replicación de cabina a cabina (o SVM a SVM).</block>
  <block id="58c0b55a67f4331cc49b073a7183e06c" category="paragraph">Una sola máquina virtual no puede poseer datos, Virtual Machine Disk (VMDK) o RDM, en más de una cabina de SRM por los siguientes motivos:</block>
  <block id="880aeda0b58c0b30120b6319ae5f3beb" category="list-text">SRM solo ve la SVM, no una controladora física individual.</block>
  <block id="6f55124e085dbeb640e4cb8ad2c97905" category="list-text">Una SVM puede controlar los LUN y los volúmenes que abarcan varios nodos en un clúster.</block>
  <block id="39d9903201320a83d45d3b36d512f051" category="cell">Mejor práctica</block>
  <block id="d86019fe4ba86b184ac71cf24a22f0c6" category="cell">Para determinar la compatibilidad, tenga presente esta regla: Para proteger una máquina virtual con el SRM y el SRA de NetApp, todas las partes de la máquina virtual deben existir en un solo SVM. Esta regla se aplica tanto al sitio protegido como al sitio de recuperación.</block>
  <block id="2e4472d35f80aa8b7eca52ae3dd43dc6" category="section-title">Distribuciones de SnapMirror compatibles</block>
  <block id="d070ad9d8397892aa7f317cbb9046661" category="paragraph">Las siguientes figuras muestran los escenarios de diseño de la relación de SnapMirror compatibles con SRM y SRA. Cada equipo virtual de los volúmenes replicados posee datos en una sola cabina de SRM (SVM) en cada sitio.</block>
  <block id="86cf5bd2bdb1b1d67f8f907f41099509" category="section-title">Diseños compatibles de Array Manager</block>
  <block id="aacc8f18d659f75715d91a983e872233" category="paragraph">Cuando se utiliza la replicación basada en cabinas (ABR) en SRM, los grupos de protección se aíslan en un solo par de cabina, como se muestra en la siguiente captura de pantalla. En este escenario,<block ref="129864522ed0e4ac80f306ecfa130ef7" prefix=" " category="inline-code"></block> y..<block ref="ec87aa7f4c8e70a139fd988f87b6549f" prefix=" " category="inline-code"></block> están entre iguales<block ref="387d04b65848414d4697f145a3782f90" prefix=" " category="inline-code"></block> y..<block ref="58bdbfcb72c2dd3d883a7ca754443a4c" prefix=" " category="inline-code"></block> en el centro de recuperación. Sin embargo, es posible seleccionar solo una de las dos parejas de cabinas al crear un grupo de protección.</block>
  <block id="1ceb46f3e1c6c7995de4ec5f05601227" category="section-title">Diseños no admitidos</block>
  <block id="611b9b35ac984f20e6594baec9181dbf" category="paragraph">Las configuraciones no compatibles tienen datos (VMDK o RDM) en varias SVM que son propiedad de una máquina virtual individual. En los ejemplos que se muestran en las siguientes figuras,<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> No se puede configurar para protección con SRM debido a<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> Tiene datos en dos SVM.</block>
  <block id="69851ac8c2fa81b32799efc8522798d5" category="paragraph">Toda relación de replicación en la que se replica un volumen individual de NetApp desde una SVM de origen a varios destinos en la misma SVM o en distintas SVM se denomina «fan-out» de SnapMirror. SRM no es compatible con fan-out. En el ejemplo que se muestra en la siguiente figura:<block ref="df777c4d2477e55571925353ce589f7e" prefix=" " category="inline-code"></block> No se puede configurar para proteger en SRM porque se replica con SnapMirror en dos ubicaciones diferentes.</block>
  <block id="3f88384b0d5cdcdc25895c644126c1b0" category="section-title">Cascada de SnapMirror</block>
  <block id="7ebde774ad43c45667d5544308a6d688" category="paragraph">SRM no admite la configuración en cascada de relaciones de SnapMirror, en las que un volumen de origen se replica en un volumen de destino, y ese volumen de destino también se replica con SnapMirror en otro volumen de destino. En el caso que se muestra en la siguiente figura, SRM no se puede utilizar para la conmutación por error entre sitios.</block>
  <block id="8bd15e818d377a0a5cf6ebc429555f79" category="section-title">SnapMirror y SnapVault</block>
  <block id="d440734d1f5d9c6e59aa97f7cbbcd525" category="paragraph">El software SnapVault de NetApp permite el backup a disco de datos empresariales entre sistemas de almacenamiento de NetApp. SnapVault y SnapMirror pueden coexistir en el mismo entorno. Sin embargo, SRM admite la conmutación por error únicamente de las relaciones de SnapMirror.</block>
  <block id="7878dfbf4b6ad3bc60d095cf89d79202" category="admonition">El SRA de NetApp admite el<block ref="e7d3e049f94ce3ff8a47f209f012173d" prefix=" " category="inline-code"></block> tipo de política.</block>
  <block id="883e69a285ae2d5fd23c80cd29285804" category="paragraph">SnapVault fue reconstruido desde sus cimientos para ONTAP 8.2. Aunque los antiguos usuarios de Data ONTAP 7-Mode deberían encontrar similitudes, se han mejoras importantes en esta versión de SnapVault. Un avance importante es la capacidad de preservar las eficiencias del almacenamiento en los datos primarios durante las transferencias de SnapVault.</block>
  <block id="9bc21373e0e299579a7ac86dcd4f513d" category="paragraph">Un cambio de arquitectura importante es que SnapVault en ONTAP 9 se replica a nivel de volumen, frente a en el nivel de qtree, como es el caso de SnapVault en 7-Mode. Esta configuración significa que el origen de una relación de SnapVault debe ser un volumen y dicho volumen debe replicar en su propio volumen en el sistema secundario SnapVault.</block>
  <block id="d447048519c85a2fb3bea0790cd109fb" category="paragraph">En un entorno en el que se utiliza SnapVault, se crean específicamente copias Snapshot con nombre en el sistema de almacenamiento primario. En función de la configuración implementada, las instantáneas con nombre se pueden crear en el sistema primario mediante una programación de SnapVault o mediante una aplicación como NetApp Active IQ Unified Manager. Las copias Snapshot con nombre que se crean en el sistema primario se replican a continuación en el destino de SnapMirror y, desde allí, se almacenan en el destino de SnapVault.</block>
  <block id="5dd37b7cd36f7d38ba2e6a63c603be4c" category="paragraph">Un volumen de origen se puede crear en una configuración en cascada en la que se replica un volumen a un destino de SnapMirror en el centro de recuperación ante desastres; a partir de ese punto, se realiza la copia en un destino de SnapVault. Un volumen de origen también puede crearse en una relación de dispersión en la que un destino es un destino de SnapMirror y el otro destino es un destino de SnapVault. Sin embargo, el SRA no reconfigura automáticamente la relación de SnapVault para usar el volumen de destino de SnapMirror como origen del almacén cuando se produce la conmutación por error del SRM o la reversión de la replicación.</block>
  <block id="5bc66b9c84b3f7cc0b375e729376b68d" category="inline-link">TR-4015 Guía de mejores prácticas para la configuración de SnapMirror para ONTAP 9.</block>
  <block id="0d510e96259254d285c6aaeb8458f45d" category="paragraph">Para obtener la información más reciente sobre SnapMirror y SnapVault para ONTAP 9, consulte<block ref="32e7c991f675bf983c547a2a174c2caf" category="inline-link-rx"></block></block>
  <block id="75f8a2d99eea9f336120aec69d8c1010" category="cell">Si se emplean SnapVault y SRM en el mismo entorno, NetApp recomienda utilizar una configuración en cascada de SnapMirror a SnapVault en la que los backups de SnapVault se realizan normalmente desde el destino de SnapMirror en el centro de recuperación ante desastres. En caso de desastre, esta configuración hace que el sitio primario sea inaccesible. Si se mantiene el destino de SnapVault en el centro de recuperación, los backups de SnapVault se pueden volver a configurar tras la conmutación por error para que los backups de SnapVault puedan continuar mientras estén en el centro de recuperación.</block>
  <block id="e082a67e3ddd7f4f92096536440cbb34" category="paragraph">En un entorno VMware, cada almacén de datos tiene un identificador único universal (UUID) y cada máquina virtual tiene un ID de objeto gestionado único (MOID). SRM no mantiene estos ID durante la conmutación por error o la conmutación tras recuperación. Dado que los UUID de almacenes de datos y los MOIDs de máquinas virtuales no se mantienen durante la conmutación por error por parte de SRM, cualquier aplicación que dependa de estos identificadores se debe volver a configurar tras la conmutación por error de SRM. Una aplicación de ejemplo es Active IQ Unified Manager de NetApp, que coordina la replicación de SnapVault con el entorno vSphere.</block>
  <block id="657a41cce55646ab17754ac1427970af" category="paragraph">La siguiente figura muestra la configuración en cascada de SnapMirror a SnapVault. Si el destino de SnapVault se encuentra en el centro de recuperación ante desastres o en un sitio terciario que no se ve afectado por una interrupción en el centro principal, es posible volver a configurar el entorno para que los backups continúen tras la conmutación por error.</block>
  <block id="e068178460f103498576eac8ddb7fb82" category="paragraph">En la siguiente figura, se muestra la configuración una vez que se ha utilizado SRM para revertir la replicación de SnapMirror al centro principal. También se ha reconfigurado el entorno para que los backups SnapVault se realicen desde el origen de SnapMirror. Esta configuración es una configuración de dispersión de SnapMirror SnapVault.</block>
  <block id="b4607a4ee7e1830ab6ba0007df206956" category="paragraph">Después de que el SRM realiza la conmutación tras recuperación y una segunda reversión de las relaciones de SnapMirror, los datos de producción vuelven a estar en el sitio principal. Estos datos ahora están protegidos del mismo modo que antes la conmutación al centro de recuperación ante desastres, mediante backups de SnapMirror y SnapVault.</block>
  <block id="63fd1f18d5d53fa97fd05a7fd96090b4" category="section-title">Uso de Qtrees en entornos de Site Recovery Manager</block>
  <block id="2d88570ceb2de0d8699a068b0140454b" category="paragraph">Los qtrees son directorios especiales que permiten aplicar cuotas del sistema de archivos para NAS. ONTAP 9 permite la creación de qtrees y pueden existir qtrees en los volúmenes replicados con SnapMirror. Sin embargo, SnapMirror no permite la replicación de qtrees individuales o a nivel de qtree. Toda la replicación de SnapMirror se realiza únicamente a nivel de volumen. Por este motivo, NetApp no recomienda el uso de qtrees con SRM.</block>
  <block id="345cb3f040f9f7f3f1a4261ed260aa79" category="section-title">Entornos FC e iSCSI mixtos</block>
  <block id="a60b166c2b69b4fdfbb733dc2193668a" category="paragraph">Con los protocolos SAN compatibles (Fibre Channel, FCoE e iSCI), ONTAP 9 ofrece servicios LUN, esto es, la capacidad de crear y asignar LUN a los hosts conectados. Dado que el clúster se compone de varias controladoras, existen varias rutas lógicas que se gestionan mediante I/o multivía con cualquier LUN individual. En los hosts se utiliza ALUA (Asymmetric LUN Access) para que se seleccione la ruta optimizada a cada LUN Si la ruta optimizada a cualquier LUN cambia (por ejemplo, debido a que se mueve el volumen que lo contiene), ONTAP 9 reconoce automáticamente y se ajusta de forma no disruptiva para este cambio. Si la ruta optimizada deja de estar disponible, ONTAP puede cambiar a otra ruta disponible sin interrupciones.</block>
  <block id="b9921ac732e72656bc2836f83bb09522" category="paragraph">El SRM de VMware y el SRA de NetApp admiten el uso del protocolo FC en un sitio y el protocolo iSCSI en el otro sitio. Sin embargo, no admite el hecho de haber una combinación de almacenes de datos conectados a FC y almacenes de datos conectados a iSCSI en el mismo host ESXi o en hosts diferentes en el mismo clúster. Esta configuración no es compatible con SRM porque, durante la conmutación por error de SRM o la conmutación por error de prueba, SRM incluye todos los iniciadores de FC e iSCSI de los hosts ESXi que están en la solicitud.</block>
  <block id="fccd44a96243e459128798803dca70aa" category="cell">El SRM y el SRA admiten protocolos mixtos de FC e iSCSI entre los sitios protegidos y de recuperación. Sin embargo, cada sitio debe configurarse con un solo protocolo, ya sea FC o iSCSI, y no con ambos protocolos en el mismo sitio. Si existe un requisito de tener configurados tanto los protocolos FC como iSCSI en el mismo sitio, NetApp recomienda que algunos hosts utilicen iSCSI y otros hosts utilicen FC. En este caso, NetApp también recomienda configurar las asignaciones de recursos de SRM para que las máquinas virtuales se configuren para conmutar al nodo de respaldo en un grupo de hosts u otro.</block>
  <block id="56687c1a324f03f5d1429500efea710e" category="doc">Solución de problemas de SRM al utilizar la replicación de vVols</block>
  <block id="14acf40cbe69d8682b4c844ac7fbf7f6" category="paragraph">El flujo de trabajo del SRM es significativamente diferente al usar la replicación de vVols a partir de lo que se usa con el SRA y los almacenes de datos tradicionales. Por ejemplo, no hay ningún concepto de administrador de cabinas. Como tal,<block ref="0ec64480a9620a1430c0ae1b6603ea01" prefix=" " category="inline-code"></block> y..<block ref="ba6c59072f543cb828e47d5bac560371" prefix=" " category="inline-code"></block> los comandos nunca se ven.</block>
  <block id="ef74d715544e3b067a6bec3218ac5044" category="paragraph">Para la solución de problemas, resulta beneficioso comprender los nuevos flujos de trabajo, que se enumeran a continuación:</block>
  <block id="47f0942d341ee10381b2eff35089d75d" category="list-text">QueryReplicationPeer: Descubre los acuerdos de replicación entre dos dominios de fallo.</block>
  <block id="136a299aae29998a147852cb0cba5b4a" category="list-text">QueryFaultDomain: Detecta la jerarquía de dominios de fallo.</block>
  <block id="c071098c5df923c31f6245e4db2f3861" category="list-text">QueryReplicationGroup: Detecta los grupos de replicación presentes en los dominios de origen o destino.</block>
  <block id="792cfe9ad3a3dc8528080a262e92989a" category="list-text">SyncReplicationGroup: Sincroniza los datos entre el origen y el destino.</block>
  <block id="39afb1e1e3b180a6230e07bb8571667e" category="list-text">QueryPointInTimeReplica: Detecta las réplicas de punto en tiempo en un destino.</block>
  <block id="9fb25fe2ff084dc9ccfb99eaccba7212" category="list-text">TestFailoverReplicationGroupStart: Inicia la conmutación por error de prueba.</block>
  <block id="bd4e1dacaca4c37a53b5286b6ae0239d" category="list-text">TestFailoverReplicationGroupStop: Finaliza la conmutación por error de prueba.</block>
  <block id="887f376a43cf9de1d6e14a8d69e588f6" category="list-text">PromoteReplicationGroup: Promueve un grupo actualmente en pruebas a la producción.</block>
  <block id="17ab16c5c0786ff381e6a085318bad9b" category="list-text">PapreFailoverReplicationGroup: Prepara para una recuperación ante desastres.</block>
  <block id="665dd64ebcc4016bda94e0e8020d8c8e" category="list-text">FailoverReplicationGroup: Ejecuta la recuperación ante desastres.</block>
  <block id="6936cf00e30b7cd4421225113a023c3e" category="list-text">ReverseReplicateGroup: Inicia la replicación inversa.</block>
  <block id="61ac8950a043e6998b458d4f8171154c" category="list-text">QueryMatchingContainer: Busca contenedores (junto con hosts o grupos de replicación) que puedan satisfacer una solicitud de aprovisionamiento con una directiva determinada.</block>
  <block id="05c9efdc056d2af4640bc441ab61b53a" category="list-text">QueryResourceMetadata: Descubre los metadatos de todos los recursos del proveedor VASA, la utilización de recursos puede devolverse como respuesta a la función queryMatchingContainer.</block>
  <block id="01fa56986f885c588b1be8c206623de8" category="paragraph">El error más común que se produce al configurar la replicación de vVols es no descubrir las relaciones de SnapMirror. Esto ocurre porque los volúmenes y las relaciones de SnapMirror se crean fuera del alcance de las herramientas de ONTAP. Por lo tanto, una práctica recomendada es asegurarse de que su relación con SnapMirror esté completamente inicializada y de que ha ejecutado una nueva detección en las herramientas de ONTAP en ambos sitios antes de intentar crear un almacén de datos vVols replicado.</block>
  <block id="3e4627f6667f830baceaaf35890b575a" category="summary">Para obtener más información sobre la información descrita en este documento, consulte los siguientes documentos o sitios web.</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="doc">Información adicional</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">Si quiere más información sobre el contenido de este documento, consulte los siguientes documentos o sitios web:</block>
  <block id="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link"><block ref="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link-rx"></block></block>
  <block id="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link"><block ref="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link-rx"></block></block>
  <block id="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link"><block ref="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link-rx"></block></block>
  <block id="c9dd6bad4c7d561872f2e2d498a990bf" category="inline-link">Herramienta de matriz de interoperabilidad (IMT)</block>
  <block id="1f82b18dcba5f32a085bc502cdd0c6b7" category="summary">Con ONTAP, el concepto de las máquinas virtuales de almacenamiento (SVM) proporciona una segmentación estricta en entornos multi-tenant seguros.</block>
  <block id="7520e12a140ccf3de279fe2fd48889e4" category="doc">Mejores prácticas de puesta en marcha</block>
  <block id="1b4574c516231b685bb37b013b789b06" category="section-title">Distribución y segmentación de SVM para SMT</block>
  <block id="446e04546ec0567eeeeef8e07368ab40" category="paragraph">Con ONTAP, el concepto de las máquinas virtuales de almacenamiento (SVM) proporciona una segmentación estricta en entornos multi-tenant seguros. Los usuarios de SVM en una SVM no pueden acceder a los recursos ni gestionarlos desde otra. De este modo, puede aprovechar la tecnología ONTAP creando SVM independientes para diferentes unidades de negocio que gestionan sus propios flujos de trabajo de SRM en el mismo clúster para mejorar la eficiencia general del almacenamiento.</block>
  <block id="f98c1d223f34b2fdaf90eab1a3bc6a25" category="paragraph">Considere la posibilidad de gestionar ONTAP mediante cuentas de ámbito SVM y LIF de administración de SVM para no solo mejorar los controles de seguridad, sino también mejorar el rendimiento. El rendimiento es inherentemente mayor cuando se usan conexiones de ámbito SVM porque el SRA no es necesario para procesar todos los recursos de todo un clúster, incluidos los recursos físicos. En su lugar, solo debe comprender los activos lógicos que se abstraen a una SVM en particular.</block>
  <block id="849d4d5e8a5d5b2747d8375d2ec03b29" category="paragraph">Al usar solo protocolos NAS (sin acceso SAN), puede incluso aprovechar el nuevo modo NAS optimizado configurando el siguiente parámetro (tenga en cuenta que el nombre es tal, ya que SRA y VASA utilizan los mismos servicios de back-end en el dispositivo):</block>
  <block id="05f551a655f40911851a53ba0c721997" category="list-text">Inicie sesión en el panel de control en<block ref="501a3478972ee5e3d6f109bdc0514bdc" prefix=" " category="inline-code"></block> Y haga clic en interfaz CLI basada en Web.</block>
  <block id="b0cc185c73ca964d1429a601551c68f5" category="list-text">Ejecute el comando<block ref="4f35e9b3adeccfaf0287d002b134221c" prefix=" " category="inline-code"></block>.</block>
  <block id="5f7e35f90689bef91afe9f01257c61ac" category="list-text">Ejecute el comando<block ref="aa610e3ab4e5162f432950793f30a387" prefix=" " category="inline-code"></block>.</block>
  <block id="ba2a1e4d95dc56709260e82cca20a789" category="list-text">Ejecute el comando<block ref="6d83e9fce5e947159c3c34b9f499e80e" prefix=" " category="inline-code"></block>.</block>
  <block id="2d14ca751c8ce5a724606e4f75f02c50" category="section-title">Implementar herramientas de ONTAP y consideraciones para vVols</block>
  <block id="fa3a193f1892cf0f45f4a95a35aa3c4b" category="paragraph">Si tiene pensado utilizar SRM con vVols, debe gestionar el almacenamiento utilizando las credenciales de ámbito del clúster y una LIF de gestión de clústeres. Esto se debe a que el proveedor de VASA debe comprender la arquitectura física subyacente para satisfacer las políticas requiere normativas de almacenamiento de VM. Por ejemplo, si tiene una política que requiere almacenamiento all-flash, el proveedor VASA debe poder ver qué sistemas son all-flash.</block>
  <block id="31d279d1cc3bc5a4281567ba697f678d" category="paragraph">Otra práctica recomendada para la implementación es no almacenar nunca el dispositivo de herramientas ONTAP en un almacén de datos vVols que gestiona. Esto podría provocar una situación en la que no se puede encender el proveedor VASA porque no se puede crear el VVol de intercambio para el dispositivo porque el dispositivo está sin conexión.</block>
  <block id="97399fb37deca0d463aa5c7dc8d064a6" category="section-title">Prácticas recomendadas para gestionar sistemas ONTAP 9</block>
  <block id="18f8b81b7fb7ea92f333e127583df17c" category="paragraph">Como se ha mencionado anteriormente, puede gestionar clústeres de ONTAP utilizando credenciales de ámbito de clúster o de SVM y LIF de gestión. Para obtener un rendimiento óptimo, es posible que desee considerar el uso de las credenciales del ámbito SVM siempre que no utilice vVols. Sin embargo, al hacerlo, debe conocer algunos requisitos y perder algunas funciones.</block>
  <block id="fec05e53ca7d96aaf3e4c1a1b2502bea" category="list-text">La cuenta de SVM predeterminada de vsadmin no tiene el nivel de acceso requerido para realizar tareas de las herramientas de ONTAP. Por lo tanto, debe crear una nueva cuenta de SVM.</block>
  <block id="d508cbe8ee8a3aa0f975b96403baf33c" category="list-text">Si utiliza ONTAP 9,8 o una versión posterior, NetApp recomienda crear una cuenta de usuario con menos privilegios de control de acceso basado en roles mediante el menú de usuarios de ONTAP System Manager junto con el archivo JSON disponible en el dispositivo de herramientas de ONTAP en<block ref="137f8d4bb89dcc34c3bfe48f2a61c95e" prefix=" " category="inline-code"></block>. Use la contraseña de administrador para descargar el archivo JSON. Puede utilizarse para cuentas de SVM o de ámbito de clúster.</block>
  <block id="a7a83b5e4f375c0585588b9c7ff92219" category="inline-link">Toolchest del sitio de soporte de NetApp</block>
  <block id="fdfe9ba9104df6a32fff0f859291ea3c" category="paragraph">Si utiliza ONTAP 9.6 o una versión anterior, debe utilizar la herramienta RBAC User Creator (RUC) disponible en<block ref="bdbf96c18cf8ac76d01fba7057b81b87" category="inline-link-rx"></block>.</block>
  <block id="ea7a3d08d55dc3e8ecf89d2a5d5e302d" category="list-text">Debido a que el complemento de interfaz de usuario de vCenter, el proveedor VASA y el servidor SRA son servicios completamente integrados, debe añadir almacenamiento al adaptador del SRA del SRM de la misma forma que añada almacenamiento en la interfaz de usuario del para vCenter para las herramientas de ONTAP. De lo contrario, es posible que el servidor SRA no reconozca las solicitudes que se envían desde el SRM a través del adaptador SRA.</block>
  <block id="b473de4177eeaa79a66448798a446db3" category="list-text">No se realiza la comprobación de la ruta de NFS cuando se utilizan las credenciales de ámbito de SVM. Esto se debe a que la ubicación física se abstrae de forma lógica de la SVM. Sin embargo, este no es un motivo de preocupación, ya que los sistemas ONTAP modernos ya no sufren una disminución notable del rendimiento cuando se utilizan rutas indirectas.</block>
  <block id="6e62430b92a7c5a0b8512436b163a10d" category="list-text">Es posible que no se informe del ahorro de espacio agregado debido a la eficiencia del almacenamiento.</block>
  <block id="93d86aa51e0909549d1b1210f887aef3" category="list-text">Si es compatible, los duplicados de uso compartido de carga no se pueden actualizar.</block>
  <block id="647d380b52e259fe7ed2e2582bc54b27" category="list-text">Es posible que no se realicen registros de EMS en sistemas ONTAP gestionados con credenciales de ámbito de SVM.</block>
  <block id="c5cd657df037c277c37216b73efb0b08" category="summary">Si es posible, utilice siempre herramientas ONTAP para aprovisionar almacenes de datos y volúmenes. De este modo se garantiza que los volúmenes, rutas de unión, LUN, iGroups, políticas de exportación, y otros ajustes se configuran de forma compatible.</block>
  <block id="d3b26e9021e83573a3d2a9050400a33a" category="doc">Mejores prácticas operativas</block>
  <block id="4d15db58f26b374b36c283df6b5a5fc1" category="paragraph">El SRM admite iSCSI, Fibre Channel y NFS versión 3 con ONTAP 9 al usar la replicación basada en cabinas a través de SRA. SRM no admite la replicación basada en cabinas para NFS versión 4.1 con almacenes de datos tradicionales o vVols.</block>
  <block id="61f54ceeb0338787a2ee2d801cbc62cd" category="paragraph">Para confirmar la conectividad, siempre compruebe que puede montar y desmontar un almacén de datos de prueba nuevo en el sitio de recuperación ante desastres del clúster de ONTAP de destino. Pruebe cada protocolo que pretenda utilizar para la conectividad de almacenes de datos. Una práctica recomendada es usar las herramientas de ONTAP para crear su almacén de datos de prueba, ya que está haciendo toda la automatización del almacén de datos según las indicaciones del SRM.</block>
  <block id="0ac3e8abbf45a28af68d22b0f59a973e" category="paragraph">Los protocolos SAN deben ser homogéneos para cada sitio. Puede mezclar NFS y SAN, pero los protocolos SAN no deben mezclarse dentro de un sitio. Por ejemplo, puede utilizar FCP en el sitio A y iSCSI en el sitio B. No debe usar FCP e iSCSI en el sitio A. El motivo es que el SRA no crea iGroups mixtos en el sitio de recuperación y el SRM no filtra la lista de iniciadores dada al SRA.</block>
  <block id="63b6c8d5e17ef7185a34c4ddd86f9d19" category="inline-link-macro">configuración de volúmenes para crecer o reducir automáticamente</block>
  <block id="a1874a28c8389c5c687d10167e80dc1f" category="paragraph">el ajuste de tamaño automático de volumen debe estar establecido en<block ref="4d200fce73a8e1cc965cfc2c43343824" prefix=" " category="inline-code"></block> Para volúmenes que contienen almacenes de datos SAN y<block ref="d89f4f8b1d7c18847b88b46142f61535" prefix=" " category="inline-code"></block> Para almacenes de datos NFS. Más información acerca de <block ref="ebd664f1c7cf128a3758282775d35e72" category="inline-link-macro-rx"></block>.</block>
  <block id="e401bd7c98141814eaf5528ddb318da6" category="section-title">Gestión basada en la política de almacenamiento (SPBM) y vVols</block>
  <block id="be41c3baf700984021c43e2e6b661b0a" category="paragraph">La siguiente captura de pantalla proporciona un ejemplo de las programaciones de SnapMirror que se muestran en el asistente Create VM Storage Policy.</block>
  <block id="f6292d9eb6ea467a3c3560a65b7f63b5" category="paragraph">El proveedor de VASA de ONTAP admite la conmutación por error a un almacenamiento diferente. Por ejemplo, el sistema puede conmutar al respaldo de ONTAP Select en una ubicación perimetral a un sistema AFF en el centro de datos principal. Independientemente de la similitud de almacenamiento, siempre debe configurar las asignaciones de políticas de almacenamiento y las asignaciones inversa de las políticas de almacenamiento de máquinas virtuales habilitadas para la replicación para garantizar que los servicios proporcionados en el sitio de recuperación cumplan las expectativas y los requisitos. La siguiente captura de pantalla resalta una asignación de directivas de ejemplo.</block>
  <block id="1eb90dc8f7adfd00c74af3b815e2ac15" category="section-title">Cree volúmenes replicados para almacenes de datos vVols</block>
  <block id="550d51e15336d4a33bcbb0f26a6810f7" category="paragraph">Hay que tener cuidado cuando se trata de vVols y SRM. No mezcle nunca máquinas virtuales protegidas y sin protección en el mismo almacén de datos vVols. La razón es que, cuando utiliza SRM para conmutar por error a su sitio de recuperación ante desastres, solo se conecta a las máquinas virtuales que forman parte del grupo de protección en caso de desastre. Por lo tanto, cuando se vuelve a proteger (SnapMirror de recuperación ante desastres se vuelve a proteger a producción), es posible que sobrescriba los equipos virtuales que no se dieron el error y contengan datos valiosos.</block>
  <block id="6d717f70d89096b731dfc63d7a1379e1" category="section-title">Acerca de parejas de cabinas</block>
  <block id="2219228418c053eb593ce0a1f318da47" category="paragraph">Al configurar parejas de cabinas en SRM, siempre debe añadirlas a SRM de la misma forma que las añadió a las herramientas de ONTAP, lo que significa que deben usar el mismo nombre de usuario, contraseña y LIF de gestión. Este requisito garantiza que el SRA se comunique correctamente con la matriz. La siguiente captura de pantalla ilustra cómo puede aparecer un clúster en las herramientas de ONTAP y cómo se puede añadir a un administrador de cabinas.</block>
  <block id="3b34135c8c4d2b14ceb7ebf595f00193" category="section-title">Acerca de los grupos de replicación</block>
  <block id="6be59afd3c8bb91501f55a7e77ebe794" category="paragraph">Los grupos de replicación contienen colecciones lógicas de máquinas virtuales que se recuperan juntas. Las herramientas de ONTAP VASA Provider crean automáticamente grupos de replicación por usted. Dado que la replicación de SnapMirror de ONTAP se produce en el nivel de volumen, todas las máquinas virtuales de un volumen se encuentran en el mismo grupo de replicación.</block>
  <block id="c727c1020d3128dd7495a6e3e6f23736" category="paragraph">Un aspecto final que se debe tener en cuenta para los grupos de replicación es que cada uno de ellos es, por su naturaleza, un grupo de consistencia lógico (que no se debe confundir con los grupos de consistencia SRM). Esto se debe a que todas las máquinas virtuales del volumen se transfieren juntas con la misma copia de Snapshot. Si tiene equipos virtuales que deben ser coherentes entre sí, considere almacenarlos en el mismo FlexVol.</block>
  <block id="9f8a350a2113ea4be6b4e5e5112514a3" category="section-title">Acerca de los grupos de protección</block>
  <block id="df77671ab2743af7f1d1457c200eb12c" category="paragraph">Los grupos de protección definen las máquinas virtuales y los almacenes de datos en grupos que se recuperan conjuntamente del sitio protegido. El sitio protegido es donde existen las máquinas virtuales configuradas en un grupo de protección durante las operaciones normales de estado constante. Es importante tener en cuenta que, aunque SRM puede mostrar varios administradores de cabinas para un grupo de protección, un grupo de protección no puede abarcar varios administradores de cabinas. Por este motivo, no debe abarcar los archivos de equipos virtuales entre almacenes de datos en diferentes SVM.</block>
  <block id="b148467d645c3613c1c7a2607764c515" category="section-title">Acerca de los planes de recuperación</block>
  <block id="fd28cd9834ad3aa213c4fec2881064b5" category="paragraph">Los planes de recuperación definen qué grupos de protección se recuperan en el mismo proceso. Se pueden configurar varios grupos de protección en el mismo plan de recuperación. Además, para ofrecer más opciones para la ejecución de planes de recuperación, se puede incluir un solo grupo de protección en varios planes de recuperación.</block>
  <block id="77aa84394124509e5e4006dcfd18789f" category="paragraph">Los planes de recuperación permiten a los administradores de SRM definir flujos de trabajo de recuperación asignando las máquinas virtuales a un grupo de prioridad de 1 (más alta) a 5 (más baja), siendo 3 (medio) el valor predeterminado. Dentro de un grupo de prioridad, las máquinas virtuales pueden configurarse para las dependencias.</block>
  <block id="030d749269f8866de516a551b0286001" category="paragraph">NetApp recomienda encarecidamente trabajar con sus equipos de aplicaciones para comprender el orden de las operaciones necesarias en un escenario de conmutación por error y construir sus planes de recuperación según corresponda.</block>
  <block id="cebb1167d3e78885137c837f0abf8026" category="section-title">Probar la recuperación tras fallos</block>
  <block id="6ae8acfc86f5df3426d525fb95767506" category="paragraph">NetApp también recomienda confirmar la funcionalidad de aplicaciones «en invitado» ocasionalmente, especialmente tras reconfigurar el almacenamiento de máquinas virtuales.</block>
  <block id="bd47371bcd8b3d08d6b4b15481b08d93" category="paragraph">Cuando se realiza una operación de recuperación de pruebas, se crea una red privada de burbuja de pruebas en el host ESXi para los equipos virtuales. Sin embargo, esta red no está conectada automáticamente a ningún adaptador de red físico y, por lo tanto, no proporciona conectividad entre los hosts ESXi. Para permitir la comunicación entre máquinas virtuales que se ejecutan en diferentes hosts ESXi durante las pruebas de recuperación ante desastres, se crea una red privada física entre los hosts ESXi en el sitio de recuperación ante desastres. Para verificar que la red de prueba es privada, la red de burbuja de prueba se puede separar físicamente o mediante VLAN o etiquetado VLAN. Esta red debe separarse de la red de producción porque, a medida que se recuperan los equipos virtuales, no se pueden colocar en la red de producción con direcciones IP que puedan entrar en conflicto con los sistemas de producción reales. Cuando se crea un plan de recuperación en SRM, es posible seleccionar la red de pruebas creada como la red privada para conectar los equipos virtuales a durante la prueba.</block>
  <block id="2be58fc410ddf2ba9c350135a617944a" category="paragraph">Una vez que la prueba se ha validado y ya no es necesaria, realice una operación de limpieza. La ejecución de la limpieza devuelve las máquinas virtuales protegidas a su estado inicial y restablece el plan de recuperación al estado Ready.</block>
  <block id="6f07b53963ee80903f0f13654de2cc3a" category="section-title">Consideraciones sobre la conmutación por error</block>
  <block id="9d33d94019b4a595a1ea232926a4da1b" category="paragraph">Hay otros factores que se deben tener en cuenta a la hora de conmutar por error un sitio además del orden de las operaciones mencionado en esta guía.</block>
  <block id="74abdd5cb502cd65bcf1d7ca484ab0c2" category="paragraph">Un problema que puede tener que lidiar es las diferencias de redes entre sitios. Es posible que algunos entornos puedan usar las mismas direcciones IP de red en el sitio primario y en el sitio de recuperación tras desastres. Esta capacidad se conoce como una configuración de red LAN virtual (VLAN) ampliada o extendida. Es posible que otros entornos tengan que utilizar diferentes direcciones IP de red (por ejemplo, diferentes VLAN) en el sitio principal con respecto al sitio de recuperación ante desastres.</block>
  <block id="9b8890fe5b1ab29543118b12a7bd0a07" category="inline-link-macro">Opciones de NSX-T con SRM</block>
  <block id="25154023650451d6cc971fc54bff8898" category="paragraph">VMware ofrece varias formas de resolver este problema. En primer lugar, las tecnologías de virtualización de redes como el centro de datos NSX-T de VMware abstraen toda la pila de redes de las capas 2 a 7 del entorno operativo, permitiendo soluciones más portátiles. Más información acerca de <block ref="3e6a2bd8e1acf69d423b7944c6543271" category="inline-link-macro-rx"></block>.</block>
  <block id="b56336aa967325217297d8725b64eb0b" category="inline-link-macro">Documentación de VMware</block>
  <block id="d32598436410006707b2ad1d79395f02" category="paragraph">Para configurar SRM de modo que aplique diferentes ajustes de red a varios equipos virtuales sin tener que editar las propiedades de cada uno del plan de recuperación, VMware ofrece una herramienta llamada DR-ip-customizer. Aprenda a usar esta utilidad, consulte <block ref="837c7339284b78d4fd5550c5d0fb1a68" category="inline-link-macro-rx"></block>.</block>
  <block id="3c8c527afa8ce5009c8f707f7fd4fabf" category="section-title">Vuelva a proteger</block>
  <block id="3b496038cb575fc404f8b0783e570f7a" category="paragraph">Después de una recuperación, el sitio de recuperación se convierte en el nuevo sitio de producción. Dado que la operación de recuperación rompió la replicación de SnapMirror, el nuevo sitio de producción no está protegido contra ningún desastre futuro. Una mejor práctica es proteger el nuevo site de producción en otro site inmediatamente después de una recuperación. Si el sitio de producción original está operativo, el administrador de VMware puede utilizar el sitio de producción original como un nuevo sitio de recuperación para proteger el nuevo sitio de producción, invirtiendo efectivamente la dirección de la protección. La reprotección solo está disponible en fallos no catastróficos. Por lo tanto, en algún momento deben recuperarse los servidores vCenter Server, los servidores ESXi, los servidores SRM y las bases de datos correspondientes originales. Si no están disponibles, deben crearse un nuevo grupo de protección y un nuevo plan de recuperación.</block>
  <block id="2bf236f8aceaaff2b305848df524c42e" category="paragraph">Una operación de conmutación tras recuperación es fundamentalmente una conmutación por error en una dirección diferente a la anterior. Como práctica recomendada, compruebe que el sitio original vuelve a los niveles aceptables de funcionalidad antes de intentar realizar la conmutación tras recuperación o, en otras palabras, la conmutación por error al sitio original. Si la instalación original sigue en peligro, deberá retrasar la conmutación tras recuperación hasta que se solucione el fallo lo suficiente.</block>
  <block id="cb03753531bad31391d7156433b98ae6" category="paragraph">Otra práctica recomendada para la conmutación tras recuperación es siempre realizar una conmutación al nodo de respaldo de prueba después de completar la reprotección y antes de llevar a cabo la conmutación tras recuperación final. Esto verifica que los sistemas en el sitio original pueden completar la operación.</block>
  <block id="900a3b65ea54b6dcff72ed0d6ac66fdf" category="section-title">Volver a proteger el sitio original</block>
  <block id="12d059a2c7519f2e3497b30a71121503" category="paragraph">La ejecución de la reprotección después de la conmutación tras recuperación hace que el entorno vuelva a estar en el estado que estaba al principio, cuando la replicación de SnapMirror se ejecuta de nuevo desde el centro de producción al centro de recuperación.</block>
  <block id="39e5fc9eb192f011ab14dae6c2974c4e" category="list-text">*Modelado de amenazas.* el propósito del modelado de amenazas es descubrir defectos de seguridad en una característica, componente o producto al principio del ciclo de vida del desarrollo del software. Un modelo de amenaza es una representación estructurada de toda la información que afecta la seguridad de una aplicación. En esencia, es una visión de la aplicación y su entorno a través del objetivo de la seguridad.</block>
  <block id="9f16ab3a50bca32d19c4729319035c8d" category="list-text">*Pruebas de seguridad de aplicaciones dinámicas (DAST).* esta tecnología está diseñada para detectar condiciones vulnerables en aplicaciones en su estado de funcionamiento. DAST prueba las interfaces HTTP y HTML expuestas de las aplicaciones web.</block>
  <block id="267bed0525e4dab477e4c24ca5a1794e" category="list-text">*Moneda de código de terceros.* como parte del desarrollo de software con software de código abierto (OSS), debe tratar las vulnerabilidades de seguridad que pueden estar asociadas con cualquier OSS incorporado en su producto. Esto es un esfuerzo continuo porque una nueva versión de OSS podría tener una vulnerabilidad recién descubierta reportada en cualquier momento.</block>
  <block id="db7bc87c89c1ee76d313865a32fc0e06" category="list-text">*Análisis de vulnerabilidades.* el propósito del análisis de vulnerabilidades es detectar vulnerabilidades de seguridad comunes y conocidas en los productos de NetApp antes de que se lancen a los clientes.</block>
  <block id="1a4c104571630526efc77b84e82380fe" category="list-text">* Pruebas de penetración.* la prueba de penetración es el proceso de evaluar un sistema, una aplicación web o una red para encontrar vulnerabilidades de seguridad que podrían ser explotadas por un atacante. Las pruebas de penetración (pruebas de Pen) en NetApp las realiza un grupo de empresas de terceros aprobadas y fiables. Su alcance de prueba incluye el lanzamiento de ataques contra una aplicación o software similar a intrusos hostiles o piratas informáticos que utilizan métodos o herramientas de explotación sofisticados.</block>
  <block id="7e98fc3ea1ec077cfd1727a58e9c9020" category="section-title">Funciones de seguridad de los productos</block>
  <block id="dff88c2ef0b49b09246ffd6f9ec55195" category="list-text">*Banner de inicio de sesión.* SSH está desactivado de forma predeterminada y sólo permite inicios de sesión de una vez si está activado desde la consola de VM. Se muestra el siguiente banner de inicio de sesión una vez que el usuario introduce un nombre de usuario en la solicitud de inicio de sesión:</block>
  <block id="399875025e8e96cc13102a4dd72f2434" category="paragraph">*ADVERTENCIA:* el acceso no autorizado a este sistema está prohibido y será procesado por ley. Al acceder a este sistema, acepta que sus acciones pueden supervisarse si se sospecha un uso no autorizado.</block>
  <block id="2d8330ed99c80a842ffbd1362e038e5e" category="paragraph">Una vez que el usuario complete el inicio de sesión a través del canal SSH, se muestra el siguiente texto:</block>
  <block id="677528ad13d460c058ac50e8a62092cf" category="list-text">*Control de acceso basado en roles (RBAC).* dos tipos de controles RBAC están asociados con las herramientas ONTAP:</block>
  <block id="ac38773d017495a97d5b88f242578cb8" category="list-text">Privilegios nativos de vCenter Server</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link">este enlace</block>
  <block id="31cedac82fef311cb790a12f96897223" category="list-text">Privilegios específicos del plugin de vCenter. Para obtener más información, consulte<block ref="e5f6920797dbff91ef59367270a82669" category="inline-link-rx"></block>.</block>
  <block id="5d32469f8a65b884a8f70abf95fe485a" category="list-text">*Canales de comunicaciones cifrados.* toda comunicación externa ocurre a través de HTTPS utilizando la versión 1.2 de TLS.</block>
  <block id="600d4f98483fae8e58054f976d7e0c0e" category="list-text">*Exposición mínima del puerto.* sólo los puertos necesarios están abiertos en el firewall.</block>
  <block id="0406f8902379502d1eba01f043c232b7" category="paragraph">En la siguiente tabla se describen los detalles de los puertos abiertos.</block>
  <block id="69fc9fe9cbb7709e97a433352aecf77d" category="cell">Puerto TCP v4/v6 #</block>
  <block id="02674a4ef33e11c879283629996c8ff8" category="cell">Dirección</block>
  <block id="86408593c34af77fdd90df932f8b5261" category="cell">Función</block>
  <block id="0c95054981de037de06e544a52eb3613" category="cell">8143</block>
  <block id="a8e6fe5b9e68f30a146cefebaa7edcc3" category="cell">entrante</block>
  <block id="d16c4afdc5f340936b747baf91efc843" category="cell">Conexiones HTTPS para la API de REST</block>
  <block id="5bd529d5b07b647a8863cf71e98d651a" category="cell">8043</block>
  <block id="1f4deeb2f64336d4ff65ea3d2b4ffe2f" category="cell">Conexiones HTTPS</block>
  <block id="cb4b69eb9bd10da82c15dca2f86a1385" category="cell">9060</block>
  <block id="5852f8019b572f4cdef5bab783fa799f" category="cell">Conexiones HTTPS
Se utiliza para conexiones SOAP a través de https
Este puerto se debe abrir para permitir que un cliente se conecte al servidor API de herramientas de ONTAP.</block>
  <block id="b6d767d2f8ed5d21a44b0e5886680cb9" category="cell">22</block>
  <block id="f4e339608b243f9b57b78ffaf061b498" category="cell">SSH (deshabilitado de forma predeterminada)</block>
  <block id="d82d678e9583c1f5f283ec56fbf1abb7" category="cell">9080</block>
  <block id="ef34781e03f49b5db5dd8fa267c4c41b" category="cell">Conexiones HTTPS - VP y SRA - conexiones internas sólo del bucle invertido</block>
  <block id="a44ba9086b2b83ccf2baf7c678723449" category="cell">9083</block>
  <block id="fe01ac95967cd8cb5f5b5669b685277a" category="cell">Conexiones HTTPS: VP y SRA
Se utiliza para conexiones SOAP a través de https</block>
  <block id="abea47ba24142ed16b7d8fbf2c740e0d" category="cell">1162</block>
  <block id="4a0724da5c6f4e4817663ae822550800" category="cell">VP paquetes de captura SNMP</block>
  <block id="5cce8dede893813f879b873962fb669f" category="cell">1527</block>
  <block id="91c15b8eb529bf2100c10383d1010a1e" category="cell">exclusivamente para uso interno</block>
  <block id="60135f95267c6e0711bf5a2858dfff2f" category="cell">Puerto de base de datos Derby, sólo entre este equipo y él mismo, no se aceptan conexiones externas -- sólo conexiones internas</block>
  <block id="13f3cf8c531952d72e5847c4183e6910" category="cell">443</block>
  <block id="1ef2b5426b0824e93e33753fa87ddbf5" category="cell">bidireccional</block>
  <block id="e4b8a8d8761aab7733e317b585d5d606" category="cell">Se utiliza para las conexiones a clústeres de ONTAP</block>
  <block id="bf6184406d1e18fffc86ecf770fbb391" category="inline-link">artículo de base de conocimientos</block>
  <block id="fedac49792829de4ff38fcf7a3846faa" category="list-text">*Compatibilidad con certificados firmados por la entidad de certificación (CA).* las herramientas de ONTAP para VMware vSphere admiten certificados firmados por CA. Vea esto<block ref="0903a062b2072644a9b744a7fece4216" category="inline-link-rx"></block> si quiere más información.</block>
  <block id="9fca19988370da2a459b24505e9d23d5" category="list-text">*Registro de auditoría.* los paquetes de soporte se pueden descargar y son extremadamente detallados. Las herramientas de ONTAP registran toda la actividad de inicio de sesión y cierre de sesión de los usuarios en un archivo de registro independiente. Las llamadas de API VASA se registran en un registro de auditoría de VASA dedicado (cxf.log local).</block>
  <block id="7d60a2806aedd934b75cce55d6693689" category="list-text">*Políticas de contraseña.* se siguen las siguientes directivas de contraseñas:</block>
  <block id="f82f7513742f08b9d2784923213bdc75" category="list-text">Las contraseñas no han iniciado sesión en ningún archivo de registro.</block>
  <block id="83040c348e071499488a8128db207545" category="list-text">Las contraseñas no se comunican en texto sin formato.</block>
  <block id="bc319862df3312f423a50fece7730db9" category="list-text">Las contraseñas se configuran durante el propio proceso de instalación.</block>
  <block id="853c2ea85b86882d0ea73b606a9800a4" category="list-text">El historial de contraseñas es un parámetro configurable.</block>
  <block id="b3d3877bc96752ae50a409c72597d47a" category="list-text">La antigüedad mínima de la contraseña se establece en 24 horas.</block>
  <block id="fb0bdec50022a37424a405b53da7c9c8" category="list-text">El proceso de finalización automática de los campos de contraseña está desactivado.</block>
  <block id="3a04f054be8ad983ea82fd5079519810" category="list-text">Las herramientas de ONTAP cifran toda la información de credenciales almacenada mediante el hash SHA256.</block>
  <block id="46e61d6e7c848d43ddcede8efd36c3d8" category="doc">Complemento de SnapCenter, VMware vSphere</block>
  <block id="ae9e79ac4b60eba67cf1c7508417b42c" category="paragraph">La ingeniería de software del complemento SnapCenter de NetApp para VMware vSphere utiliza las siguientes actividades de desarrollo seguro:</block>
  <block id="b25a1098aff7d0c5ee590f1e1a114bb9" category="list-text">*Pruebas de seguridad de aplicaciones dinámicas (DAST).* Tecnologías diseñadas para detectar condiciones vulnerables en aplicaciones en estado en ejecución. DAST prueba las interfaces HTTP y HTML expuestas de las aplicaciones web.</block>
  <block id="6cc1fee6b4fc48755d78e93170bbed93" category="list-text">*Moneda de código de terceros.* como parte del desarrollo de software y el uso de software de código abierto (OSS), es importante abordar las vulnerabilidades de seguridad que pueden estar asociadas con OSS que se han incorporado a su producto. Se trata de un esfuerzo continuo, ya que la versión del componente OSS puede tener una vulnerabilidad recién descubierta reportada en cualquier momento.</block>
  <block id="87bd0fb9b4198f33535e0e1888a809f5" category="list-text">* Pruebas de penetración.* la prueba de penetración es el proceso de evaluar un sistema, una aplicación web o una red para encontrar vulnerabilidades de seguridad que podrían ser explotadas por un atacante. Las pruebas de penetración (pruebas de Pen) en NetApp las realiza un grupo de empresas de terceros aprobadas y fiables. El alcance de su prueba incluye el lanzamiento de ataques contra una aplicación o software como intrusos hostiles o hackers que utilizan métodos o herramientas de explotación sofisticados.</block>
  <block id="e91db3b3278f7bd95cc704d74c5c9597" category="paragraph">El plugin de SnapCenter de NetApp para VMware vSphere incluye las siguientes funciones de seguridad en cada versión:</block>
  <block id="4abd7d1d5d223683d3346671efb7e89c" category="list-text">*Acceso restringido al shell.* SSH está desactivado de forma predeterminada, y sólo se permiten inicios de sesión una vez si están habilitados desde la consola de VM.</block>
  <block id="8c264fa5ca2c588d960d98bd30cbc897" category="list-text">*Advertencia de acceso en el banner de inicio de sesión.* se muestra el siguiente banner de inicio de sesión después de que el usuario introduzca un nombre de usuario en el indicador de inicio de sesión:</block>
  <block id="0d6633ada3a9803e206b2359d859e892" category="paragraph">Una vez que el usuario completa el inicio de sesión a través del canal SSH, se muestra la siguiente salida:</block>
  <block id="b883bf79639dfce77e395b8458ee69e4" category="list-text">Privilegios nativos de vCenter Server.</block>
  <block id="721796b1cb3468f0daf819180184d460" category="inline-link">Control de acceso basado en roles (RBAC)</block>
  <block id="1d08c46b7567a29be0690a92b9722a58" category="list-text">Privilegios específicos del complemento de VMware vCenter. Para obtener más información, consulte<block ref="f351263ad3706bd0a472039400dece78" category="inline-link-rx"></block>.</block>
  <block id="acab4c655c4a7b4db67fc07e22b86222" category="list-text">*Canales de comunicaciones cifrados.* toda comunicación externa ocurre a través de HTTPS utilizando TLS.</block>
  <block id="47a37e2d5fc8b7c936ad9b2b7a569a08" category="paragraph">En la siguiente tabla se proporcionan los detalles de los puertos abiertos.</block>
  <block id="10bd16a816f831080065e807daa36a9a" category="cell">Número de puerto TCP v4/v6</block>
  <block id="edf0320adc8658b25ca26be5351b6c4a" category="cell">8144</block>
  <block id="d4a973e303ec37692cc8923e3148eef7" category="cell">8080</block>
  <block id="2c25c3d66f80eeaa8d6e5a144c6f942e" category="cell">Conexiones HTTPS para interfaz gráfica de usuario de OVA</block>
  <block id="14b3e670eec63cc0cc456fd904bbfbd9" category="cell">SSH (deshabilitado de forma predeterminada)</block>
  <block id="16fc18d787294ad5171100e33d05d4e2" category="cell">3306</block>
  <block id="4cbf9c234f6b34c242a110cb993252bd" category="cell">MySQL (sólo conexiones internas; las conexiones externas están deshabilitadas de forma predeterminada)</block>
  <block id="29ab4efbdb7c727c81ee1382593bc5e2" category="cell">Nginx (servicios de protección de datos)</block>
  <block id="89f152cad33314315b4995ed1ca71535" category="inline-link">Cómo crear o importar un certificado SSL al plugin de SnapCenter para VMware vSphere (SCV)</block>
  <block id="450adc59e39f23172756ac9369494a2d" category="list-text">*Compatibilidad con certificados firmados por entidad de certificación (CA).* el plugin de SnapCenter para VMware vSphere es compatible con la función de certificados firmados por CA. Consulte<block ref="9f83d87d5d9f604d96288df21d450fac" category="inline-link-rx"></block>.</block>
  <block id="05a1aa8021df4579874c4eeb8788e5c9" category="list-text">*Políticas de contraseña.* las siguientes directivas de contraseñas están en vigor:</block>
  <block id="2c87609dbbc3630573c64e271de8207d" category="list-text">Toda la información de credenciales se almacena mediante el hash SHA256.</block>
  <block id="0f1a6fa0a65f9d5c3c4a16b070104d7a" category="list-text">*Imagen del sistema operativo base.* el producto se entrega con el SO base Debian para OVA con acceso restringido y acceso al shell desactivado. Esto reduce el espacio necesario para los ataques. Todos los sistemas operativos base de la versión SnapCenter se actualizan con los parches de seguridad más recientes disponibles para obtener la máxima cobertura de seguridad.</block>
  <block id="83cd5867ba912e517fa1100299fd1cf3" category="paragraph">NetApp desarrolla funciones de software y parches de seguridad con respecto al dispositivo del plugin de SnapCenter para VMware vSphere y, a continuación, se los libera a los clientes como una plataforma de software integrada. Dado que estos dispositivos incluyen dependencias específicas de sistemas suboperativos de Linux y nuestro software exclusivo, NetApp recomienda no realizar cambios en el sistema operativo de subsistema, ya que esto tiene un gran potencial para afectar al dispositivo de NetApp. Esto podría afectar a la capacidad de NetApp para dar soporte al dispositivo. NetApp recomienda probar e implementar nuestra última versión de código para los dispositivos, ya que se los publica para resolver cualquier problema relacionado con la seguridad.</block>
  <block id="1bc6cee680286aae1b12889369b7f18a" category="summary">MySQL en ONTAP</block>
  <block id="dac8ea4fbfd87a535663c227b91f50e3" category="doc">Programadores de I/O.</block>
  <block id="215dca219378b291ae287eb076489fdd" category="paragraph">El kernel de Linux permite un control de bajo nivel sobre la forma en que se programa la E/S para bloquear los dispositivos.</block>
  <block id="dc36d23ef487690f1698c69d9e49cee2" category="paragraph">Los valores predeterminados en varias distribuciones de Linux varían considerablemente. MySQL recomienda que utilice<block ref="722d122e81cbbe543bd5520bb8678c0e" prefix=" " category="inline-code"></block> o a<block ref="30e482a8ab57cfc19075dece53b0a56b" prefix=" " category="inline-code"></block> Planificador de I/O con I/O asíncrono nativo (AIO) en Linux. En general, los clientes de NetApp y las pruebas internas muestran mejores resultados con NoOps.</block>
  <block id="6def78482bd1915cb81f0f5c19ee8fe6" category="paragraph">El motor de almacenamiento InnoDB de MySQL utiliza el subsistema de E/S asíncrono (AIO nativo) en Linux para realizar solicitudes de lectura anticipada y escritura para páginas de archivos de datos. Este comportamiento es controlado por el<block ref="2c03186a22d036ce7dad84be5de2f2ce" prefix=" " category="inline-code"></block> opción de configuración, que está activada de forma predeterminada. Con AIO nativo, el tipo de programador de E/S tiene mayor influencia en el rendimiento de E/S. Realice pruebas de rendimiento para determinar qué programador de I/O ofrece los mejores resultados para su carga de trabajo y su entorno.</block>
  <block id="e7b09beaf26efc7d8bee91786cf794b5" category="paragraph">Consulte la documentación relevante de Linux y MySQL para obtener instrucciones sobre la configuración del programador de I/O.</block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="doc">Configuración del almacenamiento</block>
  <block id="2f09ac000b4a1808cb795b7bdbb20ecc" category="doc">innodb_log_file_size</block>
  <block id="b8674b2897b288ca55b74328df4780b3" category="paragraph">Seleccionar el tamaño correcto para el tamaño del archivo de registro InnoDB es importante para las operaciones de escritura y para tener un tiempo de recuperación decente después de un fallo del servidor.</block>
  <block id="b61bad6f7bf48bf9abda0c86c9beed79" category="paragraph">Dado que hay tantas transacciones registradas en el archivo, el tamaño del archivo de registro es importante para las operaciones de escritura. Cuando se modifican los registros, el cambio no se vuelve a escribir inmediatamente en el tablespace. En su lugar, el cambio se registra al final del archivo de registro y la página se marca como sucia. InnoDB utiliza su registro para convertir las operaciones de I/O aleatorias en operaciones de I/O secuenciales</block>
  <block id="e87d83a3c0af4df83efb4784b5182f8f" category="paragraph">Cuando el log está lleno, la página sucia se escribe en el tablespace en secuencia para liberar espacio en el archivo log. Por ejemplo, supongamos que un servidor se bloquea en medio de una transacción y que las operaciones de escritura solo se registran en el archivo de registro. Antes de que el servidor pueda volver a activarse, debe pasar por una fase de recuperación en la que se reproduzcan los cambios registrados en el archivo de registro. Cuantas más entradas haya en el archivo de registro, más tiempo tardará el servidor en recuperarse.</block>
  <block id="8321756b7fedf72543a1b0917bf92613" category="paragraph">En este ejemplo, el tamaño del archivo log afecta tanto al tiempo de recuperación como al rendimiento de escritura. Al elegir el número correcto para el tamaño del archivo log, equilibre el tiempo de recuperación con respecto al rendimiento de escritura. Normalmente, cualquier cosa entre 128M y 512M es una buena relación calidad-precio.</block>
  <block id="d4ae77cd65c244ceb4277b27553d6931" category="doc">Bases de datos MySQL en ONTAP</block>
  <block id="598132a821e8cc696fbbae934047d991" category="paragraph">MySQL y sus variantes, incluyendo MariaDB y Percona MySQL, es la base de datos más popular del mundo.</block>
  <block id="35701e1bcd40c8e1a520fc33d0e14842" category="doc">innodb_flush_method</block>
  <block id="138738e11d5fda5c496edaa92e32e158" category="paragraph">El parámetro innodb_flush_method especifica cómo InnoDB abre y vacía los archivos log y de datos.</block>
  <block id="c262c8cd82b96f69fbbc058d7a35683b" category="section-title">Optimizaciones</block>
  <block id="d1e67ebe6122765789852eb430c42c75" category="paragraph">En la optimización de InnoDB, la configuración de este parámetro modifica el rendimiento de la base de datos cuando es aplicable.</block>
  <block id="51ca63a7fb332d4d18e7139ea5787c50" category="paragraph">Las siguientes opciones son para vaciar los archivos a través de InnoDB:</block>
  <block id="a9b8d4c72b58a9554274cba7904d47e2" category="list-text"><block ref="e590322920bebc1156ab585bd6597d76" prefix="" category="inline-code"></block>. InnoDB utiliza el<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> llamada del sistema para vaciar los archivos de datos y de registro. Esta opción es el valor predeterminado.</block>
  <block id="8198b1fd4bf2fafa4f4e8ffb4a8ac900" category="list-text"><block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix="" category="inline-code"></block>. InnoDB utiliza el<block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix=" " category="inline-code"></block> opción para abrir y vaciar los archivos de registro y fsync() para vaciar los archivos de datos. InnoDB no utiliza<block ref="a48be70a21bca2cf4b3e481efed66ae4" prefix=" " category="inline-code"></block> Directamente, porque ha habido problemas con él en muchas variedades de UNIX.</block>
  <block id="f89f9147df5dde99a7944d2028b59e7e" category="list-text"><block ref="6a334fd488ef92b18584207148410cc4" prefix="" category="inline-code"></block>. InnoDB utiliza el<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> opción (o.<block ref="42d27f470f62deaad644fef8618b59bb" prefix=" " category="inline-code"></block> En Solaris) para abrir los archivos de datos y usos<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> para vaciar los archivos de datos y de registro. Esta opción está disponible en algunas versiones de GNU/Linux, FreeBSD y Solaris.</block>
  <block id="5e90100e134d805a66f8cda2e73f5298" category="list-text"><block ref="d66655d6d13113f23421f282ed1eaeb7" prefix="" category="inline-code"></block>. InnoDB utiliza el<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> Durante el vaciado de I/O; sin embargo, omite el<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> llamada del sistema posterior. Esta opción no es adecuada para algunos tipos de sistemas de archivos (por ejemplo, XFS). Si no está seguro de si su sistema de archivos requiere un<block ref="4d0b2ade287f8f35e993511729bc75a1" prefix=" " category="inline-code"></block> llamada al sistema (por ejemplo, para conservar todos los metadatos del archivo), utilice el<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> en su lugar.</block>
  <block id="c680d437163cc6bab4f9bdb35c3073d0" category="section-title">Observación</block>
  <block id="907dee0040812e8e7d1fd00b870b5063" category="paragraph">En las pruebas de laboratorio de NetApp, el<block ref="e590322920bebc1156ab585bd6597d76" prefix=" " category="inline-code"></block> La opción predeterminada se utilizó en NFS y SAN, y fue un gran improvisador de rendimiento<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block>. Mientras se utiliza el método de vaciado como<block ref="6a334fd488ef92b18584207148410cc4" prefix=" " category="inline-code"></block> Con ONTAP, hemos observado que el cliente escribe muchas escrituras de un solo byte en el borde del bloque de 4096 KB de forma en serie. Estas escrituras aumentan la latencia en la red y el rendimiento disminuye.</block>
  <block id="2f0b9319cf6d59e07ea4b1ef65a12be1" category="doc">open_file_limits</block>
  <block id="11e52b21a9795b7dcf947027b0ec5d01" category="paragraph">La<block ref="2f0b9319cf6d59e07ea4b1ef65a12be1" prefix=" " category="inline-code"></block> el parámetro determina el número de archivos que el sistema operativo permite que mysqld abra.</block>
  <block id="e0732f22b2900006e8fcb6367fd162f7" category="paragraph">El valor de este parámetro en tiempo de ejecución es el valor real permitido por el sistema y puede ser diferente del valor especificado al iniciar el servidor. El valor es 0 en sistemas donde MySQL no puede cambiar el número de archivos abiertos. Eficaz<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> el valor se basa en el valor especificado en el inicio del sistema (si lo hay) y en los valores de<block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix=" " category="inline-code"></block> y..<block ref="023a3b50ddf424c9a1d51984190a0c92" prefix=" " category="inline-code"></block> mediante el uso de estas fórmulas:</block>
  <block id="6b840ff0a7667f4642a0844269657fc4" category="list-text">10 +<block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix=" " category="inline-code"></block> + <block ref="023a3b50ddf424c9a1d51984190a0c92" prefix="(" category="inline-code"></block> 2)</block>
  <block id="d3de183489c20b8efa2947eeff3028d7" category="list-text"><block ref="0bc91339c0d774f560a9a38fc9dfac30" prefix="" category="inline-code"></block> 5</block>
  <block id="2c08922fbaba089e7c2982df43fd352a" category="list-text">Límite del sistema operativo si es positivo</block>
  <block id="8ca153937fcbdf56497ad779a91f31d1" category="list-text">Si el límite del sistema operativo es infinito:<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> el valor se especifica en el inicio; 5.000 si no hay ninguno</block>
  <block id="98038bb4026a70f5ee4041522c6eebe4" category="paragraph">El servidor intenta obtener el número de descriptores de archivo utilizando el máximo de estos cuatro valores. Si no se pueden obtener muchos descriptores, el servidor intenta obtener tantos como el sistema permita.</block>
  <block id="3ee58d04a0dc9b2551698643e0421005" category="doc">innodb_lru_scan_profund</block>
  <block id="29d0f4f8b383d39e73abd11ac73ca28a" category="paragraph">La<block ref="3ee58d04a0dc9b2551698643e0421005" prefix=" " category="inline-code"></block> El parámetro influye en los algoritmos y la heurística de la operación de vaciado para el pool de buffers de InnoDB.</block>
  <block id="eeb16232629bd788f0d29c104105bba2" category="paragraph">Este parámetro es principalmente interesante para los expertos en rendimiento que ajustan las cargas de trabajo con un gran volumen de I/O. Para cada instancia de pool de buffers, este parámetro especifica hasta qué punto en la lista de páginas de uso menos reciente (LRU) el thread del limpiador de páginas debe continuar escaneando, buscando páginas sucias para vaciar. Esta operación en segundo plano se realiza una vez por segundo.</block>
  <block id="39359bf2914e4e1cf84a9dea580fd20a" category="paragraph">Puede ajustar el valor hacia arriba o hacia abajo para minimizar el número de páginas libres. No establezca el valor mucho más alto de lo necesario, ya que los escaneos pueden tener un costo de rendimiento significativo. Además, considere ajustar este parámetro al cambiar el Núm. De instancias del pool de buffers, porque<block ref="f2c8312d381c16c6c95a727c3f61a4c7" prefix=" " category="inline-code"></block> define la cantidad de trabajo que realiza el thread de limpieza de páginas cada segundo.</block>
  <block id="513a275422fae2456617321a2f3fc0af" category="paragraph">Una configuración inferior a la predeterminada es adecuada para la mayoría de las cargas de trabajo. Considere aumentar el valor solo si cuenta con capacidad de I/O de reserva con una carga de trabajo típica. Por el contrario, si una carga de trabajo con gran cantidad de escritura satura la capacidad de E/S, disminuya el valor, especialmente si tiene un pool de buffers grande.</block>
  <block id="62812b938ba1113b81bd7f612ad0e6f8" category="doc">innodb_buffer_pool_size</block>
  <block id="d7a8b502d05f5e477158eb80c1fb8dae" category="paragraph">El pool de buffers de InnoDB es la parte más importante de cualquier actividad de ajuste.</block>
  <block id="5cb6c45d18482180f34ae727b53379fb" category="paragraph">InnoDB depende en gran medida del pool de buffers para almacenar en caché los índices y remar los datos, el índice hash adaptativo, el buffer INSERT y muchas otras estructuras de datos utilizadas internamente. El pool de búfer también almacena en búfer los cambios en los datos para que las operaciones de escritura no sean necesarias inmediatamente en el almacenamiento, lo que mejora el rendimiento. El pool de buffers es una parte integral de InnoDB y su tamaño debe ajustarse en consecuencia. Tenga en cuenta los siguientes factores al definir el tamaño del pool de buffers:</block>
  <block id="03f07291794c3b9cb00d04cb9f30be81" category="list-text">Para una máquina exclusiva de InnoDB, establezca el tamaño del pool de buffers en 80% o más de RAM disponible.</block>
  <block id="7b0119b7fa59f87d23d5c65da456b226" category="list-text">Si no es un servidor dedicado de MySQL, establezca el tamaño en 50% de RAM.</block>
  <block id="a6a9695e1464f5554c0006c55facfadf" category="doc">Descriptores de archivo</block>
  <block id="8e222c68dd214db9f8a1b5b572ee6267" category="paragraph">Las utiliza para abrir nuevas conexiones, almacenar tablas en la caché, crear tablas temporales para resolver consultas complicadas y acceder a las persistentes. Si mysqld no puede abrir nuevos archivos cuando sea necesario, puede dejar de funcionar correctamente. Un síntoma común de este problema es el error 24, “Demasiados archivos abiertos”. El número de descriptores de archivo que mysqld puede abrir simultáneamente se define por el<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> opción establecida en el archivo de configuración <block ref="86d0d007043d911697753b35e2c18f35" prefix="(" category="inline-code"></block>). Pero<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> también depende de los límites del sistema operativo. Esta dependencia hace que la configuración de la variable sea más complicada.</block>
  <block id="07561a91f81dfe3c8e4364aac8bdbea4" category="paragraph">MySQL no puede definir su<block ref="3d39e9c5aa2f78830dd6993cec18e93e" prefix=" " category="inline-code"></block> opción superior a la especificada en<block ref="dd1c6d8164dfd1cee0afa39b177e843b" prefix=" " category="inline-code"></block>. Por lo tanto, debe establecer explícitamente estos límites en el nivel del sistema operativo para permitir que MySQL abra archivos según sea necesario. Hay dos formas de comprobar el límite de archivos en Linux:</block>
  <block id="84e705ac120a887df441f4161dc29409" category="list-text">La<block ref="2eabb4efed7dffb32ea1170eab71b798" prefix=" " category="inline-code"></block> command le proporciona rápidamente una descripción detallada de los parámetros que se permiten o bloquean. Los cambios realizados por la ejecución de este comando no son permanentes y se borrarán tras un reinicio del sistema.</block>
  <block id="a4c404dc92855948bc4c007a86091dbe" category="list-text">Cambios en la<block ref="b803f460349bd101b1de260021ef0e60" prefix=" " category="inline-code"></block> el archivo es permanente y no se ve afectado por un reinicio del sistema.</block>
  <block id="cbcab8220d4ffddbdc44f9936125d83d" category="paragraph">Asegúrese de cambiar los límites duros y suaves para el usuario mysql. Los siguientes extractos son de la configuración:</block>
  <block id="97dc47f90c600a96fac6642560ffaceb" category="paragraph">En paralelo, actualice la misma configuración en<block ref="90f16be5b82ca0aa94088c89fe00b3dd" prefix=" " category="inline-code"></block> para utilizar completamente los límites de archivo abierto.</block>
  <block id="395ec860c9530814e94538b7121a8319" category="doc">innodb_flush_log_at_trx_commit</block>
  <block id="2f2c7742844f13de59d435b9099c78cc" category="paragraph">Cuando se produce un cambio en los datos, este no se escribe inmediatamente en el almacenamiento.</block>
  <block id="0b36b8f791a48c7b4692e7df069dabc8" category="paragraph">En su lugar, los datos se registran en un buffer de log, que es una parte de la memoria que InnoDB asigna a los cambios de buffer que se registran en el archivo log. InnoDB vacía el buffer en el archivo log cuando se confirma una transacción, cuando el buffer se llena, o una vez por segundo, lo que ocurra primero. La variable de configuración que controla este proceso es innodb_flush_log_at_trx_commit. Las opciones de valor incluyen:</block>
  <block id="280a38864b81c14ba3db52801e087ed0" category="list-text">Cuando lo ajuste<block ref="cab9a35054c49f0ba619a6e6943f461b" prefix=" " category="inline-code"></block>, InnoDB escribe los datos modificados (en el grupo de buffers de InnoDB) en el archivo log (ib_logfile) y vacía el archivo log (escribir en almacenamiento) cada segundo. Sin embargo, no hace nada cuando se confirma la transacción. Si hay un fallo de alimentación o un bloqueo del sistema, ninguno de los datos sin vaciar es recuperable, ya que no se escribe en el archivo de registro o en las unidades.</block>
  <block id="5967bb5566cb7cd8bdb0b372ceb21565" category="list-text">Cuando lo ajuste<block ref="1ab7a7611b59147e84a38b6f3e7d9d09" prefix=" " category="inline-code"></block>, InnoDB escribe el buffer de log en el log de transacciones y se vacía en un almacenamiento duradero para cada transacción. Por ejemplo, para todas las confirmaciones de transacciones, InnoDB escribe en el log y, a continuación, escribe en el almacenamiento. Un almacenamiento más lento afecta negativamente al rendimiento; por ejemplo, se reduce el número de transacciones InnoDB por segundo.</block>
  <block id="9e9b3a43cb7a1b13c5ee3f6519d7f60e" category="list-text">Cuando lo ajuste<block ref="44d4dfee9b1c95f8768bec989cd3baf5" prefix=" " category="inline-code"></block>, InnoDB escribe el buffer de log en el archivo log en cada confirmación; sin embargo, no escribe datos en el almacenamiento. InnoDB vacía los datos una vez cada segundo. Incluso si hay un fallo de alimentación o un fallo del sistema, los datos de la opción 2 están disponibles en el archivo de registro y son recuperables.</block>
  <block id="14f3e0328e25aa02b37bd6817a442a58" category="paragraph">Si el rendimiento es el objetivo principal, establezca el valor en 2. Como InnoDB escribe en las unidades una vez por segundo, no por cada confirmación de transacción, el rendimiento mejora drásticamente. Si se produce un fallo en el suministro eléctrico o un fallo, los datos se pueden recuperar del registro de transacciones.</block>
  <block id="4a34cbb1957909093a2e216fc1cd0962" category="paragraph">Si la seguridad de los datos es el objetivo principal, establezca el valor en 1 para que, para cada confirmación de transacción, InnoDB se vacíe en las unidades. Sin embargo, el rendimiento puede verse afectado.</block>
  <block id="53be3047aa6f8a62c640cc8b4d6089c6" category="admonition">*NetApp recomienda* Establecer el valor innodb_flush_log_trx_commit en 2 para un mejor rendimiento.</block>
  <block id="2199371f8380c97ad11a03fba3b501c9" category="doc">innodb_io_capacity</block>
  <block id="ac165f23bb7435219b226ed6e76c5fa4" category="paragraph">En el plug-in InnoDB, se agregó un nuevo parámetro llamado innodb_io_capacity desde MySQL 5,7.</block>
  <block id="b4f38c42ef968074288f239b42e92b7f" category="paragraph">Controla el número máximo de IOPS que realiza InnoDB (lo que incluye la tasa de vaciado de páginas desfasadas y el tamaño de lote [ibuf] del buffer de inserción). El parámetro innodb_io_capacity define un límite superior de IOPS por tareas en segundo plano de InnoDB, como vaciar páginas del pool de buffers y fusionar datos del buffer de cambios.</block>
  <block id="9679a08c293f29d9546c42207b09d418" category="paragraph">Defina el parámetro innodb_io_capacity en el número aproximado de operaciones de E/S que el sistema puede realizar por segundo. Lo ideal es mantener la configuración lo más baja posible, pero no tan baja que las actividades en segundo plano se ralenticen. Si el valor es demasiado alto, los datos se eliminan del pool de buffers e insertan el buffer demasiado rápido para que el almacenamiento en caché proporcione una ventaja significativa.</block>
  <block id="668b6acc98c3469094062ed50b43e43a" category="admonition">*NetApp recomienda* que si utiliza esta configuración en NFS, analice el resultado de la prueba de IOPS (SysBench/fio) y establezca el parámetro en consecuencia. Utilice el valor más pequeño posible para vaciar y depurar para mantener el ritmo a menos que vea más páginas modificadas o sucias de las que desee en el pool de buffers de InnoDB.</block>
  <block id="038b11d42ee14bd77b6370c575c63b16" category="admonition">No utilice valores extremos como 20.000 o más a menos que haya demostrado que los valores más bajos no son suficientes para su carga de trabajo.</block>
  <block id="62385f5ceb285bca676cb0561555d719" category="paragraph">El parámetro InnoDB_IO_CAPACITY regula las tasas de vaciado y la E/S relacionada</block>
  <block id="c957ef06af970a7526a73e741b47fef1" category="admonition">Puede dañar seriamente el rendimiento si se configura este parámetro o el parámetro innodb_io_capacity_max demasiado alto y se desperdician las operaciones de I/O con vaciado prematuro.</block>
  <block id="d32067c550345cae14e678b4def6aa22" category="doc">MySQL sobre SAN</block>
  <block id="b238d5dd75fe5ed855c5b3047e074050" category="paragraph">MySQL con SAN puede configurarse con dos opciones usando el modelo de dos volúmenes habitual.</block>
  <block id="58d94bb6e53e154e2f4b16efa09f4c0d" category="paragraph">Las bases de datos más pequeñas pueden colocarse en parejas de LUN estándar siempre que las demandas de I/O y capacidad estén dentro de los límites de un único sistema de archivos LUN. Por ejemplo, una base de datos que requiere aproximadamente 2K 000 IOPS aleatorias se puede alojar en un único sistema de archivos con una sola LUN. Del mismo modo, una base de datos con un tamaño de solo 100GB TB podría adaptarse en una única LUN sin crear un problema de gestión.</block>
  <block id="c33bcb4f520265bb106616e844397ffb" category="paragraph">Las bases de datos de mayor tamaño requieren varios LUN. Por ejemplo, una base de datos que requiere 100K 000 IOPS probablemente necesitará al menos ocho LUN. Una única LUN se convertiría en un cuello de botella debido al número inadecuado de canales SCSI a las unidades. Igualmente, una base de datos de 10TB TB sería difícil gestionar una sola LUN de 10TB TB. Los administradores de volúmenes lógicos están diseñados para unir las funcionalidades de rendimiento y capacidad de varias LUN y así mejorar el rendimiento y la capacidad de gestión.</block>
  <block id="428e88a1415b00f5eb396829b4bd9a2c" category="paragraph">En ambos casos, debería ser suficiente una pareja de volúmenes de ONTAP. Con una configuración sencilla, la LUN de archivo de datos se colocaría en un volumen dedicado, al igual que las LUN de registro. Con una configuración de gestor de volúmenes lógico, todos los LUN del grupo de volúmenes de archivos de datos estarían en un volumen dedicado, y las LUN del grupo de volúmenes de registro estarían en un segundo volumen dedicado.</block>
  <block id="e8c31916b755be39cb0a66804a1d8f8b" category="paragraph">*NetApp recomienda* el uso de dos sistemas de archivos para implementaciones de MySQL en SAN:</block>
  <block id="fe9d8ca2c46747e16ed31f64638e66e6" category="list-text">El primer sistema de archivos almacena todos los datos MySQL, incluidos los tablespaces, los datos y el índice.</block>
  <block id="04d82ed32fa1eeaa6df117c178062441" category="list-text">El segundo sistema de archivos almacena todos los registros (registros binarios, registros lentos y registros de transacciones).</block>
  <block id="15bcb76b7e8b441c0d2a6e723f70c20c" category="paragraph">Hay varias razones para separar los datos de esta manera, incluyendo:</block>
  <block id="02774797d31a8f1c6d805860038c32a3" category="list-text">Los patrones de E/S de los archivos de datos y los archivos de registro son diferentes. Separarlos permitirá más opciones con controles de calidad de servicio.</block>
  <block id="6cab2c793e807e2d0c57f5b0d96505c1" category="list-text">Para un uso óptimo de la tecnología Snapshot es necesario poder restaurar los archivos de datos de forma independiente. La combinación de archivos de datos con archivos de registro interfiere con la restauración de archivos de datos.</block>
  <block id="553ad1f7b6f5cfee021e5cf56e56a289" category="list-text">La tecnología SnapMirror de NetApp se puede usar para proporcionar una funcionalidad de recuperación ante desastres simple y con bajo objetivo de punto de recuperación para una base de datos; no obstante, se requieren diferentes programaciones de replicación para los archivos y registros de datos.</block>
  <block id="ff5f52a69a35dd41da3e3c4b810e4f94" category="admonition">Utilice esta distribución básica de dos volúmenes para preparar la solución para el futuro, de modo que todas las funciones de ONTAP se puedan utilizar si fuera necesario.</block>
  <block id="7b755794e9de5716b2d6305bd10bee1b" category="paragraph">*NetApp recomienda* formatear su unidad con el sistema de archivos ext4 debido a las siguientes características:</block>
  <block id="fa92f58d5035dec5e24a787f76504783" category="list-text">Enfoque ampliado de las funciones de gestión de bloques utilizadas en el sistema de archivos de registro en diario (JFS) y las funciones de asignación retrasada del sistema de archivos extendido (XFS).</block>
  <block id="a72d73cde02c10703b72dcae6bc7c812" category="list-text">ext4 permite sistemas de archivos de hasta 1 exbibyte (2^60 bytes) y archivos de hasta 16 tebibytes (16 * 2^40 bytes). Por el contrario, el sistema de archivos ext3 solo admite un tamaño máximo del sistema de archivos de 16TB GB y un tamaño máximo de archivo de 2TB GB.</block>
  <block id="56b4168424fa999bc383d24daf2da4eb" category="list-text">En los sistemas de archivos ext4, la asignación de bloques múltiples (mballoc) asigna varios bloques para un archivo en una sola operación, en lugar de asignarlos uno por uno, como en ext3. Esta configuración reduce la sobrecarga de llamar al asignador de bloques varias veces y optimiza la asignación de memoria.</block>
  <block id="632635d22b347f0140fb15d0eb0ed09e" category="list-text">Aunque XFS es el valor predeterminado para muchas distribuciones de Linux, administra los metadatos de manera diferente y no es adecuado para algunas configuraciones de MySQL.</block>
  <block id="aff8b2ed0a4719f014e5baeb861ea7d4" category="paragraph">*NetApp recomienda* usar opciones de tamaño de bloque 4K con la utilidad mkfs para alinearse con el tamaño de LUN de bloque existente.</block>
  <block id="0a24d0336b7b0b29a9daa97f88499884" category="paragraph"><block ref="018d13c1d8b9abcae080b8abbc7c2d8b" prefix="" category="inline-code"></block></block>
  <block id="86fc8cb3bf2cae621315896a94b35f67" category="paragraph">Las LUN de NetApp almacenan datos en bloques físicos de 4KB KB, lo que produce ocho bloques lógicos de 512 bytes.</block>
  <block id="5f441ceabc94de2a9cced94d9f53a2d0" category="paragraph">Si no se configura el mismo tamaño de bloque, las operaciones de I/O no se alinearán con los bloques físicos correctamente y podrían escribir en dos unidades distintas de un grupo RAID, lo que dará como resultado latencia.</block>
  <block id="236ac851d05b8822524001920948f23d" category="admonition">Es importante alinear las operaciones de I/O para que las operaciones de lectura/escritura sean fluidas. Sin embargo, cuando las operaciones de I/O se inician en un bloque lógico que no está al inicio de un bloque físico, la I/O se desalinea. Las operaciones de I/O se alinean solo cuando comienzan con un bloque lógico, es decir, el primer bloque lógico de un bloque físico.</block>
  <block id="282155126a94a0702cfd80daf38d4362" category="doc">Información general de configuración</block>
  <block id="3225a10b07f1580f10dee4abc3779e6c" category="cell">Parámetros</block>
  <block id="c82a6100dace2b41087ba6cf99a5976a" category="cell">Valores</block>
  <block id="b10db909b8fda84e70bf9b308d0938d9" category="cell">256M</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="7ccc31934ae8244d8263d3c09bcee186" category="cell">innodb_doublewrite</block>
  <block id="e590322920bebc1156ab585bd6597d76" category="cell">fsync</block>
  <block id="adb0c1ec32461889a5093441599260eb" category="cell">11G</block>
  <block id="774412967f19ea61d448977ad9749078" category="cell">8192</block>
  <block id="311887a53ec7390fc383fa2ad813f012" category="cell">innodb_buffer_pool_instances</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8</block>
  <block id="1006f82d8df7d2325439b28ea691737c" category="cell">open_file_limit</block>
  <block id="3c9b5f1cd6a030bcb7bed9eac80589fb" category="cell">65535</block>
  <block id="c9f5a4d3ede4d084dda0a788ed06783c" category="paragraph">Para establecer los parámetros descritos en esta sección, debe cambiarlos en el archivo de configuración de MySQL (my.cnf). Las mejores prácticas de NetApp se deben a las pruebas que se realizan internamente.</block>
  <block id="6a554ff1dc93539a626e576bf0d28a02" category="paragraph">La contenerización de bases de datos MySQL es cada vez más frecuente.</block>
  <block id="bcc002a9f2e2ade112438f50a6630498" category="paragraph">La gestión de contenedores de bajo nivel casi siempre se realiza a través de Docker. Las plataformas de gestión de contenedores, como OpenShift y Kubernetes, simplifican aún más la gestión de entornos de contenedores de gran tamaño. Los beneficios de la contenerización incluyen costos más bajos, porque no hay necesidad de licenciar un hipervisor. Además, los contenedores permiten que varias bases de datos se ejecuten aisladas entre sí mientras comparten el mismo kernel y sistema operativo subyacente. Los contenedores se pueden aprovisionar en microsegundos.</block>
  <block id="14d9b10c6196045941347a9e85704b50" category="inline-link-macro">Documentación de Astra Trident</block>
  <block id="b8c3891a902a70c4f7f774363652f4b4" category="summary">Estructura de archivos de MySQL</block>
  <block id="5713a921d815fd7d19875846450f8ea8" category="doc">Estructura de archivos</block>
  <block id="4955922857da5499a2f1be602a96b0ff" category="paragraph">InnoDB actúa como la capa media entre el almacenamiento y el servidor MySQL, almacena los datos en las unidades.</block>
  <block id="8a6fab0b8bb36427eda4071adfd7780b" category="inline-image-macro">Error: No se ha encontrado la imagen gráfica</block>
  <block id="5d416cf65dd1e2c908bf430f957c89f8" category="paragraph">MySQL I/O se clasifica en dos tipos:</block>
  <block id="e8a320970c929abda9ae744b0b9e8f5f" category="list-text">I/O de archivo aleatoria</block>
  <block id="85430c0aa096ec282f2a14156baa312e" category="list-text">E/S de archivo secuencial</block>
  <block id="b7b9a4c6983139a2673988826094a3cf" category="paragraph">Los archivos de datos se leen y se sobrescriben aleatoriamente, lo que da como resultado un elevado número de IOPS. Por lo tanto, se recomienda el almacenamiento SSD.</block>
  <block id="322f79fd77365edecd173807cb429ca2" category="paragraph">Los archivos de registro de recuperación y los archivos de registro binarios son registros transaccionales. Se escriben secuencialmente, por lo que puede obtener un buen rendimiento en HDD con la caché de escritura. Se produce una lectura secuencial en la recuperación, pero rara vez causa un problema de rendimiento, porque el tamaño de los archivos de registro suele ser menor que el de los archivos de datos y las lecturas secuenciales son más rápidas que las lecturas aleatorias (se producen en archivos de datos).</block>
  <block id="a898d206a27508975fea2e241af2f04e" category="paragraph">El buffer de doble escritura es una característica especial de InnoDB. En primer lugar, InnoDB escribe las páginas vaciadas en el buffer de doble escritura y, a continuación, escribe las páginas en sus posiciones correctas en los archivos de datos. Este proceso evita la corrupción de páginas. Sin el búfer de doble escritura, la página puede dañarse si se produce un fallo de alimentación durante el proceso de escritura en unidades. Como la escritura en el búfer de doble escritura es secuencial, está muy optimizada para HDD. Las lecturas secuenciales se producen en la recuperación.</block>
  <block id="363512900e45bc17bdd6edfa50582862" category="paragraph">Como la NVRAM de ONTAP ya proporciona protección de escritura, no es necesario el almacenamiento en búfer de doble escritura. MySQL tiene un parámetro,<block ref="02d3c518a4019ea00e34e16491d826b4" prefix=" " category="inline-code"></block>, para desactivar el buffer de doble escritura. Esta característica puede mejorar sustancialmente el rendimiento.</block>
  <block id="49a7df723922bddb4df4002b51087a1c" category="paragraph">El buffer INSERT también es una característica especial de InnoDB. Si los bloques de índice secundarios no únicos no están en la memoria, InnoDB inserta entradas en el buffer de inserción para evitar operaciones de E/S aleatorias. Periódicamente, el buffer de inserción se fusiona en los árboles de índice secundarios de la base de datos. El buffer de inserción reduce el número de operaciones de E/S fusionando las solicitudes de E/S en el mismo bloque; las operaciones de E/S aleatorias pueden ser secuenciales. El búfer de inserción también está altamente optimizado para HDD. Tanto las escrituras secuenciales como las lecturas se producen durante las operaciones normales.</block>
  <block id="6a0190340f27f29279bbfd319800289d" category="paragraph">Los segmentos de deshacer están orientados a E/S aleatorias. Para garantizar la concurrencia multiversión (MVCC), InnoDB debe registrar imágenes antiguas en los segmentos de deshacer. La lectura de imágenes anteriores de los segmentos de deshacer requiere lecturas aleatorias. Si ejecuta una transacción larga con lecturas repetibles (como mysqldump, transacción única) o ejecuta una consulta larga, pueden producirse lecturas aleatorias. Por lo tanto, almacenar segmentos de deshacer en SSD es mejor en esta instancia. Si ejecuta sólo transacciones o consultas cortas, las lecturas aleatorias no suponen un problema.</block>
  <block id="a27e0d4b650aa6db30fdd95b54c94b27" category="paragraph">*NetApp recomienda* el siguiente diseño de almacenamiento debido a las características de E/S de InnoDB.</block>
  <block id="defc1bfda928f419df5e4af79c98343e" category="list-text">Un volumen para almacenar archivos de MySQL orientados a I/O aleatorios y secuenciales</block>
  <block id="7fd750411093ebd1faa0d99dd2608514" category="list-text">Otro volumen para almacenar archivos de MySQL orientados a I/O puramente secuenciales</block>
  <block id="0561a3b014eef0e5125fa63e1626cf57" category="paragraph">Este diseño también le ayuda a diseñar políticas y estrategias de protección de datos.</block>
  <block id="9166d970028a28a614af39e6286371b7" category="paragraph">Es posible desactivar este parámetro con<block ref="8cafbd8d9096941261e87f4f9152ab92" prefix=" " category="inline-code"></block> para pruebas de rendimiento o cuando le preocupa más el rendimiento superior que la integridad de los datos o posibles fallos. InnoDB utiliza una técnica de vaciado de archivos denominada doble escritura. Antes de escribir páginas en los archivos de datos, InnoDB las escribe en un área contigua denominada buffer de doble escritura. Una vez que se hayan completado las operaciones de escritura y vaciado en el buffer de doble escritura, InnoDB escribe las páginas en sus posiciones adecuadas en el archivo de datos. Si el sistema operativo o un proceso mysqld se bloquea durante la escritura de una página, InnoDB puede encontrar más tarde una buena copia de la página desde el buffer de doble escritura durante la recuperación de fallos.</block>
  <block id="3dfd4b9a526f8a8cf17021e34638b375" category="admonition">*NetApp recomienda* deshabilitar el buffer de doble escritura. NVRAM de ONTAP sirve la misma función. El almacenamiento en búfer doble dañará innecesariamente el rendimiento.</block>
  <block id="dd5a2a602f713562e0f9f0fd8385660e" category="doc">MySQL sobre NFS</block>
  <block id="0e5e83102103fcdd25af430bf7327034" category="paragraph">La documentación de MySQL recomienda el uso de NFSv4 para puestas en marcha de NAS.</block>
  <block id="ca0d9fdc80b88e73b548638af421788f" category="section-title">Tamaños de transferencia NFS de ONTAP</block>
  <block id="efcd0ba3fcbee9896a25804677e70b4b" category="paragraph">De forma predeterminada, ONTAP limitará el tamaño de I/O de NFS a 64K. La E/S aleatoria con una base de datos MySQL utiliza un tamaño de bloque mucho más pequeño, que es muy inferior al máximo de 64K KB. Las E/S de bloques grandes suelen estar en paralelo, por lo que el máximo de 64K KB tampoco es una limitación.</block>
  <block id="4655f686de75b23f16d530ed7351c447" category="paragraph">Hay algunas cargas de trabajo en las que el máximo de 64K crea una limitación. En particular, las operaciones de un solo subproceso, como las operaciones de copia de seguridad de exploración de tabla completa, se ejecutarán de forma más rápida y eficiente si la base de datos puede realizar menos I/O pero más grandes. El tamaño óptimo de gestión de I/O para ONTAP con cargas de trabajo de base de datos es 256K. Las opciones de montaje de NFS indicadas para sistemas operativos específicos a continuación se han actualizado de la versión 64K a la 256K correspondiente.</block>
  <block id="3ab93db30f3dded2c8d71859afbb53f6" category="admonition">Nunca reduzca el tamaño máximo permitido de transferencia en ONTAP por debajo del valor de rsize/wsize de los sistemas de archivos NFS montados actualmente. Esto puede crear bloqueos o incluso corrupción de datos con algunos sistemas operativos. Por ejemplo, si los clientes NFS se establecen actualmente con un valor de rsize/wsize de 65536 000, el tamaño de transferencia máximo de ONTAP se podría ajustar entre 65536 000 y 1048576 000 sin que ello afecte a porque los propios clientes están limitados. Reducir el tamaño máximo de transferencia por debajo de 65536 puede dañar la disponibilidad o los datos.</block>
  <block id="5ea0bb5d4dab46d7971fef94ccde9369" category="paragraph">*NetApp recomienda*</block>
  <block id="09c6aa928c90ba68a4e03deadfeaa644" category="paragraph">Ajuste de la siguiente configuración de NFSv4 fstab (/etc/fstab):</block>
  <block id="0ae3c9648bc2d8c33fa57415604da370" category="paragraph"><block ref="a63a3dc825ff52908de7c9dfcb29ffa5" prefix="" category="inline-code"></block></block>
  <block id="3e0b2c100b093560f63ad57c6849bc8a" category="admonition">Un problema común con NFSv3 era los archivos de registro InnoDB bloqueados después de una interrupción del suministro eléctrico. El uso de archivos de registro de hora o cambio solucionó este problema. Sin embargo, NFSv4 tiene operaciones de bloqueo y realiza un seguimiento de archivos abiertos y delegaciones.</block>
  <block id="62e4eb800d20b46085ccb975da78bafe" category="sidebar">ONTAP es la base para la gestión y la protección de datos de numerosas tecnologías de aplicaciones y bases de datos empresariales. En las siguientes páginas se ofrece información sobre las mejores prácticas y los procedimientos de implementación para ONTAP y las aplicaciones empresariales e infraestructuras.</block>
  <block id="78898e52fcbdc5337204a384f2456d4f" category="sidebar">Microsoft SQL Server</block>
  <block id="4f60acc41a8bf3fa75e7f74768637787" category="sidebar">Protección de datos de Microsoft SQL Server</block>
  <block id="b8529ff730dcf8dd2178d72de271dc4d" category="sidebar">Bases de datos de código abierto</block>
  <block id="bb9a5a6fadabab849d2e87f0898d7601" category="sidebar">MariaDB y MySQL en ONTAP</block>
  <block id="5ad2a11eceac3ebd7cbf3b534ebdb1db" category="sidebar">PostgreSQL en ONTAP</block>
  <block id="c30dd1a85cf86d95b11c1a08f70130ce" category="sidebar">Base de datos Oracle</block>
  <block id="4948dede9f4e7c3dfe48c38f7902f6e5" category="sidebar">Oracle en ONTAP</block>
  <block id="d71074394b511143c8d1108e74a81abb" category="sidebar">Protección de datos de Oracle</block>
  <block id="f4d8825927d11df25770df5e00d6a52e" category="sidebar">Migración de Oracle</block>
  <block id="86083f3ea21c2385b4f013aae3c57858" category="sidebar">SAP HANA</block>
  <block id="677f2e7e550075f7bbbdac91e0918f2f" category="sidebar">Soluciones SAP</block>
  <block id="1b83f2b1c0b7fb3af048c2a59624fe3b" category="sidebar">SAP HANA con AFF y FC</block>
  <block id="6ab3c3f05076d213f0b1feff267607c6" category="sidebar">SAP HANA con AFF y NFS</block>
  <block id="56079badd056a19303cc26e6a4fcc7e0" category="sidebar">VMware</block>
  <block id="f07084a11252c9bca97503ea9a627c89" category="sidebar">Virtual Volumes (vVols) con ONTAP</block>
  <block id="2d90ac09cbf108bddad31dd341f8614e" category="sidebar">VMware Site Recovery Manager con ONTAP</block>
  <block id="b0dae11b82e63781abdc8f893c41b3c0" category="sidebar">Aplicaciones de negocio</block>
  <block id="999bc6b18351bbe817d26f559ba408ae" category="sidebar">SAP</block>
  <block id="2d2eef88dbdd0c34bde24e2632d9944f" category="sidebar">SAP HANA y AnyDB</block>
  <block id="399bd1ee587245ecac6f39beaa99886f" category="sidebar">PostgreSQL</block>
  <block id="f4f70727dc34561dfde1a3c529b6205c" category="sidebar">Configuración</block>
  <block id="c476a4701643b158f9f5d57bcc91951d" category="sidebar">Tecnología Snapshot</block>
  <block id="7d219314ccabde6609510141bb175a6c" category="sidebar">Instancia compartida frente a instancia dedicada</block>
  <block id="d5363ae19ecaede49e2ced297df7737a" category="sidebar">Configuración de memoria</block>
  <block id="500c09aa1bb9af431f2c18348e69bfd0" category="sidebar">Archivos tempdb</block>
  <block id="4c5d94eb4dc4bff93f6a96a08ab7b244" category="sidebar">Seguridad de datos</block>
  <block id="cf91513c6fc63cebe4b63a6647238d6d" category="sidebar">RAID</block>
  <block id="83db97189c47f7bb4edd879e8756f6e6" category="sidebar">Límites de capacidad</block>
  <block id="af81930661b267e8f1e68c4d66e9ee56" category="sidebar">Conmutación al respaldo y conmutación</block>
  <block id="dfd1f50170457b961c15bb13ad7e3bed" category="sidebar">Tamaños de los archivos de datos y de los bloques de redo</block>
  <block id="49f83bf3a15b8626eb91fde93c6b1788" category="sidebar">Oracle RAC</block>
  <block id="13d80777c8fd43e555c1f5b1b72d7ef0" category="sidebar">Configuración de hosts</block>
  <block id="7e6bb0931a72759d39514aa924b420bc" category="sidebar">AIX</block>
  <block id="6bb83af717367dd4a47f75801ae7a2b0" category="sidebar">Linux con ASMLib y AFD</block>
  <block id="619615da0f93507e22a6054ef2aea4f1" category="sidebar">Interfaces lógicas</block>
  <block id="aca8e861c6f30fe2d42d0310a387312b" category="sidebar">Configuración de Ethernet</block>
  <block id="63a5b8bd41978e8124f9ccdfa9063e9e" category="sidebar">Configuración de SAN FC</block>
  <block id="c3f378ef942f6bf228a43aaacc628fea" category="sidebar">Segmentación de LVM</block>
  <block id="254f642527b45bc260048e30704edb39" category="sidebar">Configuración</block>
  <block id="f3a78e25ce9f95fc3c61ccc39f32fb4d" category="sidebar">Oracle Direct NFS (dNFS)</block>
  <block id="989cefa74de0e10a575103f446258d99" category="sidebar">Arrendamientos y bloqueos de NFS</block>
  <block id="0d695ec265a3b0b5e7e32e33ffe4ed22" category="sidebar">Almacenamiento en caché NFS</block>
  <block id="eb4d10d6eda7c9266cd36c4eb0a223cf" category="sidebar">Utilidad de Reclamación de ASM</block>
  <block id="297e2ac2ec0bd88ad598062f4c07ee45" category="sidebar">Políticas de organización en niveles</block>
  <block id="9af6f452cd88c83f2bde555de8f93690" category="sidebar">Enviar datos a un almacén de objetos</block>
  <block id="08af6d4e6b562e2d0b418d7198f5a0f7" category="sidebar">Recuperando datos del almacén de objetos</block>
  <block id="02d01636975b3ae0c0ab22368cea8d54" category="sidebar">Estrategias de organización en niveles</block>
  <block id="7fbd108e1fc6910c941094e95a677878" category="sidebar">Archivos enteros</block>
  <block id="eb43c2427eb06b9f561363863b4a4f0b" category="sidebar">Archivos parciales</block>
  <block id="1afe200fa26ba361f59b603b22ad6392" category="sidebar">Seleccione los archivos</block>
  <block id="448d15345bb99c834095da225c529b8a" category="sidebar">Disponibilidad de datos</block>
  <block id="5869e10a9dea6d88d61bb10040557f35" category="sidebar">Integridad de los datos</block>
  <block id="7b68149402c05a52968bda6af0435c8a" category="sidebar">Backups en línea basados en Snapshot</block>
  <block id="49ba0ee205d016d8236db9c1e8c130e5" category="sidebar">Backups optimizados para Snapshot de almacenamiento</block>
  <block id="2c6d98297c340e390e0783220b038545" category="sidebar">Arquitectura física</block>
  <block id="13a854bdd11f8f57a0b25c00631f1430" category="sidebar">Arquitectura lógica</block>
  <block id="5e7988aeba0e1d3c15c5c78a0db738d1" category="sidebar">SyncMirror</block>
  <block id="3f23f85f537c810b6eca3c767c3ff00c" category="sidebar">Failover de Oracle</block>
  <block id="5ba8ee2f32815884475d1f2244ba16a6" category="sidebar">Escenarios de fallo</block>
  <block id="e31593850dc03f8f10d036df5dc8633b" category="sidebar">Migración de bases de datos de Oracle</block>
  <block id="5102abd5a9cc202678054b832caf678d" category="sidebar">Procedimientos</block>
  <block id="1495d3ed3ebff783c0f480b583372450" category="sidebar">Copia de datos del host</block>
  <block id="d81ca5686c955ed50927409eb8c14bb0" category="sidebar">Importación LUN externo</block>
  <block id="2fea59b7e470acac5ec1589d504da14e" category="sidebar">Finalización</block>
  <block id="e9cc85ef98d982c3c3e53d6b82293126" category="sidebar">Conversión de protocolos</block>
  <block id="fbbd0e8905df3950eca4d1d8f55881ad" category="sidebar">Notas adicionales</block>
  <block id="ac0465a970688dc3c326dcdd8fe2805e" category="sidebar">Optimización del rendimiento y evaluación comparativa</block>
  <block id="7cb9c3cd8b9873d39a1fe87c083cd55c" category="sidebar">Bloqueos NFS obsoletos</block>
  <block id="c0916addb4f26afa58c5a6df4f463fa5" category="sidebar">Almacenamiento unificado</block>
  <block id="c0032c6bab44eeeb6886c7a4aa67cf77" category="sidebar">Herramientas de virtualización</block>
  <block id="1c77ac70000b6804e930748d5df7be5e" category="sidebar">Gestión basada en volúmenes virtuales y políticas de almacenamiento</block>
  <block id="217601d383b816e6a2548e57b5006f92" category="sidebar">Clonado</block>
  <block id="8f2db90dd4a6fbd95ba8f0bc54fd6b27" category="sidebar">Calidad de servicio</block>
  <block id="09b4a81ec7b05cbacc7cbfa13e006254" category="sidebar">Gestión basada en la política de almacenamiento</block>
  <block id="2e8526cbe762cb1b8393d935a3b0bf16" category="sidebar">Configuración recomendada</block>
  <block id="10a764f91b59ce3c8931d55c2fd54222" category="sidebar">Implementar el almacenamiento de vVols</block>
  <block id="30f6724a02fc69093960468c0a2fbcd4" category="sidebar">Seguridad de los productos</block>
  <block id="3390e3575b3e341afa2b7172ff5b33a7" category="sidebar">Plugin de SnapCenter para VMware vSphere</block>
  <block id="62a004b95946bb97541afa471dcca73a" category="sidebar">MySQL</block>
  <block id="7f1a6761f7160e33a32105202e47303b" category="sidebar">Colocación de contenedores</block>
  <block id="bd57f4f74ca087a92a48b23d45753729" category="paragraph">El proveedor de VASA de herramientas de ONTAP se encarga de gestionar iGroups FCP e iSCSI, así como subsistemas NVMe en ONTAP basado en iniciadores detectados de hosts ESXi gestionados. Sin embargo, no se integra con switches Fibre Channel para gestionar la división en zonas. La división en zonas debe realizarse siguiendo las mejores prácticas antes de realizar ningún aprovisionamiento. A continuación se muestra un ejemplo de división en zonas de un solo iniciador en cuatro sistemas ONTAP:</block>
  <block id="6b14e3f4a37881185acf7a766f8f6272" category="paragraph">División en zonas de un solo iniciador:</block>
  <block id="17ccf64e30cb518fd7ca87ce752ad738" category="paragraph"><block ref="17ccf64e30cb518fd7ca87ce752ad738" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58b5cd2a94730c2e044c14891f1e0e87" category="paragraph">Consulte los siguientes documentos para obtener más prácticas recomendadas:</block>
  <block id="fc9e4d789d968936f8ff5ae5a99847e0" category="paragraph"><block ref="fc9e4d789d968936f8ff5ae5a99847e0" category="inline-link-rx"></block></block>
  <block id="d748a2834a7220eef4ec4775a51632f9" category="paragraph"><block ref="d748a2834a7220eef4ec4775a51632f9" category="inline-link-rx"></block></block>
  <block id="4047245d73abc6e3ae8bf58ec063e52e" category="paragraph">Los SCPs incluidos son adecuados para la mayoría de usos generales, pero sus requisitos pueden ser diferentes.</block>
  <block id="80dad10df0d1a031764e7c648c46aa23" category="paragraph">*Considera usar Max IOPS para controlar VMs desconocidas o de prueba.*</block>
  <block id="93e4f73afe8b787b33161ec273ca087f" category="paragraph">Por primera vez, disponible en VASA Provider 7,1, Max IOPS puede usarse para limitar las IOPS a un VVol específico para una carga de trabajo desconocida y así evitar el impacto en otras cargas de trabajo más críticas. Consulte la Tabla 4 para obtener más información sobre gestión del rendimiento.</block>
  <block id="bdbd10905a1446f944699405bca52654" category="paragraph">*Asegúrese de tener suficientes LIF de datos.*
Cree al menos dos LIF por nodo por par de alta disponibilidad. Se puede requerir más en función de su carga de trabajo.</block>
  <block id="4e0d7e0587bf99c9b7a64a84fd42f6bd" category="paragraph">Consulte las otras guías de prácticas recomendadas de NetApp y VMware específicas del protocolo que ha seleccionado. En general, no hay ningún cambio aparte de los ya mencionados.</block>
  <block id="97f87e9ab1d660463c63beb8745fd9e5" category="paragraph">*Ejemplo de configuración de red usando vVols sobre NFS v3*</block>
  <block id="c80b3cc8b5013bd4039769fb0f783e60" category="paragraph"><block ref="c80b3cc8b5013bd4039769fb0f783e60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dee28dd6d1a9ef7bf399f642fd9d588f" category="section-title">Tamaños de transferencia de NFS</block>
  <block id="d8299d00f914e35b80644e5781e47a77" category="paragraph"><block ref="d8299d00f914e35b80644e5781e47a77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="861f074a1ecd9d1cc088d2fe81903565" category="paragraph"><block ref="861f074a1ecd9d1cc088d2fe81903565" category="inline-image-macro-rx" type="image"></block></block>
  <block id="710e9cd79e3865d47122a799f425b31f" category="paragraph"><block ref="710e9cd79e3865d47122a799f425b31f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a656ddcc72bacc3a5900c23edf7a08e" category="paragraph"><block ref="5a656ddcc72bacc3a5900c23edf7a08e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="073ce0a0568adc64d52dd9b1d8c02c54" category="paragraph"><block ref="073ce0a0568adc64d52dd9b1d8c02c54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3401a9880dfc322da8a56c4d632361f6" category="paragraph"><block ref="3401a9880dfc322da8a56c4d632361f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="87f823f4f3b4258445d5af029afe5ad9" category="paragraph"><block ref="87f823f4f3b4258445d5af029afe5ad9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9213fe9d391179276ff6c03552486255" category="paragraph"><block ref="9213fe9d391179276ff6c03552486255" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3105b4c0642b9710179c18edcf8e8718" category="paragraph"><block ref="3105b4c0642b9710179c18edcf8e8718" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a43000eb9893bff7ab7b1ce1d3fd6a8" category="paragraph"><block ref="1a43000eb9893bff7ab7b1ce1d3fd6a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b7a8562c98b8c652bdfb6aa79788222" category="paragraph"><block ref="4b7a8562c98b8c652bdfb6aa79788222" category="inline-image-macro-rx" type="image"></block></block>
  <block id="25cec91f17a8619119f76c8adbace583" category="paragraph">Consulte también la sección sobre la alineación de los bloques de compresión <block ref="0faffd62be034c86d531acfee84d252e" category="inline-link-macro-rx"></block>. Cualquier diseño alineado con los límites de bloques de compresión de 8KB KB también se alineará con los límites de 4KB KB.</block>
  <block id="38ac6f4e1538397bd4f659237ec03ebf" category="paragraph"><block ref="38ac6f4e1538397bd4f659237ec03ebf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f01518e5f3b18a9ea241bc63a3475dbd" category="paragraph"><block ref="f01518e5f3b18a9ea241bc63a3475dbd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acce752526553bfa73c92799accd9cb8" category="summary">Descripción general de la protección de datos de Oracle</block>
  <block id="deb8cb7644231cae002f5f37c725b86f" category="paragraph">La migración a distancias más largas generalmente requiere un enfoque más creativo, como el proceso de envío de registros explicado en <block ref="86efe12ea0d3a769a4b7cfc2b6362f49" category="inline-link-macro-rx"></block>. Las redes IP de larga distancia rara vez tienen ancho de banda en cualquier lugar cercano a las velocidades LAN o SAN. En un caso, NetApp ayudó en la migración a larga distancia de una base de datos de 220TB con tasas muy altas de generación de registros de archivo. El enfoque elegido para la transferencia de datos era el envío diario de cintas, ya que este método ofrecía el máximo ancho de banda posible.</block>
  <block id="055362c7082175c34483772a43b776cf" category="paragraph">Por ejemplo, la copia de una base de datos de 10TB GB normalmente requiere aproximadamente siete horas para completarse. Si su empresa necesita permitir un fallo de siete horas, la copia de archivos es una opción fácil y segura para la migración. Si cinco horas son inaceptables, un simple proceso de envío de registros (consulte <block ref="eee8a7589b6555fc3411165c58a62ca5" category="inline-link-macro-rx"></block>) puede configurarse con un esfuerzo mínimo para reducir el tiempo de transición a aproximadamente 15 minutos. Durante este tiempo, un administrador de la base de datos puede completar el proceso. Si 15 minutos son inaceptables, el proceso final de transición se puede automatizar mediante secuencias de comandos para reducir el tiempo de transición a tan solo unos minutos. Siempre se puede acelerar la migración, pero hacerlo conlleva un coste de tiempo y esfuerzo. Los objetivos de tiempo de transición deben basarse en lo que sea aceptable para la empresa.</block>
  <block id="911e63244fc82405263306a64e535c69" category="paragraph">Sólo se debe crear un zpool después de los pasos del <block ref="e8673fdb712a2edcdf56742c7eec0045" category="inline-link-macro-rx"></block> se realizan. Si el procedimiento no se realiza correctamente, puede provocar una degradación grave del rendimiento debido a la alineación de E/S. Para un rendimiento óptimo en ONTAP es necesario alinear el I/O con un límite de 4K GbE en una unidad. Los sistemas de archivos creados en un zpool utilizan un tamaño de bloque efectivo que se controla mediante un parámetro denominado<block ref="81df978a8e3da4bee74b135548f390f3" prefix=" " category="inline-code"></block>, que se puede ver ejecutando el comando<block ref="1615297782a0dff59b20451e2ca97ea7" prefix=" " category="inline-code"></block>.</block>
  <block id="b2ca9da17ac7a0807fb313343c1ba9cb" category="list-text">La partición se ha creado con un desplazamiento de 33 sectores en lugar del 32 por defecto. Repita el procedimiento descrito en <block ref="6ba0f94fdd8f9504e3fef5712023fb85" category="inline-link-macro-rx"></block>. El histograma aparece de la siguiente manera:</block>
  <block id="eb7f9a88026c895932f70c650c364132" category="list-text">Aumente el tamaño de las LUN</block>
  <block id="0f11c45e6e7377b9d10a93534d0fa2f3" category="list-text">Agregue una LUN a un grupo de volúmenes existente y aumente el volumen lógico contenido</block>
  <block id="e4da750cce448393b2597f8f66086894" category="paragraph">Un igroup forma parte de la arquitectura de enmascaramiento LUN de ONTAP. No es posible acceder a un LUN recién creado a menos que se conceda acceso en primer lugar a un host. Para ello, cree un igroup que enumere los nombres de iniciadores iSCSI o WWN de FC a los que se debe otorgar acceso. Cuando se escribió este informe, FLI solo se admitía para los LUN FC. Sin embargo, la conversión a iSCSI posterior a la migración es una tarea sencilla, como se muestra en la <block ref="43085dc2a05784d4912331d1ed1db91d" category="inline-link-macro-rx"></block>.</block>
  <block id="525e71fb331412cd820122c3d51d453c" category="paragraph">Esto permite a los administradores de bases de datos reclamar espacio en la cabina de almacenamiento después de la eliminación de los datos. ONTAP intercepta los ceros y desasigna el espacio de la LUN. El proceso de recuperación es extremadamente rápido porque no se escriben datos en el sistema de almacenamiento.</block>
  <block id="be17af715060572d2df93d7ffe4ce6dd" category="paragraph">Los sistemas de almacenamiento ONTAP ofrecen una gran flexibilidad a la hora de crear almacenes de datos para equipos virtuales y discos virtuales. Aunque se aplican muchas prácticas recomendadas de ONTAP al usar VSC para aprovisionar almacenes de datos para vSphere (que se enumeran en la sección <block ref="2e24324ebf41be836715e1e0dd648f4f" category="inline-link-macro-rx"></block>), aquí hay algunas directrices adicionales a considerar:</block>
  <block id="141c3dc68be34b8f11c2a120b36a1eb8" category="list-text">En algunos casos, es posible que ni siquiera se necesite un almacén de datos. Para obtener el mejor rendimiento y la mejor capacidad de gestión, evite usar un almacén de datos para aplicaciones con un alto volumen de I/o como bases de datos y algunas aplicaciones. En su lugar, piense en sistemas de archivos que son propiedad del invitado, como sistemas de archivos NFS o iSCSI gestionados por el invitado o con RDM. Para obtener orientación específica sobre las aplicaciones, consulte los informes técnicos de NetApp para su aplicación. Por ejemplo: <block ref="cfa0393f870bc70fd8973ae18376facc" category="inline-link-macro-rx"></block> dispone de una sección sobre la virtualización con detalles útiles.</block>
  <block id="3cd9527ff0ddb17e00c08bdb4cd1a776" category="paragraph">Las políticas de almacenamiento de máquinas virtuales se utilizan en vSphere para gestionar funciones opcionales como Storage I/O Control o vSphere Encryption. También se utilizan con vVols para aplicar funcionalidades de almacenamiento específicas a la máquina virtual. Use la regla de tipo de almacenamiento «netapp.clustered.Data.ONTAP.VP.vvol» y «nombre del archivo profilename» para aplicar un SCP específico a las máquinas virtuales mediante el uso de la Política. Consulte el enlace:vmware-vvols-ontap.html#Best Practices[Ejemplo de configuración de red mediante vVols en NFS v3] para obtener un ejemplo de esto con el proveedor VASA de herramientas de ONTAP. Las reglas para el almacenamiento «NetApp.clustered.Data.ONTAP.VP.VASA10» se deben usar con almacenes de datos que no sean vVols.</block>
  <block id="36ad91be49fdde7d3fadeba0fb782510" category="paragraph">Una vez creada la política de almacenamiento, puede utilizarse al aprovisionar los nuevos equipos virtuales, como se muestra en <block ref="d202b3fe265f968d81802fcec9f3c381" category="inline-link-macro-rx"></block>. Las directrices para usar las funcionalidades de gestión del rendimiento con VASA Provider 7,2 se incluyen en <block ref="8fdd8868d80d04eecf1b4189862f536c" category="inline-xref-macro-rx"></block>.</block>
  <block id="14bdf3569ec0024259b2b02c5a668eae" category="paragraph">Cuando<block ref="7ccc31934ae8244d8263d3c09bcee186" prefix=" " category="inline-code"></block> Está activado (por defecto), InnoDB almacena todos los datos dos veces: Primero en el buffer de doble escritura y luego en los archivos de datos reales.</block>
  <block id="394ad91b4701dbd32675896bed204755" category="sidebar">Configuración de host para PostgreSQL</block>
  <block id="9852487272d9b2aa9026d0fddc0616fc" category="sidebar">Configuración de almacenamiento para PostgreSQL</block>
  <block id="bc237072428e0e4c415160b898946d4c" category="sidebar">Protección de datos para PostgreSQL</block>
  <block id="3423582eed75b4bd6632c18238fd78e4" category="sidebar">Configuración de base de datos para Microsoft SQL Server</block>
  <block id="6e97cf67ec5979ab5828852639efa208" category="sidebar">Configuración de almacenamiento para Microsoft SQL Server</block>
  <block id="5a4517368fb2ab5498fc2108c2ea64c5" category="sidebar">Configuración de base de datos para Oracle Database</block>
  <block id="e483c0ecf3a2b1a60f886d4a5ac553ff" category="sidebar">Configuración de host para Oracle Database</block>
  <block id="06b078afa802a679ad4694d13a8a2495" category="sidebar">Configuración de red para Oracle Database</block>
  <block id="f1991b28c5d48cb53798755acf9dfe62" category="sidebar">Configuración de almacenamiento para bases de datos de Oracle</block>
  <block id="ea9cdfcbfcf1906c15b6779f0f327028" category="sidebar">Configuración de base de datos para MySQL</block>
  <block id="308f8f580d0248ac023557cfd4b10d83" category="sidebar">Configuración de host para MySQL</block>
  <block id="830f353b3e6055499fac447b16b0c935" category="sidebar">Configuración de almacenamiento para MySQL</block>
  <block id="3106f8f17f2974fe05da16fb0cc50505" category="summary">Bases de datos PostgreSQL con SAN en ONTAP</block>
  <block id="74cacb0c34a37e2859e3b054938a344d" category="doc">PostgreSQL con sistemas de archivos SAN</block>
  <block id="1758f5c81d60f1a0ac8600fddc99a919" category="paragraph">Las bases de datos PostgreSQL con SAN generalmente se alojan en sistemas de archivos xfs, pero otras se pueden usar si es compatible con el proveedor del sistema operativo</block>
  <block id="d73e7b56b7baa813a32c521ca074e7c4" category="paragraph">Mientras que una única LUN puede admitir por lo general hasta 100K 000 IOPS, las bases de datos con un gran volumen de I/O normalmente requieren el uso de LVM con segmentación.</block>
  <block id="f7cc8c4234952826818ad4d0c2050ac9" category="paragraph">Las bases de datos PostgreSQL se pueden alojar en sistemas de archivos NFSv3 o NFSv4. La mejor opción depende de factores fuera de la base de datos.</block>
  <block id="1482c42acc1dd31ee8496c71a805e73c" category="paragraph">Por ejemplo, el comportamiento de bloqueo NFSv4 puede ser preferible en ciertos entornos agrupados en clúster. (Consulte <block ref="bc3a7e667477b8b3590fa1451dcb924c" category="inline-link-macro-rx"></block> para obtener más información).</block>
  <block id="9674525687765646f35916d0e569eda9" category="paragraph">De lo contrario, la funcionalidad de la base de datos debería ser casi idéntica, incluido el rendimiento. El único requisito es el uso del<block ref="d64a84456adc959f56de6af685d0dadd" prefix=" " category="inline-code"></block> opción de montaje. Esto es necesario para garantizar que los tiempos de espera de software no produzcan errores de E/S irrecuperables.</block>
  <block id="0c6430fad6c643c444b5d6d52b18edb4" category="paragraph">Si se elige NFSv4 como protocolo, NetApp recomienda usar NFSv4,1. Existen algunas mejoras funcionales en el protocolo NFSv4 en NFSv4,1 que mejoran la resiliencia con respecto a la versión NFSv4,0.</block>
  <block id="248212b04c23627e2719e106224d2eb3" category="paragraph">Utilice las siguientes opciones de montaje para cargas de trabajo generales de bases de datos:</block>
  <block id="9efbdff43e91279291e95690414bec95" category="paragraph">Una vez que se aumenta el tamaño de transferencia en el nivel de ONTAP, se utilizarán las siguientes opciones de montaje:</block>
  <block id="395201f6a339cc4cf6b345e0c259f383" category="section-title">NFSv3 Tablas de ranuras TCP</block>
  <block id="1f8260aa2c5a5b35bf771c26828d2096" category="paragraph">Si NFSv3 se utiliza con Linux, es fundamental configurar correctamente las tablas de ranuras TCP.</block>
  <block id="92d0a1aef2134a70d5c0f0279dc22ec6" category="doc">Copias Snapshot</block>
  <block id="0c47b4eb567b018e3d2e5882b88eaca9" category="paragraph">Las copias Snapshot de almacenamiento son réplicas puntuales de los datos objetivo. La implementación de ONTAP incluye la capacidad de establecer diversas políticas y almacenar hasta 1024 snapshots por volumen. Las copias Snapshot de ONTAP gestionan el espacio de manera eficiente. El espacio sólo se consume a medida que cambia el conjunto de datos original. También son de solo lectura. Una instantánea se puede eliminar, pero no se puede modificar.</block>
  <block id="7986a4827296ca9cd0b991ded9f8a10d" category="paragraph">En algunos casos, las copias Snapshot pueden programarse directamente en ONTAP. En otros casos, puede que se necesite software como SnapCenter para orquestar operaciones del sistema operativo o de la aplicación antes de crear snapshots. Sea cual sea el mejor método para su carga de trabajo, una estrategia de snapshot agresiva puede proporcionar seguridad de datos a través de acceso frecuente y fácilmente accesible a backups de todo tipo de elementos, desde LUN de arranque hasta bases de datos esenciales.</block>
  <block id="210c45246ad11e0b53bdb20b64266780" category="paragraph">*Nota*: Un volumen flexible de ONTAP, o más simplemente, un volumen no es sinónimo de un LUN. Los volúmenes son contenedores de gestión para datos, como archivos o LUN. Por ejemplo, se podría colocar una base de datos en un conjunto de franjas de 8 LUN, y todas las LUN estarían contenidas en un único volumen.</block>
  <block id="ad590deba1cd4423ee565e822c3a91d1" category="paragraph">Para obtener más información sobre las instantáneas, haga clic en <block ref="211d7effcac0cb0488144c6fc8b3cb7c" category="inline-link-macro-rx"></block></block>
  <block id="c4bf0f56feeec9a45e973768fbc4f47e" category="section-title">Snapshots a prueba de manipulación</block>
  <block id="d2e783db61d20da61c761d4d473bed14" category="paragraph">A partir de ONTAP 9.12.1, las copias Snapshot no solo son de lectura, sino que también se pueden proteger de eliminaciones accidentales o intencionales. La función se denomina Instantáneas a prueba de manipulaciones. Un período de retención puede establecerse y aplicarse mediante la política de Snapshot. Las instantáneas resultantes no se pueden eliminar hasta que hayan alcanzado su fecha de caducidad. No hay sustituciones administrativas o de centros de soporte.</block>
  <block id="38fef959179f8d3eb79a68a5ce747bdc" category="paragraph">Esto garantiza que un intruso, un intruso malintencionado o incluso un ataque de ransomware no puedan comprometer los backups, incluso si resultaran en acceso al propio sistema ONTAP. Al combinarlo con una programación de copias Snapshot frecuente, el resultado es una protección de datos extremadamente potente con un objetivo de punto de recuperación muy bajo.</block>
  <block id="c64db0c79e66c1c0e5b932c5d2dedfea" category="paragraph">Para obtener más información sobre las instantáneas a prueba de manipulaciones, haga clic en <block ref="134603be635c039f9224bff191c6103c" category="inline-link-macro-rx"></block></block>
  <block id="a1f41e52e9ddbd9f87ecd032c237b1c0" category="section-title">Replicación de SnapMirror</block>
  <block id="1bb837ddfb635c39a6c6e23d847823f9" category="paragraph">Las copias Snapshot también se pueden replicar en un sistema remoto. Esto incluye las copias Snapshot a prueba de manipulaciones, donde el período de retención se aplica y se aplica en el sistema remoto. El resultado son los mismos beneficios de la protección de datos que las copias Snapshot locales, pero los datos se encuentran en una segunda cabina de almacenamiento. Esto garantiza que la destrucción de la matriz original no comprometa los backups.</block>
  <block id="18d315ae923785b3f9c5234724b0ab42" category="paragraph">Un segundo sistema también abre nuevas opciones para la seguridad administrativa. Por ejemplo, algunos clientes de NetApp segregan las credenciales de autenticación para los sistemas de almacenamiento primario y secundario. Ningún usuario administrativo tiene acceso a ambos sistemas, lo que significa que un administrador malintencionado no puede eliminar todas las copias de datos.</block>
  <block id="e805272dcce51c35975e830e5ee9ecaf" category="paragraph">Para obtener más información sobre SnapMirror, haga clic en <block ref="9abdfd5d94773cf0a996248d1d722cac" category="inline-link-macro-rx"></block></block>
  <block id="500569e3cc0764260a592cb176921ca3" category="section-title">Máquinas virtuales de almacenamiento</block>
  <block id="d5174dd4c760ef1a826b3e5bc22215e5" category="paragraph">Un sistema de almacenamiento ONTAP recientemente configurado es similar a un servidor VMware ESX aprovisionado recientemente, ya que ninguno de ellos admite ningún usuario hasta que se crea un equipo virtual. Con ONTAP, puede crear una máquina virtual de almacenamiento (SVM) que se convierte en la unidad más básica de gestión del almacenamiento. Cada SVM tiene sus propios recursos de almacenamiento, configuraciones de protocolos, direcciones IP y WWN de FCP.  Esta es la base del multi-tenancy de ONTAP.</block>
  <block id="597cb258dd509add7cd999794c60d430" category="paragraph">Por ejemplo, puede configurar una SVM para cargas de trabajo de producción cruciales y una segunda SVM en un segmento de red diferente para actividades de desarrollo. A continuación, podría restringir el acceso a la SVM de producción a ciertos administradores, a la vez que otorga a los desarrolladores un control más amplio sobre los recursos de almacenamiento en la SVM de desarrollo. Es posible que también necesite proporcionar una tercera SVM a sus equipos financieros y de RR. HH. Para almacenar datos especiales para la observación.</block>
  <block id="18519d16720b1e13890c2639657b5bf8" category="paragraph">Para obtener más información acerca de las SVM, haga clic en <block ref="a06a0fd566387240178b1c926e07cb7b" category="inline-link-macro-rx"></block></block>
  <block id="7d0fc71fe28e011ca49b06214469d484" category="section-title">RBAC administrativo</block>
  <block id="4f0dae2ba2fd11c533349d6ade4f81de" category="paragraph">ONTAP ofrece un potente control de acceso basado en roles (RBAC) para inicios de sesión administrativos. Es posible que algunos administradores necesiten acceso completo al clúster, mientras que otros solo necesitarán acceso a ciertas SVM. Es posible que el personal de soporte avanzado necesite aumentar el tamaño de los volúmenes. El resultado es que puede otorgar a los usuarios administrativos el acceso necesario para realizar sus responsabilidades de trabajo, y nada más. Además, puede proteger estos inicios de sesión mediante PKI de varios proveedores, restringir el acceso sólo a las claves ssh y aplicar bloqueos de intentos de inicio de sesión fallidos.</block>
  <block id="6ae13b0198daa7d13d79a8631297e64d" category="paragraph">Para obtener más información sobre el control de acceso administrativo, haga clic en <block ref="db5be08b697b5ef26e0e94da1d5f4970" category="inline-link-macro-rx"></block></block>
  <block id="671a94a08dff3cf44fad087e2346c8b0" category="section-title">Autenticación multifactor</block>
  <block id="945c88a63c229c39ee73ab5592b3ef63" category="paragraph">Para obtener más información, haga clic en <block ref="03628d0cd13b6640ef56c399aa1c2070" category="inline-link-macro-rx"></block></block>
  <block id="852741d2a7fb0a8a1a5dd748dbbd6734" category="section-title">CONTROL DE ACCESO BASADO EN ROLES API</block>
  <block id="bbbea5fec67f15424fa77aa563754c49" category="paragraph">La automatización requiere llamadas a la API, pero no todas las herramientas requieren un acceso administrativo completo. Para ayudar a proteger los sistemas de automatización, el control de acceso basado en roles también está disponible a nivel de API. Puede limitar las cuentas de usuario de automatización a las llamadas API necesarias. Por ejemplo, el software de monitoreo no necesita acceso de cambio, solo requiere acceso de lectura. Los flujos de trabajo que aprovisionan almacenamiento no necesitan la capacidad de eliminar almacenamiento.</block>
  <block id="7604bad489eaec7e27d112c63d3e2936" category="paragraph">La autenticación de múltiples factores puede ser llevada aún más lejos al requerir que dos administradores diferentes, cada uno con sus propias credenciales, aprueben ciertas actividades. Esto incluye cambiar los permisos de inicio de sesión, ejecutar comandos de diagnóstico y eliminar datos.</block>
  <block id="e890d04cd745ac382688bbb307655e81" category="paragraph">Para obtener más información sobre la verificación multi-admin (MAV), haga clic en <block ref="88f84d4fec0424d978600980bf11baf0" category="inline-link-macro-rx"></block></block>
  <block id="b39c0496b44447232912303246b46aaa" category="paragraph">Si se esperan operaciones de I/O secuenciales pesadas, los tamaños de transferencia NFS pueden aumentar, tal como se describe en la siguiente sección.</block>
  <block id="959e8f746f4ff03f6225b95cf646e65f" category="admonition">Esta documentación sustituye al informe técnico publicado previamente _TR-4590: Guía de mejores prácticas para Microsoft SQL Server con ONTAP_</block>
  <block id="15d2f797f7375b32cb5e92538291f2af" category="list-text"><block ref="15d2f797f7375b32cb5e92538291f2af" category="inline-link-rx"></block></block>
  <block id="36d72286c0ef70108b2f7791b73fdc6d" category="list-text">Las guías anteriores aconsejan crear LIF para la localidad de datos. Es decir, monte siempre un almacén de datos con una LIF ubicada en el nodo que posee físicamente el volumen. Esto ya no es un requisito en las versiones modernas de ONTAP 9. Siempre que sea posible y si se dan credenciales de ámbito de clúster determinadas, las herramientas de ONTAP seguirán optando por equilibrar la carga entre las LIF locales de los datos, pero no es un requisito de alta disponibilidad ni rendimiento.</block>
  <block id="aa131b86ebd9f719bab1aba612ae3c3f" category="list-text">SRM tiene un mejor rendimiento cuando el número de almacenes de datos y, por lo tanto, grupos de protección se minimizan en sus planes de recuperación. Por tanto, debería considerar la optimización para la densidad de las máquinas virtuales en entornos protegidos por SRM, donde el objetivo de tiempo de recuperación es de una importancia clave.</block>
  <block id="afab42482b97a8b43c62320c373ded74" category="list-text">Use el planificador de recursos distribuido (DRS) para equilibrar la carga en los clústeres ESXi protegidos y de recuperación. Recuerde que si tiene previsto realizar una conmutación tras recuperación, al ejecutar una nueva protección, los clústeres protegidos anteriormente se convertirán en los nuevos clústeres de recuperación. DRS ayudará a equilibrar la colocación en ambas direcciones.</block>
  <block id="8ed6c5d9143eeb92cf75bb8a08bb7819" category="list-text">Siempre que sea posible, evite usar la personalización de IP con SRM, ya que esto puede aumentar su RTO.</block>
  <block id="8baa3b91d59f004ee489f4f3fd3dd4e4" category="paragraph">A partir de SRM 8,3, se admite la protección de máquinas virtuales que usan almacenes de datos vVols. Las programaciones de SnapMirror se exponen a políticas de almacenamiento de máquinas virtuales por parte del proveedor VASA cuando la replicación de vVols está habilitada en el menú de configuración de herramientas de ONTAP, como se muestra en las siguientes capturas de pantalla.</block>
  <block id="3c1a2fd7a7a41ca20efeae84dc73ba0a" category="paragraph">En el siguiente ejemplo, se muestra la habilitación de la replicación de vVols.</block>
  <block id="fc7cd76ae57374916b5edd5a2dd19fee" category="paragraph">A diferencia de los almacenes de datos vVols anteriores, los almacenes de datos vVols replicados deben crearse desde el principio con la replicación habilitada, y deben utilizar volúmenes que se han creado previamente en los sistemas ONTAP con relaciones de SnapMirror. Esto requiere configurar previamente elementos como cluster peering y SVM peering. El administrador de ONTAP debe llevar a cabo estas actividades, ya que esto facilita una separación estricta de responsabilidades entre quienes gestionan los sistemas ONTAP en varios sitios y los principales responsables de las operaciones de vSphere.</block>
  <block id="e2e7245b1b3cf4a13a6b703ead49ebee" category="paragraph">Se crea un gestor de cabinas para cada pareja de cabinas. Con las herramientas SRM y ONTAP, el emparejamiento de cabinas se realiza con el ámbito de una SVM, incluso si utiliza credenciales de clúster. Esto le permite segmentar los flujos de trabajo de recuperación ante desastres entre inquilinos en función de los cuales se hayan asignado a gestionar las SVM. Puede crear varios administradores de cabina para un clúster determinado y pueden ser asimétricos. Es posible fan out o fan in entre diferentes clústeres de ONTAP 9. Por ejemplo, puede tener SVM-A y SVM-B en el clúster-1 que replica en SVM-C en el clúster-2, SVM-D en el clúster-3 o viceversa.</block>
  <block id="3233e61306af256f9de7fd3086bc08bf" category="paragraph">La consideración de los grupos de replicación es diversa y cómo se distribuyen los equipos virtuales entre los volúmenes de FlexVol. Agrupar equipos virtuales similares en el mismo volumen puede aumentar la eficiencia del almacenamiento con sistemas ONTAP anteriores que carecen de deduplicación a nivel de agregado, pero la agrupación aumenta el tamaño del volumen y reduce la concurrencia de I/O de volúmenes. El mejor equilibrio entre rendimiento y eficiencia del almacenamiento se puede lograr en los sistemas ONTAP modernos mediante la distribución de máquinas virtuales entre volúmenes de FlexVol en el mismo agregado, aprovechando así la deduplicación a nivel de agregado y ganando una mayor paralelización de I/O en múltiples volúmenes. Puede recuperar las máquinas virtuales en los volúmenes juntos porque un grupo de protección (tratado a continuación) puede contener varios grupos de replicación. La desventaja de esta distribución es que es posible que los bloques se transmitan a través del cable varias veces, debido a que SnapMirror para volúmenes no tiene en cuenta la deduplicación del agregado.</block>
  <block id="670ea4d89ef5c48c4f2d840baf48688c" category="paragraph">Por ejemplo, su empresa podría tener una aplicación empresarial crítica de nivel 1 que dependa de un servidor Microsoft SQL para su base de datos. Por lo tanto, se deciden colocar las máquinas virtuales en el grupo de prioridad 1. Dentro del grupo de prioridad 1, comienza a planificar el pedido para que se traigan los servicios. Probablemente desee que su controlador de dominio de Microsoft Windows se inicie antes de su servidor Microsoft SQL, que tendría que estar en línea antes de su servidor de aplicaciones, etc. Debe agregar todas estas máquinas virtuales al grupo de prioridades y, después, establecer las dependencias, dado que las dependencias solo se aplican dentro de un determinado grupo de prioridad.</block>
  <block id="512ee19e5020f3ee80a9e25f3f5a6468" category="paragraph">Como práctica recomendada, realice siempre una conmutación al nodo de respaldo de prueba cuando se realice un cambio en la configuración de un almacenamiento de equipo virtual protegido. Esto garantiza que, en caso de desastre, pueda confiar en que Site Recovery Manager pueda restaurar los servicios dentro del objetivo de RTO esperado.</block>
  <block id="4da3f855cd505741909cfd49d743e68e" category="paragraph">SRM también le permite cambiar la configuración de red de un equipo virtual mientras se recupera. Esta reconfiguración incluye ajustes como las direcciones IP, las direcciones de puerta de enlace y la configuración del servidor DNS. Los diferentes ajustes de red, que se aplican a las VM individuales a medida que se recuperan, se pueden especificar en la configuración de la propiedad de una VM en el plan de recuperación.</block>
  <block id="e409450ce49f3558b068c69a77a9623a" category="paragraph">Después de la conmutación por recuperación, debe confirmar con todas las partes interesadas que sus servicios se han vuelto a la normalidad antes de ejecutar la reprotección de nuevo.</block>
  <block id="a42cf9beb4788dddb7d317e05cc08e23" category="sidebar">Archivos de base de datos y grupos de archivos</block>
  <block id="8858bb6564a2efc189c9183c495ce545" category="sidebar">Alineación de LUN</block>
  <block id="02bc4ad8a694d41c8b598dfbcb12f069" category="sidebar">Número de LUN y tamaño de LUN</block>
  <block id="066f208a93617bd82090d42624ce63cc" category="sidebar">Cambio de tamaño de LUN</block>
  <block id="9eeba6fd02cf3b6d8aee35e0ce9bf8fe" category="sidebar">Segmentación de LVM</block>
  <block id="183bdb28f19bee640319f68825827aea" category="sidebar">RPO, RTO y SLA</block>
  <block id="2172b5d51273924b537842b0db78bfd4" category="sidebar">Conceptos básicos de backup y recuperación</block>
  <block id="3403aac944f3cb6e2d2c7f7d52bc44b9" category="paragraph">A medida que los datos crecen exponencialmente, la gestión de datos se vuelve más compleja para las empresas. Esta complejidad aumenta los costes de licencias, operaciones, soporte y mantenimiento. Para reducir el coste total de propiedad, considere la posibilidad de cambiar de bases de datos comerciales a bases de datos de código abierto con un almacenamiento de back-end fiable y de alto rendimiento.</block>
  <block id="dcac08882e3396bd30210108baa1641d" category="paragraph">ONTAP es una plataforma ideal, ya que ONTAP está literalmente diseñada para bases de datos. Numerosas funciones, como las optimizaciones de latencia de I/O aleatorias, pasando por una calidad de servicio avanzada o una funcionalidad FlexClone básica, se crearon específicamente para cubrir las necesidades de cargas de trabajo de bases de datos.</block>
  <block id="1429a98a71e16287326edd7fc1f999fd" category="paragraph">Otras funciones como las actualizaciones no disruptivas (entre ellas la sustitución de almacenamiento) garantizan que sus bases de datos cruciales seguirán estando disponibles. También se puede disponer de recuperación ante desastres instantánea para entornos grandes mediante MetroCluster o seleccionar bases de datos usando SnapMirror active sync.</block>
  <block id="8df3fb35ff15e02683bfb1bc7f852c93" category="paragraph">Y lo que es más importante, ONTAP ofrece un rendimiento sin igual con la capacidad de dimensionar la solución en función de sus necesidades únicas. Nuestros sistemas de gama alta pueden ofrecer más de 1M 000 IOPS con latencias de microsegundos, pero si solo necesita 100K 000 IOPS, puede ajustar el tamaño de su solución de almacenamiento con una controladora más pequeña aún ejecutando exactamente el mismo sistema operativo de almacenamiento.</block>
  <block id="97b4cda00dd31f5be69440f48c4da149" category="summary">Configuración de base de datos PostgreSQL con ONTAP</block>
  <block id="c4f52498c0db572381512887d7584e53" category="summary">Bases de datos PostgreSQL e instantáneas de almacenamiento</block>
  <block id="b0792163c858a7c221b236d84619b5ef" category="summary">Bases de datos PostgreSQL NFS con ONTAP</block>
  <block id="189950ed46e5e8b7e92941531a5bb88b" category="doc">Bases de datos PostgreSQL con sistemas de archivos NFS</block>
  <block id="504cd1fb60a8eb7918484270e743ae3a" category="summary">Protección de datos PostgreSQL P</block>
  <block id="6cabd4dcf3582d38c441228705da3bda" category="doc">Protección de datos PostgreSQL</block>
  <block id="383a6a5241ecfc558b9fec1d7cff5239" category="summary">Tablespaces PostgreSQL</block>
  <block id="20d0e2519b3555a0a2927c8914c17280" category="summary">Software de protección de datos PostgreSQL</block>
  <block id="29e2aec511a8e307ecceacbd86c22f14" category="summary">Parámetros de inicialización de PostgreSQL</block>
  <block id="035ecd1be6cacde993302b440e396bc2" category="paragraph">La mayoría de clientes de bases de datos seleccionan ahora las cabinas all-flash, lo que crea algunas consideraciones adicionales. Por ejemplo, piense en las pruebas de rendimiento en un sistema AFF A900 de dos nodos:</block>
  <block id="33f545d041b93838074263c0efd2e9da" category="list-text">Con una tasa de lectura/escritura de 80/20:1, dos nodos de A900 pueden ofrecer más de 1M 000 IOPS de base de datos aleatorias antes de que la latencia supere incluso la marca 150µs. Esto supera con creces las demandas de rendimiento actuales de la mayoría de las bases de datos, que es difícil predecir la mejora esperada. El almacenamiento se borrará en gran medida como un cuello de botella.</block>
  <block id="0445195555faac96ebff962dbff126ea" category="summary">Parámetros de configuración de MySQL</block>
  <block id="c0b7708ffcd66fd65a9d2a4801091563" category="paragraph">NetApp recomienda algunos parámetros de configuración MySQL importantes para obtener un rendimiento óptimo.</block>
  <block id="10eb8b7e75da1815860da31490513841" category="summary">MySQL con NFS</block>
  <block id="5249e05857621fbfae51371a73006c44" category="summary">MySQL y NFSv3 mesas de ranura</block>
  <block id="d058f95e3a8d4b7b46802139d6b95982" category="paragraph">El rendimiento de NFSv3 en Linux depende de un parámetro llamado<block ref="453f2cc2326f82af1053f4aa4b75400b" prefix=" " category="inline-code"></block>.</block>
  <block id="bf2bdc980948fb9084a63963398846b2" category="paragraph">ONTAP es una plataforma ideal para la base de datos MySQL porque ONTAP está literalmente diseñada para las bases de datos. Numerosas funciones, como las optimizaciones de latencia de I/O aleatorias, pasando por una calidad de servicio avanzada o una funcionalidad FlexClone básica, se crearon específicamente para cubrir las necesidades de cargas de trabajo de bases de datos.</block>
  <block id="1b3804b7e2292e18f5e66d54f7a9fafc" category="paragraph">Y lo que es más importante, ONTAP ofrece un rendimiento sin igual con la capacidad de dimensionar la solución en función de sus necesidades únicas. Nuestros sistemas de gama alta pueden ofrecer más de 1M 000 IOPS con latencias de microsegundos, pero si solo necesita 100K 000 IOPS, puede ajustar el tamaño de su solución de almacenamiento con una controladora más pequeña aún ejecutando exactamente el mismo sistema operativo de almacenamiento.</block>
  <block id="1339877637a3f7f59745a00e04f304fd" category="summary">MySQL y innodb_log_file_size</block>
  <block id="c1c4e722764621d56a075e42ce48d0c0" category="summary">MySQL e innodb_buffer_pool_size</block>
  <block id="ae14ab6d1e5edd0e782d8897d1721eb4" category="summary">MySQL e innodb_doublewrite</block>
  <block id="689c52e3f5db5d2dafccd7d93cf1abc4" category="summary">MySQL e innodb_flush_log_at_trx_commi</block>
  <block id="639600080c225673dfdfa012fdbd6146" category="summary">Programadores MySQL e IO</block>
  <block id="32e3724e2b54692cbef969373fbfe040" category="doc">Programadores de I/O y MySQL</block>
  <block id="72985ac51e91797345b2437088a4362e" category="summary">MySQL con SAN</block>
  <block id="d5ef0a45fe252b03f538bfd134b168db" category="summary">MySQL e innodb_lru_scan_depth</block>
  <block id="df657260453f6ef228ee0ca22dd7a415" category="summary">Contenerización de MySQL</block>
  <block id="885b1b5a90f898c89b664ec58a42121c" category="doc">Contenerización de MySQL</block>
  <block id="2cbac38815d492c0afc5e7d7229601df" category="doc">MySQL e InnoDB</block>
  <block id="1115aaa86f0065e0a105795d33ef4731" category="summary">Descripciones de archivos MySQL</block>
  <block id="2828450fc6669c8df75f937e227996f1" category="doc">Descriptores de archivos MySQL</block>
  <block id="9420010a756fb6d3ddeadfa63d2170f6" category="paragraph">Para ejecutarse, el servidor MySQL necesita descriptores de archivo y los valores predeterminados no son suficientes.</block>
  <block id="62414a5a9c0e2fc12a8d028ad29164b8" category="summary">MySQL y innodb_io_capacity</block>
  <block id="6219c45bc8c26437c0b7e1a69d4cbe58" category="summary">MySQL e innodb_flush_method</block>
  <block id="35d1a5d7b12999ec27f5233dccba043f" category="summary">MySQL y open_file_limits</block>
  <block id="c031febc35017c70bf3b526723756b2a" category="doc">ISCSI y NVMe/TCP</block>
  <block id="4da35d461815e71b97bda03476e89b7b" category="paragraph">Un host que utilice iSCSI o NVMe/TCP se puede conectar directamente a un sistema de almacenamiento y funcionar normalmente. El motivo son las rutas. Las conexiones directas a dos controladoras de almacenamiento diferentes dan como resultado dos rutas independientes para el flujo de datos. La pérdida de una ruta, un puerto o una controladora no impide que se utilice la otra ruta.</block>
  <block id="40715d81cea527f13cdf470773fc3a65" category="paragraph">Se puede utilizar el almacenamiento NFS conectado directamente, pero con una limitación considerable: El fallo no funcionará si no se realiza una ejecución significativa de secuencias de comandos, que sería responsabilidad del cliente.</block>
  <block id="d0b13bfd23c05f64222869de30f81000" category="paragraph">El motivo por el que la recuperación tras fallos sin interrupciones se complica gracias al almacenamiento NFS de conexión directa es el enrutamiento que se produce en el sistema operativo local. Por ejemplo, supongamos que un host tiene una dirección IP de 192.168.1.1/24 y está directamente conectado a una controladora ONTAP con la dirección IP 192.168.1.50/24. Durante la conmutación al nodo de respaldo, esa dirección 192.168.1.50 puede conmutar al nodo de respaldo a la otra controladora y estará disponible para el host, pero ¿cómo detecta el host su presencia? La dirección 192.168.1.1 original todavía existe en la NIC host que ya no se conecta a un sistema operativo. El tráfico destinado a 192.168.1.50 seguiría enviándose a un puerto de red inoperable.</block>
  <block id="288a0a5ebbc70fb3b968ec58d36d71ab" category="paragraph">La segunda NIC del SO podría configurarse como 19 2.168.1.2 y sería capaz de comunicarse con la dirección fallida en 192.168.1.50, pero las tablas de enrutamiento locales tendrían un valor predeterminado de usar una dirección *y solo una* para comunicarse con la subred 192.168.1.0/24. Un administrador de sistema podría crear un marco de scripting que detectara una conexión de red fallida y alterara las tablas de enrutamiento locales o activara o desactivara las interfaces. El procedimiento exacto dependerá del sistema operativo en uso.</block>
  <block id="d6ce8522932df7ae76aa0b963ad9ef7d" category="paragraph">En la práctica, los clientes de NetApp disponen de NFS conectado directamente, pero normalmente solo para cargas de trabajo en las que se pueden pausar I/O durante las recuperaciones tras fallos. Cuando se utilizan montajes duros, no debe haber ningún error de E/S durante dichas pausas. El I/O se debe bloquear hasta que los servicios se restauren, ya sea mediante una conmutación de retorno tras recuperación o intervención manual para mover las direcciones IP entre las NIC del host.</block>
  <block id="3436a7073ac9f4071820b6720a7789fc" category="section-title">Conexión directa FC</block>
  <block id="b7981516813a09695906aa429b07f48f" category="paragraph">No es posible conectar directamente un host a un sistema de almacenamiento ONTAP mediante el protocolo FC. La razón es el uso de NPIV. El WWN que identifica un puerto ONTAP FC con la red de FC utiliza un tipo de virtualización denominado NPIV. Cualquier dispositivo conectado a un sistema ONTAP debe poder reconocer un WWN de NPIV. No hay proveedores de HBA actuales que ofrezcan un HBA que se pueda instalar en un host que admita un destino NPIV.</block>
  <block id="97db606ac6781989ea3b189d7be28bf2" category="section-title">Red de conexión directa</block>
  <block id="d078ae9a339971900f939db9e82f253d" category="paragraph">A veces, los administradores de almacenamiento prefieren simplificar sus infraestructuras eliminando los switches de red de la configuración. Esto puede ser soportado en algunos escenarios.</block>
  <block id="e817ecc2f82a2b78d828ec8704031da3" category="section-title">Conexión de red directa</block>
  <block id="f437881fa7e42bf0e4563bbec8176f81" category="paragraph">Los sistemas que ejecutan el software ONTAP pueden utilizar la función de calidad de servicio del almacenamiento ONTAP para limitar el rendimiento en Mbps y/o I/o por segundo (IOPS) de diferentes objetos de almacenamiento como archivos, LUN, volúmenes o SVM completas.</block>
  <block id="87e6f97c8ec2f31df616ef84401ffaf4" category="paragraph">Existen varios recursos de solución de problemas disponibles con información adicional.</block>
  <block id="52d04863ac62a6fa67e1b49a31086928" category="paragraph">Las siguientes secciones describen las mejores prácticas operativas para el almacenamiento de VMware SRM y ONTAP.</block>
  <block id="f24ef4a42850a2b3e3d77e610ae46fee" category="doc">Resiliencia para eventos planificados y no planificados</block>
  <block id="4bce11924453ef2ee7e40109f79dc66d" category="paragraph">NetApp MetroCluster y SnapMirror Active Sync son potentes herramientas que mejoran la alta disponibilidad y las operaciones no disruptivas del hardware de NetApp y del software ONTAP®.</block>
  <block id="52f49b6400100ac4558d31582b90ca4e" category="paragraph">Estas herramientas proporcionan protección en todo el sitio para todo el entorno de almacenamiento, lo que garantiza que los datos están siempre disponibles. Ya sea que utilice servidores independientes, clústeres de servidores de alta disponibilidad, contenedores Docker o servidores virtualizados, la tecnología NetApp mantiene fácilmente la disponibilidad de almacenamiento en caso de interrupción total por pérdida de alimentación, refrigeración o conectividad de red, apagado del array de almacenamiento o error de funcionamiento.</block>
  <block id="d267775072875ddbb24c16a41c22d8a2" category="paragraph">MetroCluster y SnapMirror de sincronización activa proporcionan tres métodos básicos de continuidad de datos en caso de eventos previstos o no planificados:</block>
  <block id="1d3027d09fc1db3087f05f2163af2cb7" category="list-text">Componentes redundantes para protección contra fallos de un solo componente</block>
  <block id="f3b83f3b77289efe3b53cf537b7b77f5" category="list-text">Toma de control local de alta disponibilidad para eventos que afectan a una única controladora</block>
  <block id="b6ed0cba165f6f9664dc1e57ac3419ec" category="list-text">Protección completa del sitio: Reanudación rápida del servicio al mover el almacenamiento y el acceso de clientes del clúster de origen al clúster de destino</block>
  <block id="16afcbe8821dfa582521cd62c1ec130d" category="paragraph">Esto significa que las operaciones continúan sin problemas en caso de fallo de un único componente y vuelven automáticamente al funcionamiento redundante cuando se reemplaza el componente fallido.</block>
  <block id="8fab78e8b214cad43d962b802bf568f8" category="paragraph">Todos los clústeres de ONTAP, excepto los clústeres de un solo nodo (normalmente las versiones definidas por software, como ONTAP Select, por ejemplo), tienen funciones de alta disponibilidad incorporadas denominadas toma de control y retorno al nodo primario. Cada controladora del clúster se empareja con otra controladora, lo que forma una pareja de alta disponibilidad. Estos pares garantizan que cada nodo esté conectado localmente al almacenamiento.</block>
  <block id="83e1749664841043ce8b1e894769a201" category="paragraph">La toma de control es un proceso automatizado en el que un nodo asume el almacenamiento del otro para mantener los servicios de datos. Giveback es el proceso inverso que restaura el funcionamiento normal. La toma de control puede planificarse, por ejemplo, al realizar tareas de mantenimiento del hardware o actualizaciones de ONTAP, o no planificadas, resultantes de un error de hardware o de alarma en el nodo.</block>
  <block id="834d83f4ff04b7e3948831f336559b7c" category="paragraph">Durante una toma de control, las interfaces lógicas de almacenamiento conectadas a red (LIF NAS) en configuraciones de MetroCluster conmutan automáticamente al respaldo. Sin embargo, los LIF de red de área de almacenamiento (LIF SAN) no conmutan al nodo de respaldo; seguirán utilizando la ruta directa a los números de unidad lógica (LUN).</block>
  <block id="0b0403a9258293da1f6a5fc84d24a18e" category="inline-link">Información general sobre la gestión de parejas de HA</block>
  <block id="df5ca9bc3ee60e70aa9fd870a1ce1065" category="paragraph">Si quiere más información sobre la toma de control y el retorno al nodo primario de alta disponibilidad, consulte la<block ref="5a72801b431f75b7489a0e7de50680bf" category="inline-link-rx"></block>. Vale la pena señalar que esta funcionalidad no es específica de la sincronización activa de MetroCluster o SnapMirror.</block>
  <block id="cf654073ce9eb8f38d3f05292ed83cc5" category="paragraph">El cambio de sitio con MetroCluster se produce cuando un sitio está sin conexión o como una actividad planificada para el mantenimiento de todo el sitio. El sitio restante asume la propiedad de los recursos de almacenamiento (discos y agregados) del clúster sin conexión y las SVM del sitio con el que se ha producido el fallo se conectan y se reinician en el sitio de desastre, conservando su identidad completa para el acceso de clientes y host.</block>
  <block id="4dd2305dcb9d7412784238dd42dcdc21" category="paragraph">Con la sincronización activa de SnapMirror, dado que ambas copias se usan de forma activa a la vez, los hosts existentes seguirán funcionando. El Mediador de NetApp es necesario para garantizar que la conmutación por error del sitio se produce correctamente.</block>
  <block id="823bd5c6c005e340599d915e134d851c" category="summary">Descripción general de la solución de VMware vSphere</block>
  <block id="be26d39d86de44047c65c1fed157d529" category="paragraph">VCenter Server Appliance (VCSA) es el potente sistema de gestión centralizada y un panel único para vSphere que permiten a los administradores operar clústeres ESXi de forma eficiente. Facilita funciones clave como el aprovisionamiento de máquinas virtuales, la operación vMotion, alta disponibilidad, planificador de recursos distribuidos (DRS), Tanzu Kubernetes Grid, etc. Es un componente esencial en los entornos cloud de VMware y debe diseñarse teniendo en cuenta la disponibilidad del servicio.</block>
  <block id="8ba8694e23f6560a60d85c4de549122b" category="section-title">Alta disponibilidad de vSphere</block>
  <block id="4b5543b81af03f01e26fcb74614f7062" category="paragraph">La tecnología de clúster de VMware agrupa servidores ESXi en pools de recursos compartidos para máquinas virtuales y proporciona vSphere High Availability (HA). VSphere HA proporciona una alta disponibilidad fácil de usar para aplicaciones que se ejecutan en máquinas virtuales. Cuando se habilita la función HA en el clúster, cada servidor ESXi mantiene la comunicación con otros hosts de modo que si algún host ESXi deja de responder o aísla, el clúster de alta disponibilidad puede negociar la recuperación de las máquinas virtuales que se estaban ejecutando en ese host ESXi entre los hosts supervivientes del clúster. Si se produce un fallo del sistema operativo invitado, vSphere HA reiniciará la máquina virtual afectada en el mismo servidor físico. La alta disponibilidad de vSphere permite reducir el tiempo de inactividad planificado, evitar tiempos de inactividad no planificados y recuperarse rápidamente de interrupciones.</block>
  <block id="01036edb3159652090a3f7149fe1ce2f" category="paragraph">Un clúster de alta disponibilidad de vSphere que recupera las máquinas virtuales del servidor con errores.</block>
  <block id="15496c3917565cea1f21bbc7e6eba996" category="image-alt">Diagrama de VMSC</block>
  <block id="c1bb7aa3a002a819d935439c7e347826" category="paragraph">Es importante entender que VMware vSphere no tiene conocimientos de la sincronización activa de NetApp MetroCluster o SnapMirror y ve todos los hosts ESXi del clúster de vSphere como hosts elegibles para operaciones en clúster de alta disponibilidad en función de las configuraciones de afinidad de hosts y grupos de máquinas virtuales.</block>
  <block id="dcff37ab37f2cb6a72aeb3c30e3ed5aa" category="section-title">Detección de fallo de host</block>
  <block id="7069d861b63dd4095cfb7b2ee30587f5" category="paragraph">En cuanto se crea el clúster HA, todos los hosts del clúster participan en sus elecciones y uno de los hosts se convierte en un maestro. Cada esclavo realiza latidos de red al maestro y, a su vez, el maestro realiza latidos de red en todos los hosts esclavos. El host maestro de un clúster de alta disponibilidad de vSphere es responsable de detectar el fallo de hosts esclavos.</block>
  <block id="73b629afd8ef39d8d0147696412538c8" category="paragraph">Según el tipo de error detectado, es posible que las máquinas virtuales que se ejecutan en los hosts deban conmutar al nodo de respaldo.</block>
  <block id="e12cf4015a45ff29f1f84ae1a3ee0390" category="paragraph">En un clúster de alta disponibilidad de vSphere se detectan tres tipos de fallos de host:</block>
  <block id="4eac346eb6cdd3a1a98ee9bc71ebccaa" category="list-text">Fallo: Un host deja de funcionar.</block>
  <block id="3875a4c584a7715edf4a221ce53d45fc" category="list-text">Aislamiento: Un host se convierte en una red aislada.</block>
  <block id="82fba11358d642111efbcf36273159f2" category="list-text">Partición: Un host pierde la conectividad de red con el host maestro.</block>
  <block id="5f72ceebd161159fe623ff01ac0cf1b4" category="paragraph">El host maestro supervisa los hosts esclavos del cluster. Esta comunicación se realiza a través del intercambio de latidos de la red cada segundo. Cuando el host maestro deja de recibir estos latidos de un host esclavo, comprueba si hay vida activa del host antes de declarar que el host ha fallado. La comprobación de vida que realiza el host maestro es determinar si el host esclavo está intercambiando latidos con uno de los almacenes de datos. Además, el host maestro comprueba si el host responde a los ping ICMP enviados a sus direcciones IP de gestión para detectar si simplemente está aislado de su nodo maestro o completamente aislado de la red. Para ello, haga ping en la puerta de enlace predeterminada. Se pueden especificar manualmente una o varias direcciones de aislamiento para mejorar la fiabilidad de la validación de aislamiento.</block>
  <block id="5546466ab10e5cbfbc4b286cd60b8b4a" category="section-title">_Best Practice_</block>
  <block id="0456a7ce7bf92fb68980571fdd2defa1" category="paragraph">NetApp recomienda especificar un mínimo de dos direcciones de aislamiento adicionales, y que cada una de estas direcciones sea local de sitio. Esto mejorará la fiabilidad de la validación del aislamiento.</block>
  <block id="19c262cd1e1bb07c491e359333f04a29" category="section-title">Respuesta de aislamiento del host</block>
  <block id="7a2723aad08de3c674693adf221e4a48" category="paragraph">Isolation Response es una configuración de vSphere HA que determina la acción que se activa en máquinas virtuales cuando un host de un clúster de vSphere HA pierde sus conexiones de red de gestión, pero continúa ejecutándose. Hay tres opciones para esta configuración, “Desactivado”, “Apagar y reiniciar VM” y “Apagar y reiniciar VM”.</block>
  <block id="715e310d886b45856c3ab0f69b06241b" category="paragraph">“Apagar” es mejor que “Apagar”, que no vacía los cambios más recientes en el disco o las transacciones de confirmación. Si los equipos virtuales no se apagan en 300 segundos, se apagan. Para cambiar el tiempo de espera, utilice la opción avanzada das.isolationshutdowntimeout.</block>
  <block id="620b4ae663a26c98656d1c81bec1a6c2" category="paragraph">Antes de que HA inicie la respuesta de aislamiento, primero comprueba si el agente maestro HA de vSphere posee el almacén de datos que contiene los archivos de configuración de la máquina virtual. Si no es así, el host no activará la respuesta de aislamiento, porque no hay ningún maestro para reiniciar las máquinas virtuales. El host comprobará periódicamente el estado del almacén de datos para determinar si un agente de alta disponibilidad de vSphere que posee el rol maestro.</block>
  <block id="6824ef1b1c5e58e8ea5ebc8b2cf94be2" category="paragraph">NetApp recomienda establecer la “Respuesta de aislamiento del host” en Desactivado.</block>
  <block id="6bd7b146f345eefac88b336a89aa3754" category="paragraph">Se puede producir una condición de cerebro dividido si un host se aísla o particiona desde el host maestro HA de vSphere y el maestro no puede comunicarse a través de los almacenes de datos de latido o mediante ping. El maestro declara que el host aislado está muerto y reinicia los equipos virtuales en otros hosts del cluster. Ahora existe una condición de cerebro dividido porque hay dos instancias de la máquina virtual en ejecución, solo una de las cuales puede leer o escribir los discos virtuales. Ahora se pueden evitar las condiciones del cerebro dividido configurando VM Component Protection (VMCP).</block>
  <block id="df05a421ed8ba49f97f18dc085495ee4" category="section-title">Protección de componentes de máquina virtual (VMCP)</block>
  <block id="1418d127ee81cc7f3e114029e9ba6856" category="paragraph">Una de las mejoras de funciones de vSphere 6, relevante para la alta disponibilidad, es VMCP. VMCP proporciona protección mejorada contra todas las condiciones de pérdida permanente de dispositivos (APD) y de pérdida permanente de dispositivos (PDL) para bloques (FC, iSCSI, FCoE) y almacenamiento de archivos (NFS).</block>
  <block id="fc35e15d00ef5b037a1a56c77ef3e17c" category="section-title">Pérdida permanente de dispositivo (PDL)</block>
  <block id="967b20f28092443585be2b9649d0ba93" category="paragraph">PDL es una condición que ocurre cuando un dispositivo de almacenamiento falla de forma permanente o se elimina de forma administrativa y no se espera que regrese. La cabina de almacenamiento NetApp emite un código de detección SCSI a ESXi que declara la pérdida permanente del dispositivo. En la sección Condiciones de fallo y Respuesta de VM de vSphere HA, puede configurar cuál debe ser la respuesta después de detectar una condición PDL.</block>
  <block id="7cf4fdbfc8e1deb9f567848f2df19e91" category="paragraph">NetApp recomienda configurar “Response for Datastore with PDL” en “*Apagar y reiniciar VMs*”. Cuando se detecta esta condición, una máquina virtual se reinicia instantáneamente en un host en buen estado dentro del clúster de alta disponibilidad de vSphere.</block>
  <block id="6d623de2ea8c5007def6f2349d9ad8b9" category="section-title">Todas las rutas hacia abajo (APD)</block>
  <block id="15d2d9b1f25022e7080482582e155265" category="paragraph">APD es una condición que se produce cuando el host vuelve inaccesible a un dispositivo de almacenamiento y no hay rutas disponibles a la cabina. ESXi considera que esto es un problema temporal con el dispositivo y espera que vuelva a estar disponible.</block>
  <block id="f89caca297ba86d190d90ef30c409ccf" category="paragraph">Cuando se detecta una condición de APD, se inicia un temporizador. Después de 140 segundos, la condición APD se declara oficialmente, y el dispositivo se marca como APD Time Out. Una vez transcurridos los 140 segundos, HA comenzará a contar el número de minutos especificado en el APD de retraso para failover de VM. Cuando transcurra el tiempo especificado, HA reiniciará los equipos virtuales afectados. Puede configurar VMCP para que responda de manera diferente si lo desea (Desactivado, Incidir eventos o Apagar y reiniciar VM).</block>
  <block id="8f179a61d789dab9b994ecd0ca8c53cb" category="paragraph">NetApp recomienda configurar “Response for Datastore with APD” en “*Apagar y reiniciar VMs (conservative)*”.</block>
  <block id="76d29c3c5f57a16a7f080459356c3793" category="paragraph">Conservative hace referencia a la probabilidad de que la alta disponibilidad pueda reiniciar equipos virtuales. Cuando se establece en Conservador, HA solo reiniciará la VM que se ve afectada por el APD si sabe que otro host puede reiniciarla. En caso de agresividad, HA intentará reiniciar la máquina virtual incluso si no conoce el estado de los otros hosts. Esto puede provocar que las máquinas virtuales no se reinicien si no hay ningún host con acceso al almacén de datos en el que se encuentra.</block>
  <block id="c64ef72a18526e28efe7c08b3ff3889a" category="paragraph">Si el estado APD se resuelve y el acceso al almacenamiento se restaura antes de que se agote el tiempo de espera, HA no reiniciará innecesariamente la máquina virtual a menos que se configure explícitamente para ello. Si se desea una respuesta, incluso cuando el entorno se ha recuperado de la condición APD, la respuesta para la recuperación APD después del tiempo de espera APD debe configurarse para restablecer las máquinas virtuales.</block>
  <block id="580bc3953adcf3e3a20c5497f67f8b2c" category="paragraph">NetApp recomienda configurar la respuesta para la recuperación de APD después del tiempo de espera de APD en Desactivado.</block>
  <block id="a067a9a0e98c97f62fba4698bde30edc" category="section-title">Implementación de VMware DRS para NetApp MetroCluster</block>
  <block id="3bf3e67966e8b0e07b0812dae7b86ce7" category="paragraph">VMware DRS es una función que agrega los recursos de host en un clúster y se usa principalmente para equilibrar cargas dentro de un clúster de una infraestructura virtual. VMware DRS calcula principalmente los recursos de la CPU y la memoria para realizar el equilibrio de carga en un clúster. Como vSphere no es consciente de la agrupación en cluster ampliada, considera todos los hosts en ambos sitios al equilibrar la carga. Para evitar el tráfico entre sitios, NetApp recomienda configurar reglas de afinidad de DRS para gestionar una separación lógica de equipos virtuales. Esto garantizará que, a menos que se produzca un fallo completo del sitio, HA y DRS solo utilizarán los hosts locales.</block>
  <block id="b9e04f46a88c8139fbb91780a2ff9064" category="paragraph">Si crea una regla de afinidad de DRS para su clúster, puede especificar cómo aplica vSphere esa regla durante una conmutación al respaldo de una máquina virtual.</block>
  <block id="f903d43a0acb7412db93e8201ab12be3" category="paragraph">Hay dos tipos de reglas que se pueden especificar el comportamiento de conmutación al nodo de respaldo de alta disponibilidad de vSphere:</block>
  <block id="a96c8bab3a450bb828e3093d16f7e32c" category="list-text">Las reglas de anti-afinidad de equipos virtuales obligan a los equipos virtuales especificados a permanecer separados durante las acciones de recuperación tras fallos.</block>
  <block id="1fa3a04279011cbc6001c96c0f6f27fb" category="list-text">Las reglas de afinidad de host de VM colocan las máquinas virtuales especificadas en un host particular o un miembro de un grupo definido de hosts durante las acciones de conmutación por error.</block>
  <block id="225e3f7204b6e5bf6cd388af7bb16eb4" category="paragraph">Mediante el uso de reglas de afinidad de host de VM en VMware DRS, se puede tener una separación lógica entre el sitio A y el sitio B, de modo que la VM se ejecute en el host en el mismo sitio que la cabina que está configurada como la controladora de lectura/escritura primaria para un almacén de datos determinado. Además, las reglas de afinidad de host de VM permiten que las máquinas virtuales permanezcan locales en el almacenamiento, lo que, a su vez, verifica la conexión a la máquina virtual en caso de fallos de red entre los sitios.</block>
  <block id="db03e2255e35df6fa9719c800850c397" category="paragraph">A continuación se muestra un ejemplo de los grupos de hosts y las reglas de afinidad de las máquinas virtuales.</block>
  <block id="d400b2cf908bc5f979847146ff8ac816" category="paragraph">NetApp recomienda implementar reglas de «debería» en lugar de reglas de «debe» porque vSphere HA las infringe en caso de fallo. El uso de reglas «imprescindibles» podría provocar interrupciones del servicio.</block>
  <block id="e9503bc9ad84f6517ddc938c85541dd5" category="paragraph">La disponibilidad de los servicios debe prevalecer siempre sobre el rendimiento. En el caso en que falla un centro de datos completo, las reglas “must” deben elegir hosts del grupo de afinidad de host de VM y, cuando el centro de datos no esté disponible, las máquinas virtuales no se reiniciarán.</block>
  <block id="b3c45603f3738ac1e1f8e1e87569c00c" category="section-title">Implementación de VMware Storage DRS con NetApp MetroCluster</block>
  <block id="b273633ed947791e90b7b83ad1bb2021" category="paragraph">La función VMware Storage DRS permite agregar almacenes de datos en una sola unidad y equilibra los discos de máquinas virtuales cuando se superan los umbrales de control de I/O del almacenamiento.</block>
  <block id="4669dbcf4d42583b3fae1c79fa228078" category="paragraph">El control de la I/O de almacenamiento se habilita de forma predeterminada en los clústeres DRS habilitados para Storage DRS. El control de las operaciones de I/O de almacenamiento permite a un administrador controlar la cantidad de I/O de almacenamiento que se asigna a máquinas virtuales durante periodos de congestión de I/O, lo que permite que las máquinas virtuales más importantes tengan preferencia por máquinas virtuales menos importantes para la asignación de recursos de E/S.</block>
  <block id="f06483bf36a941eebbb2f78a89b6bf68" category="paragraph">Storage DRS utiliza Storage vMotion para migrar los equipos virtuales a diferentes almacenes de datos dentro de un clúster de almacén de datos. En un entorno NetApp MetroCluster, una migración de máquinas virtuales debe controlarse dentro de los almacenes de datos de ese sitio. Por ejemplo, en condiciones ideales, la máquina virtual A, que se ejecuta en un host en el sitio A, debería migrar dentro de los almacenes de datos de la SVM en el sitio A. Si no lo hace, la máquina virtual continuará funcionando pero con un rendimiento degradado, ya que la lectura/escritura del disco virtual será desde la ubicación B a través de enlaces entre sitios.</block>
  <block id="e607d8c3dc392e521065e5494d8c85c6" category="paragraph">NetApp recomienda crear clústeres de almacenes de datos con respecto a la afinidad del sitio de almacenamiento; es decir, los almacenes de datos con afinidad del sitio A no se deben mezclar con clústeres de almacenes de datos con almacenes de datos con afinidad del sitio B.</block>
  <block id="63fe88e257ae2d072b6920d6dbcf0818" category="paragraph">Siempre que un equipo virtual se aprovisiona o se migra recientemente mediante Storage vMotion, NetApp recomienda actualizar manualmente todas las reglas de DRS de VMware específicas para dichos equipos virtuales. Esto determinará la afinidad de la máquina virtual en el nivel del sitio tanto para el host como para el almacén de datos y, por lo tanto, reducirá la sobrecarga de red y almacenamiento.</block>
  <block id="4adcd8d9323839ff088dc4f8f0bdcce2" category="paragraph">Hay varios pasos para crear almacenamiento vVols para las máquinas virtuales.</block>
  <block id="2438f6a80b933cf058ad052d26ac0703" category="paragraph">El clonado de un objeto de almacenamiento le permite crear rápidamente copias para un uso adicional, como el aprovisionamiento de equipos virtuales adicionales, operaciones de backup/recuperación de datos, etc.</block>
  <block id="1a795345e422d7dbcca8fe38671a9371" category="summary">Directrices de implementación y diseño de VMSC.</block>
  <block id="b73deaadc37ea1c7a13ad17af6730c42" category="doc">Directrices de implementación y diseño de VMSC</block>
  <block id="3512760e2d3fc1a9dd2116e83bb0cada" category="paragraph">Este documento describe las guías de diseño e implementación para VMSC con sistemas de almacenamiento ONTAP.</block>
  <block id="556669df5b5073ab3d2ddcf638e942d9" category="section-title">Configuración de almacenamiento de NetApp</block>
  <block id="7f4d4fbe08a8a895671d05c4a82b0c85" category="inline-link">Documentación de MetroCluster</block>
  <block id="002eb41870df47521a2b59424d251f60" category="inline-link">Información general sobre la continuidad del negocio de SnapMirror</block>
  <block id="008c17a2bb74d3d9706c0f2c88499240" category="paragraph">Las instrucciones de configuración para NetApp MetroCluster (en lo que se refiere como configuración de MCC) están disponibles en<block ref="2c736bccede87dae47dcf61108f083c4" category="inline-link-rx"></block>. También puede encontrar instrucciones para SnapMirror Active Sync en<block ref="14203840309dd1b6e13f73373477bb9d" category="inline-link-rx"></block>.</block>
  <block id="447566f62201eb825a1f6fb7a570873f" category="paragraph">Después de configurar MetroCluster, administrarlo es como administrar un entorno ONTAP tradicional. Puede configurar máquinas virtuales de almacenamiento (SVM) con diferentes herramientas, como la interfaz de línea de comandos (CLI), System Manager o Ansible. Una vez que se han configurado las SVM, cree interfaces lógicas (LIF), volúmenes y números de unidad lógica (LUN) en el clúster que se utilizarán para operaciones normales. Estos objetos se replicarán automáticamente en el otro clúster mediante la red de conexión de clústeres.</block>
  <block id="b5486be95ed9ae2e4681a39cf8fe8041" category="inline-link">Información general sobre los grupos de consistencia</block>
  <block id="5440d8600dfca322be65444d14c4566f" category="paragraph">Si no utiliza MetroCluster, puede usar la sincronización activa de SnapMirror, que proporciona protección granular de almacenes de datos y acceso activo-activo en múltiples clústeres de ONTAP en diferentes dominios de fallo. SnapMirror Active Sync utiliza grupos de coherencia para garantizar la coherencia en orden de escritura entre uno o varios almacenes de datos y puede crear varios grupos de coherencia en función de los requisitos de la aplicación y del almacén de datos. Los grupos de coherencia son especialmente útiles para aplicaciones que requieren sincronización de datos entre varios almacenes de datos. La sincronización activa de SnapMirror también admite asignaciones de dispositivos sin formato (RDM) y almacenamiento conectado mediante invitado con iniciadores iSCSI invitados. Puede obtener más información sobre grupos de consistencia en<block ref="8bba9b5b97dba092834d7a48a07f102d" category="inline-link-rx"></block>.</block>
  <block id="f9ac6f5e1bf01f1df914b714d5e6cb02" category="paragraph">Hay alguna diferencia en la gestión de una configuración VMSC con sincronización activa de SnapMirror en comparación con una MetroCluster. En primer lugar, se trata de una configuración solo SAN, no se puede proteger ningún almacén de datos NFS con sincronización activa de SnapMirror. Segundo, debe asignar ambas copias de las LUN a los hosts ESXi para que accedan a los almacenes de datos replicados en ambos dominios de fallo.</block>
  <block id="c972b11c861e42787c05a2ee24828e3a" category="section-title">VMware vSphere ha</block>
  <block id="57166da54d8751e1ed084f00b3f169e3" category="section-title">Cree un clúster de vSphere HA</block>
  <block id="829006223e7bdcfd478d2261f1d5ac40" category="inline-link">Cómo se crean y configuran clústeres en vSphere Client en docs.vmware.com</block>
  <block id="2bbae4763835d2e2dd123c1b4b0ae73d" category="paragraph">La creación de un clúster de vSphere HA es un proceso de varios pasos que se documenta completamente en<block ref="dd51ccd863dd3c9fbca770681f8e68a9" category="inline-link-rx"></block>. En resumen, primero debe crear un clúster vacío y, después, utilizando vCenter, debe añadir hosts y especificar la alta disponibilidad de vSphere y otros ajustes del clúster.</block>
  <block id="d50e63b9f70efedde8dc093be8ec12b2" category="inline-link">Prácticas recomendadas para VMware vSphere Metro Storage Cluster</block>
  <block id="33d532b774d7b67104f4749e25ba03ef" category="paragraph">*Nota:* Nada en este documento reemplaza<block ref="3a8301f60ad04eb873ae8dea15ee0495" category="inline-link-rx"></block></block>
  <block id="950954623b197b80e3ebb95b0adcc3de" category="paragraph">Para configurar un clúster de alta disponibilidad, realice los siguientes pasos:</block>
  <block id="1073102bd8c6cbd17340f2a19043583f" category="list-text">Conéctese a la interfaz de usuario de vCenter.</block>
  <block id="ebf69ea3a3e34739bde13d589e85ef10" category="list-text">En Hosts and Clusters, vaya al centro de datos donde desea crear su clúster de alta disponibilidad.</block>
  <block id="d8fd85bbc0cd4746e5d80e291696b86c" category="list-text">Haga clic con el botón derecho en el objeto del centro de datos y seleccione New Cluster. En los conceptos básicos, asegúrese de haber habilitado vSphere DRS y vSphere HA. Complete el asistente.</block>
  <block id="f2c634ca704e26f96be1723db6dda32a" category="image-alt">Una captura de pantalla de una descripción de computadora generada automáticamente</block>
  <block id="f4f59bf1e324854573172ca2b5070d45" category="list-text">Seleccione el clúster y vaya a la pestaña Configure. Seleccione vSphere HA y haga clic en Edit.</block>
  <block id="329c69e52a7de6215aa4dbfa19940f2d" category="list-text">En Supervisión de host, seleccione la opción Habilitar supervisión de host.</block>
  <block id="9fc231ac455a53f2fabc59f29ab537ad" category="list-text">Mientras todavía está en la pestaña Fallos y Respuestas, en VM Monitoring, seleccione la opción VM Monitoring Only o VM and Application Monitoring.</block>
  <block id="58aea8c81a7e8b8160584574af309fbb" category="list-text">En Control de admisión, establezca la opción de control de admisión de HA en Reserva de recursos de cluster; utilice 50% CPU/MEM.</block>
  <block id="d94a9f01bee7dcc2643864bf92ab4e59" category="list-text">Se hace clic en «OK».</block>
  <block id="3f059eee365aa5c64c0be1d6dba81d69" category="list-text">Seleccione DRS y haga clic en EDIT.</block>
  <block id="7b5f9be03fd1421a9da56c2c7677ad69" category="list-text">Establezca el nivel de automatización en manual a menos que las aplicaciones lo requieran.</block>
  <block id="a8ee10582e28e3623629963a88ff5ec9" category="image-alt">vmsc 3 5</block>
  <block id="256164bb48582e5267e408f2e67e1939" category="inline-link">docs.vmware.com</block>
  <block id="91fb89f03b846483f7108d3f1bfb0156" category="list-text">Habilite VM Component Protection, consulte<block ref="fc88c93ad20ad804a211f4e6fea63e56" category="inline-link-rx"></block>.</block>
  <block id="918c2d8e02dbd2c1f4cc3a0062690387" category="list-text">Se recomiendan las siguientes configuraciones adicionales de alta disponibilidad de vSphere para VMSC con MCC:</block>
  <block id="d64ed3e9c10229648e069f56e32f4c8e" category="cell">Respuesta</block>
  <block id="f3c1d0e4118d5d9501e1a7aeed19d224" category="cell">Error del host</block>
  <block id="45d583cd5692c76d45e96536edce2a0e" category="cell">Reiniciar las máquinas virtuales</block>
  <block id="1c3a7ae924920b573baede481becd22f" category="cell">Aislamiento de hosts</block>
  <block id="2e011e74abc75a2823c627b7ee9e22a7" category="cell">Almacén de datos con pérdida permanente de dispositivo (PDL)</block>
  <block id="49476a1ad365d5f8deb36464de7fe33b" category="cell">Apagar y reiniciar los equipos virtuales</block>
  <block id="e7bbd35db169028c75e7c8ae655bf6ae" category="cell">Almacén de datos con todas las rutas inactivas (APD)</block>
  <block id="e7480b00a5e3efd904a08ca88804de45" category="cell">El huésped no es molesto</block>
  <block id="e8896c595f3effde37ef29d7c6233703" category="cell">Restablecer las máquinas virtuales</block>
  <block id="59695df3d45a3a21b8ff0bf57fda6a2b" category="cell">Política de reinicio de máquinas virtuales</block>
  <block id="a150f56b87fd99bf9bf019f8447ba68b" category="cell">Determinado por la importancia del equipo virtual</block>
  <block id="370a480458a8c63a838940f1241e14ee" category="cell">Respuesta para el aislamiento del host</block>
  <block id="11f30f9be08cd4f9e500290222ddc552" category="cell">Apagar y reiniciar equipos virtuales</block>
  <block id="fb53fafa45c0de9bd41d368c7455c9f1" category="cell">Respuesta para datastore con PDL</block>
  <block id="d7c3b9f5568eb60f08076b29490afcaf" category="cell">Respuesta del almacén de datos con APD</block>
  <block id="423b2d98eae113ae3391aa0b12f11935" category="cell">Apagar y reiniciar equipos virtuales (conservador)</block>
  <block id="132bbe6dbceb01227dba5ab04db7202b" category="cell">Demora en recuperación tras fallos de equipos virtuales para APD</block>
  <block id="8d15ed7d27d83ed6229a66b1f44b7696" category="cell">3 minutos</block>
  <block id="8c7b0644547f0ee3fe537e8ba441566d" category="cell">Respuesta para la recuperación de APD con tiempo de espera APD</block>
  <block id="4dea08318b2824f845e9b889a6e17778" category="cell">Supervisión de la sensibilidad de los equipos virtuales</block>
  <block id="f535a28adc173e28610c129d0dc578ae" category="cell">Preajuste ALTO</block>
  <block id="83164803a765d1ea1f10d50dfdd26130" category="section-title">Configurar almacenes de datos para Heartbeat</block>
  <block id="22c81b09ec3086b2dce8f68867a221e0" category="paragraph">La alta disponibilidad de vSphere utiliza almacenes de datos para supervisar hosts y máquinas virtuales cuando se produce un error en la red de gestión. Es posible configurar la forma en la que vCenter selecciona los almacenes de datos de latido. Para configurar los almacenes de datos para latir, lleve a cabo los siguientes pasos:</block>
  <block id="64809e5386c9dc53f894f772f27d1b44" category="list-text">En la sección Datastore Heartbeat, seleccione Use datastores from the Specified List y complemente automáticamente si es necesario.</block>
  <block id="fc66ba7317ceb4220dc88aa267db085d" category="list-text">Seleccione los almacenes de datos que desee utilizar vCenter en ambos sitios y pulse OK.</block>
  <block id="1d2b14769d080b9214d9e407dfc92a64" category="section-title">Configurar opciones avanzadas</block>
  <block id="a22b9827e1a78c5fb9c939a78c116a05" category="paragraph">* Detección de fallos del host *</block>
  <block id="a9316d69e5abcfaffc56fc8f5e645412" category="paragraph">Los eventos de aislamiento se producen cuando los hosts dentro de un clúster de alta disponibilidad pierden la conectividad a la red u otros hosts del clúster. De forma predeterminada, vSphere HA utilizará la puerta de enlace predeterminada para su red de gestión como dirección de aislamiento predeterminada. Sin embargo, puede especificar direcciones de aislamiento adicionales para que el host haga ping para determinar si se debe activar una respuesta de aislamiento. Agregue dos IP de aislamiento que puedan hacer ping, una por sitio. No utilice la IP de la puerta de enlace. La configuración avanzada de HA de vSphere utilizada es das.isolationaddress. Puede utilizar las direcciones IP de ONTAP o Mediator para este fin.</block>
  <block id="102d7879ceca393c309ef492c958e19d" category="inline-link">core.vmware.com</block>
  <block id="27e2292ff6db48ed2e6d50b256eae43e" category="paragraph">Consulte<block ref="43057df4f3a6b5f2fffe8b7c5a490646" category="inline-link-rx"></block> para obtener más información__.__</block>
  <block id="3f44bb4a3b9420d495e400b9afbda2c7" category="paragraph">Agregar una configuración avanzada llamada das.heartbeatDsPerHost puede aumentar el número de almacenes de datos de latido. Utilice cuatro almacenes de datos para el corazón (HB DSS): Dos por sitio. Utilice la opción “Seleccionar de la lista pero cumplido”. Esto es necesario porque si un sitio falla, usted todavía necesita dos HB DSS. Sin embargo, esas empresas no tienen que estar protegidas con sincronización activa de SnapMirror o MCC.</block>
  <block id="eaa1dfe3982e06655ce64e240c139b81" category="paragraph">Afinidad de VMware DRS para NetApp MetroCluster</block>
  <block id="e32221c52eb3b0bbeb3ca79aad6c90f6" category="paragraph">En esta sección creamos grupos DRS para equipos virtuales y hosts para cada sitio\clúster del entorno MetroCluster. A continuación, configuramos las reglas de VM\Host para alinear la afinidad de host de VM con los recursos de almacenamiento local. Por ejemplo, las máquinas virtuales de la dirección A pertenecen al grupo de máquinas virtuales sitea_vms y la ubicación A pertenecen al grupo de hosts sitea_hosts. A continuación, en VM\Host Rules, indicamos que sitea_vms debe ejecutarse en hosts en sitea_Hosts.</block>
  <block id="5bfa0d712f66aef47f8a2ea582bc0b72" category="list-text">NetApp recomienda encarecidamente la especificación *Debe ejecutarse en hosts del grupo* en lugar de la especificación *Debe ejecutarse en hosts del grupo*. En caso de que se produzca un fallo del host del sitio A, es necesario reiniciar las máquinas virtuales del sitio A en los hosts del sitio B a través de vSphere HA, pero la última especificación no permite a HA reiniciar los equipos virtuales en el sitio B, ya que es una regla estricta. La especificación anterior es una regla flexible y se infringirá en caso de alta disponibilidad, lo que permitirá la disponibilidad en lugar de rendimiento.</block>
  <block id="cc6a363013bd2a8c1e05304f1c6abd79" category="inline-link">Supervisión y rendimiento de vSphere</block>
  <block id="db9540392e62211ad47ebec39232329e" category="paragraph">*Nota:* Puede crear una alarma basada en eventos que se activa cuando una máquina virtual viola una regla de afinidad VM-Host. En vSphere Client, agregue una nueva alarma para la máquina virtual y seleccione “VM is Violating VM-Host Affinity Rule” como disparador de eventos. Para obtener más información sobre la creación y edición de alarmas, consulte<block ref="d28eed239632aed40803fe0ed2311ba6" category="inline-link-rx"></block> documentación.</block>
  <block id="124de7d2bc72d75be9e481c1cc56ada2" category="section-title">Crear grupos de hosts DRS</block>
  <block id="0759e9476d3bf1868f88356025adafb2" category="paragraph">Para crear grupos de hosts DRS específicos del sitio A y del sitio B, realice los siguientes pasos:</block>
  <block id="a69dff3dd4b284f60243dfd62fa4e57f" category="list-text">En vSphere Web Client, haga clic con el botón derecho en el clúster en el inventario y seleccione Settings.</block>
  <block id="a130b4af254ead99e9ea83044e54ea1d" category="list-text">Haga clic en VM\Host Groups.</block>
  <block id="1bb250fbf1946dd1bd7ad228032f8803" category="list-text">Haga clic en Añadir.</block>
  <block id="62c4d1538f957af2951f2c93ee191d0b" category="list-text">Escriba el nombre del grupo (por ejemplo, sitea_hosts).</block>
  <block id="df22605898fc890edbcb2a126aa202ce" category="list-text">En el menú Tipo, seleccione Grupo de hosts.</block>
  <block id="57c0028584902f6cee210dcc13bc9745" category="list-text">Haga clic en Agregar y seleccione los hosts deseados del sitio A y haga clic en Aceptar.</block>
  <block id="583e6d8c3b1006b0561d4b360e58994f" category="list-text">Repita estos pasos para agregar otro grupo de hosts para el sitio B.</block>
  <block id="18d0ad44a1e563aaf9f5871e32535a6c" category="list-text">Haga clic en Aceptar.</block>
  <block id="154964ee7fc6d3261ec55811b0ff9972" category="section-title">Crear grupos de máquinas virtuales DRS</block>
  <block id="40c1eaba5f178f243c57b595b6af4d5e" category="paragraph">Para crear grupos de máquinas virtuales DRS específicos del sitio A y del sitio B, realice los siguientes pasos:</block>
  <block id="9a209a741c26968fc13ed8192523df15" category="list-text">Escriba el nombre del grupo (por ejemplo, sitea_vms).</block>
  <block id="f947c7c9f173289b1c2565b3297095f0" category="list-text">En el menú Type, seleccione VM Group.</block>
  <block id="40a2a21a084c8d16395113cb79a19ebb" category="list-text">Haga clic en Add y seleccione las máquinas virtuales deseadas en el sitio A y, a continuación, haga clic en OK.</block>
  <block id="e2e7af699096077fe178ebf021fb2273" category="section-title">Crear reglas de host de VM</block>
  <block id="0a6075f3d3fdbe7c133268face0f5c82" category="paragraph">Para crear reglas de afinidad de DRS específicas para el sitio A y el sitio B, realice los siguientes pasos:</block>
  <block id="df4f9bcca0ceb7a67ba25d886a18743b" category="list-text">Haga clic en VM\Host Rules.</block>
  <block id="876a25c102b5c301814921d1a9c0e625" category="list-text">Escriba el nombre de la regla (por ejemplo, sitea_affinity).</block>
  <block id="d4b5f57f4e2bd5c357ad9b1fbdc2cf8e" category="list-text">Compruebe que la opción Activar regla está activada.</block>
  <block id="d1169f525bd934df7f1a7e3bcf401997" category="list-text">En el menú Type, seleccione Virtual Machines to Hosts.</block>
  <block id="77328c16c697ce1d6c036c3f950e7542" category="list-text">Seleccione el grupo de VM (por ejemplo, sitea_vms).</block>
  <block id="b36943ce975d4c5c6e9481a4ca396270" category="list-text">Seleccione el grupo Host (por ejemplo, sitea_Hosts).</block>
  <block id="32fbcb32cfae9a0656233943c28f7c94" category="list-text">Repita estos pasos para añadir otra regla VM\Host para el sitio B.</block>
  <block id="ff0ded925b170243e5154c9a687bb925" category="section-title">DRS de almacenamiento de VMware vSphere para NetApp MetroCluster</block>
  <block id="b0cb5ad168b84040eff8132c70e41fdb" category="section-title">Crear clústeres de almacenes de datos</block>
  <block id="488f70e76f3c9ddf155b693e31c5a1e1" category="paragraph">Para configurar un clúster de almacén de datos para cada sitio, complete los siguientes pasos:</block>
  <block id="1dfbc2b980c0b56a5d9889c6d9a25460" category="list-text">Use el cliente web de vSphere, vaya al centro de datos donde reside el clúster de alta disponibilidad en Storage.</block>
  <block id="dfc332b252ad3de167b6a336d7e70d46" category="list-text">Haga clic con el botón derecho en el objeto del centro de datos y seleccione Storage &gt; New Datastore Cluster.</block>
  <block id="7ce7f4ad7022187801efdf33d1fab92d" category="list-text">Seleccione la opción ON Storage DRS y haga clic en Next.</block>
  <block id="6196801f8f77bab7132531adbb268512" category="list-text">Establezca todas las opciones en Sin automatización (Modo manual) y haga clic en Siguiente.</block>
  <block id="cfcdd0a8a765af314fb460ad445fb375" category="list-text">NetApp recomienda configurar el DRS de almacenamiento en modo manual, de modo que el administrador decida y controle cuándo es necesario realizar las migraciones.</block>
  <block id="51a3bc726f294f3376fcaa12ccdf8b3b" category="list-text">Compruebe que la casilla de verificación Activar Métrica de E/S para Recomendaciones de SDRS está activada; los valores de métrica se pueden dejar con los valores predeterminados.</block>
  <block id="829b62dbd6a4923b66591b2bff38ed5b" category="list-text">Seleccione el clúster de alta disponibilidad y haga clic en Next.</block>
  <block id="30fe6cfa0a4c5fb23fccfe149cefc006" category="list-text">Seleccione los almacenes de datos que pertenecen al sitio A y haga clic en Next.</block>
  <block id="4ea461b22638db4c94aa076d62a2065f" category="list-text">Revise las opciones y haga clic en Finish.</block>
  <block id="7b79e97caff76847cf350f1197c49953" category="list-text">Repita estos pasos para crear el clúster de almacenes de datos del sitio B y verifique que solo estén seleccionados los almacenes de datos del sitio B.</block>
  <block id="d8f83b09bd6b864f22076c109cfaae66" category="section-title">Disponibilidad del vCenter Server</block>
  <block id="605b8c1efcf2de9164e5d5425c67bdcd" category="paragraph">Los dispositivos vCenter Server Appliances (VCSA) deben estar protegidos con alta disponibilidad de vCenter. La alta disponibilidad de vCenter le permite implementar dos VCSA en un par de alta disponibilidad activo-pasivo. Uno en cada dominio de fallo. Puede obtener más información sobre la alta disponibilidad de vCenter en<block ref="173ca8434bdf39dd0a60efe576d066cd" category="inline-link-rx"></block>.</block>
  <block id="2b6203f34def274ff7424bf1d64a9bca" category="paragraph">La configuración de ajustes de red cuando se usa vSphere con sistemas que ejecutan el software ONTAP es sencilla y similar a la de otra configuración de red.</block>
  <block id="70901a02a148fd2dfc1ff5736f4f5336" category="list-text">Hay que separar el tráfico de la red de almacenamiento de otras redes. Se puede lograr una red independiente a través de una VLAN dedicada o switches independientes para el almacenamiento. Si la red de almacenamiento comparte rutas físicas como los enlaces ascendentes, puede que necesite calidad de servicio o puertos adicionales para garantizar el ancho de banda suficiente. No conecte los hosts directamente al almacenamiento; utilice switches para que tengan rutas redundantes y permita que VMware HA funcione sin intervención alguna. Consulte <block ref="2d54da766c3f840b00eab5923273fca5" category="inline-link-macro-rx"></block> para obtener más información.</block>
  <block id="59cfc5aaa0678bcb883492b4397c71b8" category="cell">Sí (ONTAP 9.14.1)</block>
  <block id="a58c81d13cac4e9b37bba2bd7fc3a93d" category="paragraph">El hipervisor vSphere líder del sector de VMware se puede poner en marcha como un clúster ampliado conocido como vSphere Metro Storage Cluster (VMSC).</block>
  <block id="e5239709587bb3ebb34629be6c41ac7b" category="paragraph">Las soluciones VMSC son compatibles con NetApp® MetroCluster™ y SnapMirror Active Sync (anteriormente conocido como continuidad empresarial de SnapMirror o SMBC) y proporcionan continuidad empresarial avanzada si uno o más dominios de fallo sufren una interrupción total. La resistencia a los diferentes modos de fallo depende de las opciones de configuración que elija.</block>
  <block id="e3224e391e08365c1593c07b9fe99cfa" category="section-title">Soluciones de disponibilidad continua para entornos vSphere</block>
  <block id="ffa76ec5527e36c51f49fe091541cca6" category="paragraph">NetApp MetroCluster utiliza la función de alta disponibilidad (conmutación por error de controladora o director financiero) de NetApp para proteger frente a fallos de controladora. También incluye tecnología SyncMirror local, recuperación tras fallos en clúster en caso de desastre (conmutación por error de controladora bajo demanda o CFOD), redundancia de hardware y separación geográfica para lograr altos niveles de disponibilidad. SyncMirror refleja de forma síncrona los datos en las dos mitades de la configuración de MetroCluster mediante la escritura de los datos en dos plexes: El plex local (en la bandeja local) que sirve los datos de forma activa y el plex remoto (en la bandeja remota) normalmente no ofrece datos. La redundancia de hardware se pone en marcha para todos los componentes de MetroCluster, como las controladoras, el almacenamiento, los cables, los switches (utilizados con Fabric MetroCluster) y los adaptadores.</block>
  <block id="54823008c0a63d8491d2c84e13356f84" category="paragraph">La sincronización activa de SnapMirror de NetApp ofrece protección granular de almacenes de datos con protocolos SAN FCP e iSCSI, lo que permite proteger de forma selectiva solo las cargas de trabajo de alta prioridad. Ofrece acceso activo-activo tanto a sitios locales como remotos, a diferencia de NetApp MetroCluster, que es una solución activa-en espera. En la actualidad, la sincronización activa es una solución asimétrica en la que se prefiere un lado sobre el otro, lo que proporciona un mejor rendimiento. Esto se logra mediante la funcionalidad ALUA (acceso asimétrico de unidad lógica), que informa automáticamente al host ESXi qué prefieren las controladoras. Sin embargo, NetApp ha anunciado que la sincronización activa pronto permitirá un acceso totalmente simétrico.</block>
  <block id="d3e911c902a6b066f9c31d471d16fb21" category="paragraph">Para crear un clúster HA/DRS de VMware en dos sitios, los hosts ESXi se usan y gestionan mediante una instancia de vCenter Server Appliance (VCSA). Las redes de gestión de vSphere, vMotion® y máquinas virtuales están conectadas a través de una red redundante entre los dos sitios. El servidor vCenter que gestiona el clúster HA/DRS puede conectarse a los hosts ESXi en ambos sitios y se debe configurar mediante vCenter HA.</block>
  <block id="da76be2bc20d4e043d9a2019b817214f" category="inline-link">¿Cómo se crean y configuran clústeres en vSphere Client</block>
  <block id="e02f3e9258a23204655bd512ec53911d" category="paragraph">Consulte<block ref="c06ae090600e7aa086edfa28514435e7" category="inline-link-rx"></block> Para configurar una alta disponibilidad de vCenter.</block>
  <block id="bdd88c75f085534f6e2cdc7726cf1dd6" category="paragraph">También debe consultar<block ref="3a8301f60ad04eb873ae8dea15ee0495" category="inline-link-rx"></block>.</block>
  <block id="38910d3dab2318849fd5f1a1dfbe0152" category="inline-link">Guía de compatibilidad de almacenamiento de VMware</block>
  <block id="eab65c9bc6c74eff9aee0d7f0c44276d" category="paragraph">VSphere Metro Storage Cluster (VMSC) es una configuración certificada que protege las máquinas virtuales (VM) y los contenedores frente a fallos. Esto se logra mediante el uso de conceptos de almacenamiento extendidos junto con clústeres de hosts ESXi, que se distribuyen en diferentes dominios de fallo, como bastidores, edificios, campus o incluso ciudades. Las tecnologías de almacenamiento de sincronización activa de NetApp MetroCluster y SnapMirror se usan para proporcionar una protección con un objetivo de punto de recuperación=0 o cerca del objetivo de punto de recuperación=0 respectivamente en los clústeres de hosts. La configuración de VMSC está diseñada para garantizar que los datos estén siempre disponibles incluso en caso de que falle un «sitio» completo, físico o lógico. Un dispositivo de almacenamiento que forme parte de la configuración de VMSC debe estar certificado tras someterse a un proceso de certificación VMSC exitoso. Todos los dispositivos de almacenamiento admitidos se pueden encontrar en la<block ref="293ceee3268d7991d7fe245e02c1c5c9" category="inline-link-rx"></block>.</block>
  <block id="838b66b875df1b432ac420a98cba3db6" category="paragraph">Si desea obtener más información sobre las directrices de diseño para vSphere Metro Storage Cluster, consulte la siguiente documentación:</block>
  <block id="07aaf2aebfd07b8763284018d1ebbf57" category="inline-link">Compatibilidad de VMware vSphere con NetApp MetroCluster</block>
  <block id="a4a5fd5b00daf98bd381d80257378acd" category="list-text"><block ref="a4a5fd5b00daf98bd381d80257378acd" category="inline-link-rx"></block></block>
  <block id="c3dc11e39d996a00b095022f4e56583d" category="inline-link">Compatibilidad de VMware vSphere con Continuidad del negocio de SnapMirror de NetApp</block>
  <block id="8f675397d9c0ef95aa8b3f0ada9d601a" category="list-text"><block ref="f53214cfd764fa0267c92323be0d7337" category="inline-link-rx"></block> (Ahora conocido como SnapMirror active sync)</block>
  <block id="ee0a206d2287c89b2a7b780e07929b81" category="paragraph">Según las consideraciones de latencia, NetApp MetroCluster puede ponerse en marcha en dos configuraciones diferentes para utilizarlas con vSphere:</block>
  <block id="b553530def78406c0977f70d5e90b9e8" category="list-text">Stretch MetroCluster</block>
  <block id="2d90abe978ed8084d304295ad0a8c8fd" category="list-text">Fabric MetroCluster</block>
  <block id="b03023e82bda6a71adc49c4834e3b6ab" category="paragraph">A continuación se muestra un diagrama topológico de alto nivel de MetroCluster de ampliación.</block>
  <block id="b0c20dc8226bb49f35f0f68f7ef77bba" category="image-alt">Diagrama VMSC con MCC</block>
  <block id="119be031ef4485d20c7683d291d0e9f6" category="inline-link">Documentación de MetroCluster</block>
  <block id="ad9122c6d75ebaa024669fde1c0bdfb8" category="paragraph">Consulte<block ref="d8a206747dbcec13122724b2aee18957" category="inline-link-rx"></block> Para obtener información específica sobre diseño e implementación para MetroCluster.</block>
  <block id="b47354fcd7d17ab4fbb3283f71677efe" category="paragraph">SnapMirror Active Sync también se puede poner en marcha de dos formas distintas.</block>
  <block id="314084a577b998d8089dff72c98c58b0" category="list-text">Asimétrico</block>
  <block id="40e2e641bad11918585c3dd4f76c2716" category="list-text">Simétrico (vista previa privada en ONTAP 9.14.1)</block>
  <block id="b9ca5ba97cf75d3dafb51f78e073770a" category="inline-link">Documentos de NetApp</block>
  <block id="1c71125ba0668792e46d93c17dc6c428" category="paragraph">Consulte<block ref="9ace5d3ebe2fe57037322de54ac9a869" category="inline-link-rx"></block> Para obtener información específica de diseño e puesta en marcha para SnapMirror, sincronización activa.</block>
  <block id="bca8b52c503406abc3e9e50c5352d0a2" category="paragraph">Este documento presenta la solución ONTAP para VMware Site Recovery Manager (SRM), el software de recuperación ante desastres (DR) líder en el sector de VMware, que incluye la información de producto más reciente y las mejores prácticas para simplificar la puesta en marcha, reducir el riesgo y simplificar la gestión continua.</block>
  <block id="4f46fffb0ac7017fd2b42c10d6aa03fc" category="paragraph">Realizar backups de sus máquinas virtuales y recuperarlos rápidamente se encuentran entre los grandes puntos fuertes de ONTAP para vSphere, y es fácil gestionar esta capacidad dentro de vCenter con el plugin de SnapCenter para VMware vSphere.</block>
  <block id="b69cd5a82aaf0c524a71d46ec6fdd29c" category="cell">La conexión de enlaces de sesión NFS v4,1 requiere ONTAP 9.14.1 y posterior</block>
  <block id="80303385ad0f7147caa1af6d2162852b" category="paragraph">El complemento también es la interfaz de gestión para muchas funciones del proveedor VASA para ONTAP, que admite la gestión basada en políticas de almacenamiento con vVols. Una vez registradas las herramientas de ONTAP para VMware vSphere, utilícelo para crear perfiles de funcionalidad de almacenamiento, asignarlas al almacenamiento y garantizar el cumplimiento de los perfiles por parte del almacén de datos con el tiempo. El proveedor de VASA también proporciona una interfaz para crear y gestionar almacenes de datos de VVol.</block>
  <block id="d9c9eb44a58ee1ce90daa68527aa8930" category="summary">Escenarios de fallo para VMSC con MCC</block>
  <block id="e7c7574b0826c9074f480de76c889ba8" category="paragraph">En las siguientes secciones se resumen los resultados esperados de varios escenarios de fallo con sistemas VMSC y NetApp MetroCluster.</block>
  <block id="c8a2eebb480fef69e6ed917ea7f7a9d3" category="section-title">Fallo de ruta de almacenamiento única</block>
  <block id="b99e8e694b032f593bbd01f6205b4a98" category="paragraph">En esta situación, si se produce un error en componentes como el puerto HBA, el puerto de red, el puerto del switch de datos de interfaz de usuario o un cable FC o Ethernet, esa ruta particular al dispositivo de almacenamiento se marca como muerta por el host ESXi. Si se configuran varias rutas para el dispositivo de almacenamiento proporcionando resiliencia en el puerto de HBA/red/switch, ESXi idealmente ejecuta una conmutación de rutas. Durante este periodo, las máquinas virtuales permanecen en ejecución sin que se vean afectadas, porque se cuida de la disponibilidad del almacenamiento mediante varias rutas al dispositivo de almacenamiento.</block>
  <block id="1fff6650ef9c430da0f875c203d5dab0" category="paragraph">*Nota:* No hay cambios en el comportamiento de MetroCluster en este escenario, y todos los almacenes de datos siguen intactos desde sus respectivos sitios.</block>
  <block id="80fc15dd1deb985234440745e8a78d4c" category="paragraph">En entornos en los que se utilizan volúmenes NFS/iSCSI, NetApp recomienda tener al menos dos vínculos superiores de red configurados para el puerto NFS vmkernel en el vSwitch estándar y lo mismo en el grupo de puertos en el que se asigna la interfaz de NFS vmkernel para el vSwitch distribuido. La agrupación de NIC se puede configurar en activo-activo o activo-en espera.</block>
  <block id="0c8694e8ef7f8935edbfac605753bc95" category="paragraph">Además, para las LUN iSCSI, la multivía debe configurarse vinculando las interfaces de vmkernel con los adaptadores de red iSCSI. Si quiere más información, consulte la documentación de almacenamiento de vSphere.</block>
  <block id="0fc808fdb968eb089fbc5124c0a8e15a" category="paragraph">En entornos en los que se usan LUN de Fibre Channel, NetApp recomienda tener al menos dos HBA, lo que garantiza la resistencia a nivel de HBA/puerto. NetApp también recomienda la división en zonas de un solo iniciador a un único destino como práctica recomendada para configurar la división en zonas.</block>
  <block id="238c3d1c7bf8b5b42237392383a4c7ab" category="paragraph">Debe utilizarse Virtual Storage Console (VSC) para establecer normativas de accesos múltiples, porque establece normativas para todos los dispositivos de almacenamiento de NetApp nuevos y existentes.</block>
  <block id="217811709dfb096c78e73934de01271c" category="section-title">Fallo de un host ESXi único</block>
  <block id="93bc89a0478478dd84d8159a18f6c1a2" category="image-alt">Un fallo de host único.</block>
  <block id="15023af3b440b4004f509e961bfe1e30" category="paragraph">En esta situación, si hay un fallo de host ESXi, el nodo maestro del clúster de alta disponibilidad de VMware detecta el fallo del host porque ya no recibe los latidos de red. Para determinar si el host está realmente inactivo o sólo una partición de red, el nodo maestro supervisa los latidos del almacén de datos y, si están ausentes, realiza una comprobación final haciendo ping en las direcciones IP de gestión del host fallido. Si todas estas comprobaciones son negativas, el nodo maestro declara a este host un host fallido y todas las máquinas virtuales que se estaban ejecutando en este host fallido se reinician en el host superviviente del cluster.</block>
  <block id="9a11158d52f71012ae8722b09bf8bf29" category="paragraph">Si se han configurado las reglas de afinidad de host y VM de DRS (las VM del grupo de VM sitea_vms deben ejecutar hosts en el grupo de hosts sitea_Hosts), el maestro de HA primero comprueba los recursos disponibles en el sitio A. Si no hay hosts disponibles en el sitio A, el maestro intenta reiniciar las máquinas virtuales en los hosts del sitio B.</block>
  <block id="7922c92ff860eb0508dc8cc8aae3ffdd" category="paragraph">Es posible que las máquinas virtuales se inicien en los hosts ESXi en el otro sitio si hay una restricción de recursos en el sitio local. Sin embargo, las reglas de afinidad de host y máquina virtual de DRS definidas corregirán si se viola alguna regla migrando las máquinas virtuales de nuevo a cualquier host ESXi sobreviviente en el sitio local. En los casos en que DRS se defina en manual, NetApp recomienda invocar DRS y aplicar las recomendaciones para corregir la ubicación de la máquina virtual.</block>
  <block id="387b5a49326be3a47e081682e75e19b4" category="paragraph">No hay ningún cambio en el comportamiento de MetroCluster en este escenario y todos los almacenes de datos siguen estando intactos en sus sitios respectivos.</block>
  <block id="a11ffa7d20dab792fe5aa9c27017493e" category="section-title">Aislamiento de hosts ESXi</block>
  <block id="17e01652089acd413e26ea89cf98a2b8" category="image-alt">Aislamiento de hosts ESXi</block>
  <block id="8a4b746274e9d7129602d54434624806" category="paragraph">En esta situación, si la red de gestión del host ESXi está inactiva, el nodo principal del clúster de alta disponibilidad no recibirá ningún latido y, por lo tanto, este host se aísla en la red. Para determinar si ha fallado o solo está aislado, el nodo maestro comienza a supervisar el latido del almacén de datos. Si está presente, el nodo maestro declara que el host está aislado. Dependiendo de la respuesta de aislamiento configurada, el host puede optar por apagarse, apagar las máquinas virtuales o incluso dejar encendidas las máquinas virtuales. El intervalo predeterminado para la respuesta de aislamiento es de 30 segundos.</block>
  <block id="a070f7923919fed39772c5d3f91bf482" category="section-title">Fallo de la bandeja de discos</block>
  <block id="e8acf0e4f25cdd641c9a047482d56ba5" category="paragraph">En esta situación, se produce un fallo de más de dos discos o una bandeja entera. Los datos se sirven desde el plex superviviente sin interrupción de los servicios de datos. El fallo del disco puede afectar a un plex local o remoto. Los agregados se mostrarán como degradado porque solo está activo un plex. Una vez sustituidos los discos que han fallado, los agregados afectados se sincronizarán automáticamente para volver a compilar los datos. Tras realizar la resincronización, los agregados volverán automáticamente al modo reflejado normal. Si ha fallado más de dos discos dentro de un mismo grupo RAID, es necesario reconstruir el plex desde cero.</block>
  <block id="4f90d34a41c7ebc83024a5e3ca35ff3a" category="image-alt">Fallo de una bandeja de discos única.</block>
  <block id="8af0b36d49baf198133a234e76b06445" category="paragraph">*Nota:* Durante este período, no hay impacto en las operaciones de E/S de la máquina virtual, pero hay un rendimiento degradado porque se accede a los datos desde la bandeja de discos remotos a través de enlaces ISL.</block>
  <block id="1c872dcd4bcebb1d7567f383901dfc0d" category="section-title">Fallo de una controladora de almacenamiento única</block>
  <block id="68badb604dbd29653979fdc7083cbffe" category="paragraph">En este escenario, una de las dos controladoras de almacenamiento falla en un sitio. Dado que hay un par de alta disponibilidad en cada sitio, el fallo de un nodo de forma transparente activa automáticamente la conmutación al otro nodo. Por ejemplo, si falla el nodo A1, su almacenamiento y sus cargas de trabajo se transfieren automáticamente al nodo A2. Las máquinas virtuales no se verán afectadas porque todos los plexes permanecen disponibles. Los nodos del segundo sitio (B1 y B2) no se ven afectados. Además, vSphere HA no realizará ninguna acción porque el nodo principal del clúster seguirá recibiendo los latidos de red.</block>
  <block id="0ac25682ea568511724f2e0819127d89" category="image-alt">Fallo de un nodo único</block>
  <block id="e7b4c0523308b3fd46189b6ab4867fe5" category="paragraph">Si la conmutación al respaldo forma parte de un desastre gradual (el nodo A1 conmuta al nodo A2) y hay un fallo posterior de A2 o el fallo completo del sitio A, el cambio tras un desastre puede ocurrir en el sitio B.</block>
  <block id="7b590b52d9f3d4d40cda67758ff92ba1" category="section-title">Fallos de enlace de interinterruptor</block>
  <block id="9df08f82abe35d87c6f7c96b18dab755" category="section-title">Fallo de enlace de interswitch en la red de gestión</block>
  <block id="ed0711cbc7a050952e0e370bab079bff" category="image-alt">Fallo de enlace entre switches en la red de gestión</block>
  <block id="a32c6c77bb8d407cf5825aec175bab4b" category="paragraph">En este escenario, si los enlaces ISL en la red de gestión de host de interfaz de usuario producen un error, los hosts ESXi del sitio A no podrán comunicarse con los hosts ESXi del sitio B. Esto dará lugar a una partición de red porque los hosts ESXi de un sitio concreto no podrán enviar los latidos de red al nodo maestro del clúster HA. Como tal, habrá dos segmentos de red debido a la partición y habrá un nodo maestro en cada segmento que protegerá las VM de fallos de host dentro del sitio en particular.</block>
  <block id="36974534f1a2014a3e7e229d795ef51b" category="paragraph">*Nota:* Durante este período, las máquinas virtuales permanecen en ejecución y no hay cambios en el comportamiento de MetroCluster en este escenario. Todos los almacenes de datos siguen estando intactos en sus respectivos sitios.</block>
  <block id="628309883a8d1307131d205b200c56ae" category="section-title">Fallo de enlace interswitch en la red de almacenamiento</block>
  <block id="a9da7e2a43bcea673a22b949355e619d" category="image-alt">Fallo de enlace interswitch en la red de almacenamiento</block>
  <block id="625db96c5ee1e9b5197b6cb3c1715021" category="paragraph">En este escenario, si los enlaces ISL en la red de almacenamiento de back-end fallan, los hosts del sitio A perderán acceso a los volúmenes de almacenamiento o las LUN del clúster B en el sitio B y viceversa. Las reglas de VMware DRS se definen de modo que la afinidad de sitios de almacenamiento host facilita que los equipos virtuales funcionen sin que el sitio se vea afectado.</block>
  <block id="8d9609f32cbee8fa5080f95d71a2a142" category="paragraph">Durante este período, las máquinas virtuales permanecen en ejecución en sus respectivos sitios y no hay cambios en el comportamiento de MetroCluster en este escenario. Todos los almacenes de datos siguen estando intactos en sus respectivos sitios.</block>
  <block id="719831bfdda20be14c04e2b165cce85e" category="paragraph">Si por algún motivo se violó la regla de afinidad (por ejemplo, VM1, que se suponía que se ejecutaba desde la ubicación A donde sus discos residen en nodos del clúster local A, se está ejecutando en un host del sitio B), se accederá al disco de la máquina virtual de forma remota a través de enlaces ISL. Debido a un fallo de enlace ISL, VM1 ejecutándose en la instalación B no podría escribir en sus discos porque las rutas al volumen de almacenamiento están inactivas y la máquina virtual determinada está inactiva. En estos casos, VMware HA no realiza ninguna acción puesto que los hosts envían latidos de forma activa. Esas máquinas virtuales deben apagarse y encenderse manualmente en sus respectivos sitios. La siguiente figura ilustra una VM que viola una regla de afinidad DRS.</block>
  <block id="09ba89b1ea49214c15fbf8ea6f129cb0" category="image-alt">Una máquina virtual que infringe una regla de afinidad de DRS no puede escribir en los discos después de un fallo de ISL</block>
  <block id="49f26967af2ad76cacf7888cbeeb0590" category="section-title">Todos los fallos de interswitch o la partición completa del centro de datos</block>
  <block id="bc331d84348670dff6731555166fa378" category="paragraph">En este escenario, todos los enlaces ISL entre los sitios están inactivos y los dos sitios están aislados uno de otro. Como se explicó en escenarios anteriores, como el fallo ISL en la red de gestión y en la red de almacenamiento, las máquinas virtuales no se ven afectadas por un fallo de ISL completo.</block>
  <block id="a40e8cf2a5b5b1e22fec9f26cce85b9d" category="paragraph">Una vez que los hosts ESXi hayan particionado entre sitios, el agente de alta disponibilidad de vSphere comprobará si hay latidos del almacén de datos y, en cada sitio, los hosts ESXi locales podrán actualizar los latidos del almacén de datos a sus respectivos volúmenes/LUN de lectura/escritura. Los hosts del sitio A asumirán que los otros hosts ESXi del sitio B han fallado porque no hay latidos de red/almacén de datos. La alta disponibilidad de vSphere en el sitio A intentará reiniciar las máquinas virtuales del sitio B, lo cual fallará en algún momento porque no se podrá acceder a los almacenes de datos del sitio B debido a un fallo del ISL de almacenamiento. Una situación similar se repite en el sitio B.</block>
  <block id="3543d47d1f3a8dc6989a32f62ce3ea77" category="image-alt">Todos los fallos de ISL o la partición completa del centro de datos</block>
  <block id="3a096ef571101010add81b37081d3276" category="paragraph">NetApp recomienda determinar si alguna máquina virtual ha infringido las reglas de DRS. Los equipos virtuales que se ejecuten desde un sitio remoto estarán inactivos ya que no podrán acceder al almacén de datos y vSphere HA reiniciará esa máquina virtual en el sitio local. Una vez que los enlaces ISL vuelvan a estar en línea, la máquina virtual que se estaba ejecutando en el sitio remoto se desactivará, ya que no puede haber dos instancias de máquinas virtuales ejecutándose con las mismas direcciones MAC.</block>
  <block id="87e9384cb464ff9a4ce385fc59a178a2" category="image-alt">Una partición del centro de datos donde VM1 violó una regla de afinidad DRS</block>
  <block id="0951e388ebea20c49e71af25ef84947d" category="section-title">Fallo de interswitch Link en ambas estructuras en NetApp MetroCluster</block>
  <block id="1e9be78885a356d1a2ec0ab0d4a4cecb" category="paragraph">En un escenario en el que uno o varios ISL fallan, el tráfico continúa por los enlaces restantes. Si todos los ISL de ambas estructuras fallan, de modo que no hay ningún enlace entre los sitios para el almacenamiento y la replicación de NVRAM, cada controladora seguirá proporcionando sus datos locales. Al restaurar un mínimo de un ISL, la resincronización de todos los complejos se realizará automáticamente.</block>
  <block id="715cbc6f6bcf5da6b73f10233847d3a1" category="paragraph">Las escrituras que se produzcan después de que todos los ISL estén inactivos no se reflejarán en el otro sitio. Una conmutación de sitios en caso de desastre, mientras la configuración se encuentra en este estado, por lo tanto, incurriría en la pérdida de los datos que no se habían sincronizado. En este caso, se requiere intervención manual para la recuperación después del cambio. Si es probable que no haya ISL disponibles durante un largo período de tiempo, un administrador puede optar por cerrar todos los servicios de datos para evitar el riesgo de pérdida de datos si es necesario una conmutación por desastre. La realización de esta acción debe evaluarse para la probabilidad de que se produzca un desastre que requiera la conmutación del servicio antes de que esté disponible al menos un ISL. Como alternativa, si los ISL fallan en un escenario en cascada, un administrador podría activar una conmutación de sitios planificada a uno de los sitios antes de que todos los enlaces hayan fallado.</block>
  <block id="89f375bfe8be0893bf175b89ce754b8e" category="image-alt">Fallo de enlace interswitch en ambas estructuras en NetApp MetroCluster.</block>
  <block id="bc813a6fdbbeebf4d230b7e33d8c3a76" category="section-title">Fallo de enlace de clúster con conexión entre iguales</block>
  <block id="1919456d1613248a128c65a84b235fe5" category="paragraph">En un supuesto de fallo de enlace de clústeres con conexión entre iguales, dado que los ISL de estructura aún están activos, los servicios de datos (lecturas y escrituras) continúan en ambos sitios en ambos complejos. No se puede propagar ningún cambio de configuración del clúster (por ejemplo, añadir una nueva SVM o aprovisionar un volumen o un LUN en una SVM existente) al otro sitio. Estos se mantienen en los volúmenes de metadatos de CRS locales y se propagan automáticamente al otro clúster al restaurar el enlace de clúster entre iguales. Si se necesita una conmutación por error forzada antes de poder restaurar el enlace de clúster entre iguales, se volverán a reproducir automáticamente los cambios pendientes de configuración de clúster desde la copia replicada remota de los volúmenes de metadatos del sitio superviviente como parte del proceso de conmutación por error.</block>
  <block id="77130a0b52e4379c6b6667cf7f8e155c" category="image-alt">Error de enlace de clústeres con conexión entre iguales</block>
  <block id="9dc32d7afddc9a265c5c2713db55fc70" category="section-title">Fallo completo del sitio</block>
  <block id="d0d6a03c382bc5412f1822e5c97d5142" category="paragraph">En un supuesto de fallo del sitio A completo, los hosts ESXi del sitio B no obtendrán el latido de red de los hosts ESXi del sitio A porque están inactivos. El maestro de alta disponibilidad en el sitio B verificará que los latidos del almacén de datos no están presentes, declarará que los hosts del sitio A han fallado e intentará reiniciar el sitio A de los equipos virtuales en el sitio B. Durante este periodo, el administrador de almacenamiento realiza una conmutación de sitios para reanudar los servicios de los nodos fallidos en el sitio superviviente. Esto restaura todos los servicios de almacenamiento del sitio A en el sitio B. Después de que el sitio haya volúmenes o LUN disponibles en el sitio B, el agente maestro de alta disponibilidad intentará reiniciar el sitio A, máquinas virtuales del sitio B.</block>
  <block id="23e5761401326cc21bcf9d108b9e3e7f" category="paragraph">Si el intento del agente maestro HA de vSphere de reiniciar una máquina virtual (lo que implica registrarla y encenderla) falla, el reinicio se vuelve a intentar después de un retraso. El retardo entre reinicios se puede configurar hasta un máximo de 30 minutos. VSphere HA intenta estos reinicios durante un número máximo de intentos (seis intentos de forma predeterminada).</block>
  <block id="641031c1f370e06434afd215f8610dae" category="paragraph">*Nota:* El maestro HA no inicia los intentos de reinicio hasta que el administrador de colocación encuentre el almacenamiento adecuado, por lo que en el caso de un fallo completo del sitio, eso sería después de que se haya realizado el cambio.</block>
  <block id="085a4a3eba6c30fa589bfee20eb0c294" category="paragraph">Si el sitio A se ha cambiado, un fallo posterior de uno de los nodos del sitio B superviviente se puede gestionar sin problemas mediante la conmutación al nodo superviviente. En este caso, solo un nodo realiza el trabajo de cuatro nodos. En este caso, la recuperación consistiría en realizar un retorno al nodo local. A continuación, cuando se restaura el sitio A, se realiza una operación de conmutación para restaurar el funcionamiento en estado constante de la configuración.</block>
  <block id="2b9b713afb0d80ef371a0b55e58366b6" category="image-alt">Fallo de sitio completo</block>
  <block id="e6364c2f5314a32cd95be04b4c2112e6" category="paragraph">Las siguientes secciones describen los procedimientos y las mejores prácticas para usar vVols de VMware con almacenamiento de ONTAP.</block>
  <block id="a9da618400fb93b20c20f5343efaefa7" category="sidebar">VMware vSphere Metro Storage Cluster con ONTAP</block>
  <block id="2f58fa882a22b5af5f0741f03abaf611" category="sidebar">Clúster de almacenamiento vSphere Metro con ONTAP</block>
  <block id="4a884da785a62e8b1758932191ff42de" category="paragraph">La virtualización de bases de datos con VMware, Oracle OLVM o KVM es una opción cada vez más común para los clientes de NetApp que eligieron la virtualización incluso para las bases de datos más importantes.</block>
  <block id="3a8ba1ff8824968961222d6b447b4973" category="section-title">Compatibilidad</block>
  <block id="3231d83af741101eb02b16e5d7a6dffc" category="paragraph">Existen muchos malentendidos acerca de las normativas de soporte de Oracle para la virtualización, especialmente para los productos VMware. No es raro escuchar que Oracle no admite la virtualización. Esta noción es incorrecta y conduce a la pérdida de oportunidades para beneficiarse de la virtualización. El ID de documento de Oracle 249212,1 analiza los requisitos reales y los clientes rara vez consideran que son una preocupación.</block>
  <block id="722bd611ee4f38780607b400c8a604c0" category="paragraph">Si se produce un problema en un servidor virtualizado y dicho problema es desconocido previamente para los Servicios de Soporte Oracle, es posible que se solicite al cliente que reproduzca el problema en el hardware físico. Es posible que un cliente de Oracle que ejecuta una versión de borde de sangrado de un producto no desee utilizar la virtualización debido a la posibilidad de problemas de compatibilidad, pero esta situación no ha sido un mundo real para los clientes de virtualización que utilizan versiones de productos de Oracle generalmente disponibles.</block>
  <block id="c8a4476ecddeda66dbd2c354c8fb2c6b" category="paragraph">Los clientes que están considerando la virtualización de sus bases de datos deben basar sus decisiones sobre almacenamiento en sus necesidades empresariales. Aunque esta es una afirmación generalmente verdadera para todas las decisiones DE TI, es especialmente importante para los proyectos de bases de datos, porque el tamaño y el alcance de los requisitos varían considerablemente.</block>
  <block id="835ce293f862d9fb74e50f4cf928c56d" category="paragraph">Existen tres opciones básicas para la presentación del almacenamiento:</block>
  <block id="327813abbc0ae1e9d3abe282303bf00c" category="list-text">LUN virtualizados en almacenes de datos de hipervisores</block>
  <block id="1a1af5efffda8c766ead9f73fc782e0e" category="list-text">Sistemas de archivos NFS montados por la máquina virtual (no desde un almacén de datos basado en NFS)</block>
  <block id="f9bf9489147891f7ee7ba15126a27fda" category="list-text">Asignaciones directas de dispositivos. Los clientes no se ven favorecidos por los RDM de VMware, pero los dispositivos físicos siguen siendo a menudo asignados de forma similar directamente con la virtualización de KVM y OLVM.</block>
  <block id="69b0ac6bf6ea8e1ab4e4fc896294da01" category="paragraph">El método de presentar almacenamiento a un invitado virtualizado no suele afectar al rendimiento. Todos los SO host, los controladores de red virtualizados y las implementaciones de almacenes de datos de hipervisor están muy optimizados y, por lo general, pueden consumir todo el ancho de banda de red FC o IP disponible entre el hipervisor y el sistema de almacenamiento, siempre que se sigan las prácticas recomendadas básicas. En algunos casos, obtener un rendimiento óptimo puede ser ligeramente más sencillo usando un método de presentación de almacenamiento en comparación con otro, pero el resultado final debería ser comparable.</block>
  <block id="a2e8fb5328f6558e3a119d8c224a1897" category="paragraph">El factor clave para decidir cómo presentar el almacenamiento a un invitado virtualizado es la capacidad de gestión. No hay un método correcto o incorrecto. El mejor enfoque depende de las necesidades operativas, las habilidades y las preferencias de TI.</block>
  <block id="e4919ac0a074fa1bba5303f596a5f591" category="paragraph">Los factores a considerar incluyen:</block>
  <block id="c422e10bbf04c180f4c47f81ed9a1f7a" category="list-text">*Transparencia.* Cuando una VM administra sus sistemas de archivos, es más fácil para un administrador de bases de datos o un administrador del sistema identificar el origen de los sistemas de archivos para sus datos. No se accede a los sistemas de archivos y LUN de manera diferente a con un servidor físico.</block>
  <block id="42de52ad09be3101fc535dea2aedce1d" category="list-text">*Consistencia.* Cuando una VM es propietaria de sus sistemas de archivos, el uso o no uso de una capa de hipervisor afecta a la capacidad de gestión. Los mismos procedimientos para aprovisionamiento, supervisión, protección de datos, etc. se pueden utilizar en todo el conjunto, incluidos los entornos virtualizados y no virtualizados.</block>
  <block id="0562446bc5eefe9a584e23ffb3061cbf" category="paragraph">Por otro lado, en un centro de datos virtualizado al 100% de lo contrario, puede que sea preferible también utilizar el almacenamiento basado en almacenes de datos en toda la huella en la misma razón mencionada anteriormente: Consistencia: La capacidad de usar los mismos procedimientos para aprovisionamiento, protección, montorización y protección de datos.</block>
  <block id="7269a37b557c66664c0377693f62ec8a" category="list-text">*Estabilidad y resolución de problemas.* Cuando una VM es propietaria de sus sistemas de archivos, ofrecer un rendimiento bueno y estable y solucionar problemas son más simples porque toda la pila de almacenamiento está presente en la VM. El único rol del hipervisor es transportar tramas FC o IP. Cuando se incluye un almacén de datos en una configuración, esto complica la configuración introduciendo otro conjunto de tiempos de espera, parámetros, archivos de registro y posibles errores.</block>
  <block id="c160b6d86853c20a432e2407b82866e6" category="list-text">* Bloqueo del proveedor.* Después de colocar los datos en un almacén de datos, usar un hipervisor diferente o extraer los datos del entorno virtualizado se vuelve completamente difícil.</block>
  <block id="a42abd01a1e0c89cfa2112dc09378967" category="list-text">*Activación de instantáneas.* Los procedimientos de respaldo tradicionales en un entorno virtualizado pueden convertirse en un problema debido al ancho de banda relativamente limitado. Por ejemplo, un tronco 10GbE de cuatro puertos podría ser suficiente para soportar las necesidades de rendimiento diarias de muchas bases de datos virtualizadas, pero tal tronco sería insuficiente para realizar copias de seguridad con RMAN u otros productos de copia de seguridad que requieran transmitir una copia de tamaño completo de los datos. El resultado es que un entorno virtualizado cada vez más consolidado debe realizar backups a través de snapshots de almacenamiento. Esto evita la necesidad de sobrecargar la configuración del hipervisor únicamente para admitir los requisitos de ancho de banda y CPU de la ventana de backup.</block>
  <block id="86c36175331b4a95c083fabdcca8b8a0" category="paragraph">El uso de sistemas de archivos propiedad de invitados a veces facilita el uso de backups y restauraciones basados en copias Snapshot, ya que los objetos de almacenamiento que necesitan protección pueden dirigirse con mayor facilidad. Sin embargo, cada vez es más grande la cantidad de productos de protección de datos de virtualización que se integran bien con los almacenes de datos y las copias Snapshot. La estrategia de backup debe consistir completamente antes de tomar una decisión sobre cómo presentar el almacenamiento a un host virtualizado.</block>
  <block id="8c19dda4c4cab5e52edf9463f196b97d" category="section-title">Segmentación de almacenes de datos</block>
  <block id="8fa77493c52e71f201ccdb67db26446d" category="paragraph">Cuando se usan bases de datos con almacenes de datos, hay un factor crucial que debe tenerse en cuenta con respecto al rendimiento: La segmentación.</block>
  <block id="53ab623a905e6ec84d908f0b99a8d1c8" category="paragraph">Las tecnologías de almacenes de datos como VMFS pueden abarcar varios LUN, pero no son dispositivos segmentados. Las LUN se concatenan. El resultado final pueden ser puntos de sobrecarga de la LUN. Por ejemplo, una base de datos de Oracle típica puede tener un grupo de discos ASM de 8 LUN. Se pueden aprovisionar los 8 LUN virtualizados en un almacén de datos VMFS de 8 LUN, pero no hay garantía de cuáles LUN residirán los datos. La configuración resultante podría ser todos los 8 LUN virtualizados que ocupen una única LUN dentro del almacén de datos VMFS. Esto se convierte en un cuello de botella en el rendimiento.</block>
  <block id="e6bb99e411f5495b03c1e0a4e75a1434" category="paragraph">La segmentación suele ser necesaria. Con algunos hipervisores, incluido KVM, es posible crear un almacén de datos con la segmentación de LVM, como se describe <block ref="dd0ff2598ebb26feb9ff73a59186b79f" category="inline-link-macro-rx"></block>. Con VMware, la arquitectura parece un poco diferente. Cada LUN virtualizado debe colocarse en un almacén de datos VMFS diferente.</block>
  <block id="506c2c0c7f5b70af3df68c45c46f45a7" category="paragraph">Por ejemplo:</block>
  <block id="6ec151851a31c86edd358bc49f80908c" category="paragraph"><block ref="6ec151851a31c86edd358bc49f80908c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70ff2667d6b190dea65bae42217aa310" category="paragraph">El impulsor principal de este enfoque no es ONTAP, sino que se debe a una limitación inherente al número de operaciones que una sola máquina virtual o LUN de hipervisor puede prestar servicio en paralelo. Por lo general, una sola LUN de ONTAP puede admitir muchas más IOPS de las que puede solicitar un host. El límite de rendimiento de una LUN es casi universal debido al SO del host. Como resultado, la mayoría de las bases de datos necesitan entre 4 y 8 LUN para satisfacer sus necesidades de rendimiento.</block>
  <block id="59f9d8d1b212a8ff6bd3476975e17620" category="paragraph">Las arquitecturas de VMware deben planificar sus arquitecturas con cuidado para asegurarse de que no se encuentren los máximos de almacén de datos o ruta de LUN con este enfoque. Además, no es necesario disponer de un conjunto único de almacenes de datos VMFS para cada base de datos. La principal necesidad es asegurarse de que cada host tenga un conjunto limpio de 4-8 rutas de I/O desde las LUN virtualizadas hasta las LUN de back-end del sistema de almacenamiento propiamente dicho. En raras ocasiones, incluso más almacenes de datos pueden ser útiles para las demandas de rendimiento realmente extremas, pero 4-8 LUN suelen ser suficientes para el 95% de todas las bases de datos. Un solo volumen ONTAP que contiene 8 LUN puede admitir hasta 250.000 IOPS de bloques de Oracle aleatorias con una configuración típica de SO/ONTAP/red.</block>
  <block id="7564f732469e12963d8b416572cf4efb" category="section-title">¿Qué es vSphere Metro Storage Cluster?</block>
  <block id="830d984ea50f71fa76636d0524167a3a" category="doc">Información general sobre las funciones de protocolo y almacenes de datos de vSphere</block>
  <block id="1d1d9d816e63b6c7d3057732579e8889" category="list-text">Si se utiliza el plugin de NetApp NFS para VMware VAAI, se debe establecer el protocolo como<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> en lugar de<block ref="61a52f7a75745796f63ec9e3ea2547b4" prefix=" " category="inline-code"></block> cuando se crea o se modifica la regla de política de exportación. La función de copia de descarga de VAAI requiere que funcione el protocolo NFSv4, aunque el protocolo de datos sea de NFSv3 GbE. Especificando el protocolo como<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> Incluye versiones NFSv3 y NFSv4.</block>
  <block id="cc0f7f705e4495c607aea288505e31bf" category="sidebar">Información general de VMSC</block>
  <block id="de9a829f775bc333b77fdacbc333f7a1" category="sidebar">Solución de alta disponibilidad de vSphere</block>
  <block id="70b29c8dabeb7a16884003c35e163f96" category="sidebar">Diseño de VMSC</block>
  <block id="6c4755219197ce467bf892a552c8663a" category="sidebar">Resiliencia de VMSC</block>
  <block id="13376e3e9b02a56731aa64aeb10947b2" category="sidebar">Escenarios VMSC con MCC</block>
  <block id="7f38ad8ab5454e76108c14e424240237" category="doc">Configuración de FC para bases de datos de Oracle</block>
  <block id="f0a36f02b824ef55cbd63aa2700a4ec9" category="summary">Backups y recuperación de las bases de datos de Oracle basados en snapshots</block>
  <block id="77243afc69ab08d8277d0e23dda813d9" category="doc">Backups en línea de bases de datos de Oracle</block>
  <block id="4ac7e99e454283880f5bdf93e9d59eb9" category="summary">Organización en niveles de FabricPool de archivos completos en bases de datos de Oracle</block>
  <block id="3dd6786160916127fc2f6fc2ec955bbe" category="summary">Utilidad de reclamación de ASM con detección de bloques cero de ONTAP</block>
  <block id="bd2f93a60ac38752d2c10a0bdbc6ea07" category="doc">Utilidad de Reclamación de ASM y detección de bloques cero de ONTAP</block>
  <block id="89c60635365825dfa13d154785577592" category="summary">Configuración de Oracle y TCP/IP y ethernet</block>
  <block id="aaa024a70ffabce1e14fdc1a4b17fe8d" category="doc">Configuración TCP/IP y ethernet para bases de datos Oracle</block>
  <block id="665de76ea0059ac13982f04e19e74216" category="summary">Bases de datos de Oracle con Microsoft Windows</block>
  <block id="0d4fbbc8820271a0ce5d46a15e7bf90f" category="paragraph">Temas de configuración de bases de datos de Oracle en Microsoft Windows con ONTAP.</block>
  <block id="422956aac4f76239935ded6a492144f2" category="summary">ONTAP está diseñado para bases de datos de Oracle. Descubra cómo.</block>
  <block id="795da6575a33e265d7d9a5774cd10e6f" category="summary">Backups de grupos de coherencia para bases de datos de Oracle en ONTAP</block>
  <block id="33c729820ffa60f55745fa3c259e273c" category="doc">Backups de grupos de coherencia de base de datos de Oracle</block>
  <block id="56abf0735f338713ce53e8cdecd6994e" category="paragraph">Para realizar el backup más sencillo posible, sólo coloque toda la base de datos de Oracle en un único volumen ONTAP</block>
  <block id="190d2bad1c6e231bc18c33e002e663c7" category="summary">Base de datos Oracle y conectividad ONTAP de conexión directa</block>
  <block id="0953588ff4980e20b797cd3bb6d1260f" category="summary">Conmutación al nodo de respaldo de bases de datos de Oracle con MetroCluster</block>
  <block id="4a3f422632f7d08bf0e6c05affea24e4" category="summary">Bases de datos de Oracle con SyncMirror</block>
  <block id="5bbdf1e19bb3f7b70de51a3764fc5f19" category="doc">Backups optimizados de Snapshot de almacenamiento de bases de datos de Oracle</block>
  <block id="a962af081661ee46d4ef879de33c841e" category="paragraph">Cuando se lanzó Oracle 12c, ya que no es necesario colocar una base de datos en modo de backup dinámico, se simplificaron aún más las tareas de backup y recuperación basadas en Snapshots. El resultado es la capacidad de programar backups basados en snapshots directamente en un sistema de almacenamiento y mantener la capacidad para realizar una recuperación completa o de un momento específico.</block>
  <block id="fdf9dde4dc297fff7ac7b3c1458b0dad" category="doc">Segmentación de LVM con bases de datos de Oracle</block>
  <block id="d3c8171a7167ce43c547aac8fdd86cfb" category="doc">Migración de archivos de datos de Oracle</block>
  <block id="9718528cb14225785c79e3afc4152efc" category="doc">Ajuste del tamaño de LUN y número de LUN de la base de datos de Oracle</block>
  <block id="cc04f79220a102bde5449a7c301b1a86" category="summary">Conmutación por error en la base de datos de Oracle con sincronización activa de SnapMirror</block>
  <block id="965468e7c31a9b37ffa82836603c784c" category="paragraph">El principal motivo para alojar una base de datos Oracle en una sincronización activa de SnapMirror es proporcionar conmutación por error transparente durante eventos de almacenamiento planificados y no planificados.</block>
  <block id="ea7df930bd6bec6222e23d2b3af02a50" category="paragraph">SnapMirror Active Sync admite dos tipos de operaciones de conmutación por error de almacenamiento: Planificadas y no planificadas, que funcionan de formas ligeramente diferentes. El administrador inicia manualmente una conmutación al respaldo planificada para una rápida conmutación a un sitio remoto, mientras que el mediador inicia automáticamente la conmutación al respaldo no planificada en el tercer sitio. El objetivo principal de una conmutación por error planificada es realizar actualizaciones y revisiones incrementales, realizar pruebas de recuperación ante desastres o adoptar una política formal de operaciones de conmutación entre sitios durante todo el año para demostrar su capacidad de sincronización activa completa.</block>
  <block id="f7c8b0ba16967990d91c2ca78d655eaa" category="paragraph">Los diagramas muestran lo que sucede durante las operaciones normales, de conmutación por error y de conmutación tras recuperación. Para facilitar la ilustración, representan una LUN replicada. En una configuración de sincronización activa de SnapMirror real, la replicación se basa en volúmenes, donde cada volumen contiene uno o varios LUN; pero, para simplificar la imagen, se ha eliminado la capa del volumen.</block>
  <block id="cfa86460b638615878bbee89b1b6d4c7" category="paragraph">La línea verde es una ruta activa, pero supondría más latencia, ya que el I/O de esa ruta debería transmitirse a través de la ruta de sincronización activa de SnapMirror. La latencia adicional dependería de la velocidad de la interconexión entre los sitios que se usa para la sincronización activa de SnapMirror.</block>
  <block id="175d350addf4717d454787f950938adf" category="paragraph"><block ref="175d350addf4717d454787f950938adf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="033e21b9b80fa06986d25123f3025db5" category="paragraph"><block ref="033e21b9b80fa06986d25123f3025db5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4d4f8b4d1153d0a9894be19e1f52e4e" category="paragraph"><block ref="f4d4f8b4d1153d0a9894be19e1f52e4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22ea45ef5d49a1b807d571799d80613d" category="paragraph">Una vez que el sistema de origen vuelve al servicio, SnapMirror Active Sync puede volver a sincronizar la replicación pero en dirección contraria. La configuración ahora es esencialmente la misma que el punto de partida, excepto que se han invertido los sitios de reflejo activo.</block>
  <block id="3dd37fdc28ae50bae909f461c8eae979" category="paragraph"><block ref="3dd37fdc28ae50bae909f461c8eae979" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2702e101c97ce9a58738b1a4089319df" category="summary">Arquitectura lógica de MetroCluster y bases de datos de Oracle</block>
  <block id="784fdd6bf0ebb9c00eaefafc3f9a9cee" category="doc">Bases de datos RAID y Oracle</block>
  <block id="204d288bf0e9d1ee9912d68d6282d7a9" category="summary">Bases de datos de Oracle con AIX</block>
  <block id="90b3697759466f587c318ce55df76258" category="doc">Bases de datos de Oracle con IBM AIX</block>
  <block id="14ab10a24aa8f6c18bfdfd0d8a394dcb" category="paragraph">Temas de configuración para bases de datos de Oracle en IBM AIX con ONTAP.</block>
  <block id="b67d277a8a8f29f7b869c9bdbff5fcd1" category="summary">Bases de datos de Oracle y políticas de recuperación de FabricPool</block>
  <block id="2e34d4efdcf01f27eb9407a010ca1621" category="summary">Migración de Oracle con FLI: Transición</block>
  <block id="c5753b0ef1dfc2c724f24235a689d1ab" category="summary">Políticas de organización en niveles de FabricPool de bases de datos de Oracle</block>
  <block id="57d15767e9302dbb67058ed0bd9eebac" category="doc">Bases de datos de Oracle y NVFAIL</block>
  <block id="4f03272fa32b53344924740fd30fc52d" category="summary">Bases de datos Oracle con Solaris</block>
  <block id="91b10dcdb3d328fd4cbcf83d1ad8332e" category="summary">Bases de datos de Oracle de instancia única con sincronización activa de SnapMirror</block>
  <block id="eddade472f3875eca5684dbc91b70ee5" category="paragraph"><block ref="eddade472f3875eca5684dbc91b70ee5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="206960915d76763c590449d5ef03639a" category="summary">Bases de datos de Oracle en ONTAP y la función de instantáneas</block>
  <block id="4bc550014af4fefad8f4cc8f0827c4b5" category="doc">Bases de datos de Oracle y backups basados en snapshots</block>
  <block id="cf5bc9d838fb937caa7978b4a9b0f98a" category="paragraph">La base de la protección de datos de bases de datos de Oracle en ONTAP es la tecnología Snapshot de NetApp.</block>
  <block id="ba5a23e78f51c1bcb1b82efbe1797502" category="summary">Parámetros de la base de datos Oracle: Db_file_multiblock_read_count</block>
  <block id="085e756798c73ce14f874c6f323311dc" category="doc">Parámetros de la base de datos Oracle: db_FILE_MULBLOCK_READ_COUNT</block>
  <block id="ea84db84607112a0d40fca3ff45dfffa" category="summary">Gestión del rendimiento de bases de datos de Oracle con calidad de servicio de ONTAP</block>
  <block id="0af83eb081b1a831789867d7f0867610" category="summary">Herramientas de automatización y gestión de bases de datos de Oracle</block>
  <block id="7c58d5a62a9c29d2a846b210deea95f2" category="paragraph">El valor principal de ONTAP en un entorno de bases de datos de Oracle proviene de las tecnologías principales de ONTAP, como las copias Snapshot instantáneas, la replicación simple de SnapMirror y la creación eficiente de los volúmenes FlexClone.</block>
  <block id="64e5bd65ef1bbae4e5cbcc7405087f5a" category="summary">Oracle RAC con sincronización activa de SnapMirror</block>
  <block id="cf5f83a34537791646d1c495844a0ca7" category="paragraph">La sincronización activa de SnapMirror ofrece un control granular sobre la replicación de conjuntos de datos para fines como el equilibrio de carga o la recuperación tras fallos de aplicaciones individuales. La arquitectura general parece un cluster RAC ampliado, pero algunas bases de datos están dedicadas a sitios específicos y la carga general se distribuye.</block>
  <block id="ef3f19fdb50e0ad5fa58f9f8dc6eb361" category="paragraph">Además de la granularidad, los principios y opciones básicos para Oracle RAC con SnapMirror active syncare igual que <block ref="f7453402f1e4779ea0ec67d873358932" category="inline-link-macro-rx"></block></block>
  <block id="591b3149d6cb247a04883c411dab3e24" category="summary">Sumas de comprobación e integridad de la base de datos de Oracle</block>
  <block id="56f014c6fc8fac3e242c9d2e42c654c0" category="paragraph">ONTAP y sus protocolos admitidos incluyen varias funciones que protegen la integridad de las bases de datos de Oracle, incluidos los datos en reposo y la transmisión de datos a través de la red.</block>
  <block id="31b3368edcb737b712ee02926409c837" category="doc">Bases de datos de Oracle, MetroCluster y NVFAIL</block>
  <block id="490e2f530e53cf85f8ce9b052a8336ec" category="paragraph">NVFAIL es una función general de integridad de los datos en ONTAP que se ha diseñado para maximizar la protección de la integridad de los datos con las bases de datos.</block>
  <block id="f2cf6b943d224a732c92223538580ee9" category="doc">Instancia única de Oracle en MetroCluster</block>
  <block id="4a8b1598ce3e861debc907a154c550bb" category="summary">Bases de datos de Oracle con sincronización activa de SnapMirror</block>
  <block id="2c0931d05d138f5ed298de6301f8b914" category="paragraph">La sincronización activa de SnapMirror permite un mirroring síncrono selectivo RPO=0 para bases de datos de Oracle y entornos de aplicaciones individuales.</block>
  <block id="23ac407fd735aa143b377c5ce899450a" category="paragraph">La sincronización activa de SnapMirror es básicamente una función de SnapMirror mejorada para SAN que permite a los hosts acceder a un LUN tanto desde el sistema donde se aloja el LUN como desde el sistema que aloja su réplica.</block>
  <block id="b3bb502fe4549a90a1e8172726d68f50" category="paragraph">SnapMirror Active Sync y SnapMirror Sync comparten un motor de replicación; sin embargo, SnapMirror Active Sync incluye funciones adicionales como conmutación por error de aplicaciones transparente y conmutación de retorno tras recuperación para aplicaciones empresariales.</block>
  <block id="e1ffc166cd6595b5b47f9c72a57357ed" category="paragraph">La relación de sincronización activa de SnapMirror está entre una pareja de SVM ubicadas en diferentes clústeres. Ambas SVM pueden servir datos, pero ALUA utilizará preferentemente la SVM que actualmente tiene la propiedad de las unidades donde residen los LUN. El I/O a la SVM remota se proxy mediante la interconexión de sincronización activa de SnapMirror.</block>
  <block id="a6c7f963d0151b1e80b754596853d273" category="paragraph">En condiciones de funcionamiento normal, la copia remota es una réplica síncrona RPO=0 en todo momento, con una excepción. Si los datos no se pueden replicar, con la sincronización activa de SnapMirror liberará el requisito de replicar datos y reanudar el servicio de I/O. Los clientes que consideran la pérdida del enlace de replicación casi al desastre o que no desean que las operaciones empresariales se detengan cuando los datos no se pueden replicar prefieren esta opción.</block>
  <block id="ea1d91c32fcf0f4a1090fd0da341c014" category="paragraph">Al contrario que otras soluciones de recuperación ante desastres del almacenamiento, SnapMirror Active Sync ofrece una flexibilidad de plataforma asimétrica. No es necesario que el hardware de cada sitio sea idéntico. Esta funcionalidad permite ajustar el tamaño adecuado del hardware que se utiliza para dar soporte a SnapMirror de sincronización activa. El sistema de almacenamiento remoto puede ser idéntico al sitio principal si necesita soportar una carga de trabajo de producción completa, pero si un desastre provoca una reducción de I/O, es posible que un sistema más pequeño en el sitio remoto sea más rentable.</block>
  <block id="fafda72eb75b06280cc3e888b9db81c8" category="paragraph">El Mediador ONTAP es una aplicación de software que se descarga del soporte técnico de NetApp. Mediator automatiza las operaciones de conmutación por error tanto para el clúster de almacenamiento de sitio principal como para el remoto. Puede ponerse en marcha en una pequeña máquina virtual (VM) alojada en las instalaciones o en el cloud. Una vez configurado, actúa como tercer sitio en el que se supervisan las situaciones de conmutación por error en ambos sitios.</block>
  <block id="3873b13983c66ae61dd877b0443a3828" category="summary">Recuperación ante desastres de la base de datos de Oracle y del grupo de consistencia</block>
  <block id="ede2d3fcaec1bb9dcda5a75c90f37368" category="summary">Maximización de la disponibilidad con base de datos de Oracle en ONTAP</block>
  <block id="9688c9c1c1d15e2f91a3a5b8e5f14bd4" category="doc">Disponibilidad de base de datos de Oracle con ONTAP</block>
  <block id="44e95a6c3878f189a550b4c0314d3b33" category="paragraph">NetApp sabe que los datos más críticos se encuentran en las bases de datos.</block>
  <block id="7aa93b5fc17b83fc9e4816155f8f59ab" category="summary">Pruebas de rendimiento de bases de datos de Oracle</block>
  <block id="f0d314849d584b208a69d7a0dc70ac03" category="doc">Optimización del rendimiento y procedimientos de evaluación comparativa de bases de datos de Oracle</block>
  <block id="0b3a030b64747fb3830c79e1ffbef7ee" category="summary">Interrupciones del acceso a la base de datos de Oracle y al almacén de objetos</block>
  <block id="99a1755be2504777b7e266ed14b33168" category="doc">Recuperación tras fallos y cambio del controlador ONTAP de las bases de datos de Oracle</block>
  <block id="8dbb58cb7fbd4c7db3f14b9674e7d4e6" category="summary">Recuperación rápida de bases de datos de Oracle con SnapRestore</block>
  <block id="fd0d4a1100bcbce28e8252537f7c4ef4" category="summary">Acuerdos de nivel de servicio de protección de datos de Oracle</block>
  <block id="48130805e35d0c7ab5afbcb71abb1ad0" category="doc">Planificación del objetivo de tiempo de recuperación, el objetivo de punto de recuperación y los acuerdos de nivel de servicio</block>
  <block id="f359cd007fda575e70269cac76fab4af" category="paragraph">ONTAP le permite adaptar con facilidad una estrategia de protección de datos de base de datos de Oracle a sus requisitos empresariales.</block>
  <block id="05f9f35345d8f2164958f3b6b7098fa7" category="summary">Organización en niveles parcial de FabricPool de archivos de Oracle</block>
  <block id="48e2495d3eeb1b57ea7d073e06620063" category="doc">Migración de bases de datos Oracle a través del envío de registros</block>
  <block id="2cba4042f0a43491e4ea8f14238ae6e4" category="summary">Organización en niveles de copias Snapshot de Oracle y FabricPool</block>
  <block id="6f7b1d0f996b7d49f60586ce7fbeca36" category="doc">Oracle con organización en niveles de copias Snapshot de FabricPool</block>
  <block id="35b12c67685c33721c1a59e8b736fd61" category="summary">Almacenamiento en caché NFS con bases de datos de Oracle</block>
  <block id="1404b2da267c376dac716bd5455f4ff3" category="summary">Migración de Oracle con FLI: Conversión de protocolos</block>
  <block id="c37c1629ee55e6d553c16bbab86adbde" category="doc">Migración de bases de datos de Oracle a sistemas de almacenamiento de ONTAP</block>
  <block id="f1d34b6e878aac7179a735d301e4fb76" category="paragraph">El aprovechamiento de las funciones de una nueva plataforma de almacenamiento tiene un requisito inevitable: Los datos deben estar situados en el nuevo sistema de almacenamiento. ONTAP simplifica el proceso de migración, lo que incluye migraciones y actualizaciones de ONTAP a ONTAP, importaciones de LUN externas y procedimientos para utilizar directamente el sistema operativo del host o el software de base de datos de Oracle.</block>
  <block id="b7433f552fcf8a4e34f2ccc357037d4e" category="doc">Copia de datos de host de la base de datos de Oracle</block>
  <block id="1cede70bc6077ecbac9a77b03d1bc6e1" category="summary">Planificación de protección de datos para bases de datos de Oracle</block>
  <block id="e2bc0913921cafeb725765069883b685" category="paragraph">La arquitectura correcta de protección de datos de base de datos de Oracle depende de los requisitos empresariales relacionados con la retención de datos, la capacidad de recuperación y la tolerancia a interrupciones durante diversos eventos.</block>
  <block id="c0b79db5f258f0c991a383cbdbf001dd" category="inline-link-macro">SnapMirror síncrono activo</block>
  <block id="b271ca7bfee9443d4e34c93aec3bf582" category="paragraph">En esta sección se aborda la protección de datos remota, para la que los datos se replican en un sitio remoto con el fin de almacenar en una ubicación externa segura y la recuperación ante desastres. Es preciso tener en cuenta que estas tablas no abordan la protección de datos de mirroring síncrono. Para este requisito, consulte la documentación de NetApp MetroCluster, que incluye <block ref="5c964f26ec7fbbad5ac67aaa5dcf9269" category="inline-link-macro-rx"></block> y.. <block ref="616da5f81198f2eba9be909bb0f0b117" category="inline-link-macro-rx"></block></block>
  <block id="8a05777f407870cbc2668230c8117503" category="summary">Bases de datos Oracle con Linux y controlador de filtro ASMLib/ASM</block>
  <block id="494900ae2c2cdb5abdba3806f4dfaeb0" category="doc">Bases de datos Oracle con ASMLib/AFD (controlador de filtro de ASM)</block>
  <block id="afae47e326854c63cbc85989720416e0" category="summary">Migración de Oracle con FLI: Planificación</block>
  <block id="85cef7bf4ac9d983cf8e1e11785eeef1" category="summary">Migración de Oracle con FLI: Finalización</block>
  <block id="a92eff1aa9c637ada9c5a8c7c71a5edc" category="doc">El cambio de tamaño del LUN de la base de datos de Oracle y el cambio de tamaño basado en LVM</block>
  <block id="0c5284e14535835121effc8afb702b28" category="summary">Recuperación ante desastres en bases de datos de Oracle con ONTAP</block>
  <block id="2ba21d57ee7f1d78a405b9e80c6aaf6b" category="paragraph">Para la mayoría de los clientes, la recuperación ante desastres requiere algo más que poseer una copia remota de datos, requiere la capacidad para usar rápidamente esos datos. NetApp ofrece dos tecnologías para satisfacer esta necesidad: La sincronización activa de MetroCluster y SnapMirror</block>
  <block id="107bcc34799abe752a088be24869419c" category="paragraph">La sincronización activa de SnapMirror se basa en SnapMirror síncrono. Con MetroCluster, cada controladora de ONTAP es responsable de replicar los datos de la unidad en una ubicación remota. Con la sincronización activa de SnapMirror, básicamente cuenta con dos sistemas ONTAP diferentes que mantienen copias independientes de los datos de su unidad lógica, pero que cooperan para presentar una única instancia de esa LUN. Desde el punto de vista del host, se trata de una única entidad de LUN.</block>
  <block id="d8f57e6104c0329961c4d91e154c4f27" category="paragraph">Aunque SnapMirror Active Sync y MetroCluster funcionan de manera diferente internamente, en un host el resultado es muy similar. La principal diferencia es la granularidad. Si solo necesita replicar de forma síncrona las cargas de trabajo seleccionadas, SnapMirror active sync es la mejor opción. Si necesita replicar entornos enteros o incluso centros de datos, MetroCluster es una opción mejor. Además, SnapMirror Active Sync es actualmente solo para SAN, mientras que MetroCluster tiene un protocolo multiprotocolo, incluidos SAN, NFS y SMB.</block>
  <block id="50ae143b75fc238e91c09c750cf211c1" category="summary">Parámetros de la base de datos Oracle: Filesystemio_options</block>
  <block id="23c61da1d42f69597a6ab97e333a560f" category="doc">Parámetros de la base de datos Oracle: Filesystemio_options</block>
  <block id="8dcef4b75bc24cd58c3153dbfea25d0d" category="summary">Situaciones de fallo de sincronización activa de SnapMirror y bases de datos de Oracle</block>
  <block id="9e1d7b20d80dca74b98aba2df90c2ac0" category="doc">Situaciones de fallo de sincronización activa de SnapMirror y bases de datos de Oracle</block>
  <block id="59b0f50492db68037c67566a379980c1" category="paragraph">Hay varios escenarios de fallos de la sincronización activa de SnapMirror (SM-AS) con resultados diferentes cada uno.</block>
  <block id="e4a8a67910cb40e92db607431fb60238" category="cell">Obviamente, los servidores en el sitio fallido ya no estarán disponibles. Las aplicaciones que admiten clustering se pueden configurar para que se ejecuten en ambos sitios y continúen con las operaciones en el sitio alternativo, aunque la mayoría de estas aplicaciones requieren un desempate de sitio 3rd de manera similar al modo en que SM-AS requiere el mediador.

Sin clusters de nivel de aplicación, las aplicaciones deberán iniciarse en el sitio superviviente. Esto afectaría a la disponibilidad, pero se mantiene el objetivo de punto de recuperación=0. No se perderían datos.</block>
  <block id="cf451e0aed3c944d3f1c761387762e56" category="summary">Bases de datos de Oracle con Linux</block>
  <block id="e712ed441aacc4eeecb5656d5493c99c" category="summary">Bases de datos de Oracle con HP-UX</block>
  <block id="c36ae718fe9d7978c8781b19d0b3dee0" category="paragraph">Temas de configuración para bases de datos de Oracle en HP-UX con ONTAP.</block>
  <block id="45df37151f6a0fd8a3b55d0423459f82" category="doc">Alineación de LUN para I/O de bases de datos de Oracle</block>
  <block id="a73cbc9997ca90c0cc5b6d9e9b475272" category="summary">Mejora de la organización en niveles de FabricPool y bases de datos de Oracle</block>
  <block id="857a8adc9eda2d9e197a52323daca558" category="doc">Información general de FabricPool Tiering en bases de datos de Oracle</block>
  <block id="fd73b1ca3b942a1514078a7e59c7433b" category="summary">Base de datos de Oracle y bloqueos NFSv3 obsoletos</block>
  <block id="102aeb54bf1a69403672f53090c52878" category="summary">Recuperación ante desastres de bases de datos de Oracle a través del envío de registros</block>
  <block id="d470f5db851ef84aaa776600805af48b" category="summary">Introducción a la virtualización de bases de datos de Oracle</block>
  <block id="b8fc1174bb3f1c65475334182829f75e" category="doc">Virtualización de bases de datos de Oracle</block>
  <block id="b1b3f70e4333a9dbda75a98ceb78db39" category="summary">Arquitectura física de MetroCluster y bases de datos Oracle</block>
  <block id="250bce9fbefc7872908d9c2708fc753b" category="doc">Niveles de backup de bases de datos de Oracle</block>
  <block id="4fbe2d000cdf5390ca980149d98eec4d" category="summary">Planificación de migración de bases de datos de Oracle</block>
  <block id="d11e22f56fe0c9dd85597038a25cd80d" category="doc">Gestión de la capacidad de almacenamiento y las bases de datos de Oracle</block>
  <block id="1234e92308935cf0a5a22541f312c541" category="summary">Bases de datos de Oracle con SnapMirror y SyncMirror</block>
  <block id="a4cdac841b6453db2f51ce52a1303209" category="paragraph">La replicación de SnapMirror y la interrupción de la relación de SnapMirror de CG preservan la coherencia entre los volúmenes, y tanto la sincronización activa de SnapMirror síncrono como la sincronización activa de SnapMirror preservan la coherencia entre los volúmenes constituyentes.</block>
  <block id="454ff7e5f4a8d37cf6b16b804deca2b6" category="summary">Tamaños de bloques de bases de datos de Oracle</block>
  <block id="eed7df980a6ae17f8e0fecdecf0e25f4" category="doc">Scripts de ejemplo de procedimiento de migración de Oracle</block>
  <block id="fac6d6b61dd6bd3ee73d5b425bc5a3b7" category="doc">Thin provisioning con bases de datos de Oracle</block>
  <block id="35ebaedc3385b350dff13e0cfa869c9f" category="summary">Tiempo de espera de Oracle RAC</block>
  <block id="a920434a7bcd979e2ece4092cd8b8a19" category="doc">Timeout de Oracle Real Application Clusters (RAC)</block>
  <block id="710cf627a103721a0452cb72494ea742" category="admonition">Consulte las siguientes secciones sobre thin provisioning para obtener una explicación de la interacción entre la eficiencia del almacenamiento y la reserva fraccionaria.</block>
  <block id="8bc1cc1880ea3a623cb9b80b8cbb7b72" category="paragraph">Existen varias formas de comprimir datos. Muchas bases de datos incluyen sus propias funcionalidades de compresión, pero esto se observa muy rara vez en los entornos del cliente. La razón suele ser la penalización de rendimiento para un *cambio* a los datos comprimidos, además con algunas aplicaciones hay altos costos de licencia para la compresión a nivel de base de datos. Por último, existen las consecuencias de rendimiento generales para las operaciones de base de datos. Tiene poco sentido pagar un alto coste de licencia por CPU por una CPU que realiza compresión y descompresión de datos en lugar de trabajo real de base de datos. Una mejor opción es descargar el trabajo de compresión en el sistema de almacenamiento.</block>
  <block id="3e98696b9bb83904c14603458a8c3728" category="admonition">El tamaño de los bloques utilizado por la compresión adaptativa se puede aumentar hasta 32KB KB. Esto puede mejorar la eficiencia del almacenamiento y debe considerarse en el caso de archivos inactivos, como registros de transacciones y archivos de backup, cuando se almacena una cantidad sustancial de dichos datos en la cabina. En algunas situaciones, las bases de datos activas que usan un tamaño de bloque de 16KB KB o de 32KB KB también pueden beneficiarse de aumentar el tamaño de bloque de la compresión adaptativa para que coincida. Consulte a un representante de NetApp o de su partner para obtener orientación sobre si esto es adecuado para su carga de trabajo.</block>
  <block id="0e6f69b7cb8364ed908c411686154808" category="admonition">Los bloques de compresión superiores a los 8KB MB no se deben usar junto a la deduplicación en destinos de backup en streaming. El motivo es que los pequeños cambios en los datos de backup afectan a la ventana de compresión de 32KB:1. Si la ventana cambia, los datos comprimidos resultantes difieren en todo el archivo. La deduplicación ocurre después de la compresión, lo que significa que el motor de deduplicación ve cada backup comprimido de forma diferente. Si se requiere la deduplicación de backups en streaming, solo deberá usarse la compresión adaptativa de 8KB bloques. Es preferible recurrir a la compresión adaptativa, ya que funciona con un tamaño de bloque más pequeño y no interrumpe la eficiencia de la deduplicación. Por motivos similares, la compresión en el lado del host también interfiere con la eficiencia de la deduplicación.</block>
  <block id="e8a7060409e1a82af9dacfe72458ffac" category="paragraph">Por ejemplo, una escritura 8KB en un archivo se comprime solo si se alinea con un límite de 8KB KB en el propio sistema de archivos. Este punto significa que debe caer en los primeros 8KB del archivo, el segundo 8KB del archivo, y así sucesivamente. La forma más sencilla de garantizar una alineación correcta es utilizar el tipo de LUN correcto, cualquier partición creada debe tener un desplazamiento desde el inicio del dispositivo que sea un múltiplo de 8K y usar un tamaño de bloque del sistema de archivos que sea un múltiplo del tamaño del bloque de la base de datos.</block>
  <block id="96738983d52a374cb4a8c958e924836e" category="paragraph">Los datos como los backups o los registros de transacciones son operaciones escritas secuencialmente que abarcan varios bloques, todos ellos comprimidos. Por lo tanto, no hay necesidad de considerar la alineación. El único patrón de E/S preocupante es la sobrescritura aleatoria de archivos.</block>
  <block id="1afe2c0821b67085f9ea2d2deeb2e92a" category="paragraph">La compactación de datos es una tecnología que mejora la eficiencia de la compresión. Como se ha indicado anteriormente, la compresión adaptativa por sí sola puede proporcionar un ahorro de 2:1 KB, ya que se limita a almacenar una I/O de 8KB KB en un bloque de 4KB WAFL. Los métodos de compresión con tamaños de bloque más grandes ofrecen una mejor eficiencia. Sin embargo, no son adecuados para datos sujetos a sobrescrituras de bloques pequeños. La descompresión de 32KB unidades de datos, la actualización de una parte de 8KB, la recompresión y la escritura en las unidades genera una sobrecarga.</block>
  <block id="82116b39cd4d0d1920fab1ab4515603b" category="paragraph">El grado de ahorro obtenido varía. Por lo general, los datos que ya están comprimidos o cifrados no se pueden comprimir aún más y, por lo tanto, estos conjuntos de datos no se benefician de la compactación. Por el contrario, los archivos de datos recién inicializados que contienen poco más que metadatos de bloques y ceros se comprimen hasta 80:1.</block>
  <block id="2608473fa5767385d01f256eccbc1cc4" category="paragraph">Muchas cabinas de la competencia afirman la capacidad de deduplicar bases de datos basándose en la presunción de que una base de datos se copia varias veces. En este sentido, la deduplicación de NetApp también podría utilizarse, pero ONTAP ofrece una opción mejor: La tecnología FlexClone de NetApp. El resultado final es el mismo; se crean varias copias de una base de datos que comparten la mayoría de los bloques físicos subyacentes. El uso de FlexClone es mucho más eficiente que tomarse tiempo para copiar archivos de base de datos y después deduplicarlos. Es, de hecho, la no duplicación en lugar de la deduplicación, porque nunca se crea un duplicado.</block>
  <block id="7e96c1b651af3f28c27b78807f0310e2" category="paragraph">Se recomienda encarecidamente el aprovisionamiento ligero porque puede simplificar la gestión y, al mismo tiempo, proporcionar una mejora considerable en la capacidad utilizable con un ahorro de costes asociado. La razón es simple: Los entornos de bases de datos suelen incluir una gran cantidad de espacio vacío, un gran número de volúmenes y LUN, y datos comprimibles. El aprovisionamiento grueso provoca la reserva de espacio en el almacenamiento para volúmenes y LUN por si en algún momento llegan a estar llenos un 100 % y contienen un 100 % de datos que no se pueden comprimir. Es poco probable que esto ocurra. El thin provisioning permite reclamar y utilizar ese espacio en otra parte, y permite que la gestión de la capacidad se base en el propio sistema de almacenamiento en lugar de muchos volúmenes y LUN más pequeños.</block>
  <block id="0f55b43344575cc268bf51ae032d47c2" category="paragraph">NetApp recomienda lo siguiente:</block>
  <block id="f67b854e2d644480b0ec40d7de2b773d" category="paragraph">Los volúmenes creados en ONTAP en un sistema AFF all-flash son thin provisioning, con todas las funciones de eficiencia inline habilitadas. Aunque por lo general, las bases de datos no se benefician de la deduplicación y pueden incluir datos que no se pueden comprimir, la configuración predeterminada es adecuada para casi todas las cargas de trabajo. ONTAP está diseñado para procesar eficientemente todo tipo de datos y patrones de I/O, independientemente de que generen o no ahorros. Los valores predeterminados solo se deben cambiar si los motivos se entienden por completo y existe un beneficio para desviarse.</block>
  <block id="649141c6b8267ea3df10949a853d22cb" category="list-text">No utilice la compresión 32KB ni la deduplicación con backups de bases de datos. Consulte la sección <block ref="57ee2712afc5e59236f86db0537b05dc" category="inline-xref-macro-rx"></block> para obtener más detalles.</block>
  <block id="5059ada12bae6c7e7fac9338d88301b5" category="doc">Organización en niveles de archive log de Oracle Database</block>
  <block id="b7e89b3a1ff13c93cc5c038440e48f58" category="paragraph">Para obtener más información, inicie chttps://docs.netapp.com/us-en/ontap-automation/rest/rbac_overview.html[here.]</block>
  <block id="4abda684ecc952239d7800547dcf2995" category="sidebar">Oracle SI en MetroCluster</block>
  <block id="8ce34b299aaaa41e3dfdfefd9bd453d0" category="sidebar">Oracle SI con sincronización activa de SnapMirror</block>
  <block id="bdebc59bb8c11012c00a4be61b8bdb5d" category="summary">Puesta en marcha de instancias de Microsoft SQL Server</block>
  <block id="c2482f23723171a88547029c9448d02c" category="paragraph">Se pueden configurar varios SQL Server como una única instancia por servidor o como varias instancias. La decisión correcta generalmente depende de factores como si el servidor se va a utilizar para la producción o el desarrollo, si la instancia se considera crítica para las operaciones de negocio y los objetivos de rendimiento.</block>
  <block id="763ba5952482211e4604d7ba4e115f09" category="paragraph">Las configuraciones de instancias compartidas pueden ser inicialmente más fáciles de configurar, pero pueden provocar problemas en los que los recursos se dividen o bloquean, lo que a su vez provoca problemas de rendimiento para otras aplicaciones que tienen bases de datos alojadas en la instancia compartida de SQL Server.</block>
  <block id="030194212f0e1890126b205fdbcfe852" category="summary">Protección de Microsoft SQL Server en ONTAP</block>
  <block id="76e6e519036ed33c414d681e342c73be" category="paragraph">Proteger un entorno de base de datos de SQL Server es un esfuerzo multidimensional que va más allá de la propia base de datos. ONTAP ofrece varias funciones únicas diseñadas para proteger el aspecto de almacenamiento de la infraestructura de bases de datos.</block>
  <block id="972d09960af01a5f3831f2eac1c75d12" category="summary">Recuperación ante desastres de Microsoft SQL Server con ONTAP</block>
  <block id="db78788a721b9a9a669c4935d455a593" category="paragraph">Las bases de datos empresariales y las infraestructuras de aplicaciones a menudo requieren la replicación para protegerse de desastres naturales o de la interrupción inesperada del negocio con un tiempo de inactividad mínimo.</block>
  <block id="109f1cd3917cec9c30435aaf1b42a849" category="paragraph">La característica de replicación de grupo de disponibilidad siempre disponible de SQL Server puede ser una excelente opción, y NetApp ofrece optiosn para integrar la protección de datos con Always-On. Sin embargo, en algunos casos es posible que desee considerar la tecnología de replicación de ONTAP. Las opciones de replicación de ONTAP, como MetroCluster y SnapMirror, pueden escalarse mejor con un impacto mínimo en el rendimiento, proteger los datos que no son de SQL y, en general, proporcionar una solución de replicación y recuperación ante desastres de toda la infraestructura.</block>
  <block id="afa4ddf7487df36a358a77030600c0f7" category="section-title">SnapMirror asíncrono</block>
  <block id="aaeda7b73da30ad381d02e93ec500f29" category="paragraph">La tecnología SnapMirror ofrece una solución empresarial asíncrona, rápida y flexible para replicar datos en LAN y WAN. La tecnología SnapMirror solo transfiere los bloques de datos modificados al destino una vez que se creó el reflejo inicial, lo que reduce considerablemente los requisitos de ancho de banda de la red.</block>
  <block id="fad02ab7a45b438ba1a4c024b9edb2be" category="paragraph">Las siguientes son recomendaciones para SnapMirror para SQL Server:</block>
  <block id="ff1af055b96eb7cd0f0ab71b2cc80c3d" category="list-text">Con fines de coherencia, no programe actualizaciones de SnapMirror de las controladoras. En lugar de eso, habilite las actualizaciones de SnapMirror desde SnapCenter para actualizar SnapMirror después de haber completado el backup completo o de registro.</block>
  <block id="60654048dbcae98cde53dc0449c8e47b" category="summary">Consideración del almacenamiento de Microsoft SQL Server</block>
  <block id="bbaff7e69163b21b40fd695f17de167c" category="paragraph">La combinación de las soluciones de almacenamiento de ONTAP y Microsoft SQL Server permite crear diseños de almacenamiento de base de datos de nivel empresarial que satisfacen los requisitos de aplicaciones más exigentes en la actualidad.</block>
  <block id="71cc52562b241f23c0f5c74c589fc56c" category="paragraph">Los agregados son los contenedores de almacenamiento de nivel más bajo para las configuraciones de almacenamiento de NetApp. Existe cierta documentación heredada en Internet, que recomienda separar las operaciones de I/O en diferentes conjuntos de unidades subyacentes. No se recomienda con ONTAP. NetApp ha realizado distintas pruebas de caracterización de las cargas de trabajo de I/O utilizando agregados compartidos y dedicados con archivos de datos y archivos de registro de transacciones separados. Las pruebas muestran que un gran agregado con más grupos RAID y unidades optimiza y mejora el rendimiento del almacenamiento y tiene mayor facilidad de gestión para los administradores por dos motivos:</block>
  <block id="994dbcbb2492daba25572c539cc12968" category="list-text">Un gran agregado hace que las funcionalidades de I/O de todas las unidades estén disponibles para todos los archivos.</block>
  <block id="7d55b024d1367e74db2b935f539696d1" category="paragraph">Los volúmenes NetApp FlexVol se crean y residen dentro de los agregados. Este término a veces provoca confusión porque un volumen ONTAP no es una LUN.  Un volumen ONTAP es un contenedor de gestión para datos. Un volumen puede contener archivos, LUN o incluso objetos S3. Un volumen no ocupa espacio, solo se utiliza para la gestión de los datos contenidos.</block>
  <block id="8e6ab064c04f3cf4f6cfb70d8db3132c" category="list-text">Evite compartir volúmenes entre hosts. Por ejemplo, aunque sería posible crear 2 LUN en un único volumen y compartir cada LUN en un host diferente, esto debe evitarse porque puede complicar la gestión.</block>
  <block id="900188651b4134e36897865047c3fb5b" category="list-text">Establezca el valor de reserva de instantáneas en el volumen en cero para facilitar la supervisión desde una perspectiva operativa.</block>
  <block id="27d9533edb3ad60370502d101cd38d2b" category="list-text">Deshabilite las programaciones de Snapshot y las políticas de retención. En su lugar, utilice SnapCenter para coordinar las copias Snapshot de los volúmenes de datos de SQL Server.</block>
  <block id="a09a2d9023a555d2d5a72621bf3395b3" category="list-text">Coloque las bases de datos del sistema SQL Server en un volumen dedicado.</block>
  <block id="7b3c6a2d089eb1b6f8959e7e61a50c07" category="section-title">LUN</block>
  <block id="cc62dd0a48de1d50b120a8eaa55520e1" category="paragraph">En la siguiente sección se explica la configuración de los valores de memoria de SQL Server para optimizar el rendimiento de la base de datos.</block>
  <block id="a2f15f0d2a5091a4b232a8fa89bb43f8" category="paragraph">Cuando se ejecuta una consulta, SQL Server intenta asignar la cantidad óptima de memoria para que se ejecute de forma eficiente.</block>
  <block id="98b261ef18cdd1e1371308dbf3079163" category="paragraph">De forma predeterminada, el valor de memoria mínima por consulta asigna &gt;= a 1024KB para cada consulta que se ejecute. Es recomendable dejar este valor en el valor por defecto de 0 para permitir que SQL Server gestione dinámicamente la cantidad de memoria asignada para las operaciones de creación de índices. Sin embargo, si SQL Server tiene más RAM de la que necesita para ejecutarse de manera eficiente, el rendimiento de algunas consultas se puede aumentar si aumenta este valor. Por lo tanto, siempre y cuando la memoria esté disponible en el servidor que no esté utilizando SQL Server, ninguna otra aplicación o el sistema operativo, aumentar esta configuración puede ayudar en general al rendimiento de SQL Server. Si no hay memoria libre disponible, aumentar esta configuración puede afectar al rendimiento general.</block>
  <block id="a549d3d5e3e6aa1db52e782527a9664d" category="summary">Ubicación del archivo de base de datos de Microsoft SQL Server</block>
  <block id="329282f5b4d197877079b3b130756d76" category="paragraph">La ubicación correcta del archivo de la base de datos de SQL Server en ONTAP es crítica durante la etapa de la implementación inicial. Esto garantiza un rendimiento óptimo, gestión del espacio, tiempos de backup y restauración que pueden configurarse para que se ajusten a sus necesidades empresariales.</block>
  <block id="d8969d8106a5ac08f38277a3c0b813dc" category="paragraph">La capacidad de colocar varios archivos de datos dentro del grupo de archivos permite distribuir la carga entre diferentes dispositivos de almacenamiento, lo que ayuda a mejorar el rendimiento de I/O del sistema. Por el contrario, el registro de transacciones no se beneficia de los varios archivos, ya que SQL Server escribe en el registro de transacciones de forma secuencial.</block>
  <block id="bd87ed7f70b7f9173319df18e5b5b751" category="paragraph">Cada vez que SQL Server crece archivos, llena el espacio recién asignado con ceros. Este proceso bloquea todas las sesiones que necesitan escribir en el archivo correspondiente o, en caso de crecimiento del log de transacciones, generar registros de log de transacciones.</block>
  <block id="7a64f7e9c9b5737a434bdcc8f935c5ce" category="summary">Microsoft SQL Server y la eficiencia del almacenamiento de ONTAP</block>
  <block id="20f0346a9d65f2fba1523d3343d7c6e7" category="doc">Microsoft SQL Server y la eficiencia del almacenamiento</block>
  <block id="8cc43076ed5901d72e02ff4e67f6a56e" category="paragraph">La eficiencia del almacenamiento de ONTAP está optimizada para almacenar y gestionar datos de SQL Server de una manera que consuma la menor cantidad de espacio de almacenamiento con poco o ningún efecto en el rendimiento general del sistema.</block>
  <block id="c0841f358ea3dbbb1d972eabb129739d" category="paragraph">La eficiencia del almacenamiento es una combinación de RAID, aprovisionamiento (distribución y utilización generales), mirroring y otras tecnologías de protección de datos. Las tecnologías de NetApp, incluidas las snapshots, thin provisioning y clonado, optimizan el almacenamiento existente en la infraestructura y aplazan o evitan gastos futuros en almacenamiento. Cuanto más use estas tecnologías conjuntamente, mayor será el ahorro.</block>
  <block id="9df29e7c756637e30b37f014d02117ef" category="paragraph">SQL Server en sí también tiene funciones para comprimir y gestionar datos de forma eficiente. SQL Server soporta actualmente dos tipos de compresión de datos: Compresión de filas y compresión de páginas.</block>
  <block id="09ddfa236e0fa1173f8d86a5ad0c148f" category="summary">Directorio de registro de Microsoft SQL Server</block>
  <block id="cc2c23339c0ad05c5ae1704b4a0ecb37" category="paragraph">El directorio de registro se especifica en SQL Server para almacenar datos de backup de registros de transacciones en el nivel de host. Si utiliza SnapCenter para realizar backup de archivos de registro, cada host SQL Server que utiliza SnapCenter debe tener un directorio de registro de host configurado para realizar backups de registros. SnapCenter tiene un repositorio de base de datos, por lo que los metadatos relacionados con las operaciones de backup, restauración o clonado se almacenan en un repositorio de base de datos central.</block>
  <block id="59412263456ecc0573b76fe1c40d55fb" category="paragraph">ONTAP ofrece una solución de rendimiento y seguridad empresarial para sus bases de datos de Microsoft SQL Server y proporciona herramientas de primera calidad para gestionar su entorno.</block>
  <block id="e8b13d430655a3ab009ba8e90e51ce5a" category="paragraph">NetApp asume que el lector tiene conocimiento práctico de lo siguiente:</block>
  <block id="efd44736fee0b29831bc101f834f9425" category="list-text">Software ONTAP</block>
  <block id="abf1fb60b74d2d6ad7263baea0d8b500" category="paragraph">El alcance de esta sección de mejores prácticas se limita al diseño técnico basado en los principios de diseño y estándares preferidos que NetApp recomienda para la infraestructura de almacenamiento. La implementación integral está fuera del alcance.</block>
  <block id="60b1517ca869b5c89b928c0537f6050c" category="paragraph">Para obtener información sobre la compatibilidad de la configuración en los productos de NetApp, consulte <block ref="18e7fcfe606d6d0912191de7fd9eb56a" category="inline-link-macro-rx"></block>.</block>
  <block id="c7f2945182947499933dea6fafeb22d3" category="summary">Ubicación de tempdb de Microsoft SQL Server en ONTAP</block>
  <block id="bb33f8b391f4b3e04df25022defa095c" category="paragraph">La base de datos tempdb se puede utilizar en gran medida. Además de la ubicación óptima de los archivos de base de datos de usuario en ONTAP, modifique los archivos de datos tempdb para reducir la contención de asignación</block>
  <block id="03162932e80c8f83c1ad9e36b16c1dcf" category="summary">Configuración de CPU de Microsoft SQL Server</block>
  <block id="709c31749e3311b9855f987071c074c4" category="paragraph">Para mejorar el rendimiento del sistema, es necesario modificar la configuración de SQL Server y la configuración del servidor para utilizar el número adecuado de procesadores para su ejecución.</block>
  <block id="06b665871e25c2200433695670620090" category="paragraph">El hardware que utiliza hyperthreading permite que las CPU lógicas de hyperthreading aparezcan como CPU físicas en el sistema operativo. A continuación, SQL Server ve las CPU físicas, que presenta el sistema operativo, y puede utilizar los procesadores de hiperproceso. Esto mejora el rendimiento al aumentar la paralelización.</block>
  <block id="074e88cde37f7aba58ac120bbc874e77" category="paragraph">Hay dos opciones para la licencia de SQL Server. El primero se conoce como modelo de licencia de acceso de servidor + cliente (CAL); el segundo es el modelo de núcleo por procesador. Aunque puede acceder a todas las características del producto disponibles en SQL Server con la estrategia server + CAL, hay un límite de hardware de 20 núcleos de CPU por socket. Incluso si tiene SQL Server Enterprise Edition + CAL para un servidor con más de 20 núcleos de CPU por socket, la aplicación no puede utilizar todos esos núcleos a la vez en esa instancia.</block>
  <block id="1438665372025532002ff01f518d7146" category="paragraph">La siguiente figura muestra el mensaje de registro de SQL Server después del inicio que indica la aplicación del límite principal.</block>
  <block id="cc3873d6002920194cf7e9dd493c5863" category="paragraph">Es poco probable que necesite alterar los valores predeterminados de afinidad del procesador a menos que encuentre problemas de rendimiento, pero aún vale la pena entender qué son y cómo funcionan.</block>
  <block id="4b1333ab02dc9c91c3944aa2bcb2a8f1" category="paragraph">SQL Server utiliza todas las CPU disponibles en el sistema operativo (si se selecciona la licencia de núcleo por procesador). Crea programadores en todas las CPU para hacer el mejor uso de los recursos para cualquier carga de trabajo dada. Al realizar varias tareas, el sistema operativo u otras aplicaciones del servidor pueden cambiar los subprocesos de un procesador a otro. SQL Server es una aplicación que consume muchos recursos y el rendimiento puede verse afectado cuando esto ocurre. Para minimizar el impacto, puede configurar los procesadores de modo que toda la carga de SQL Server se dirija a un grupo preseleccionado de procesadores. Esto se logra mediante el uso de la máscara de afinidad de CPU.</block>
  <block id="4317f0d20ae625ae3139762a94175cbd" category="paragraph">De forma predeterminada, SQL Server utiliza todas las CPU disponibles durante la ejecución de la consulta si se elige la licencia central por procesador.</block>
  <block id="c36be4452a4e1f9ddab6e727019fb884" category="paragraph">Aunque esto es útil para consultas grandes, puede causar problemas de rendimiento y limitar la simultaneidad. Un mejor enfoque es limitar el paralelismo al número de núcleos físicos en un único socket de CPU. Por ejemplo, en un servidor con dos sockets de CPU físicos con 12 núcleos por socket, independientemente del hyperthreading, MAXDOP debe establecerse en 12. MAXDOP no puede restringir ni dictar qué CPU se va a utilizar. En su lugar, restringe el número de CPU que puede utilizar una única consulta por lotes.</block>
  <block id="161652c9b877efd4dc82d6029e303efe" category="admonition">*NetApp recomienda* para DSS, como almacenes de datos, comience con MAXDOP en 50 y explore el ajuste hacia arriba o hacia abajo si es necesario. Asegúrese de medir las consultas críticas de la aplicación al realizar cambios.</block>
  <block id="ff03ad08d7a38270e44c8c74372d0e7c" category="summary">Protección de bases de datos de Microsoft SQL Server en ONTAP con comandos SnapCenter y T-SQL.</block>
  <block id="027202a07b43ba49311d98b7812a6c84" category="doc">Protección de datos de Microsoft SQL Server con el software de gestión NetApp</block>
  <block id="3d04647c86c0578e30a105080ae9fded" category="paragraph">La planificación del backup de la base de datos se basa en los requisitos del negocio. Al combinar la tecnología Snapshot de NetApp de ONTAP y el aprovechamiento de las API de Microsoft SQL Server, puede realizar rápidamente backup consistente con las aplicaciones independientemente del tamaño de las bases de datos del usuario. Para obtener requisitos de gestión de datos más avanzados o de escalado horizontal, NetApp ofrece SnapCenter.</block>
  <block id="a72812111b6cfc428e19135820c476bc" category="paragraph">SnapCenter es el software de protección de datos de NetApp para aplicaciones empresariales. Las bases de datos de SQL Server pueden protegerse de forma rápida y fácil con el complemento de SnapCenter para SQL Server y con operaciones de sistema operativo gestionadas por el plugin de SnapCenter para Microsoft Windows.</block>
  <block id="62c187efa0cd9f4191b84ae987d522c9" category="paragraph">La instancia de SQL Server puede ser una configuración independiente, una instancia de clúster de conmutación por error o puede estar siempre en un grupo de disponibilidad. El resultado es que, a partir de un solo panel, las bases de datos pueden protegerse, clonarse y restaurarse a partir de copias principales o secundarias. SnapCenter puede gestionar bases de datos de SQL Server tanto en las instalaciones, en el cloud como en configuraciones híbridas.Las copias de bases de datos también se pueden crear en pocos minutos en el host original o alternativo para fines de desarrollo o generación de informes.</block>
  <block id="aa9d4f1a26d2dda8703ffef3bd4e2d4d" category="admonition">*NetApp recomienda* usar SnapCenter para crear copias snapshot. También funciona el método de T-SQL descrito a continuación, pero SnapCenter ofrece una automatización completa del proceso de backup, restauración y clonación. También realiza una detección para garantizar que se crean las snapshots correctas. No se necesita ninguna configuración previa.
...
SQL Server también requiere coordinación entre el SO y el almacenamiento para garantizar que los datos correctos están presentes en las snapshots en el momento de la creación. En la mayoría de los casos, el único método seguro para hacerlo es con SnapCenter o T-SQL. Es posible que las instantáneas creadas sin esta coordinación adicional no se puedan recuperar de forma fiable.</block>
  <block id="8a3aceb6ed4b21af2f2c00ecb032f75f" category="paragraph">En SQL Server 2022, Microsoft introdujo las copias Snapshot de T-SQL que ofrecen una ruta para el scripting y la automatización de las operaciones de backup. En lugar de realizar copias de tamaño completo, puede preparar la base de datos para instantáneas. Una vez que la base de datos está lista para el backup, se pueden aprovechar las API DE REST DE ONTAP para crear snapshots.</block>
  <block id="eeeb4e610a7896c1b1f2e2ea9b3f52a0" category="list-text">Congelar una base de datos con el comando ALTER. Esto prepara la base de datos para una instantánea coherente en el almacenamiento subyacente. Después de congelar, puede descongelar la base de datos y registrar la instantánea con el comando BACKUP.</block>
  <block id="fd95362fecccbbb7b017317e8bede3b5" category="admonition">Esta documentación sobre ONTAP y la base de datos MySQL sustituye a _TR-4722: Base de datos MySQL sobre las mejores prácticas de ONTAP que se había publicado anteriormente._</block>
  <block id="03591504f4566055ad54d9422f8a0488" category="paragraph">NetApp ofrece Astra Trident para proporcionar funcionalidades de gestión avanzadas del almacenamiento. Por ejemplo, Astra Trident permite que un contenedor creado en Kubernetes aprovisione automáticamente su almacenamiento en el nivel apropiado, aplique políticas de exportación, establezca políticas de Snapshot e incluso clone un contenedor a otro. Para obtener más información, consulte <block ref="2b8a155fc083396b96b18cee0ba5eab0" category="inline-link-macro-rx"></block>.</block>
  <block id="887757e2405372a0b9e17cc054ab38f3" category="paragraph">La razón por la que SnapRestore funciona tan rápido y eficientemente se debe a la naturaleza de una copia Snapshot, que es esencialmente una vista paralela de solo lectura del contenido de un volumen en un momento determinado. Los bloques activos son los bloques reales que se pueden cambiar, mientras que la copia Snapshot es una vista de solo lectura del estado de los bloques que constituyen los archivos y la LUN en el momento de crear la copia Snapshot.</block>
  <block id="f9b673452d1da030fef3f976bbbbb103" category="paragraph">En este ejemplo, la base de datos de origen se encuentra en un sistema ONTAP. El método más sencillo para crear un backup de una base de datos es mediante una instantánea. La base de datos se coloca en modo de backup dinámico durante unos segundos mientras a.<block ref="252ce13e6c150af4d3e7eea5fca266bc" prefix=" " category="inline-code"></block> la operación se ejecuta en el volumen que aloja los archivos de datos.</block>
  <block id="630a571b99791968d41f9caba4a3e39c" category="paragraph">El resultado es una instantánea en disco llamada<block ref="a8b3bc9f12cd194b80d404c30e9015ee" prefix=" " category="inline-code"></block> que contiene una imagen de los archivos de datos mientras se encuentra en modo de copia de seguridad activa. Si se combinan con los archive logs adecuados para que los archivos de datos sean coherentes, se pueden utilizar los datos de esta copia Snapshot como base de la restauración o el clon. En este caso, se replica en el nuevo servidor.</block>
  <block id="96a1129a5a4b32943286cafd5e0ca2e1" category="paragraph">En este ejemplo, se usa SnapMirror para replicar el backup en caliente de la copia Snapshot en una nueva ubicación.</block>
  <block id="0c4e214451012c456ece194f5465deb2" category="paragraph">SnapCenter incluye las funciones básicas, como los backups y restauraciones basados en Snapshot, la replicación de SnapMirror y SnapVault, y otras funciones necesarias para funcionar a escala para grandes empresas. Estas funciones avanzadas incluyen una funcionalidad ampliada de control de acceso basado en roles (RBAC), API RESTful para integrarse con productos de orquestación de terceros, gestión central no disruptiva de complementos de SnapCenter en hosts de bases de datos y una interfaz de usuario diseñada para entornos a escala de cloud.</block>
  <block id="ee4b6ce05339d0d985309ece9b7d4372" category="inline-link-macro">TR-4067 NFS en prácticas recomendadas de ONTAP</block>
  <block id="7a3ba6ac400bdd362b5db9daabcefca2" category="paragraph">El protocolo NFS incluye varias versiones con diferentes requisitos. Para obtener una descripción completa de la configuración de NFS con ONTAP, consulte <block ref="d594eac583da3f61bc51209142764c76" category="inline-link-macro-rx"></block>. Las siguientes secciones cubren algunos de los requisitos más críticos y los errores comunes del usuario.</block>
  <block id="dabc72adea00cc712e7650b066f1d8c6" category="inline-link">Prácticas recomendadas de TR-4067 NFS en ONTAP</block>
  <block id="36911cfd2b35ef0ca97dab53c7e045f0" category="paragraph">Cambiar a NFSv4 es más complicado que simplemente cambiar las opciones de montaje de vers=3 a vers=4,1. Para obtener una explicación más completa de la configuración de NFSv4 con ONTAP, que incluye instrucciones para configurar el sistema operativo, consulte<block ref="92f446ddde3e320c4e32b449cbe3112d" category="inline-link-rx"></block>. En las siguientes secciones de este documento técnico se explican algunos de los requisitos básicos para el uso de NFSv4.</block>
  <block id="a80438f1b3354b284cf31082c45b33b3" category="summary">Infraestructura de almacenamiento de Hyper-V con ONTAP</block>
  <block id="cfbb26e347d5746581822f8046be20c4" category="paragraph">La infraestructura de almacenamiento de Hyper-V se puede alojar en sistemas de almacenamiento de ONTAP. Almacenamiento para Hyper-V para almacenar los archivos de equipos virtuales y sus discos se pueden suministrar usando LUN de NetApp o recursos compartidos CIFS de NetApp, como se muestra en la siguiente figura.</block>
  <block id="25aa60030552ee28c6e802f74d96f111" category="inline-image-macro">Infraestructura de almacenamiento de Hyper-V en NetApp,width=624,height=338</block>
  <block id="818a20c74e71223c5a644895a6dd4095" category="paragraph"><block ref="818a20c74e71223c5a644895a6dd4095" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c5672e01a7d0a8e068c2573fbdd4c2" category="section-title">Almacenamiento Hyper-V en LUN de NetApp</block>
  <block id="1d9f855d005777411eca330fd3c883a1" category="inline-link-macro">Aprovisionamiento en entornos SAN</block>
  <block id="d02671c8f4f293bf5688d34f44e5b87b" category="list-text">Aprovisionar una LUN de NetApp en la máquina del servidor de Hyper-V. Si quiere más información, consulte la sección «<block ref="9659d1fb07c4af2143cd165cb4b6822e" category="inline-link-macro-rx"></block>."</block>
  <block id="2771a58b129233810f1c389eedd2207f" category="list-text">Abra Hyper-V Manager en la sección Herramientas del Administrador de servidores.</block>
  <block id="ee15a170a42b1f37e0d70bf3b367f2ee" category="list-text">Seleccione el servidor de Hyper-V y haga clic en Configuración de Hyper-V.</block>
  <block id="b9cc0276ae5386d0ed5e9ed31ceb340d" category="list-text">Especifique la carpeta predeterminada para almacenar la máquina virtual y su disco como la LUN. Al hacerlo, se establece la ruta predeterminada como LUN para el almacenamiento de Hyper-V. Si desea especificar la ruta de forma explícita para una máquina virtual, puede hacerlo durante la creación de la máquina virtual.</block>
  <block id="72feffd29972ad4bc2fb9f5705e60864" category="inline-link-macro">Aprovisionamiento en entornos SMB</block>
  <block id="ace87f7890ab6204f4ef6abd0afaf28a" category="paragraph">Antes de comenzar los pasos enumerados en esta sección, revise la sección “<block ref="f9d723fa339e7968f40a99719593036c" category="inline-link-macro-rx"></block>.». Para configurar el almacenamiento de Hyper-V en el recurso compartido de CIFS de NetApp, lleve a cabo los siguientes pasos:</block>
  <block id="d3f9aa7fc4289533bdeb015bbd645a22" category="list-text">Especifique la carpeta predeterminada para almacenar la máquina virtual y su disco como el recurso compartido de CIFS. Al hacerlo, se define la ruta predeterminada como recurso compartido de CIFS para el almacenamiento de Hyper-V. Si desea especificar la ruta de forma explícita para una máquina virtual, puede hacerlo durante la creación de la máquina virtual.</block>
  <block id="a531c67c9d6be93b7864c891efc5480a" category="paragraph">Cada equipo virtual en Hyper-V puede, a su vez, proporcionarse con los LUN de NetApp y los recursos compartidos de CIFS que se proporcionaban al host físico. Este procedimiento es el mismo que para cualquier host físico. Los siguientes métodos se pueden usar para aprovisionar almacenamiento a una máquina virtual:</block>
  <block id="b7756c6e1b92d15f0367db534aa4fdc2" category="list-text">Añadir un LUN de almacenamiento mediante el iniciador FC dentro de la máquina virtual</block>
  <block id="dda418820dd5a8b649a681b73da4ba97" category="list-text">Agregar una LUN de almacenamiento mediante el iniciador iSCSI dentro de la máquina virtual</block>
  <block id="ee0537a6d83f8b83e99ac0b7b3d0af82" category="list-text">Agregar un disco físico en modo de paso a una máquina virtual</block>
  <block id="a842c008b079c30c444ab4c9d78524e6" category="list-text">Agregar VHD/VHDX a una máquina virtual desde el host</block>
  <block id="50fba9282607c757ab39ad110cd0fde4" category="list-text">Cuando un equipo virtual y sus datos se almacenan en el almacenamiento de NetApp, NetApp recomienda ejecutar la deduplicación de NetApp a intervalos regulares a nivel de volumen. Esta práctica provoca un ahorro de espacio considerable cuando se alojan equipos virtuales idénticos en un recurso compartido de CSV o SMB. La deduplicación se ejecuta en la controladora de almacenamiento y no afecta al rendimiento del sistema host ni de los equipos virtuales.</block>
  <block id="6421e175d1ef977d73a52a6a90626eb8" category="list-text">Cuando utilice LUN iSCSI para Hyper-V, asegúrese de habilitarlo<block ref="0a6a9fc5db5706ee3ac704f21780cb07" prefix=" " category="inline-code"></block> y..<block ref="d8ed6ba87266cde713ed7ac6c907ff7e" prefix=" " category="inline-code"></block> En la configuración del firewall en el host de Hyper-V. De este modo, se permite que el tráfico iSCSI pase hacia y desde el host de Hyper-V y el controlador de NetApp.</block>
  <block id="6b4ecf09c5310b6b905c86b910a57012" category="list-text">NetApp recomienda desactivar la opción Permitir que el sistema operativo de gestión comparta este adaptador de red para el conmutador virtual de Hyper-V. Al hacerlo, se crea una red dedicada para las máquinas virtuales.</block>
  <block id="d39c100d166d09a8e573d5c4980c0674" category="list-text">El aprovisionamiento de un equipo virtual mediante Fibre Channel requiere un N_Port ID Virtualizationâ€“enabled FC HBA. Se admite un máximo de cuatro puertos FC.</block>
  <block id="8f20505d01de58b8e00048581d2d7244" category="list-text">Si el sistema host se configura con varios puertos FC y se presenta a la máquina virtual, debe instalarse MPIO en la máquina virtual para habilitar el acceso multivía.</block>
  <block id="e003acc3eceda748125d4c7bf41052e7" category="list-text">Los discos de paso a través no se pueden aprovisionar al host si se está utilizando MPIO en ese host, ya que los discos de paso no son compatibles con MPIO.</block>
  <block id="aa7c5f68a034b43fa3bafa90ea6a6c2b" category="list-text">El disco utilizado para los archivos VHD/VHDx debe utilizar el formato 64K para la asignación.</block>
  <block id="bc8be72fdc9d6054f356bb2b7f80fd12" category="inline-link">Matriz de interoperabilidad de NetApp</block>
  <block id="34de012edea0d70cf76edda88efae407" category="list-text">Para obtener información sobre los HBA de FC, consulte<block ref="03bbc27528de80852aa5d0d1250f8442" category="inline-link-rx"></block>.</block>
  <block id="5aa08a9ab39b4ff0ad3ec476f9c0a7a9" category="inline-link">Descripción general de Fibre Channel virtual para Hyper-V</block>
  <block id="17d2fe1a1b42dbc4c914a82ff9a06cbf" category="list-text">Para obtener más información acerca de Fibre Channel virtual, consulte Microsoft<block ref="ffefda586e5fabc71f0e43393b116d4c" category="inline-link-rx"></block> página.</block>
  <block id="fadcc8cea091e223f4d4a49a0c02b9cb" category="paragraph">Microsoft ODX, también conocido como copia de datos descargados, habilita transferencias de datos directas dentro del dispositivo de almacenamiento o entre dispositivos de almacenamiento compatibles sin transferir los datos a través de la computadora del host. NetApp ONTAP admite la función ODX para los protocolos CIFS y SAN. ODX puede mejorar el rendimiento potencialmente si las copias se encuentran en el mismo volumen, reducir la utilización de la CPU y la memoria en el cliente y reducir la utilización de ancho de banda de I/O de la red.</block>
  <block id="6736b7040d05d12679268b13fae93377" category="paragraph">Con ODX, es más rápido y eficiente copiar archivos dentro de los recursos compartidos SMB, dentro de las LUN y entre los recursos compartidos SMB y las LUN si está en el mismo volumen. Este método es más útil en una situación para la que se necesitan varias copias de la imagen maestra de un sistema operativo (VHD/VHDX) en el mismo volumen. Se pueden realizar varias copias de la misma imagen maestra en un tiempo considerablemente menor si las copias se encuentran en el mismo volumen. ODX también se aplica en almacenamiento de Hyper-V para mover almacenamiento de máquinas virtuales.</block>
  <block id="53003aec095203ae2075a8150e8ead4e" category="paragraph">Si la copia se realiza entre volúmenes, es posible que no haya un aumento significativo del rendimiento en comparación con las copias basadas en host.</block>
  <block id="80f704dacc785527bc57a7851889f8b3" category="paragraph">Para habilitar la función ODX en CIFS, ejecute los siguientes comandos de la CLI en la controladora de almacenamiento de NetApp:</block>
  <block id="9c8ee5398727fdb2573f25e0535d686d" category="list-text">Habilite ODX para CIFS.
#establecer el nivel de privilegio para el diagnóstico
cluster::&gt; diagnóstico set -privilege</block>
  <block id="574eac1c36a4e6832136e6cf051cc147" category="list-text">Para habilitar la función ODX en SAN, ejecute los siguientes comandos de la CLI en la controladora de almacenamiento de NetApp:
#establecer el nivel de privilegio para el diagnóstico
cluster::&gt; diagnóstico set -privilege</block>
  <block id="ea782640f98557c065767874aded89e7" category="list-text">Para CIFS, ODX solo está disponible cuando el cliente y el servidor de almacenamiento admiten SMB 3,0 y la función ODX.</block>
  <block id="c2dca5b1810c92e856cc04f6f2a88586" category="list-text">En entornos SAN, ODX solo está disponible cuando tanto el cliente como el servidor de almacenamiento admiten la función ODX.</block>
  <block id="f41987326c80680c60b359697adfa4cc" category="inline-link">Mejora del rendimiento de Microsoft Remote Copy</block>
  <block id="fcb65106bb1fd73c88cf9528cb579ed5" category="inline-link">Transferencias de datos descargados de Microsoft</block>
  <block id="65994fb0563b49bfe0e59359edf5513d" category="paragraph">Para obtener más información acerca de ODX, consulte<block ref="29f9e15a4017cdf9ae06e098a7a28381" category="inline-link-rx"></block> y..<block ref="f884f78ec6d36ebebd3d9fc57e8c3734" category="inline-link-rx"></block> .</block>
  <block id="20029977789a74e480e6f8d14c07b48a" category="paragraph">Los clusters de conmutación por error proporcionan alta disponibilidad y escalabilidad a los servidores de Hyper-V. Un cluster de recuperación tras fallos es un grupo de servidores Hyper-V independientes que funcionan conjuntamente para aumentar la disponibilidad y la escalabilidad de los equipos virtuales.</block>
  <block id="982112e1f4d4e4c9d7ded4eff9e38200" category="paragraph">Los servidores en clúster de Hyper-V (denominados nodos) están conectados por la red física y por el software de clúster. Estos nodos utilizan almacenamiento compartido para almacenar los archivos de la máquina virtual, lo que incluye archivos de configuración, archivos de disco duro virtual (VHD) y copias Snapshot. El almacenamiento compartido puede ser un recurso compartido SMB/CIFS de NetApp o un volumen compartido en cluster encima de una LUN de NetApp, como se muestra en la figura 6. Este almacenamiento compartido proporciona un espacio de nombres consistente y distribuido a los que todos los nodos del cluster pueden acceder de forma simultánea. Por lo tanto, si un nodo falla en el clúster, el otro nodo proporciona servicio mediante un proceso llamado conmutación al respaldo. Los clústeres de conmutación por error se pueden gestionar mediante el complemento Administrador de clúster de conmutación por error y los cmdlets de Windows PowerShell de agrupación en clúster de conmutación por error.</block>
  <block id="1b5f8c43b61e9249f3c82e39f9649160" category="section-title">Volúmenes compartidos de clúster</block>
  <block id="c3e01cf065f02a4feb72ac75d534fa2e" category="paragraph">Los volúmenes compartidos en cluster permiten que múltiples nodos de un clúster de conmutación por error tengan acceso de lectura/escritura simultáneamente a la misma LUN de NetApp que se aprovisiona como volumen NTFS o ReFS. Con los volúmenes compartidos en cluster, los roles en cluster pueden relevar rápidamente de un nodo a otro sin necesidad de cambiar la propiedad de la unidad, ni de desmontar y montar un volumen. Los volúmenes compartidos en cluster también simplifican la gestión de un número potencialmente grande de LUN en un clúster de recuperación tras fallos. Los CSV proporcionan un sistema de archivos en cluster de uso general que se coloca por encima de NTFS o ReFS.</block>
  <block id="92f30d2ddb9cc7fbf92029307c6dbe98" category="inline-image-macro">Cluster de recuperación tras fallos de Hyper-V y NetApp, width=624,height=271</block>
  <block id="873c6f06eca771e8f918112aaf233170" category="paragraph"><block ref="873c6f06eca771e8f918112aaf233170" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c1d777ad1068fcefc91b140eba543bf" category="list-text">NetApp recomienda desactivar la comunicación del clúster en la red iSCSI para evitar que la comunicación del clúster interno y el tráfico de CSV fluyan por la misma red.</block>
  <block id="b53334a2710cb18a4e717240b312807f" category="list-text">NetApp recomienda tener rutas de red redundantes (varios switches) para ofrecer resiliencia y calidad de servicio.</block>
  <block id="f251ad17cf6806e0e3667148cda40e43" category="list-text">Los discos utilizados para CSV deben particionarse con NTFS o ReFS. Los discos formateados con FAT o FAT32 no se pueden utilizar para un CSV.</block>
  <block id="161432666d89990b3c1112afe633ff8e" category="list-text">Los discos utilizados para CSV deben utilizar el formato 64K para la asignación.</block>
  <block id="36cf7806cbb55a382b64bd9b65b2939b" category="inline-link-macro">Implemente el cluster Hyper-V</block>
  <block id="390167e852a9bfc97d6ed31462a05b2f" category="paragraph">Si desea obtener información sobre la implantación de un cluster de Hyper-V, consulte el apéndice B: <block ref="8a150f92c22920868769b8738759e23d" category="inline-link-macro-rx"></block>.</block>
  <block id="32730f5882545bbe6a81ac49049968f0" category="section-title">Migración en vivo de Hyper-V: Migración de equipos virtuales</block>
  <block id="d7f2f7b4116921a3d8d4b8e5892420a7" category="paragraph">A veces, es necesario durante la vida útil de las máquinas virtuales para moverlas a un host diferente en el clúster de Windows. Hacerlo puede ser necesario si el host se está quedando sin recursos del sistema o si el host es necesario reiniciarse por razones de mantenimiento. Del mismo modo, podría ser necesario mover un equipo virtual a otro LUN o recurso compartido de SMB. Esto puede ser necesario si el LUN o el recurso compartido actual se está quedando sin espacio o tiene una rentabilidad inferior al rendimiento esperado. La migración en vivo de Hyper-V mueve las máquinas virtuales en ejecución de un servidor Hyper-V físico a otro sin afectar la disponibilidad de las máquinas virtuales a los usuarios. Puede migrar equipos virtuales activos entre servidores de Hyper-V que forman parte de un clúster de conmutación al nodo de respaldo o entre servidores de Hyper-V independientes que no forman parte de ningún cluster.</block>
  <block id="92829881718abd402c6c73b34be944da" category="section-title">Migración activa en un entorno en cluster</block>
  <block id="e8881f62af8c1495a1f4869b97e95505" category="paragraph">Las máquinas virtuales pueden moverse sin problemas entre los nodos de un clúster. La migración de VM es instantánea porque todos los nodos del clúster comparten el mismo almacenamiento y tienen acceso a la máquina virtual y a su disco. La siguiente figura muestra la migración activa en un entorno en cluster.</block>
  <block id="8cda6697809dd81e112a12c43f6f89f4" category="inline-image-macro">Migración dinámica en un entorno en clúster,width=580,height=295</block>
  <block id="d668981cacbbf412643956687c03fc0d" category="paragraph"><block ref="d668981cacbbf412643956687c03fc0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4797d6b2727c9902e114fa95ed076fc2" category="list-text">Disponga de un puerto dedicado para el tráfico de migración dinámica.</block>
  <block id="7c021f26d9ab2ec9934fc24d167ceaa4" category="list-text">Disponga de una red de migración activa de host dedicado para evitar problemas relacionados con la red durante la migración.</block>
  <block id="a725857d2338d476a409fd1fb67b1f56" category="inline-link-macro">Apéndice C: Implementación de la migración en vivo de Hyper-V en un entorno en cluster</block>
  <block id="45f7134e494aae2cba3b60b3fe769caa" category="paragraph">Para obtener más información sobre la puesta en marcha de la migración en vivo en un entorno en clúster, consulte <block ref="b584c2d96a6b139fbe05976580afae94" category="inline-link-macro-rx"></block>.</block>
  <block id="07cb5e9c694ee3a8dcc475a38371ad5c" category="paragraph">Puede migrar en vivo una máquina virtual entre dos servidores de Hyper-V independientes y no agrupados en clúster. Este proceso puede utilizar una migración dinámica sin uso compartido o sin uso compartido.</block>
  <block id="e71df2d29ba96f271b3da69baa09714f" category="list-text">En la migración dinámica compartida, la máquina virtual se almacena en un recurso compartido de SMB. Por lo tanto, cuando migra una máquina virtual en vivo, el almacenamiento de la máquina virtual permanece en el recurso compartido SMB central para que el otro nodo pueda acceder de forma instantánea, como se muestra en la siguiente figura.</block>
  <block id="87b94a12a79a6dbc08decd540810bb26" category="inline-image-macro">Migración dinámica compartida en un entorno no agrupado,width=331,height=271</block>
  <block id="f442dd66197cc65f49ad8ec9c50e8076" category="paragraph"><block ref="f442dd66197cc65f49ad8ec9c50e8076" category="inline-image-macro-rx" type="image"></block></block>
  <block id="207d1150dff7488c7f8bfafe7036a222" category="list-text">En la migración en vivo sin compartir, cada servidor de Hyper-V tiene su propio almacenamiento local (puede ser un recurso compartido SMB, una LUN o DAS) y el almacenamiento del equipo virtual es local en su servidor de Hyper-V. Cuando se migra una máquina virtual activa, el almacenamiento de la máquina virtual se refleja en el servidor de destino a través de la red cliente y, a continuación, se migra la máquina virtual. El equipo virtual almacenado en DAS, un LUN o un recurso compartido de SMB/CIFS puede moverse a un recurso compartido SMB/CIFS en el otro servidor Hyper-V, tal como se muestra en la siguiente figura. También se puede trasladar a una LUN, como se muestra en la segunda figura.</block>
  <block id="8df9231bc9de1239aa92c6a9d1116db4" category="inline-image-macro">Migración activa sin elementos compartidos en un entorno no en clúster a recursos compartidos de SMB,width=624,height=384</block>
  <block id="c6acea552c059bcc9ccb207ad6b8cee1" category="paragraph"><block ref="c6acea552c059bcc9ccb207ad6b8cee1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="559b3e5c1d4ea7b8f3eaf8cbc0e4155e" category="inline-image-macro">Migración activa sin elementos compartidos en un entorno no en clúster a LUN,width=624,height=384</block>
  <block id="3d0d53528ff4699abb6fab11a6bf756d" category="paragraph"><block ref="3d0d53528ff4699abb6fab11a6bf756d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b19cfe6ea61be3a5ed442a8a975a6406" category="inline-link-macro">Apéndice D: Implemente Hyper-V Live Migration fuera de un entorno en cluster</block>
  <block id="b7c375b5c0ef95eecd45b0a4614c2c68" category="paragraph">Para obtener más información sobre la puesta en marcha de la migración en vivo fuera de un entorno en clúster, consulte <block ref="52490817f607e6265e62f91bb3c3799a" category="inline-link-macro-rx"></block>.</block>
  <block id="061731a1a3266df0eda8efe87e649dbb" category="section-title">Migración dinámica de almacenamiento de Hyper-V</block>
  <block id="ecaa2ddd351a3f5a9704aaea9a13abaf" category="paragraph">Durante la vida útil de un equipo virtual, es posible que deba mover el almacenamiento de un equipo virtual (VHD/VHDX) a otro LUN o recurso compartido de SMB. Esto puede ser necesario si el LUN o el recurso compartido actual se está quedando sin espacio o tiene una rentabilidad inferior al rendimiento esperado.</block>
  <block id="1f976b42d4bb2c18a943d132252997d6" category="paragraph">El LUN o el recurso compartido que aloja actualmente el equipo virtual puede quedarse sin espacio, reasignarse o reducir el rendimiento. En estas circunstancias, el equipo virtual se puede mover sin necesidad de sufrir tiempos de inactividad a otro LUN o recurso compartido en un volumen, agregado o clúster diferentes. Este proceso es más rápido si el sistema de almacenamiento tiene capacidad de copia/descarga. Los sistemas de almacenamiento de NetApp son compatibles con la descarga de copias de forma predeterminada para los entornos CIFS y SAN.</block>
  <block id="bbaae8d50419225b92db654852107b29" category="paragraph">La función ODX realiza copias de archivos completos o secundarios entre dos directorios que residen en servidores remotos. Una copia se crea copiando datos entre los servidores (o el mismo servidor si los archivos de origen y de destino están en el mismo servidor). La copia se crea sin que el cliente lea los datos del origen o escriba en el destino. Este proceso reduce el uso de memoria y procesador para el cliente o el servidor y minimiza el ancho de banda de E/S de la red. La copia es más rápida si está dentro del mismo volumen. Si la copia se realiza entre volúmenes, es posible que no haya un aumento significativo del rendimiento en comparación con las copias basadas en host. Antes de continuar con una operación de copia en el host, confirme que los ajustes de descarga de copia estén configurados en el sistema de almacenamiento.</block>
  <block id="843c69ad55fb8bac002321dee51a4770" category="paragraph">Cuando se inicia la migración activa de almacenamiento de equipos virtuales desde un host, se identifican el origen y el destino, y la actividad de copia se descarga al sistema de almacenamiento. Debido a que el sistema de almacenamiento realiza la actividad, el uso de la CPU, la memoria o la red del host es insignificante.</block>
  <block id="27d2fda0da241bb37583fba1af25cd09" category="paragraph">Las controladoras de almacenamiento de NetApp admiten los siguientes escenarios ODX diferentes:</block>
  <block id="48a53ae81ff0c821cba0e11bd2383bf3" category="list-text">*IntraSVM.* Los datos son propiedad de la misma SVM:</block>
  <block id="ec3d44fd176b5d51f4f60dff319cea6b" category="list-text">*Intravolume, intranode.* Los archivos de origen y destino o LUN residen dentro del mismo volumen. La copia se realiza con la tecnología de archivos FlexClone, lo que proporciona ventajas adicionales de rendimiento de la copia remota.</block>
  <block id="980ca02c9855a39b86e9fbf5acd955b4" category="list-text">*Intervolume, intranode.* Los archivos de origen y destino o LUN están en diferentes volúmenes que están en el mismo nodo.</block>
  <block id="8a4d33d47a803a1796b431a0df5a8016" category="list-text">*Intervolumen, internodos.* Los archivos de origen y destino o LUN se encuentran en diferentes volúmenes ubicados en diferentes nodos.</block>
  <block id="81d5c73c98489729a8f91afe4936dbd2" category="list-text">*InterSVM.* Los datos son propiedad de diferentes SVM.</block>
  <block id="ea9799ac312b9050a36864c98be8f73f" category="list-text">*Intervolumen, internodos.* Los archivos de origen y destino o LUN están en diferentes volúmenes que están en diferentes nodos.</block>
  <block id="3693f5a47e6bfc0762c5b2c174e653be" category="list-text">*Intercluster.* A partir de ONTAP 9,0, ODX también es compatible con transferencias de LUN de interconexión de clústeres en entornos SAN. ODX entre clústeres solo se admite para protocolos SAN, no para SMB.</block>
  <block id="8e459b300b9b5f521f0cc464bc1a7137" category="paragraph">Una vez finalizada la migración, las políticas de backup y replicación se deben volver a configurar para reflejar el nuevo volumen que contiene las máquinas virtuales. No se puede utilizar ninguna copia de seguridad anterior realizada.</block>
  <block id="9cabe6ff649f754acc3a863e852828e8" category="paragraph">El almacenamiento VM (VHD/VHDX) se puede migrar entre los siguientes tipos de almacenamiento:</block>
  <block id="49a63af944b72883bd718eb8c8ff01c8" category="list-text">Das y el recurso compartido de SMB</block>
  <block id="85fbd1c03217c7c62157aac97d16ecf9" category="list-text">Das y LUN</block>
  <block id="876c6424f49d57e8be596b8caadf5a61" category="list-text">Un recurso compartido de SMB y un LUN</block>
  <block id="1518cb86dc78f6083ed8b1d292b87ed8" category="list-text">Entre las LUN</block>
  <block id="7257cd316393b74da62868c27652c6c0" category="list-text">Entre recursos compartidos de SMB</block>
  <block id="17785c3ef4bbda06e9db9c15908dc0c6" category="inline-image-macro">Migración activa del almacenamiento Hyper-V, width=339, height=352</block>
  <block id="eccf932baf8f6019c69035ea09e26c2c" category="paragraph"><block ref="eccf932baf8f6019c69035ea09e26c2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="319572d5872182625e2834b8615517f2" category="inline-link-macro">Apéndice E: Implemente Hyper-V Storage Live Migration</block>
  <block id="04a136595cb35e5c42e3ea764e9cd259" category="paragraph">Para obtener más información sobre la implementación de una migración activa de almacenamiento, consulte <block ref="e0d213bcf75379722df0c1b3af5063a2" category="inline-link-macro-rx"></block>.</block>
  <block id="86174aa4d77b1853f72b6e1a6f32c753" category="paragraph">Hyper-V Replica replica las máquinas virtuales de Hyper-V desde un sitio primario para replicar las máquinas virtuales en un sitio secundario, lo que proporciona de forma asíncrona recuperación ante desastres para las máquinas virtuales. El servidor Hyper-V del centro principal que aloja los equipos virtuales se conoce como servidor primario; el servidor Hyper-V del centro secundario que recibe las máquinas virtuales replicadas se conoce como servidor de réplica. En la siguiente figura se muestra un ejemplo de ejemplo de réplica de Hyper-V. Puede utilizar la réplica de Hyper-V para equipos virtuales entre servidores de Hyper-V que forman parte de un cluster de conmutación por error o entre servidores de Hyper-V independientes que no forman parte de ningún cluster.</block>
  <block id="28e90920ae557bd81a8056f93fb4b0ee" category="inline-image-macro">Réplica Hyper-V, anchura = 624 mm, altura = 201 mm</block>
  <block id="4fc821418df9e4488323cc70692d5083" category="paragraph"><block ref="4fc821418df9e4488323cc70692d5083" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c340dc334134096f68b880b42a8692c" category="section-title">Replicación</block>
  <block id="b9bce4677e5b3ea1c310fddca6123c9f" category="paragraph">Después de activar la réplica de Hyper-V para una máquina virtual en el servidor primario, la replicación inicial crea una máquina virtual idéntica en el servidor de réplica. Después de la replicación inicial, Hyper-V Replica mantiene un archivo de registro para los discos duros virtuales de la máquina virtual. El archivo de registro se reproduce en orden inverso al VHD de réplica de acuerdo con la frecuencia de replicación. Este registro y el uso de orden inverso garantizan que los cambios más recientes se almacenan y replican de forma asíncrona. Si la replicación no ocurre en línea con la frecuencia esperada, se emite una alerta.</block>
  <block id="ec9fc8b78968b1d0daadf7598a4e2ab6" category="paragraph">Hyper-V Replica admite replicación ampliada en la que se puede configurar un servidor de réplica secundario para la recuperación ante desastres. Se puede configurar un servidor de réplica secundario para que el servidor de réplica reciba los cambios en los equipos virtuales de réplica. En un escenario de replicación ampliada, los cambios en los equipos virtuales primarios en el servidor primario se replican en el servidor de réplica. A continuación, los cambios se replican en el servidor de réplicas ampliado. Los equipos virtuales se pueden conmutar por error al servidor de réplica ampliado solo cuando dejan de funcionar los servidores primario y de réplica.</block>
  <block id="a3f36244dba1d116dac91134dda3b9db" category="paragraph">La conmutación por error no es automática, el proceso debe activarse manualmente. Existen tres tipos de conmutación al nodo de respaldo:</block>
  <block id="f8487dcb10cf762a4d3f28da4635bd2a" category="list-text">*Test failover.* Este tipo se utiliza para verificar que una VM de réplica puede iniciarse correctamente en el servidor de réplica y se inicia en la VM de réplica. Este proceso crea una VM de prueba duplicada durante la recuperación tras fallos y no afecta a la replicación regular de producción.</block>
  <block id="09f4056fddf2108616fe7bf3194540ba" category="list-text">*Failover planificado.* Este tipo se utiliza para conmutar las VM durante el tiempo de inactividad planificado o cortes esperados. Este proceso se inicia en la máquina virtual principal, la cual debe desactivarse en el servidor primario antes de ejecutar una conmutación al respaldo planificada. Después de que la máquina conmute por error, Hyper-V Replica inicia la VM de réplica en el servidor de réplica.</block>
  <block id="0ad8df7e141c378e7ad1debc5721cecf" category="list-text">*Failover no planificado.* Este tipo se utiliza cuando se producen cortes inesperados. Este proceso se inicia en el equipo virtual de réplica y solo se debe usar si falla el equipo primario.</block>
  <block id="d8afbc541b39d23648c823057cffe3a5" category="section-title">Recuperación</block>
  <block id="53b169078c7c6ecee01802b49b675c54" category="paragraph">Al configurar la replicación para una máquina virtual, puede especificar el número de puntos de recuperación. Los puntos de recuperación representan puntos temporales a partir del cual se pueden recuperar datos desde una máquina replicada.</block>
  <block id="31e96602ee944674a6ee07052bc6552a" category="inline-link-macro">Implemente la réplica de Hyper-V fuera de un entorno en clúster</block>
  <block id="fd09d6344b235cdd2863e5027a2716e8" category="list-text">Para obtener información sobre la implementación de la réplica de Hyper-V fuera de un entorno en clúster, consulte la sección «<block ref="376f647d5b86bfed7dfffbd7c50e7d1e" category="inline-link-macro-rx"></block>."</block>
  <block id="23b6fa788d78e992f84931ddd3cef629" category="inline-link-macro">Implementar la réplica de Hyper-V en un entorno en clúster</block>
  <block id="a3538f75015c27ee42ac1f1c0b535a61" category="list-text">Para obtener información sobre la implementación de la réplica de Hyper-V en un entorno en clúster, consulte la sección «<block ref="e81baea973ee37d0bb61473f872cfb84" category="inline-link-macro-rx"></block>."</block>
  <block id="57a0eb5139789611b6b213a5f3fa5412" category="summary">Este apéndice describe la puesta en marcha de un clúster Hyper-V de alta disponibilidad en el almacenamiento de NetApp.</block>
  <block id="e286734bc8843e9f46f2812455917ea5" category="paragraph">En este apéndice se describe la puesta en marcha de un clúster Hyper-V.</block>
  <block id="fa0edb5816386e7e049e5c77d9cdb367" category="list-text">Existen al menos dos servidores de Hyper-V conectados entre sí.</block>
  <block id="a7bad6853c4b367ee245a88ab3195af0" category="list-text">Hay al menos un switch virtual configurado en cada servidor de Hyper-V.</block>
  <block id="ebdc83ef4c8d2993b67ae667bcb0cd50" category="list-text">La función de cluster de conmutación por error está activada en cada servidor de Hyper-V.</block>
  <block id="65e98c7fa4c69ce7bd0d182ede13991a" category="list-text">Los recursos compartidos de SMB o volúmenes compartidos en cluster se utilizan como almacenamiento compartido para almacenar equipos virtuales y sus discos para la agrupación en cluster de Hyper-V.</block>
  <block id="22f4b86bcfebce25bb61ddd3ee8d6f7f" category="list-text">El almacenamiento no se debe compartir entre clústeres diferentes. Solo debe tener un recurso compartido CSV/CIFS por clúster.</block>
  <block id="c2377be670723e586c1324a4a12607a5" category="list-text">Si el recurso compartido de SMB se utiliza como almacenamiento compartido, se deben configurar los permisos en el recurso compartido de SMB para otorgar acceso a las cuentas de equipo de todos los servidores de Hyper-V del clúster.</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="section-title">Puesta en marcha</block>
  <block id="3627e168149dcf185918371a7adb5680" category="list-text">Inicie sesión en uno de los servidores de Windows Hyper-V como miembro del grupo de administradores.</block>
  <block id="0cc618f3a272a1fc35b193fc6efa1122" category="list-text">Inicie Server Manager**.**</block>
  <block id="f30124a5c887cea53cc6397d6c9e40a6" category="list-text">En la sección Herramientas, haga clic en Administrador de clústeres de conmutación por error.</block>
  <block id="54be8be618f1803d7fc1579e2fad9a6c" category="list-text">Haga clic en el menú Create Cluster from Actions.</block>
  <block id="6bcb4b141d153c7cee9fc6b2633a703c" category="list-text">Proporcione los detalles del servidor Hyper-V que forma parte de este cluster.</block>
  <block id="58ee4cb30b6b0dd4665be3c60c65e0f1" category="list-text">Valide la configuración del clúster. Seleccione Yes when prompted for cluster configuration validation y seleccione las pruebas necesarias para validar si los servidores de Hyper-V cumplen los requisitos previos para formar parte del cluster.</block>
  <block id="8a2ec0e7f4a4ecb848794b1aba47839b" category="list-text">Una vez que la validación se realiza correctamente, se inicia el asistente Create Cluster. En el asistente, proporcione el nombre del clúster y la dirección IP del clúster para el nuevo clúster. A continuación, se crea un nuevo cluster de recuperación tras fallos para el servidor de Hyper-V.</block>
  <block id="ce73c2e33e5d228466b28690400c8c14" category="list-text">Haga clic en el clúster recién creado en el Administrador de clústeres de conmutación al nodo de respaldo y gestiónelo.</block>
  <block id="904aa93ec80c2a5ca93ed8ace0e52220" category="list-text">Defina almacenamiento compartido para que utilice el clúster. Puede ser un recurso compartido de SMB o un volumen compartido en clúster.</block>
  <block id="d69f1a0923232e84331ec6d30315124c" category="list-text">Si se utiliza un recurso compartido de SMB como almacenamiento compartido, no es necesario realizar pasos especiales.</block>
  <block id="3b045123cc5f216c3aa18614a4cabf45" category="list-text">Configurar un recurso compartido de CIFS en una controladora de almacenamiento de NetApp. Para ello, consulte la sección «<block ref="f9d723fa339e7968f40a99719593036c" category="inline-link-macro-rx"></block>".</block>
  <block id="c0edb31f94845e5a1f67d2f79db4408f" category="list-text">Para usar un CSV como almacenamiento compartido, complete los siguientes pasos:</block>
  <block id="dfd86a662700832b7931201c3abdf13f" category="list-text">Configure LUN en una controladora de almacenamiento de NetApp. Para ello, consulte la sección «Provisionamiento en entornos SAN».</block>
  <block id="49873862ecc43076ac3a4de327f3efdb" category="list-text">Asegúrese de que todos los servidores Hyper-V del cluster de recuperación tras fallos pueden ver las LUN de NetApp. Para hacerlo con todos los servidores de Hyper-V que forman parte del cluster de recuperación tras fallos, asegúrese de que sus iniciadores se hayan añadido al iGroup en el almacenamiento de NetApp. También asegúrese de que se detectan sus LUN y asegúrese de que MPIO está habilitado.</block>
  <block id="4fe4609b22418e84ea85667368c2e742" category="list-text">En cualquiera de los servidores de Hyper-V del cluster, realice los siguientes pasos:</block>
  <block id="de824a62ee353b5481bb4eeb5c13d899" category="list-text">Ponga el LUN en línea, inicialice el disco, cree un nuevo volumen sencillo y formatee con NTFS o ReFS.</block>
  <block id="340f3a4d7fad2c45eadfe69d5b56ce38" category="list-text">En el Administrador de clústeres de conmutación por error, expanda el clúster, expanda Almacenamiento, haga clic con el botón derecho en Discos y, a continuación, haga clic en Agregar discos. Al hacerlo, se abre el asistente para agregar discos a un clúster mostrando la LUN como un disco. Haga clic en OK para añadir la LUN como disco.</block>
  <block id="a685089b1d550296b9407033a7411217" category="list-text">Ahora el LUN se denomina Clustered Disk y se muestra como Almacenamiento disponible en Discos.</block>
  <block id="2970ece9496766e632c3e2c23145cfcf" category="list-text">Haga clic con el botón derecho en LUN (Clustered Disk) y haga clic en Add to Cluster Shared Volumes. Ahora la LUN se muestra como un volumen compartido en clúster.</block>
  <block id="c473a447596255e12e2e772012c42b17" category="list-text">El CSV es visible y accesible simultáneamente desde todos los servidores Hyper-V del cluster de conmutación por error en su ubicación local C:\ClusterStorage\.</block>
  <block id="b735c11dd95d1b42d173adb43b3a1df2" category="list-text">Crear un equipo virtual de alta disponibilidad:</block>
  <block id="27f977a1c170f87899be67daf203a268" category="list-text">En el Administrador de clústeres de conmutación por error, seleccione y expanda el clúster que creó anteriormente.</block>
  <block id="569f3bea800216a760ac935540b72c1e" category="list-text">Haga clic en Roles y, a continuación, en Máquinas virtuales en Acciones. Haga clic en New Virtual Machine.</block>
  <block id="4380a9c5c56776fad0f4492a0d3c63f5" category="list-text">Seleccione el nodo del clúster donde debe residir la máquina virtual.</block>
  <block id="a8be7e73ae88a070ad15a4a6f6d515fe" category="list-text">En el asistente Virtual Machine Creation, proporcione el almacenamiento compartido (recurso compartido de SMB o CSV) como la ruta para almacenar la máquina virtual y sus discos.</block>
  <block id="9da4e10b0da989c65844cd59ed2a0991" category="list-text">Utilice Hyper-V Manager para establecer el almacenamiento compartido (recurso compartido de SMB o CSV) como ruta predeterminada para almacenar el equipo virtual y sus discos para un servidor de Hyper-V.</block>
  <block id="064cd683bf50cb65205de6b9298201b3" category="list-text">Probar la recuperación tras fallos no planificada. Detenga el servicio de clúster en el servidor propietario de la máquina virtual.</block>
  <block id="c7bfaead2ee1aea320b1d91da7ba31d7" category="summary">Obtenga información sobre el almacenamiento de NetApp y el entorno de Windows Server</block>
  <block id="5c8c98e7f403562b754941b4d0c17f65" category="paragraph">Como se menciona en la <block ref="ba92ae7cf3bb4a058d2b231c16067714" category="inline-link-macro-rx"></block>, Las controladoras de almacenamiento NetApp proporcionan una arquitectura realmente unificada que admite protocolos de archivos, bloques y objetos. Esto incluye SMB/CIFS, NFS, NVMe/TCP, NVMe/FC, iSCSI, FC (FCP) y S3, y crean un acceso unificado a clientes y hosts. El mismo controlador de almacenamiento puede ofrecer simultáneamente un servicio de almacenamiento basado en bloques en forma de LUN SAN y servicio de archivos como NFS y SMB/CIFS. ONTAP también está disponible como cabina All SAN (ASA) que optimiza el acceso del host a través de multivía activo-activo simétrico con iSCSI y FCP, mientras que los sistemas ONTAP unificados utilizan accesos múltiples activo-activo asimétrico. En ambos modos, ONTAP utiliza ANA para la gestión multivía de NVMe over Fabrics (NVMe-oF).</block>
  <block id="98ae8a9e34d3f73da98da55a46678554" category="paragraph">Una controladora de almacenamiento de NetApp que ejecute el software ONTAP puede admitir las siguientes cargas de trabajo en un entorno Windows Server:</block>
  <block id="b39d47dbcb48e2064ea0978dea0793ae" category="list-text">Equipos virtuales alojados en recursos compartidos de SMB 3,0 disponibles continuamente</block>
  <block id="be1d5dd432dd053b97f14401fc060813" category="list-text">Equipos virtuales alojados en LUN de volumen compartido de clúster (CSV) que se ejecutan en iSCSI o FC</block>
  <block id="fc27a7625c9ffb2fe9dd539f1960c978" category="list-text">Bases de datos de SQL Server en recursos compartidos de SMB 3,0</block>
  <block id="658f98073361780ad39f8c0d45eca2f8" category="list-text">Bases de datos de SQL Server en NVMe-oF, iSCSI o FC</block>
  <block id="d2ed21657f98def30346884514f11cce" category="list-text">Otras cargas de trabajo de aplicaciones</block>
  <block id="b7da44d6d6578097c611512549b04555" category="paragraph">Además, las funciones de eficiencia del almacenamiento de NetApp como la deduplicación, las copias FlexClone(R) de NetApp, la tecnología Snapshot de NetApp, thin provisioning, compresión, además, el almacenamiento por niveles aporta un valor significativo para las cargas de trabajo que se ejecutan en Windows Server.</block>
  <block id="b76d8ce5a4b5758745257d0223494701" category="section-title">Gestión de datos de ONTAP</block>
  <block id="37b74b1418c82d2f0f3a093c4da8e7de" category="paragraph">ONTAP es un software de gestión que se ejecuta en una controladora de almacenamiento de NetApp. Se conoce como un nodo, una controladora de almacenamiento NetApp es un dispositivo de hardware con un procesador, RAM y NVRAM. El nodo se puede conectar a unidades de disco SATA, SAS o SSD, o a una combinación de dichas unidades.</block>
  <block id="16e8274a6170bfb8f7a4b80869edaca0" category="paragraph">Varios nodos se agregan en un sistema en clúster. Los nodos del clúster se comunican entre sí continuamente para coordinar las actividades del clúster. Los nodos también pueden mover datos de un nodo a otro de manera transparente utilizando rutas redundantes a una red de clúster dedicada que consta de dos switches Ethernet de 10Gb Gb. Los nodos del clúster pueden sustituirse entre sí para proporcionar alta disponibilidad durante cualquier escenario de conmutación por error. Los clústeres se administran en todo el clúster en lugar de por nodo y los datos se proporcionan desde una o varias máquinas virtuales de almacenamiento (SVM). Un clúster debe tener al menos una SVM para suministrar datos.</block>
  <block id="a93b9d090163c0668a090fac714f7578" category="paragraph">La unidad básica de un clúster es el nodo y los nodos se añaden al clúster como parte de un par de alta disponibilidad (HA). Los pares de ALTA disponibilidad permiten una alta disponibilidad comunicándose entre sí a través de una interconexión de alta disponibilidad (independiente de la red de clúster dedicada) y manteniendo conexiones redundantes a los discos del par de alta disponibilidad. Los discos no se comparten entre pares de alta disponibilidad, aunque las bandejas pueden contener discos que pertenecen a cualquier miembro de una pareja de alta disponibilidad. La siguiente figura muestra una instalación de sistemas de almacenamiento de NetApp en un entorno Windows Server.</block>
  <block id="4472647bb1219b68f4b76e737a20ce52" category="inline-image-macro">Implementación de almacenamiento de NetApp en el entorno de Windows Server,width=624,height=479</block>
  <block id="79ea3c938053f84aab6e3d9a963056f6" category="paragraph"><block ref="79ea3c938053f84aab6e3d9a963056f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7df39ad25b0e96b5a09cafef15c90e83" category="paragraph">Una SVM de ONTAP es un servidor de almacenamiento lógico que proporciona acceso a datos a LUN y/o un espacio de nombres NAS desde una o más interfaces lógicas (LIF). Por lo tanto, la SVM es la unidad básica de segmentación del almacenamiento que permite una multitenencia segura en ONTAP. Cada SVM se configura para tener volúmenes de almacenamiento aprovisionados desde un agregado físico e interfaces lógicas (LIF) asignados a una red Ethernet física o a puertos de destino FC.</block>
  <block id="ded35f53d6a4c12f9aa23622a273290c" category="paragraph">Los discos lógicos (LUN) o los recursos compartidos CIFS se crean dentro de los volúmenes de una SVM y se asignan a hosts y clústeres de Windows para proporcionarles espacio de almacenamiento, como se muestra en la siguiente figura. Las SVM son independientes de nodos y basadas en clústeres; pueden usar recursos físicos, como volúmenes o puertos de red en cualquier lugar del clúster.</block>
  <block id="66bfba6c82925242c27d2f07403b627e" category="inline-image-macro">Máquina virtual de almacenamiento de ONTAP, width=572, height=443</block>
  <block id="9bcb5e161ae4c106ccd0f2dc96989097" category="paragraph"><block ref="9bcb5e161ae4c106ccd0f2dc96989097" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f64c369fcdc9c990f5540ce53430671" category="paragraph">El almacenamiento puede aprovisionarse a Windows Server tanto en entornos SAN como NAS. En un entorno SAN, el almacenamiento se proporciona como discos de las LUN del volumen de NetApp como almacenamiento basado en bloques. En un entorno NAS, el almacenamiento se proporciona como recursos compartidos CIFS/SMB en volúmenes NetApp como almacenamiento de archivos. Estos discos y recursos compartidos se pueden aplicar en Windows Server de la siguiente manera:</block>
  <block id="8572daf67b8cf4929b8a104909d42a03" category="list-text">Almacenamiento para hosts de Windows Server para cargas de trabajo de aplicaciones</block>
  <block id="460622219d2e0a7fe2d7339d37894127" category="list-text">Almacenamiento para Nano Server y contenedores</block>
  <block id="24148b9d626dc3494e0f1a07f5ddf180" category="list-text">Almacenamiento para hosts Hyper-V individuales para almacenar equipos virtuales</block>
  <block id="c9d2a95802a3dc0a7c1033928d3cfc3f" category="list-text">Almacenamiento compartido para clústeres de Hyper-V en forma de volúmenes compartidos en cluster para almacenar equipos virtuales</block>
  <block id="76c319d8818e93b50538dff2f4427cbc" category="list-text">Almacenamiento para bases de datos de SQL Server</block>
  <block id="13a4fb282282699692756c149d94bbbe" category="paragraph">Para conectar, configurar y administrar el almacenamiento de NetApp desde Windows Server 2016, utilice uno de los siguientes métodos:</block>
  <block id="81ef8774b45c60d7387b0e91d9c4eb05" category="list-text">*Shell seguro (SSH).* Utilice cualquier cliente SSH en Windows Server para ejecutar comandos de NetApp CLI.</block>
  <block id="935df6062271011aad64300fe0f8a6c7" category="list-text">*System Manager.* Este es el producto de capacidad de gestión basado en la interfaz gráfica de usuario de NetApp.</block>
  <block id="85c7991eb4ed1078ecb54aacffe3a3a2" category="list-text">*Kit de herramientas PowerShell de NetApp.* Este es el kit de herramientas PowerShell de NetApp para automatizar e implementar scripts y flujos de trabajo personalizados.</block>
  <block id="1fb25b443082bb79703b1237630cd9b6" category="section-title">Kit de herramientas PowerShell de NetApp</block>
  <block id="6fdf83f83f373e8193dd6c6b485dccd0" category="paragraph">El kit de herramientas PowerShell de NetApp (PSTK) es un módulo PowerShell que ofrece automatización integral y permite la administración del almacenamiento de NetApp ONTAP. El módulo ONTAP contiene más de 2.000 cmdlets y ayuda con la administración de FAS, All Flash FAS (AFF) de NetApp, hardware genérico y recursos cloud.</block>
  <block id="a5038d870bfecae7a8fb1fb0d8ba892b" category="list-text">NetApp no es compatible con espacios de almacenamiento de Windows Server. Los espacios de almacenamiento sólo se utilizan para JBOD (solo un montón de discos) y no funcionan con ningún tipo de RAID (almacenamiento de conexión directa [DAS] o SAN).</block>
  <block id="b37ae3efea13417cff3fdb198db41274" category="list-text">ONTAP no admite los pools de almacenamiento en clúster en Windows Server.</block>
  <block id="436593f3429fec64588705fe44025823" category="list-text">NetApp admite el formato de disco duro virtual compartido (VHDX) para la agrupación en clústeres invitados en entornos SAN de Windows.</block>
  <block id="a3a862b96d666cb7005617313f703378" category="list-text">Windows Server no admite la creación de pools de almacenamiento mediante LUN iSCSI o FC.</block>
  <block id="570d38aae09bbf84ba37f9219909a7cb" category="list-text">Para obtener más información acerca del kit de herramientas PowerShell de NetApp, visite la<block ref="12f72d9ce1eab5b7cd58718fecdd145c" category="inline-link-rx"></block>.</block>
  <block id="699f0a44719fb3de5404046fc6caa8af" category="inline-link">TR-4475: Guía de prácticas recomendadas del kit de herramientas PowerShell para NetApp</block>
  <block id="532d077f114744273b1a7cd2a4794077" category="list-text">Para obtener información acerca de las prácticas recomendadas del kit de herramientas PowerShell de NetApp, consulte<block ref="87b47631a9123c9d2a382039a9ba503e" category="inline-link-rx"></block>.</block>
  <block id="64f3248fbae79dd41841377bf7dd37c6" category="paragraph">Las redes Ethernet se pueden separar ampliamente en los siguientes grupos:</block>
  <block id="0047d4a23ffec6d4afe912d0a2598e58" category="list-text">Una red de cliente para las máquinas virtuales</block>
  <block id="d6cf6da705ce58c7b649fea1cd43c470" category="list-text">Una red de almacenamiento más (conexión iSCSI o SMB a los sistemas de almacenamiento)</block>
  <block id="0d8658721aaab8eb43f9b6d72283b8f8" category="list-text">Una red de comunicación de clúster (latido del corazón y otra comunicación entre los nodos del clúster)</block>
  <block id="338c97ec16c135df1c972ba5b92db129" category="list-text">Una red de gestión (para supervisar y solucionar problemas del sistema)</block>
  <block id="7b6753ef35b59e8866faf1b43b213520" category="list-text">Una red de migración (para la migración dinámica del host)</block>
  <block id="0f31fc2f15105bd45773e0fe5a33814a" category="list-text">Replicación de VM (una réplica de Hyper-V)</block>
  <block id="11ef3cd9dc7173f009417493a7a51f57" category="list-text">NetApp recomienda tener puertos físicos dedicados para cada una de las funcionalidades anteriores para el rendimiento y el aislamiento de la red.</block>
  <block id="84f729d0d6ae07e1ea7697e418337328" category="list-text">Para cada uno de los requisitos de red anteriores (a excepción de los requisitos de almacenamiento), se pueden agregar varios puertos de red físicos para distribuir la carga o proporcionar tolerancia a fallos.</block>
  <block id="89831505b6fb0eb3bfb78852c3e8838a" category="list-text">NetApp recomienda que se haya creado un switch virtual dedicado en el host de Hyper-V para la conexión del almacenamiento invitado en el equipo virtual.</block>
  <block id="301b0a1048a669cb6b56215ce25f83d2" category="list-text">Asegúrese de que las rutas de datos iSCSI del host Hyper-V y del invitado utilizan diferentes puertos físicos y conmutadores virtuales para lograr un aislamiento seguro entre el invitado y el host.</block>
  <block id="38d14a6f7d54295d21bfb890bbfac145" category="list-text">NetApp recomienda evitar la agrupación de NIC para los NIC iSCSI.</block>
  <block id="3b5eab23ccdc37978e26fa584647f2f5" category="list-text">NetApp recomienda utilizar ONTAP multipath input/output (MPIO) configurado en el host con fines de almacenamiento.</block>
  <block id="6395caf6c767d5f8026b684721c1e27e" category="list-text">NetApp recomienda utilizar MPIO en un equipo virtual invitado si se utilizan iniciadores iSCSI invitados. El uso de MPIO debe evitarse en el invitado si se utilizan discos de paso a través. En este caso, la instalación de MPIO en el host debería ser suficiente.</block>
  <block id="55892ded4e0eac09cd2bd256ea8e4f49" category="list-text">NetApp recomienda no aplicar políticas de calidad de servicio al switch virtual asignado a la red de almacenamiento.</block>
  <block id="9e33949565ff57eed3e484a27adca687" category="list-text">NetApp recomienda no utilizar la dirección IP privada automática (APIPA) en NIC físicas porque APIPA no se puede enrutar y no se ha registrado en el DNS.</block>
  <block id="b06f6cf7b5c4e8ac8117fe6238a15184" category="list-text">NetApp recomienda activar tramas gigantes para redes CSV, iSCSI y migración dinámica con el fin de aumentar el rendimiento y reducir los ciclos de CPU.</block>
  <block id="d34fac956ae63cd93b204c541399ec3f" category="list-text">NetApp recomienda desactivar la opción Permitir que el sistema operativo de gestión comparta este adaptador de red para el conmutador virtual Hyper-V para crear una red dedicada para las máquinas virtuales.</block>
  <block id="0d3e51fc3c7ecb31cb6dcf3ea104060c" category="list-text">NetApp recomienda crear rutas de red redundantes (varios switches) para la migración dinámica y la red iSCSI para ofrecer resiliencia y calidad de servicio.</block>
  <block id="72a46482f366b350b6b0215baa631137" category="summary">Recursos adicionales para Microsoft Windows y Hyper-V.</block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="doc">Dónde encontrar información adicional</block>
  <block id="0650b34324cf33e3bf1ba6d5db9aa14c" category="list-text">Novedades de Hyper-V en Windows Server +
<block ref="8508224d602483e88bde8402b5d1f2d1" category="inline-link-rx"></block></block>
  <block id="1139a59d4aa15acd59f31d05c5a9d642" category="summary">Este apéndice describe la implementación de la réplica de Hyper-V fuera de un entorno en clúster.</block>
  <block id="be9cfe5b3b6e5354686be0cb736fe70d" category="list-text">Necesita servidores Hyper-V independientes ubicados en las mismas ubicaciones geográficas o independientes que sirvan de servidores primarios y de réplica.</block>
  <block id="427aef80e259ae74b835c2b646e8fba8" category="list-text">Si se utilizan sitios separados, el firewall de cada sitio debe configurarse para permitir la comunicación entre los servidores primario y de réplica.</block>
  <block id="3ac92c1d06a47463c6ea9f2c4289a625" category="list-text">El servidor de réplica debe tener espacio suficiente para almacenar las cargas de trabajo replicadas.</block>
  <block id="6db575d6d23958eefd722c2559c2ae2b" category="list-text">Configure el servidor de réplicas.</block>
  <block id="f348eb2699776a23b340068fa13ba378" category="list-text">Para que las reglas del firewall entrante permitan el tráfico de replicación entrante, ejecute el siguiente cmdlet de PowerShell:</block>
  <block id="b3741a0bf4f272b05520af3145ce6b20" category="list-text">Haga clic en Configuración de Hyper-V en Acciones.</block>
  <block id="0b81c69f5b40344714e859c333f7e46d" category="list-text">Haga clic en Configuración de Replicación y seleccione Habilitar este equipo como servidor de réplica.</block>
  <block id="23e173753ad1fc5a192335afcd91aaa2" category="list-text">En la sección Autenticación y puertos, seleccione el método de autenticación y el puerto.</block>
  <block id="c67571ac7fd00493d3ca7147b7756914" category="list-text">En la sección Autorización y almacenamiento, especifique la ubicación en la que se almacenarán los equipos virtuales y los archivos replicados.</block>
  <block id="c6f470c780ac40391a73366709e36fae" category="list-text">Activar la replicación de equipos virtuales para equipos virtuales en el servidor primario. La replicación de VM se habilita por VM y no para todo el servidor de Hyper-V.</block>
  <block id="84f81856434a0c817bfd8ec7ba575d63" category="list-text">En Hyper-V Manager, haga clic con el botón derecho en una máquina virtual y haga clic en Enable Replication para abrir el asistente Enable Replication.</block>
  <block id="bb27dca619d145c6538ad523a5c5aec7" category="list-text">Proporcione el nombre del servidor de réplica en el que se debe replicar la máquina virtual.</block>
  <block id="368e47c642802a224da6a1e9196c2345" category="list-text">Proporcione el tipo de autenticación y el puerto del servidor de réplica que se configuró para recibir tráfico de replicación en el servidor de réplica.</block>
  <block id="df839b9a847de722b03fb6f8db4abd3d" category="list-text">Seleccione los discos duros virtuales que desea replicar.</block>
  <block id="7e2b2defa62bab724dad332e0efe93d4" category="list-text">Seleccione la frecuencia (duración) a la que se envían los cambios al servidor de réplica.</block>
  <block id="f1358329d5a84d751f47c4d4e4882286" category="list-text">Configure los puntos de recuperación para especificar el número de puntos de recuperación que se deben mantener en el servidor de réplica.</block>
  <block id="13bb9737452c217970585237bf9a3c67" category="list-text">Seleccione Initial Replication Method para especificar el método para transferir la copia inicial de los datos del equipo virtual al servidor de réplica.</block>
  <block id="e7773df7e8bec8a84ededaaba6cc3b5c" category="list-text">Revise el resumen y haga clic en Finish.</block>
  <block id="eaa408dd6135876f9368b7e9e8447340" category="list-text">Este proceso crea una réplica de VM en el servidor de réplica.</block>
  <block id="c6c9686c38a42b00345f77c5ddbe044a" category="list-text">Ejecute una conmutación por error de prueba para asegurarse de que la VM de réplica funciona correctamente en el servidor de réplica. La prueba crea una VM temporal en el servidor de réplica.</block>
  <block id="4b07a5223e241d6b4d7935c2282616a5" category="list-text">Inicie sesión en el servidor de réplicas.</block>
  <block id="baaaeb9b824a8922645198d46a10e27a" category="list-text">En Hyper-V Manager, haga clic con el botón derecho en una VM de réplica, haga clic en Replicación y, a continuación, en Probar conmutación por error.</block>
  <block id="b9950331695e861c821d48077fe8b1f1" category="list-text">Elija el punto de recuperación que desea utilizar.</block>
  <block id="b1d034cdaa7ef0d2bc761b948c78838a" category="list-text">Este proceso crea una VM con el mismo nombre que se agrega con -Test.</block>
  <block id="8c95c5ef4d5593fe860313c283fab784" category="list-text">Verificar la máquina virtual para asegurarse de que todo funciona bien.</block>
  <block id="e5c73308bdacf8978516ccda5462e80a" category="list-text">Después de la conmutación por error, la VM de prueba de réplica se elimina si selecciona Detener failover de prueba para ella.</block>
  <block id="c4eacda4a6022cafe1bfc0d735075dce" category="list-text">Ejecute una conmutación al respaldo planificada para replicar los cambios más recientes del equipo virtual principal al equipo virtual de réplica.</block>
  <block id="7c3c0f256f21e1f117a98a5afa47dd56" category="list-text">Inicie sesión en el servidor primario.</block>
  <block id="2d6fd035cbd8062dcc29935ff448420e" category="list-text">Apague el equipo virtual para que se conmute al nodo de respaldo.</block>
  <block id="582c3456f1d3f75fd04a3dfcdb20c132" category="list-text">En Hyper-V Manager, haga clic con el botón derecho en la máquina virtual desactivada, haga clic en Replication y, a continuación, en Planned Failover.</block>
  <block id="4ed0c56504eba0632689dfc8056e3c49" category="list-text">Haga clic en Failover para transferir los últimos cambios de VM al servidor de réplica.</block>
  <block id="f490046b13ec9105a4adb8f885b5688f" category="list-text">Ejecute una conmutación al respaldo no planificada en caso de un fallo del equipo virtual principal.</block>
  <block id="c01438bcded7cda6d1ee326fa268f93c" category="list-text">En Hyper-V Manager, haga clic con el botón derecho en una réplica de VM, haga clic en Replication y, a continuación, haga clic en Failover.</block>
  <block id="94faab2d3840f3d8320e20ad4a90e6cd" category="list-text">Haga clic en Failover para conmutar la máquina virtual al nodo de respaldo.</block>
  <block id="4be45953e45cfa5fc987ba108c1e5793" category="summary">Este apéndice describe la puesta en marcha de la migración en vivo en un entorno en clúster.</block>
  <block id="388b92a1de3321595dcfbdc1c67ce749" category="paragraph">Para utilizar la migración dinámica en un entorno en clúster, complete los siguientes pasos:</block>
  <block id="b66a6c742469f1d08a2d11bcf4f211ff" category="list-text">En el Administrador de clústeres de conmutación por error, seleccione y expanda el clúster. Si el clúster no está visible, haga clic en Administrador de clústeres de conmutación por error, haga clic en Connect to Cluster y proporcione el nombre del clúster.</block>
  <block id="e3883376513ba0aeb2f3d190d4e0377d" category="list-text">Haga clic en Roles, donde se enumeran todas las máquinas virtuales disponibles en un clúster.</block>
  <block id="e164db40505184b94012bbbd4aa4c1a2" category="list-text">Haga clic con el botón derecho en la máquina virtual y haga clic en Move. Esto le proporciona tres opciones:</block>
  <block id="6a1e101231f8f4bcd4a75390cc0eddc2" category="list-text">*Migración en vivo.* Puede seleccionar un nodo manualmente o permitir que el clúster seleccione el mejor nodo. En la migración dinámica, el cluster copia la memoria utilizada por la máquina virtual del nodo actual a otro nodo. Por lo tanto, cuando la máquina virtual se migra a otro nodo, la información de memoria y estado que necesita la máquina virtual ya está puesta para la máquina virtual. Este método de migración es casi instantáneo, pero solo se puede migrar en vivo un equipo virtual cada vez.</block>
  <block id="4374953843b8a5507e79ee5145fd88cd" category="list-text">*Migración rápida.* Puede seleccionar un nodo manualmente o permitir que el clúster seleccione el mejor nodo. En una rápida migración, el clúster copia la memoria utilizada por un equipo virtual a un disco del almacenamiento. Por lo tanto, cuando la máquina virtual se migra a otro nodo, la información de memoria y estado que necesita el equipo virtual se puede leer rápidamente desde el disco en el otro nodo. Con una migración rápida, se pueden migrar varios equipos virtuales de forma simultánea.</block>
  <block id="f1321d73ebfb5a92e710d313fd53c21c" category="list-text">*Migración de almacenamiento de máquinas virtuales.* Este método utiliza el asistente Mover almacenamiento de máquinas virtuales. Con este asistente, puede seleccionar el disco del equipo virtual junto con otros archivos que se moverán a otra ubicación, que puede ser un recurso compartido CSV o de SMB.</block>
  <block id="36397d251acf4232a7e91edc7ae649c7" category="summary">Almacenamiento NAS de ONTAP para Hyper-V usando SMB3</block>
  <block id="a06ae7fcee90c7ab1e1321d0dd8b2242" category="paragraph">ONTAP proporciona almacenamiento NAS de alto rendimiento y resistente para las máquinas virtuales de Hyper-V que utilizan el protocolo SMB3.</block>
  <block id="2efbb65fec3bad963652820bc484fe59" category="paragraph">Cuando se crea una SVM con el protocolo CIFS, un servidor CIFS se ejecuta sobre la SVM que forma parte del dominio de Windows Active Directory. Los recursos compartidos de SMB se pueden utilizar para un directorio inicial y para alojar cargas de trabajo de Hyper-V y SQL Server. ONTAP admite las siguientes funciones de SMB 3,0:</block>
  <block id="55339f66c60fe6973920932c368d5b51" category="list-text">Identificadores persistentes (archivos compartidos disponibles de forma continua)</block>
  <block id="94713d3b3a69a2fd695bffeb252007d3" category="list-text">Protocolo de observación</block>
  <block id="adb115272d11e09afdfd8702a652d626" category="list-text">Recuperación tras fallos de cliente en clúster</block>
  <block id="f5025b9fcd1b24276af8ec2da3aa4cd7" category="list-text">Reconocimiento de la escalabilidad horizontal</block>
  <block id="81abcea6e16bc538d9843e8808b2066b" category="list-text">ODX</block>
  <block id="f4ad9c4d51155dbb3fb746c7c497c145" category="list-text">VSS remoto</block>
  <block id="56a26f5f5f602966c3a3088fc05c7383" category="paragraph">El uso del almacenamiento de NetApp en entornos NAS en Windows Server tiene los siguientes requisitos:</block>
  <block id="5f3a2953a5f6d187ed4babba3c754b95" category="list-text">El clúster de ONTAP tiene una licencia CIFS válida.</block>
  <block id="2744237d602ca5ed3f1a6370ed8ebe91" category="list-text">Se crea al menos un agregado.</block>
  <block id="89917a1bea2d5c48569d9ed0a9526f74" category="list-text">Se crea una interfaz lógica de datos (LIF) y las LIF de datos deben configurarse para CIFS.</block>
  <block id="87a2c188e55f400a5936550cc2f91148" category="list-text">Hay un servidor de dominio de Windows Active Directory y credenciales de administrador de dominio configuradas con DNS.</block>
  <block id="da920c4d42bb062c9dbfd877c84ef133" category="list-text">Cada nodo del clúster NetApp se sincroniza por hora con la controladora de dominio de Windows.</block>
  <block id="f04e0c239705cd7c6e249d3ed6991627" category="section-title">Controlador de dominio de Active Directory</block>
  <block id="2e0bc40db7949b4af757ea11110ae955" category="paragraph">Una controladora de almacenamiento de NetApp puede unirse y funcionar en un Active Directory similar a un servidor Windows Server. Durante la creación de la SVM, es posible configurar el DNS proporcionando los detalles del nombre de dominio y del servidor de nombres. La SVM intenta buscar una controladora de dominio de Active Directory mediante la consulta del DNS de un servidor de protocolo ligero de acceso a directorios (LDAP)/Active Directory de forma similar a Windows Server.</block>
  <block id="dee2aa3e7614e2fc47c6fbbb5cd123b5" category="paragraph">Para que la configuración de CIFS funcione correctamente, las controladoras de almacenamiento de NetApp deben estar sincronizadas por hora con el controlador de dominio de Windows. NetApp recomienda desfase de tiempo entre la controladora de dominio de Windows y la controladora de almacenamiento de NetApp que no supere los cinco minutos. Se recomienda configurar el servidor de protocolo de tiempo de redes (NTP) para que el clúster de ONTAP se sincronice con un origen de tiempo externo. Para configurar la controladora de dominio de Windows como servidor NTP, ejecute el siguiente comando en su clúster de ONTAP:</block>
  <block id="2d60b04429a0c7bcf1dc0021d1c01046" category="list-text">Cree una nueva SVM con el protocolo NAS CIFS habilitado. Una SVM nueva se puede crear con cualquiera de los siguientes métodos:</block>
  <block id="7c5160d336371c9cd497410a57a7211e" category="list-text">Comandos de la CLI en NetApp ONTAP</block>
  <block id="26ed02718973e705cd69ee6e109400e0" category="list-text">System Manager</block>
  <block id="fc05c3b0a7017fa6841b856230e365bb" category="list-text">El kit de herramientas PowerShell de NetApp</block>
  <block id="bbee3ec15cf30d6e65d6a020f6d4af1e" category="list-text">Configure el protocolo CIFS</block>
  <block id="8de4bddcd1cd8e4614e52342eef41752" category="list-text">Proporcione el nombre del servidor CIFS.</block>
  <block id="a817c1f7bf7af809fd90c63b2a8e4447" category="list-text">Proporcione el Active Directory al que se debe unir el servidor CIFS. Debe contar con las credenciales de administrador de dominio para unir al servidor CIFS a Active Directory.</block>
  <block id="bf8cf0b24d936c2fe2e3681004650bf0" category="list-text">Asigne la SVM con LIF en cada nodo del clúster.</block>
  <block id="5d77fb569194f93fead7154a8d1d1bc3" category="list-text">Inicie el servicio CIFS en la SVM.</block>
  <block id="547edc4d2fb156c3e495e6325eae5a4a" category="list-text">Cree un volumen con el estilo de seguridad NTFS a partir del agregado.</block>
  <block id="1418b945a2d25e4f6514fc52e9d6c7ef" category="list-text">Crear un Qtree en el volumen (opcional).</block>
  <block id="f0bbe023b40d4d11ed83d36a68894cae" category="list-text">Crear recursos compartidos que correspondan al directorio del volumen o qtree para que se pueda acceder a ellos desde Windows Server. Seleccione Enable Continuous Availability for Hyper-V durante la creación del recurso compartido si el recurso compartido se utiliza para el almacenamiento de Hyper-V. Esto permite una alta disponibilidad para los recursos compartidos de archivos.</block>
  <block id="9ef47a6b1a5d19245750aa732054173a" category="list-text">Edite el recurso compartido creado y modifique los permisos según sea necesario para acceder al recurso compartido. Los permisos para el recurso compartido SMB se deben configurar para otorgar acceso a las cuentas de equipo de todos los servidores que acceden a este recurso compartido.</block>
  <block id="413353879b081038ef89f78350859cad" category="paragraph">El protocolo NAS CIFS está integrado de manera nativa en ONTAP. Por lo tanto, Windows Server no requiere ningún software cliente adicional para acceder a los datos en NetApp ONTAP. Aparece una controladora de almacenamiento de NetApp en la red como servidor de archivos nativo y admite la autenticación de Microsoft Active Directory.</block>
  <block id="053003e418b94e54d509f16e6a5ac54f" category="paragraph">Para detectar el recurso compartido de CIFS creado anteriormente con Windows Server, lleve a cabo los siguientes pasos:</block>
  <block id="9eb306535570bd14746bad4f0768684f" category="list-text">Inicie sesión en Windows Server como miembro del grupo de administradores.</block>
  <block id="4cac21133029fce3cd01fb6d42f8bedb" category="list-text">Vaya a run.exe y escriba la ruta completa del recurso compartido CIFS creado para acceder al recurso compartido.</block>
  <block id="cf48b5bae22bbcd1956b57470865f653" category="list-text">Para asignar de forma permanente el recurso compartido en Windows Server, haga clic con el botón derecho en este equipo, haga clic en Asignar unidad de red y proporcione la ruta del recurso compartido CIFS.</block>
  <block id="c888866731e18ef4ef9ac046ce7c70aa" category="list-text">Algunas tareas de gestión de CIFS pueden realizarse usando Microsoft Management Console (MMC). Antes de realizar estas tareas, debe conectar el MMC al almacenamiento NetApp ONTAP mediante los comandos del menú MMC.</block>
  <block id="304c9374426bb10ac275b8d050d77a72" category="list-text">Para abrir MMC en Windows Server, haga clic en Administración de equipos en la sección Herramientas del Administrador del servidor.</block>
  <block id="e731a6a9193d81f0140801ba9fb7c316" category="list-text">Haga clic en Más acciones y Conectarse a otro equipo, lo que abre el cuadro de diálogo Seleccionar equipo.</block>
  <block id="92b70da99a18efe7530353abe1820089" category="list-text">Introduzca el nombre del servidor CIFS o la dirección IP de la LIF de SVM para conectarse al servidor CIFS.</block>
  <block id="2d6dbdc8809506c631cd711d19c21958" category="list-text">Expanda Herramientas del sistema y Carpetas compartidas para ver y administrar archivos abiertos, sesiones y recursos compartidos.</block>
  <block id="3a38167e840fd7939f34e194afadd957" category="list-text">Para confirmar que no hay tiempo de inactividad cuando un volumen se mueve de un nodo a otro o en caso de fallo de un nodo, NetApp recomienda habilitar la opción de disponibilidad continua en el recurso compartido de archivos.</block>
  <block id="7a98f276625e5966a817f0783982ef86" category="list-text">Cuando se aprovisionan equipos virtuales para un entorno de Hyper-V a través de SMB, NetApp le recomienda que habilite la copia de datos descargados en el sistema de almacenamiento. De este modo, se reduce el tiempo de aprovisionamiento de las máquinas virtuales.</block>
  <block id="8bb66ec4b6ef9437bd1c4c88328028b9" category="list-text">Si el clúster de almacenamiento aloja varias cargas de trabajo de SMB como SQL Server, Hyper-V y CIFS, NetApp recomienda alojar diferentes cargas de trabajo de SMB en SVM separadas en agregados separados. Esta configuración es ventajosa porque cada una de estas cargas de trabajo garantiza distribuciones por volúmenes y redes de almacenamiento únicas.</block>
  <block id="5e64ba0ef524e2fd309390ce90b5ad91" category="list-text">NetApp recomienda conectar los hosts de Hyper-V y el almacenamiento NetApp ONTAP con una red 10GB GbE, si hay alguno disponible. En el caso de la conectividad de red de 1GB GbE, NetApp recomienda crear un grupo de interfaces que consta de varios puertos 1GB GbE.</block>
  <block id="ce424317fa59851e16cfbe4cbac13386" category="list-text">Cuando se migran máquinas virtuales de un recurso compartido SMB 3,0 a otro, NetApp recomienda habilitar la funcionalidad de descarga de la copia CIFS en el sistema de almacenamiento para que la migración sea más rápida.</block>
  <block id="be7159d8a65544f2712c72dc0254f9be" category="list-text">Cuando se aprovisionan volúmenes para entornos SMB, los volúmenes deben crearse con el estilo de seguridad NTFS.</block>
  <block id="bb17c7edf27266c09bc64edcc1299db5" category="list-text">La configuración de hora de los nodos del clúster debe configurarse según corresponda. Utilice NTP si el servidor CIFS de NetApp debe participar en el dominio de Windows Active Directory.</block>
  <block id="261b72d9729025ebf489205324a048d5" category="list-text">Las asas persistentes solo funcionan entre nodos de un par de alta disponibilidad.</block>
  <block id="e185fb0d3a49c7a3318c954d8aa25c05" category="list-text">El protocolo testigo solo funciona entre nodos de un par de alta disponibilidad.</block>
  <block id="67d7fd26a92bba839041dd45a19cec56" category="list-text">Los recursos compartidos de archivos disponibles continuamente solo son compatibles con las cargas de trabajo de Hyper-V y SQL Server.</block>
  <block id="fa2e04a9f0cdcb5ad0e9f1e5ad1ada82" category="list-text">El multicanal SMB es compatible desde ONTAP 9,4 en adelante.</block>
  <block id="f357368b2f195de4f8b4463eed2bf004" category="list-text">No se admite RDMA.</block>
  <block id="f55cb235b18bf3d499f9276cd235bfb6" category="list-text">REFS no es compatible.</block>
  <block id="fb97dc994a0600d8610daca021159b33" category="paragraph">Nano Server no requiere software de cliente adicional para acceder a los datos del recurso compartido de CIFS en una controladora de almacenamiento de NetApp.</block>
  <block id="2be09e0be799992463b5c9542ce31dd8" category="paragraph">Para copiar archivos de Nano Server a un recurso compartido de CIFS, ejecute los siguientes cmdlets en el servidor remoto:</block>
  <block id="2e0d4f41db110bf64a66493b31c9b168" category="list-text"><block ref="6f88c516ba3d9ab0cd23b81fc43dd697" prefix="" category="inline-code"></block> Es el recurso compartido de CIFS en la controladora de almacenamiento de NetApp.</block>
  <block id="5e017ad7a7df43934bccc7c27031a140" category="list-text">Para copiar archivos en Nano Server, ejecute el siguiente cmdlet:</block>
  <block id="d153ba0c2e04ac16dcece009a842216e" category="paragraph">Para copiar todo el contenido de una carpeta, especifique el nombre de la carpeta y use el parámetro -Recurse al final del cmdlet.</block>
  <block id="c9f4515194bc7b2927aa17b7d9b4aa25" category="summary">Cómo configurar la migración dinámica del almacenamiento de Hyper-V.</block>
  <block id="a49764977574be237e816e868b16bd9e" category="doc">Implemente Hyper-V Storage Live Migration</block>
  <block id="587db979ac1f69c45774cb09d6d6670b" category="paragraph">Descubre cómo configurar la migración dinámica del almacenamiento de Hyper-V.</block>
  <block id="0146445d75059a401441fd65f1bae1e0" category="list-text">Debe tener un servidor de Hyper-V independiente con almacenamiento independiente (DAS o LUN) o almacenamiento SMB (local o compartido entre otros servidores de Hyper-V.</block>
  <block id="71c2ecf4798ba7bf00669c37826cb55b" category="inline-link-macro">Migración en vivo fuera de un entorno en cluster</block>
  <block id="4a8052295fad176b01067c772f7c7e5d" category="list-text">El servidor de Hyper-V debe configurarse para la migración dinámica. Revise la sección sobre la implementación en <block ref="0e7f526c94c2d5b9ef424b7a8a1c9587" category="inline-link-macro-rx"></block>.</block>
  <block id="43434644e024fa3073cc9c64dba551d0" category="list-text">Abra Hyper-V Manager.</block>
  <block id="3999a6e17f16c7f048684f76a1a59e38" category="list-text">Haga clic con el botón derecho en una máquina virtual y haga clic en Mover.</block>
  <block id="1d838d1a72e03329477d7f4024eec108" category="list-text">Seleccione Mover el almacenamiento de la máquina virtual.</block>
  <block id="45d2d7245527e5e6e9be62e79d5a46d8" category="list-text">Seleccione opciones para mover el almacenamiento en función de sus preferencias.</block>
  <block id="13d0ba1c0320910efd0d040f2d461527" category="list-text">Proporcione la nueva ubicación para los elementos de la VM.</block>
  <block id="6efadc6e298c560f1699100ac97c7378" category="list-text">Revise el resumen y haga clic en OK para mover el almacenamiento de la máquina virtual.</block>
  <block id="b2d949a2d7f46bb1e39037d38eea14e4" category="summary">Eficiencia del almacenamiento de ONTAP con Microsoft Hyper-V</block>
  <block id="bd2eab4ffe0ab602b60386dfdd3ef913" category="paragraph">ONTAP proporciona eficiencia de almacenamiento líder del sector para entornos virtualizados incluido Microsoft Hyper-V. NetApp también ofrece programas de garantía de eficiencia del almacenamiento.</block>
  <block id="e957a0e8016b502f05bb1966b2ec6064" category="paragraph">La deduplicación de NetApp funciona eliminando bloques duplicados en el volumen de almacenamiento, almacenando solo una copia física, independientemente del número de copias lógicas presentes. Por lo tanto, la deduplicación crea la ilusión de que existen numerosas copias de dicho bloque. La deduplicación elimina automáticamente bloques de datos duplicados en bloques de 4KB KB en todo el volumen. Este proceso recupera el almacenamiento para alcanzar ahorros de espacio y rendimiento potencial al reducir el número de escrituras físicas en el disco. La deduplicación puede proporcionar un ahorro de espacio superior al 70% en entornos Hyper-V.</block>
  <block id="44ee5e4157e5291ffc8bc5d1d9b5959d" category="paragraph">Thin provisioning es una manera eficiente de aprovisionar almacenamiento, ya que el almacenamiento no se asigna previamente. Es decir, cuando se crea un volumen o LUN mediante thin provisioning, el espacio del sistema de almacenamiento no se utiliza. El espacio sigue sin utilizar hasta que se escriben los datos en la LUN o el volumen y solo se utiliza el espacio necesario para almacenar dichos datos. NetApp recomienda habilitar thin provisioning en el volumen y deshabilitar la reserva de LUN.</block>
  <block id="8bc14f0cb78851f59e85c1d447c2c99f" category="section-title">Calidad de servicio</block>
  <block id="5f4c07a9f526ef861fd661ab7d801ef0" category="paragraph">La calidad de servicio del almacenamiento en Clustered ONTAP le permite agrupar objetos de almacenamiento y establecer límites de rendimiento en el grupo. La calidad de servicio de almacenamiento puede utilizarse para limitar el rendimiento a las cargas de trabajo y supervisar el rendimiento de las cargas de trabajo. Con esta capacidad, un administrador de almacenamiento puede separar las cargas de trabajo por organización, aplicación, unidad empresarial o entornos de producción o desarrollo.</block>
  <block id="8649c492f1adfda9b6ab44990a1a7580" category="paragraph">En entornos empresariales, la calidad de servicio del almacenamiento ayuda a conseguir lo siguiente:</block>
  <block id="ca944817219b4a5d2cb25894ee7bac2d" category="list-text">Impide que las cargas de trabajo de los usuarios se afecten entre sí.</block>
  <block id="1d5819479882e9b1b8133fda618801e5" category="list-text">Protege aplicaciones cruciales con tiempos de respuesta específicos que deben satisfacerse en entornos de TECNOLOGÍA como servicio (ITaaS).</block>
  <block id="b06d1116eb0db3e3c8c51d1707dfcf99" category="list-text">Evita que los clientes se afecten entre sí.</block>
  <block id="1d7dd784ada3e9fe62630025fa82dc80" category="list-text">Evita la degradación del rendimiento con la adición de cada nuevo inquilino.</block>
  <block id="3c7577ceba90e087950e69f357ce949b" category="paragraph">La calidad de servicio le permite limitar la cantidad de I/O enviada a una SVM, un volumen flexible, una LUN o un archivo. El número de operaciones o el rendimiento bruto pueden limitar las I/O.</block>
  <block id="0ac164a0cdedc812bd371348407d8df2" category="paragraph">La siguiente figura ilustra la SVM con su propia política de calidad de servicio, que aplica un límite máximo de rendimiento.</block>
  <block id="4cd97525569a4c4f332a1fbadea31367" category="inline-image-macro">Máquina virtual de almacenamiento con su propia política de calidad de servicio,width=319,height=341</block>
  <block id="11751e265ace69b487d325224006c7e5" category="paragraph"><block ref="11751e265ace69b487d325224006c7e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="42674eda4c194d913efb361684c8b8c6" category="paragraph">Para configurar una SVM con su propia política de calidad de servicio y su grupo de políticas de supervisión, ejecute los siguientes comandos en el clúster de ONTAP:</block>
  <block id="2398ac10b8f12f8d175464af41b6cc27" category="summary">Obtenga información sobre la implementación de Microsoft Windows Nano Server</block>
  <block id="60aa20a9330bfedece833eb6496e61dc" category="doc">Implemente Nano Server</block>
  <block id="751f4ae88fb7c0e83c557b594f24f467" category="paragraph">Obtenga información sobre la implementación de Microsoft Windows Nano Server.</block>
  <block id="ffd8df9c68fc3e1710ed9dc15dec9225" category="paragraph">Para implementar un Nano Server como host de Hyper-V, realice los siguientes pasos:</block>
  <block id="2c8cf6c7616e7bf4d627844c10ef6914" category="list-text">Copie la carpeta NanoServerImageGenerator de la carpeta \NanoServer de la ISO de Windows Server al disco duro local.</block>
  <block id="e93afc2a7bab8945ac834e9f955ab2c8" category="list-text">Para crear un servidor Nano VHD/VHDX, realice los siguientes pasos:</block>
  <block id="f0b4451826a1b48587dce5ccbdf7a1e7" category="list-text">Inicie Windows PowerShell como administrador, navegue hasta la carpeta NanoServerImageGenerator copiada en el disco duro local y ejecute el siguiente cmdlet:</block>
  <block id="3b515a3daeec18784951623c4ef02332" category="list-text">Cree un VHD para Nano Server como host de Hyper-V ejecutando el siguiente cmdlet de PowerShell. Este comando solicita una contraseña de administrador para el nuevo disco duro virtual.</block>
  <block id="2ef6d24f20fa6986cbd70ea844d3e16e" category="list-text">En el siguiente ejemplo, creamos un VHD de Nano Server con la función de host Hyper-V con clustering de conmutación por error activado. Este ejemplo crea un VHD Nano Server a partir de una ISO montada en f:\. El VHD recién creado se coloca en una carpeta llamada NanoServer en la carpeta desde donde se ejecuta el cmdlet. El nombre del equipo es NanoServer y el VHD resultante contiene la edición estándar de Windows Server.</block>
  <block id="7f165cd40e3ab8b56d69cfdf799ebb23" category="list-text">Con el cmdlet New-NanoServerImage, configure los parámetros que establecen la dirección IP, la máscara de subred, la puerta de enlace predeterminada, el servidor DNS, el nombre de dominio, y así sucesivamente.</block>
  <block id="9ba9f17628c7c8e123a1c4d0b154e1e0" category="list-text">Utilice el VHD en una máquina virtual o en un host físico para implementar Nano Server como host de Hyper-V:</block>
  <block id="7482916c1c66ae16c274920ca01eda80" category="list-text">Para la implementación en un equipo virtual, cree un nuevo equipo virtual en Hyper-V Manager y utilice el disco duro virtual creado en el paso 3.</block>
  <block id="8a1f197a1a3903636fe46d151b55f1a4" category="list-text">Para la implementación en un host físico, copie el VHD en el equipo físico y configúrelo para arrancar desde este nuevo VHD. Primero, monte el VHD, ejecute bcdboot e:\windows (donde el VHD está montado en E:\), desmonte el VHD, reinicie el equipo físico y arranque en el Nano Server.</block>
  <block id="1a2fbb26db89a11f849f5a17170449b5" category="list-text">Unir el Nano Server a un dominio (opcional):</block>
  <block id="fa966a71fb7e787a036cc8ae2df719c2" category="list-text">Inicie sesión en cualquier equipo del dominio y cree un blob de datos ejecutando el siguiente cmdlet de PowerShell:</block>
  <block id="5e83141959914643e6e309d32cb02675" category="list-text">Copie el archivo odjblob en Nano Server ejecutando los siguientes cmdlets de PowerShell en una máquina remota:</block>
  <block id="9493ca9bfebee08582b48c95f6ad1768" category="list-text">Reinicie Nano Server.</block>
  <block id="24d48ec9863eca883370d9e471e7dec1" category="section-title">Conéctese a Nano Server</block>
  <block id="11e7dceca10309920a26c38df3c5f421" category="paragraph">Para conectarse al Nano Server de forma remota mediante PowerShell, realice los siguientes pasos:</block>
  <block id="08d7b9e67b4bbd447b1fa3d9103976e8" category="list-text">Agregue Nano Server como un host de confianza en el equipo remoto ejecutando el siguiente cmdlet en el servidor remoto:</block>
  <block id="0b1f1a420d35761f550f4a9f3b9e2ecb" category="list-text">Si el entorno es seguro y desea configurar todos los hosts que se van a agregar como hosts de confianza en un servidor, ejecute el siguiente comando:</block>
  <block id="06879aa989dffc1c877a92441f72d474" category="list-text">Inicie la sesión remota ejecutando el siguiente cmdlet en el servidor remoto. Proporcione la contraseña para el servidor Nano cuando se le solicite.</block>
  <block id="c5363e6f2cab660a02c04316d65097b5" category="paragraph">Para conectarse al Nano Server de forma remota utilizando las herramientas de administración de GUI desde un Windows Server remoto, complete los siguientes comandos:</block>
  <block id="d97c0d550aa0ad1af548a89c27d9f7ea" category="list-text">Inicie sesión en Windows Server como miembro del grupo de administradores.</block>
  <block id="ff621b1b3a7bcf389fc4c97a55bf9505" category="list-text">Para administrar un servidor Nano de forma remota desde el Administrador del servidor, haga clic con el botón derecho en Todos los servidores, haga clic en Agregar servidores, proporcione la información del servidor Nano y agréguela. Ahora puede ver el Nano Server en la lista de servidores. Seleccione el Nano Server, haga clic con el botón derecho del ratón y comience a administrarlo con las diversas opciones proporcionadas.</block>
  <block id="2343c80f9e6b008ea95cc15026c9c094" category="list-text">Para administrar servicios en un Nano Server de forma remota, complete los siguientes pasos:</block>
  <block id="1430c8ff3134db821cc65ac53e010d4d" category="list-text">Abra Servicios en la sección Herramientas del Administrador del servidor.</block>
  <block id="358fe30f1157bd64dad7a3aba4e40f94" category="list-text">Haga clic con el botón derecho del ratón en Servicios (Local).</block>
  <block id="72fa515e487f796b536e03179e63e7db" category="list-text">Haga clic en Conectar al servidor.</block>
  <block id="50ec7cc625733992673123275ff834d6" category="list-text">Proporcione los detalles de Nano Server para ver y administrar los servicios en Nano Server.</block>
  <block id="f322fcdc841439901a45a176928f80e0" category="list-text">Si el rol Hyper-V está habilitado en Nano Server, complete los siguientes pasos para administrarlo de forma remota desde Hyper-V Manager:</block>
  <block id="14994643f0c569708527514d0405c1e5" category="list-text">Haga clic con el botón derecho en Hyper-V Manager.</block>
  <block id="8e0877f5a8a5d540837664b9de1070ca" category="list-text">Haga clic en Conectar al servidor y proporcione los detalles de Nano Server. Ahora el Nano Server se puede administrar como un servidor Hyper-V para crear y administrar VM sobre él.</block>
  <block id="b2c5e9024429f1b7f8581d1747d25fd6" category="list-text">Si el rol de agrupación en clúster de conmutación por error está activado en Nano Server, realice los siguientes pasos para gestionarlo de forma remota desde el administrador de clústeres de conmutación por error:</block>
  <block id="31b3efaeee0b35b5bde4f1353f947b93" category="list-text">Abra el Administrador de clústeres de conmutación por error en la sección Herramientas del Administrador del servidor.</block>
  <block id="2cb85a898a7a975600dcc1bea85df531" category="list-text">Realice operaciones relacionadas con la agrupación en clústeres con Nano Server.</block>
  <block id="2810ba8ba9d5e4319af85df66ddf2286" category="summary">Seguridad de almacenamiento de ONTAP con Hyper-V.</block>
  <block id="2fae32629d4ef4fc6341f1751b405e45" category="doc">Seguridad</block>
  <block id="6ca21561032e8c064bc8514ab2e92740" category="paragraph">ONTAP ofrece un sistema de almacenamiento seguro para el sistema operativo Windows.</block>
  <block id="615e826f5576798f024d7959ccefc794" category="section-title">Antivirus de Windows Defender</block>
  <block id="2861d3b5f4351fd51979bf98547a050b" category="paragraph">Windows Defender es un software antimalware instalado y habilitado en Windows Server de forma predeterminada. Este software protege activamente Windows Server contra malware conocido y puede actualizar regularmente las definiciones antimalware a través de Windows Update. Los LUN de NetApp y los recursos compartidos de SMB se pueden analizar mediante Windows Defender.</block>
  <block id="a86f08bae2bbd68aa81b64f748f3ccb8" category="inline-link">Descripción general de Windows Defender</block>
  <block id="4b51dd417e2be3fdc9a793c3290e3a63" category="paragraph">Para obtener más información, consulte<block ref="d66127569e4d44a2d0a35bc9d20b1ea7" category="inline-link-rx"></block>.</block>
  <block id="ce71fc775b37c52dabd938808de8d0f9" category="section-title">BitLocker</block>
  <block id="8d9091beebb755bb6e68a4f04d3288f6" category="paragraph">El cifrado de la unidad BitLocker es una característica de protección de datos continuada desde Windows Server 2012. Este cifrado protege los discos físicos, las LUN y los volúmenes compartidos en cluster.</block>
  <block id="0494cad48bf6f5dd2105391f0426af1a" category="paragraph">Antes de habilitar BitLocker, el CSV debe ponerse en modo de mantenimiento. Por lo tanto, NetApp recomienda que las decisiones relativas a la seguridad basada en BitLocker se tomen antes de crear VM en el CSV para evitar tiempos de inactividad.</block>
  <block id="e2e4ca1a6c3bcca61ed5ec3ea10c90c0" category="summary">Aprenda a implementar y configurar la réplica de Hyper-V con el clúster de conmutación por error de Windows Server.</block>
  <block id="5674fdbee301f444dd0ca3836c682957" category="list-text">Si se utilizan sitios separados, se debe configurar el firewall de cada sitio para permitir la comunicación entre los clústeres primario y de réplica.</block>
  <block id="6cc66ed27b17f9c380f924d533e633d6" category="list-text">El clúster de réplica debe tener suficiente espacio para almacenar las cargas de trabajo replicadas.</block>
  <block id="ff71768b9e039ee5012c181eb29bdc39" category="list-text">Active las reglas de firewall en todos los nodos de un clúster. Ejecute el siguiente cmdlet de PowerShell con privilegios de administrador en todos los nodos en los clústeres primario y de réplica.</block>
  <block id="ac005fe375c3903e88ed3801a8646b0a" category="list-text">Configure el cluster de réplicas.</block>
  <block id="3a57da55cdc319b0580af329b8776df6" category="list-text">Configure el broker de réplica Hyper-V con un nombre NetBIOS y una dirección IP para utilizarlo como punto de conexión al cluster que se utiliza como cluster de réplica.</block>
  <block id="643ce0b9206c6c138b36b79315a468f2" category="list-text">Abra el Administrador de clústeres de conmutación por error.</block>
  <block id="52243c461a19e74a8e4b64d801979142" category="list-text">Expanda el clúster, haga clic en Roles y haga clic en el panel Configurar rol desde Acciones.</block>
  <block id="f87ee1c8e6945b31ba45ee813ea7c124" category="list-text">Seleccione Broker de Réplica Hyper-V en la página Seleccionar Rol.</block>
  <block id="fdbea454936dca227734d3f978334254" category="list-text">Proporcione el nombre de NetBIOS y la dirección IP que se utilizarán como punto de conexión al clúster (punto de acceso del cliente).</block>
  <block id="bb8627cc57d25f02546b85f38d97ae04" category="list-text">Este proceso crea un rol de intermediario de réplica Hyper-V. Compruebe que se ha conectado correctamente.</block>
  <block id="9b11f91c42607554f82ca0c4a5739d14" category="list-text">Configurar los ajustes de replicación.</block>
  <block id="662af7cfca9243c46223a416df05d774" category="list-text">Haga clic con el botón derecho en el broker de réplicas creado en los pasos anteriores y haga clic en Configuración de Replicación.</block>
  <block id="45375ee44c681920240b13f25bf53d9e" category="list-text">Seleccione Activar este cluster como servidor de réplica.</block>
  <block id="88aeceb8128e3b94092a3e66ac2236db" category="list-text">En la sección Autorización y almacenamiento, seleccione los servidores permitidos para replicar los equipos virtuales en este clúster. Además, especifique la ubicación predeterminada donde se almacenan las máquinas virtuales replicadas.</block>
  <block id="3d9241b7079c08f25c850a7d8ac5eebd" category="inline-link-macro">Réplica fuera de un entorno en clúster</block>
  <block id="3077be518a570235f65497aa5b227e9b" category="paragraph">La replicación es similar al proceso descrito en la sección <block ref="85d27647a4d4ffb042b0371e9654ea4c" category="inline-link-macro-rx"></block>.</block>
  <block id="f8b7d7bb25e13b6b771e58da1fa078cb" category="summary">Aprovisione almacenamiento ONTAP para Windows y Hyper-V en entornos SAN</block>
  <block id="24294828f9d26e2b73b5b1e0eda7a2d0" category="paragraph">Las SVM de ONTAP admiten los protocolos de bloque iSCSI y FC. Cuando se crea una SVM con el protocolo de bloque iSCSI o FC, la SVM obtiene un nombre completo de iSCSI (IQN) o un nombre FC Worldwide (WWN), respectivamente. Este identificador presenta un destino SCSI para los hosts que acceden al almacenamiento en bloques de NetApp.</block>
  <block id="7f33f1b99e752967fce41fe3dec9f051" category="section-title">Aprovisionar LUN de NetApp en Windows Server</block>
  <block id="025d3d39bb1937ffe40a12b1917e28b6" category="paragraph">El uso del almacenamiento de NetApp en entornos SAN en Windows Server tiene los siguientes requisitos:</block>
  <block id="3e306b32d1acc6cfcca681b93d8d57cd" category="list-text">Se configura un clúster de NetApp con una o más controladoras de almacenamiento NetApp.</block>
  <block id="3e0ea625c6f590606b5242be6455347c" category="list-text">El clúster de NetApp o las controladoras de almacenamiento tienen una licencia iSCSI válida.</block>
  <block id="5bf7c7c03ed76506f8822badb526f0a8" category="list-text">Hay disponibles los puertos configurados iSCSI y/o FC.</block>
  <block id="46434438c1896350bc085c1a67785198" category="list-text">La división en zonas de FC se realiza en un switch de FC para FC.</block>
  <block id="1e704db41d570618bd723b41d0db395e" category="list-text">Una SVM debería tener un LIF por red Ethernet o una estructura de Fibre Channel en cada controladora de almacenamiento que vaya a servir datos con iSCSI o Fibre Channel.</block>
  <block id="daa700de515c2e157d34b0e12c154478" category="list-text">Cree una nueva SVM con el protocolo de bloque iSCSI y/o FC habilitado. Una SVM nueva se puede crear con cualquiera de los siguientes métodos:</block>
  <block id="ec642b047305fbfe6db973f313768eae" category="list-text">Comandos de la CLI en almacenamiento de NetApp</block>
  <block id="43736124eda42b8dec979b188b9d891b" category="list-text">Configure el protocolo iSCSI y/o FC.</block>
  <block id="51dbb9050f89d2c5cbfda6a46bb48963" category="list-text">Inicie el servicio iSCSI y/o FC en la SVM.</block>
  <block id="5058f1af8388633f609cadb75a75dc9d" category="paragraph">.</block>
  <block id="80967cdacf7a48c49276c07097765c46" category="list-text">Cree conjuntos de puertos iSCSI y/o FC usando los LIF de SVM.</block>
  <block id="2d59cbd9d3169fc27e47164a0bf60c42" category="list-text">Cree un iGroup iSCSI y/o FC para Windows mediante el conjunto de puertos creado.</block>
  <block id="b6efc79e22c0381d9fcc8c3f40ff674f" category="list-text">Añada un iniciador al iGroup. El iniciador es el IQN para iSCSI y WWPN para FC. Pueden consultarse desde Windows Server ejecutando el cmdlet de PowerShell Get-InitiatorPort.</block>
  <block id="ab39c1b30c8045ee5b2419b682b64e5c" category="paragraph">El IQN para iSCSI en Windows Server también se puede comprobar en la configuración de las propiedades del iniciador iSCSI.</block>
  <block id="83f0120a854049de17bd46bb97e5c5fa" category="list-text">Cree una LUN usando el asistente Crear LUN y asócielo con el iGroup creado.</block>
  <block id="186c31b1cbf72f8c54f9c6a0edca1cfe" category="paragraph">Windows Server utiliza la extensión MPIO de acceso asimétrico a unidad lógica (ALUA) para determinar las rutas directas e indirectas para los LUN. Aunque todas las LIF que son propiedad de una SVM aceptan solicitudes de lectura/escritura para sus LUN, solo uno de los nodos del clúster posee los discos que respaldan ese LUN en un momento dado. Esto divide las rutas disponibles a una LUN en dos tipos, directa o indirecta, tal y como se muestra en la siguiente figura.</block>
  <block id="7dc177b120da05827161978955c8104e" category="paragraph">Una ruta directa para una LUN es una ruta en la que las LIF de una SVM y la LUN a la que se accede residen en el mismo nodo. Para pasar de un puerto de destino físico a un disco, no es necesario atravesar la red de clúster.</block>
  <block id="b456728920702bd70bc705a1af06be72" category="paragraph">Las rutas indirectas son rutas de datos en las que los LIF de una SVM y la LUN a la que se accede residen en nodos diferentes. Los datos deben atravesar la red de clúster para pasar de un puerto de destino físico al disco.</block>
  <block id="6b08a0deb0bef5f6429e5fb7bab4da29" category="inline-image-macro">Múltiples rutas en el entorno SAN,width=624,height=232</block>
  <block id="e5106eaf1ca3b8ff0d6a4555b38845de" category="paragraph"><block ref="e5106eaf1ca3b8ff0d6a4555b38845de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e6c7f4878b6fa562299bd45be030c4d" category="section-title">MPIO</block>
  <block id="a076aaca1951b14cae30726d37df2173" category="paragraph">NetApp ONTAP proporciona un almacenamiento de alta disponibilidad en el que pueden existir varias rutas desde la controladora de almacenamiento al servidor de Windows. La multivía es la capacidad de tener varias rutas de datos desde un servidor hasta una cabina de almacenamiento. El multivía protege frente a fallos de hardware (cortes de cable, fallos de switch y adaptador de bus de host [HBA], etc.) y puede proporcionar límites de rendimiento superiores al utilizar el rendimiento agregado de múltiples conexiones. Cuando una ruta o conexión deja de estar disponible, el software de rutas múltiples cambia automáticamente la carga a una de las otras rutas disponibles. La función MPIO combina las distintas rutas físicas del almacenamiento como una única ruta lógica que se utiliza para el acceso a los datos con el fin de ofrecer resiliencia al almacenamiento y balanceo de carga. Para utilizar esta función, la función MPIO debe estar habilitada en Windows Server.</block>
  <block id="90881f9a41c6c14a994dd6d410b5eae3" category="section-title">Habilite MPIO</block>
  <block id="1f4614ecf24e855792cb4a72e2ca4a86" category="paragraph">Para activar MPIO en Windows Server, lleve a cabo los siguientes pasos:</block>
  <block id="bb35cb72ffe2e8dd1a02cf65b86c6cd3" category="list-text">Inicie Server Manager.</block>
  <block id="d580309cd21fec5dd6a0fc9e095dacbe" category="list-text">En la sección Administrar, haga clic en Agregar funciones y características.</block>
  <block id="19c0c759d805032bc93817553dbc8ef9" category="list-text">En la página Seleccionar operaciones, seleccione E/S multirruta</block>
  <block id="63c2082592ff76eac0541130a24e7670" category="section-title">Configurar MPIO</block>
  <block id="655995aa16b525227f20b4e6b55a22cf" category="paragraph">Cuando utiliza el protocolo iSCSI, debe indicar a Windows Server que aplique soporte multivía a los dispositivos iSCSI en las propiedades de MPIO.</block>
  <block id="3cdb8cf9c5fe85e070ceba959169e83f" category="paragraph">Para configurar MPIO en Windows Server, lleve a cabo los siguientes pasos:</block>
  <block id="bd27f39c0a288d0682b789a806d1eec7" category="list-text">Inicie sesión en Windows Server como miembro del grupo de administradores.</block>
  <block id="a267872bfc142a132ea159cb0904930f" category="list-text">En la sección Herramientas, haga clic en MPIO.</block>
  <block id="46205f4b1d4b254565cae2fd6970a3a6" category="list-text">En MPIO Properties on Discover Multi-paths, seleccione Add Support for iSCSI Devices y haga clic en Add. A continuación, se le pedirá que reinicie el equipo.</block>
  <block id="8c372bcf6ff4084f9e072d698d449b18" category="list-text">Reinicie Windows Server para ver el dispositivo MPIO que aparece en la sección Dispositivos MPIO de Propiedades de MPIO.</block>
  <block id="28f21ae88e9953ac3d80686cfb49832b" category="section-title">Configure iSCSI</block>
  <block id="a12e2e6108a8b8cb032c190ebe798d79" category="paragraph">Para detectar el almacenamiento en bloques iSCSI en Windows Server, lleve a cabo los siguientes pasos:</block>
  <block id="623f636e32ba5729ab907ad3eeeb5adb" category="list-text">En la sección Herramientas, haga clic en Iniciador iSCSI.</block>
  <block id="d259349ad54c81b69ffb57d045a7c135" category="list-text">En la pestaña Discovery, haga clic en Discover Portal.</block>
  <block id="9055f8c4230cf1268018d9b81d1c30e0" category="list-text">Proporcione la dirección IP de las LIF asociadas con la SVM creada para el almacenamiento de NetApp para el protocolo SAN. Haga clic en Avanzado, configure la información en la ficha General y haga clic en Aceptar.</block>
  <block id="56fe767f1eb1a3401bb37455b6e1c804" category="list-text">El iniciador iSCSI detecta automáticamente el destino iSCSI y lo muestra en la pestaña Destinos.</block>
  <block id="f6357f1aad932cb8ef210a786e72e1e9" category="list-text">Seleccione el destino iSCSI en los destinos detectados. Haga clic en Conectar para abrir la ventana Conectar con destino.</block>
  <block id="28d26404caba20cb28577f61c51a7e1f" category="list-text">Debe crear varias sesiones desde el host de Windows Server a los LIF iSCSI de destino en el clúster de almacenamiento de NetApp. Para ello, lleve a cabo los siguientes pasos:</block>
  <block id="3aef6deb3c61c368bc66313781c8e351" category="list-text">En la ventana Conectar a destino, seleccione Habilitar MPIO y haga clic en Avanzado.</block>
  <block id="d754cac9ca73d1113c5fa5908ca2dc97" category="list-text">En Configuración avanzada, en la pestaña General, seleccione el adaptador local como iniciador iSCSI de Microsoft y seleccione la IP de iniciador y la IP de portal de destino.</block>
  <block id="fdcb9587e9c4d393ea337f94fb0e1f5f" category="list-text">También debe conectarse mediante la segunda ruta. Por lo tanto, repita el paso 5 al paso 8, pero esta vez seleccione la IP del iniciador y la IP del portal de destino para la segunda ruta.</block>
  <block id="cb35c153406b8cdeb5963bd9a0ceb501" category="list-text">Seleccione el destino iSCSI en Discovered Targets en la ventana principal de iSCSI Properties y haga clic en Properties.</block>
  <block id="2a3977b58760a2b4c9e557175a5e494e" category="list-text">La ventana Propiedades muestra que se han detectado varias sesiones. Seleccione la sesión, haga clic en Devices y, a continuación, haga clic en MPIO para configurar la política de equilibrio de carga. Se muestran todas las rutas configuradas para el dispositivo y se admiten todas las políticas de equilibrio de carga. NetApp recomienda generalmente round robin con subconjunto, y esta configuración es la predeterminada para las cabinas con ALUA habilitado. Round robin es el valor predeterminado para cabinas activo-activo que no admiten ALUA.</block>
  <block id="7b7b8262c038321869fc17ba522bbe07" category="paragraph">Para detectar el almacenamiento en bloques iSCSI o FC en Windows Server, lleve a cabo los siguientes pasos:</block>
  <block id="7554b29976a023cca6089775e3a7fd73" category="list-text">Haga clic en Administración de equipos en la sección Herramientas del Administrador de servidores.</block>
  <block id="b7e726cedaa814db32dbfe4395773cc4" category="list-text">En Administración de equipos, haga clic en la sección Administración de discos en almacenamiento y, a continuación, haga clic en Más acciones y Volver a analizar discos. Al hacerlo se muestran las LUN iSCSI sin configurar.</block>
  <block id="8fd13d2e47a19c784864b40dc7e4621f" category="list-text">Haga clic en la LUN detectada y conéctela. A continuación, seleccione Inicializar disco con la partición MBR o GPT. Cree un nuevo volumen simple proporcionando el tamaño del volumen y la letra de la unidad y formatéelo usando FAT, FAT32, NTFS o el sistema de archivos resistente (ReFS).</block>
  <block id="31ef353687ab7c0fb280206b2eba67d0" category="list-text">NetApp recomienda habilitar thin provisioning en los volúmenes que alojan las LUN.</block>
  <block id="de065768c0f0b724b1926b25d92fdcef" category="list-text">Para evitar problemas con la multivía, NetApp recomienda usar las 10Gb sesiones o las 1GB sesiones en una LUN determinada.</block>
  <block id="ed4eb5407c23e138e99781446b4170d8" category="list-text">NetApp recomienda confirmar que ALUA está habilitado en el sistema de almacenamiento. De forma predeterminada, ALUA está habilitado en ONTAP.</block>
  <block id="df0f70c4f2bca2f5f0216ab40982d08a" category="list-text">En el host de Windows Server al que se asigna el LUN de NetApp, habilite el servicio iSCSI (TCP-in) para el servicio entrante y el servicio iSCSI (TCP-out) para saliente en la configuración del firewall. Estos ajustes permiten que el tráfico iSCSI pase hacia y desde el host de Hyper-V y la controladora NetApp.</block>
  <block id="defe090ca065bb89790c1a0b2d533ad0" category="section-title">Aprovisionamiento de LUN de NetApp en Nano Server</block>
  <block id="a7b1fc24d300b03d303a4e66fd5eaf19" category="inline-link-macro">Implemente Nano Server.</block>
  <block id="c56e09ae358fe6206c8e4059eb76252b" category="paragraph">Además de los requisitos previos mencionados en la sección anterior, el rol de almacenamiento debe estar habilitado desde el lado de Nano Server. Por ejemplo, Nano Server debe implementarse utilizando la opción -Storage. Para implementar Nano Server, consulte la sección “<block ref="00a4a5119b1e43564baa188fc895d5ff" category="inline-link-macro-rx"></block>"</block>
  <block id="152dbede177bc5347922fdc2b306adf2" category="paragraph">Para aprovisionar LUN de NetApp en un servidor Nano, realice los siguientes pasos:</block>
  <block id="fe02f402a046a8784957e096b11835e3" category="list-text">Conéctese al Nano Server remotamente usando las instrucciones en la sección “<block ref="60e7ef5a283935545371795472ceb490" category="inline-link-macro-rx"></block>."</block>
  <block id="1b3c1a51c3603283ec4f7ab199a89ad3" category="list-text">Para configurar iSCSI, ejecute los siguientes cmdlets de PowerShell en Nano Server:</block>
  <block id="5e885af04f617a09b29600bd064e0a82" category="list-text">Añada un iniciador al iGroup.</block>
  <block id="8a73c7acbdf9fc31a87cebe8de47a176" category="list-text">Configurar MPIO.</block>
  <block id="8e08d5639ddc5bf9f71aeea2f9df6706" category="list-text">Detectar almacenamiento basado en bloques.</block>
  <block id="ad04ba98fa2a26c6e2a4f71314b1c4c7" category="section-title">Arranque desde SAN</block>
  <block id="e29512aa6180bca309f145289f08337c" category="paragraph">Un host físico (servidor) o un equipo virtual Hyper-V puede arrancar el SO de Windows Server directamente desde un LUN de NetApp en lugar de su disco duro interno. En el enfoque de arranque desde SAN, la imagen del SO desde la que se arranca reside en una LUN de NetApp conectada a un host físico o equipo virtual. En el caso de un host físico, el HBA del host físico está configurado para usar la LUN de NetApp para arrancar. Para una máquina virtual, la LUN de NetApp se conecta como disco en modo de paso para el arranque.</block>
  <block id="2cf07cb81d5366158ac32b0d02e3bf39" category="paragraph">Con la tecnología FlexClone de NetApp, las LUN de arranque con una imagen de SO pueden clonarse al instante y conectarse a los servidores y máquinas virtuales para proporcionar rápidamente imágenes de sistemas operativos limpios, como se muestra en la siguiente figura.</block>
  <block id="e60c0a021a1a11ca0fd66050c818b441" category="inline-image-macro">Arranque las LUN con FlexClone de NetApp,width=561,height=357</block>
  <block id="79f4f54e05eb2f1c2084e0542e66f182" category="paragraph"><block ref="79f4f54e05eb2f1c2084e0542e66f182" category="inline-image-macro-rx" type="image"></block></block>
  <block id="738e6a96e2bf795b59ac62d4827a779e" category="list-text">El host físico (servidor) tiene un iSCSI o FC HBA adecuados.</block>
  <block id="7957c1b3b06b3ca5c17a05da5e59c9ec" category="list-text">Ha descargado un controlador de dispositivo HBA adecuado para el servidor compatible con Windows Server.</block>
  <block id="1810f78aa22a9972644e65ac2cdad107" category="list-text">El servidor tiene una unidad de CD/DVD o un medio virtual adecuado para insertar la imagen ISO de Windows Server y se ha descargado el controlador del dispositivo HBA.</block>
  <block id="0af744e0f07c6b198e478b2ba83aca3a" category="list-text">Se aprovisiona un iSCSI o un LUN FC de NetApp en la controladora de almacenamiento de NetApp.</block>
  <block id="30e2bee2ccadbae82d2d5aeddd5b4078" category="paragraph">Para configurar el arranque desde SAN para un host físico, realice los siguientes pasos:</block>
  <block id="7d90eb9f56cbfbfe2930a2d651f51f3a" category="list-text">Active BootBIOS en el HBA del servidor.</block>
  <block id="034cb1858f7a3762e67e18bff38aa62a" category="list-text">Para los HBA iSCSI, configure la IP de iniciador, el nombre del nodo iSCSI y el modo de inicio del adaptador en los ajustes del BIOS de inicio.</block>
  <block id="aeae1f3a4453e2d3e333de58d3f28c4a" category="list-text">Al crear un iGroup para iSCSI y/o FC en una controladora de almacenamiento de NetApp, agregue el iniciador de HBA del servidor al grupo. El iniciador de HBA del servidor es el WWPN para el HBA de FC o el nombre del nodo iSCSI de iSCSI HBA.</block>
  <block id="1ec419dd357b1eacb28eec8cfd657908" category="list-text">Cree una LUN en la controladora de almacenamiento de NetApp con un ID de LUN de 0 y asócielo con el iGroup creado en el paso anterior. Esta LUN actúa como LUN de arranque.</block>
  <block id="52ec2612ed3c17b60d5c662122410366" category="list-text">Restrinja el HBA a una ruta única al LUN de arranque. Se pueden añadir rutas adicionales después de instalar Windows Server en el LUN de arranque para aprovechar la función de rutas múltiples.</block>
  <block id="0fa69ac9076a9031393e6f5d4aa909d5" category="list-text">Utilice la utilidad BootBIOS del HBA para configurar el LUN como dispositivo de arranque.</block>
  <block id="58347d33bbc0409dce93e92c5983619a" category="list-text">Reinicie el host e introduzca la utilidad BIOS del host.</block>
  <block id="1b9013d7a416c62e05336b3791451d0d" category="list-text">Configure el BIOS del host para que el LUN de inicio sea el primer dispositivo en el orden de inicio.</block>
  <block id="3472e7b0e2c4389366cf3e0f09f6376d" category="list-text">Desde la ISO de Windows Server, inicie la configuración de instalación.</block>
  <block id="8423662d97649ae1012d665b6594f514" category="list-text">Cuando la instalación le pregunte ¿Dónde desea instalar Windows?, haga clic en Cargar controlador en la parte inferior de la pantalla de instalación para iniciar la página Seleccionar controlador para instalar. Proporcione la ruta del controlador del dispositivo HBA descargado anteriormente y finalice la instalación del controlador.</block>
  <block id="4d0de28cb0fe5a517374a0c7fdaaff27" category="list-text">Ahora la LUN de inicio creada anteriormente debe estar visible en la página de instalación de Windows. Seleccione el LUN de inicio para la instalación de Windows Server en el LUN de arranque y finalice la instalación.</block>
  <block id="0dbc8e7afe6136a3b34471c047b28f83" category="paragraph">Para configurar el arranque desde SAN para una máquina virtual, lleve a cabo los siguientes pasos:</block>
  <block id="6af97eac32eef9a62687eac41262ae48" category="list-text">Al crear un iGroup para iSCSI o FC en una controladora de almacenamiento de NetApp, agregue el IQN para iSCSI o el WWN para FC del servidor de Hyper-V a la controladora.</block>
  <block id="c18de5a7c8558c6b9b749ea9d61336da" category="list-text">Cree LUN o clones de LUN en la controladora de almacenamiento de NetApp y asócielo con el iGroup creado en el paso anterior. Estas LUN actúan como LUN de arranque para las máquinas virtuales.</block>
  <block id="dac33c93e3d9b5c90a34c39aa579711a" category="list-text">Detectar las LUN en el servidor de Hyper-V, conectarlas e inicializarlas.</block>
  <block id="441d10873880501fa764914d0bf1f044" category="list-text">Desconectar las LUN.</block>
  <block id="0490d2908eb59e831010f6c50ebdf6ea" category="list-text">Cree VM con la opción Adjuntar un Disco Duro Virtual más adelante en la página Conectar Disco Duro Virtual.</block>
  <block id="2b2b3b281225dec976273bad7f4dacf0" category="list-text">Añada una LUN como disco en modo de paso a una máquina virtual.</block>
  <block id="ab82d3a85d9187f45c1cac0bd2922647" category="list-text">Abra la configuración de la máquina virtual.</block>
  <block id="d2e03542bea91031de7772d6cb0b7b13" category="list-text">Haga clic en Controlador IDE 0, seleccione Disco duro y haga clic en Agregar. Al seleccionar IDE Controller 0, este disco se convierte en el primer dispositivo de inicio para la máquina virtual.</block>
  <block id="1904d13d92aac636b46007dec34eb357" category="list-text">Seleccione Disco duro físico en las opciones de Disco duro y seleccione un disco de la lista como disco de paso. Los discos son LUN configuradas en los pasos anteriores.</block>
  <block id="19e47f17e14687afa5f6c07833dbd7aa" category="list-text">Instale Windows Server en el disco de paso.</block>
  <block id="30f837081d56a5f1605e52592a38d5f4" category="list-text">Asegúrese de que las LUN estén sin conexión. De lo contrario, no se puede agregar el disco como disco en modo de paso a una máquina virtual.</block>
  <block id="9865f9e3af02eaca8b480229a22515f4" category="list-text">Cuando haya varias LUN, asegúrese de anotar el número de disco de la LUN en la gestión de discos. Es necesario porque los discos de la máquina virtual aparecen con el número de disco. Además, la selección del disco como disco en modo de paso para la máquina virtual se basa en este número de disco.</block>
  <block id="15b11e66e58b25dffc74ff36f6529d4d" category="list-text">NetApp recomienda usar ONTAP MPIO configurado en el host con fines de almacenamiento.</block>
  <block id="154e178d8f948264ecf34dcfd8ad3112" category="summary">En este apéndice se describe cómo utilizar la migración dinámica de Hyper-V fuera de un entorno en clúster</block>
  <block id="3a37015d23bf5b95b8aaeeb60e7149f6" category="paragraph">Esta sección describe la puesta en marcha de la migración activa de Hyper-V fuera de un entorno en clúster.</block>
  <block id="34076d85579973b175bda646666488f5" category="list-text">Servidores de Hyper-V independientes con almacenamiento independiente o almacenamiento SMB compartido.</block>
  <block id="6d3867adf71fde2bd2e28c3530f980e2" category="list-text">La función Hyper-V instalada en los servidores de origen y destino.</block>
  <block id="860a24a5665c79d337512cf7091c1f27" category="list-text">Ambos servidores Hyper-V pertenecen al mismo dominio o a dominios que confían entre sí.</block>
  <block id="599b01a5eeab6af8dcd5d22203b25b3b" category="paragraph">Para realizar la migración activa en un entorno no agrupado, configure los servidores Hyper-V de origen y destino para que puedan enviar y recibir operaciones de migración en directo. En ambos servidores de Hyper-V, complete los siguientes pasos:</block>
  <block id="5c8aa736f4d71f22237d67e44338e090" category="list-text">En Acciones, haga clic en Configuración de Hyper-V.</block>
  <block id="146cc3da35b3cb4807f19e5c342f3d0b" category="list-text">Haga clic en Live Migrations y seleccione Enable Live Migrations entrantes y salientes.</block>
  <block id="000104d6631c201d8476c728987584e9" category="list-text">Elija si desea permitir el tráfico de migración en vivo en cualquier red disponible o solo en redes específicas.</block>
  <block id="bbba185068a3a5aa887f5064ee5fc3de" category="list-text">Opcionalmente, puede configurar el protocolo de autenticación y las opciones de rendimiento en la sección Avanzadas de Migración en Directo.</block>
  <block id="0d91ef025d958a7706b6abf25f2160a5" category="list-text">Si se utiliza CredSSP como protocolo de autenticación, asegúrese de iniciar sesión en el servidor Hyper-V de origen desde el servidor Hyper-V de destino antes de mover el equipo virtual.</block>
  <block id="4671ab6d9ed8f69134f49812ab7a7c35" category="list-text">Si Kerberos se utiliza como protocolo de autenticación, configure la delegación restringida. Para hacerlo, es necesario tener acceso al controlador de dominio de Active Directory. Para configurar la delegación, realice los siguientes pasos:</block>
  <block id="3c3a519ac45fd3a37ae321645897af94" category="list-text">Inicie sesión en el controlador de dominio de Active Directory como administrador.</block>
  <block id="15be526c72b91c88e16f64f6c832eb6b" category="list-text">En la sección Herramientas, haga clic en Usuarios y equipos de Active Directory.</block>
  <block id="444f95dff8ac9b4c8c6335d66d6ae4a7" category="list-text">Expanda el dominio y haga clic en Equipos.</block>
  <block id="a07ecc7f9ab368b241540687975a30aa" category="list-text">Seleccione el servidor Hyper-V de origen de la lista, haga clic con el botón derecho en él y haga clic en Propiedades.</block>
  <block id="a3a23c7b6ce827c11b3cdb698108c307" category="list-text">En la pestaña Delegación, seleccione Confiar en esta computadora sólo para la delegación a los servicios especificados.</block>
  <block id="4070350eb1a20fec8173f5ee230b8566" category="list-text">Seleccione Utilizar solo Kerberos.</block>
  <block id="36d92877123542287dffc5912e198436" category="list-text">Haga clic en Agregar, que abre el asistente Agregar servicios.</block>
  <block id="2a206fdec4cfdbdd63ff3dd2265bbb34" category="list-text">En Agregar servicios, haga clic en Usuarios y equipos, que abre Seleccionar usuarios o equipos**.**</block>
  <block id="6fb0c1f70349caf1f37bdb1c7b73efe4" category="list-text">Proporcione el nombre del servidor Hyper-V de destino y haga clic en Aceptar.</block>
  <block id="261db7be66ebd6db420e928cb4b402f7" category="list-text">Para mover el almacenamiento de equipos virtuales, seleccione CIFS.</block>
  <block id="f4288db12d8f66e52ec2ac189f491e82" category="list-text">Para mover máquinas virtuales, seleccione el servicio Microsoft Virtual System Migration.</block>
  <block id="9149d965e2ccf728685f671fb1046ab9" category="list-text">En la ficha Delegación, haga clic en Aceptar.</block>
  <block id="9bc766cbcc4911cf673963ca303576bc" category="list-text">En la carpeta Equipos, seleccione el servidor Hyper-V de destino de la lista y repita el proceso. En Seleccionar usuarios o equipos, proporcione el nombre del servidor Hyper-V de origen.</block>
  <block id="5868e6c6d4568bb2c1245c731ab1f681" category="list-text">Mover la máquina virtual.</block>
  <block id="ab102f10122268c6b0663d464d3192da" category="list-text">Seleccione Move the Virtual Machine.</block>
  <block id="8b95cb0524fdc80c99bdf8cb976556d2" category="list-text">Especifique el servidor Hyper-V de destino para la máquina virtual.</block>
  <block id="25b70b154b120ba061f03c292637a9a4" category="list-text">Seleccione las opciones de movimiento. Para Migración en vivo compartida, seleccione Mover únicamente la máquina virtual. Para Shared Nothing Live Migration, elija cualquiera de las otras dos opciones en función de sus preferencias.</block>
  <block id="8c60fc97ae35b3af22d644ab2b9186e7" category="list-text">Proporcione la ubicación de la máquina virtual en el servidor Hyper-V de destino en función de sus preferencias.</block>
  <block id="dd714dbbaab89194e2aefdf439089cff" category="list-text">Revise el resumen y haga clic en OK para mover la máquina virtual.</block>
  <block id="8ab11353f8fda3f130084c6ff3c1f32e" category="summary">Descripción general de la virtualización de Microsoft Windows y Hyper-V con ONTAP</block>
  <block id="e905fd86484ea1bf5b665b34fc9e24b4" category="paragraph">Microsoft Windows Server es un sistema operativo (SO) de clase empresarial que cubre redes, seguridad, virtualización, cloud privado, cloud híbrido, infraestructura de puestos de trabajo virtuales, protección de acceso, protección de información, servicios web, infraestructura de plataforma de aplicaciones, y mucho más.</block>
  <block id="16b5970810caafa8d6f89bee6e0398f2" category="admonition">*Esta documentación sustituye a los informes técnicos publicados anteriormente _TR-4568: Directrices de puesta en funcionamiento de NetApp y mejores prácticas de almacenamiento para Windows Server_*</block>
  <block id="0456fa2f3608424ca9c4149cfbb9692a" category="list-title">El software de gestión ONTAP(R) de NetApp se ejecuta en las controladoras de almacenamiento de NetApp. Está disponible en múltiples formatos.</block>
  <block id="dbf037f8e99a1d5b52fe58af78568561" category="list-text">Arquitectura unificada que admite protocolos de archivos, objetos y bloques. Esto permite a las controladoras de almacenamiento actuar tanto como dispositivos NAS como SAN, así como almacenes de objetos</block>
  <block id="23748de0bc860150d3c6b27a4d472042" category="list-text">Una cabina All SAN (ASA) que se centra únicamente en protocolos de bloque y optimiza los tiempos de reanudación de I/O (IORT) añadiendo accesos múltiples activo-activo simétricos para los hosts de conexión</block>
  <block id="d0114359083804284c542907b2f8cd60" category="list-text">Una arquitectura unificada definida por software</block>
  <block id="30063e1e8c837a5b52057909e747b2d8" category="list-text">ONTAP Select ejecutándose en VMware vSphere o KVM</block>
  <block id="0f76eddbf2cd8ceb8e89447591876ab9" category="list-text">Cloud Volumes ONTAP se ejecuta como instancia de cloud nativo</block>
  <block id="f7d26dbdc8e2b21b211abf2157e73536" category="list-text">Primeras ofertas de proveedores de cloud a hiperescala</block>
  <block id="4d82a1ec1af02725042c8c785564ee7a" category="list-text">Amazon FSX para ONTAP de NetApp</block>
  <block id="7450cfde7058dc5e1f7909d0280fd7ae" category="list-text">Azure NetApp Files</block>
  <block id="1215f8190533dfdf63d2224a6d88266f" category="list-text">NetApp Volumes para Google Cloud</block>
  <block id="7ad18871bdb08a3899a3f7ed4e463284" category="paragraph">ONTAP proporciona funciones de eficiencia del almacenamiento de NetApp, como la tecnología Snapshot(R) de NetApp, clonado, deduplicación, thin provisioning, thin replication compresión, almacenamiento virtual por niveles y mucho más con un rendimiento y una eficiencia mejorados.</block>
  <block id="538a662f2ecbeba6af56e41386484f67" category="paragraph">Juntos, Windows Server y ONTAP pueden funcionar en entornos de gran tamaño y aportar un gran valor a la consolidación de centros de datos y las implementaciones de cloud privado o híbrido. Esta combinación también proporciona cargas de trabajo no disruptivas de forma eficiente y admite una escalabilidad fluida.</block>
  <block id="8f0442ea7c58fe8ab4000f5aaeac415b" category="paragraph">Este documento está destinado a arquitectos de sistemas y almacenamiento que diseñan soluciones de almacenamiento de NetApp para Windows Server.</block>
  <block id="f6f27d1607ed17a4b610676f16f68357" category="paragraph">En este documento hacemos las siguientes suposiciones:</block>
  <block id="e9d690b9eb25093e460ea369baa55496" category="inline-link">Guía de administración del sistema para administradores de clústeres</block>
  <block id="d54e01b4234443b582b1d0cc44ce1c19" category="list-text">El lector tiene un conocimiento general de las soluciones de hardware y software de NetApp. Consulte<block ref="87244016000a25428f0fcae2d3732d46" category="inline-link-rx"></block> para obtener más detalles.</block>
  <block id="c501659fe58b766ec2ead9a0c974e530" category="inline-link">Gestión de SAN Clustered Data ONTAP</block>
  <block id="75ac79ee68c2245f6d8b8cc32a3eae9e" category="inline-link">Gestión de NAS</block>
  <block id="48fa880bcded409e494bd8e2e8c64a97" category="list-text">El lector tiene conocimientos generales de protocolos de acceso en bloque, como iSCSI, FC y el protocolo de acceso a archivos SMB/CIFS. Consulte<block ref="123a6e61ead9566ba44616c8f29f1ba3" category="inline-link-rx"></block> Para obtener información relacionada con SAN. Consulte<block ref="9933d9f07fd1633df051103d1b03340e" category="inline-link-rx"></block> Para información relacionada con CIFS/SMB.</block>
  <block id="02279515531a2de57bfdffa958d40813" category="list-text">El lector posee conocimientos generales sobre el sistema operativo Windows Server y Hyper-V.</block>
  <block id="e1e99607c6efe5e3439e886c50500015" category="paragraph">Si quiere obtener una matriz completa y actualizada regularmente de configuraciones SAN y NAS probadas y compatibles, consulte la<block ref="5555d80b97794db0ba7e8564a4b85ca4" category="inline-link-rx"></block> En el sitio de soporte de NetApp. Con IMT, puede determinar las versiones exactas de producto y funciones compatibles con su entorno concreto. El NetApp IMT define los componentes y las versiones del producto que son compatibles con las configuraciones compatibles con NetApp. Los resultados específicos dependen de la instalación que realice cada cliente de acuerdo con las especificaciones publicadas.</block>
  <block id="3eb0aeddd8b10d858bd2028c6f983308" category="summary">Mejores prácticas operativas para el almacenamiento de VMware SRM y ONTAP</block>
  <block id="35d022831f6b84d57c0d19770bd37b82" category="list-text">ONTAP 9 se puede configurar para eliminar automáticamente instantáneas para mantener el tiempo de actividad en caso de una condición de falta de espacio cuando autosize no puede suministrar suficiente capacidad de emergencia. La configuración predeterminada para esta funcionalidad no elimina automáticamente las copias Snapshot que crea SnapMirror. Si se eliminan las snapshots de SnapMirror, el SRA de NetApp no puede revertir ni resincronizar la replicación del volumen afectado. Para evitar que ONTAP elimine snapshots de SnapMirror, configure la funcionalidad de eliminación automática de Snapshot para intentar.</block>
  <block id="70ca1a895029f273d425b715900ff37a" category="inline-image-macro">Replicación de vVols</block>
  <block id="0c1274faebf0b61ccee15ede78b00b55" category="paragraph"><block ref="0c1274faebf0b61ccee15ede78b00b55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2c5aade1021a3c4cd296db5e8cca90b" category="inline-image-macro">Programaciones de SnapMirror</block>
  <block id="a1066290411892a896db86292d410eb3" category="paragraph"><block ref="a1066290411892a896db86292d410eb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1079afba0a1986bf5bb313da40d31a49" category="inline-image-macro">asignación de políticas</block>
  <block id="32e0e862ac943abe75cff3d58b3e5d2b" category="paragraph"><block ref="32e0e862ac943abe75cff3d58b3e5d2b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3dd63afe980253ca98d9e32784c2f1fc" category="paragraph">Esto viene con un nuevo requisito en nombre del administrador de vSphere. Dado que los volúmenes se crean fuera del ámbito de las herramientas de ONTAP, no conoce los cambios que ha realizado el administrador de ONTAP hasta el periodo de repetición de la detección programado periódicamente. Por este motivo, se recomienda ejecutar la redetección siempre que se cree una relación de volúmenes o SnapMirror que se utilice con vVols. Simplemente haga clic con el botón derecho en el host o clúster y seleccione Herramientas de ONTAP &gt; Actualizar host y almacenamiento de datos, como se muestra en la siguiente captura de pantalla.</block>
  <block id="2802aa9f39078d087d6ee0f565b18e51" category="inline-image-macro">Actualizar datos de host y almacenamiento</block>
  <block id="416223ee42c638c719e40efc871fe8a1" category="paragraph"><block ref="416223ee42c638c719e40efc871fe8a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="06b2d4b91b5c9eaa8c20a1c270f95b3c" category="inline-image-macro">clúster</block>
  <block id="6c0893d9a45aaff00c1ef0daf0867ada" category="paragraph"><block ref="6c0893d9a45aaff00c1ef0daf0867ada" category="inline-image-macro-rx" type="image"></block></block>
  <block id="820b71b9a8a55fe48690a5f973c5480e" category="paragraph">La ingeniería de software con Herramientas de ONTAP para VMware vSphere emplea las siguientes actividades de desarrollo seguro:</block>
  <block id="ecdc76c84c9674a3148f3d464298469c" category="paragraph">Las herramientas de ONTAP para VMware vSphere incluyen las siguientes funciones de seguridad en cada versión.</block>
  <block id="0785fa6b3221e7345916be824259dc2f" category="paragraph">Cuando se usan SDRS con herramientas de ONTAP para VMware vSphere, primero debe crear un almacén de datos con el plugin, utilizar vCenter para crear el clúster de almacén de datos y, a continuación, añadir el almacén de datos. Una vez creado el clúster de almacenes de datos, es posible añadir almacenes de datos adicionales al clúster de almacenes de datos directamente desde el asistente de aprovisionamiento de la página Details.</block>
  <block id="043d75b2a25cf6f38bccaf9211c5bcc5" category="summary">Esta página describe las mejores prácticas para implementar una solución de almacenamiento de ONTAP en un entorno de VMware vSphere.</block>
  <block id="760f70bd45ae12af9fa6bee90f402eeb" category="cell">Consulte NFS.MaxQueueDepth en <block ref="1f38ac07598dbb4b06912539aafa4211" category="inline-link-macro-rx"></block>.</block>
  <block id="5c6034b4452ec29d83cf38ddf5f9e2f6" category="paragraph">La arquitectura ONTAP es una plataforma de almacenamiento flexible y escalable que proporciona servicios SAN (FCP, iSCSI y NVMe-oF) y NAS (NFS v3 y v4,1) para almacenes de datos. Los sistemas de almacenamiento NetApp AFF, ASA y FAS utilizan el sistema operativo ONTAP para ofrecer protocolos adicionales para acceso al almacenamiento invitado, como S3 y SMB/CIFS.</block>
  <block id="647fe6e64f77a1f54f9bb61154ab2a4f" category="summary">Más recursos de vVols</block>
  <block id="852ee2d26adc87d2379ffeb9287f7642" category="inline-image-macro">Herramientas de ONTAP para la consola de VMware vSphere 9,8 vVols</block>
  <block id="12947c7ceaf237f27fd206edb07cc0c1" category="paragraph"><block ref="12947c7ceaf237f27fd206edb07cc0c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2c48e84c0d02dd4e236da05038bd9a" category="paragraph">ONTAP admite almacenes de datos de VVol tanto VMFS como NFS. El uso de vVols con almacenes DE datos SAN aporta algunas de las ventajas de NFS, como la granularidad a nivel de equipo virtual. Aquí encontrará algunas prácticas recomendadas para tener en cuenta y información adicional en <block ref="7be3ce63e842612697a6d91b19b8afcd" category="inline-link-macro-rx"></block>:</block>
  <block id="436b5d96360742275889cb237fe2ab70" category="inline-image-macro">Componentes de vVols</block>
  <block id="1706c14e85f152d61bab2f65d32810a1" category="paragraph"><block ref="1706c14e85f152d61bab2f65d32810a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43f38d7beb04aa98b65d2317c2f1659f" category="inline-image-macro">Herramientas de ONTAP para vSphere</block>
  <block id="aa5b1d896aebe8a04ceac7c2a16b2cd3" category="paragraph"><block ref="aa5b1d896aebe8a04ceac7c2a16b2cd3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4b0e8af5e898d44e394489b0c629abb" category="image-alt">Grupos de hosts de VM y reglas de afinidad</block>
  <block id="9a2f41e25337439aa55e14c7e16bf211" category="summary">La solución de ONTAP para Site Recovery Manager de VMware (SRM)</block>
  <block id="a2fca395a283b61cb3e85ebc206c6274" category="paragraph">ONTAP ha sido una solución de almacenamiento líder para entornos VMware vSphere desde su introducción en el centro de datos moderno en 2002, y continúa añadiendo funcionalidades innovadoras para simplificar la gestión y reducir los costes.</block>
  <block id="f98dd9d12416a648450df8c99d10878a" category="summary">Esta es una descripción general de VMware vSphere Virtual Volumes (vVols) con ONTAP</block>
  <block id="674c41ba00ec77fc9d294abbba7e7b7d" category="paragraph">ONTAP ha sido una solución de almacenamiento líder para entornos VMware vSphere durante más de dos décadas y continúa añadiendo funcionalidades innovadoras para simplificar la gestión al tiempo que reduce los costes.</block>
  <block id="ae7454da5e20b82b7fe67eb1ff88c923" category="admonition">Esta documentación sustituye a los informes técnicos _TR-4400 publicados previamente: VMware vSphere Virtual Volumes (vVols) con ONTAP_</block>
  <block id="ee82b7a98212a75a2397dd9c5f9b1ab4" category="paragraph">ONTAP ha admitido la especificación VASA desde su versión inicial en 2012. Aunque otros sistemas de almacenamiento de NetApp son compatibles con VASA, este documento se centra en las versiones compatibles actualmente de ONTAP 9.</block>
  <block id="669b30b7e6d5ef1d862fe65880b816a8" category="paragraph">Además de ONTAP 9 en los sistemas AFF, ASA y FAS, NetApp admite cargas de trabajo de VMware en ONTAP Select, Amazon FSx para NetApp con VMware Cloud en AWS, Azure NetApp Files con la solución de VMware Azure, Cloud Volumes Service con Google Cloud VMware Engine y el almacenamiento privado de NetApp en Equinix sin embargo, la funcionalidad específica puede variar según el proveedor de servicios y la conectividad de red disponible. También está disponible el acceso desde invitados de vSphere a los datos almacenados en dichas configuraciones, así como en Cloud Volumes ONTAP.</block>
  <block id="afd715f07b1ec06fe77bf23a2d7bf185" category="paragraph">_Para obtener más información acerca de las prácticas recomendadas para ONTAP y VMware vSphere, consulte <block ref="5dbb4949ffa7cb97fe4eaffc517a1111" category="inline-link-macro-rx"></block>_</block>
  <block id="bfdc61fd18bd1a23d9660561bc8999b7" category="list-text">*Cloud Volumes ONTAP.* el software para la gestión de datos Cloud Volumes ONTAP de NetApp proporciona control, protección, flexibilidad y eficiencia para sus datos en el cloud que elija. Cloud Volumes ONTAP es un software para la gestión de datos nativo en el cloud e integrado en el almacenamiento de ONTAP. Utilícelo con Cloud Manager para poner en marcha y gestionar instancias de Cloud Volumes ONTAP junto con sus sistemas ONTAP locales. Aproveche las funcionalidades avanzadas de NAS e iSCSI SAN junto con la gestión de datos unificada, incluidas copias Snapshot y replicación de SnapMirror.</block>
  <block id="e88c947a5d8f4c0daec271a8595604a7" category="inline-image-macro">Vista Active IQ Unified Manager Virtual Machines</block>
  <block id="9078040b61fc8a9bd0215e8f35ff788c" category="paragraph"><block ref="9078040b61fc8a9bd0215e8f35ff788c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ef2f850d3f17cacfbd404bade7eed5b" category="inline-image-macro">Topología ampliada de AIQUM</block>
  <block id="75817aa97084cb93e0292a1f0549551f" category="paragraph"><block ref="75817aa97084cb93e0292a1f0549551f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbd6cdb70073007e002f1ae45c2f7e4a" category="summary">Topologías de replicación mediante ONTAP con SnapMirror y VMware SRM.</block>
  <block id="4e749568996a3331860532ac7a470fdb" category="inline-image-macro">Diseño de la relación de SnapMirror</block>
  <block id="3d2c169d59a49a498b2d7e714c5a6ce2" category="paragraph"><block ref="3d2c169d59a49a498b2d7e714c5a6ce2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="706bdd824ec69e00026180eaf2801d2e" category="paragraph"><block ref="706bdd824ec69e00026180eaf2801d2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba1aebb9b3c7be6b408863c12bbc2844" category="paragraph"><block ref="ba1aebb9b3c7be6b408863c12bbc2844" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea07c4b81c3f00ae8bbef49ac8562d1c" category="paragraph"><block ref="ea07c4b81c3f00ae8bbef49ac8562d1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12a757dd793cbe082927530094a72d26" category="inline-image-macro">parejas de cabinas</block>
  <block id="263506cdbbc7c35e461fc5f1044b9c79" category="paragraph"><block ref="263506cdbbc7c35e461fc5f1044b9c79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b26873df0260bdc332a7511f6823cf63" category="inline-image-macro">Configuraciones no admitidas</block>
  <block id="120528a3f7d5a39fdd0d67fb0e2b94a4" category="paragraph"><block ref="120528a3f7d5a39fdd0d67fb0e2b94a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="160a69c7a04198d870353b06dbf714a9" category="paragraph"><block ref="160a69c7a04198d870353b06dbf714a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="742a3ab0c9a97e5a438c8edfb1b271d2" category="paragraph"><block ref="742a3ab0c9a97e5a438c8edfb1b271d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d0a05359b36f0932509cfa007b46e853" category="inline-image-macro">Cascada de las relaciones de SnapMirror</block>
  <block id="2057708d80974a7573d92b3e0d8a9258" category="paragraph"><block ref="2057708d80974a7573d92b3e0d8a9258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd92dffb12f75e4b81ad67d8668ae698" category="inline-image-macro">SnapMirror a SnapVault en cascada</block>
  <block id="13ece5df0d16f65585acbfb9ebad113c" category="paragraph"><block ref="13ece5df0d16f65585acbfb9ebad113c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c74d71595c83ecb05581a89554ca8bb2" category="inline-image-macro">SnapMirror a SnapVault en cascada inversa</block>
  <block id="5bb35c000e450925b37eff3feca75a24" category="paragraph"><block ref="5bb35c000e450925b37eff3feca75a24" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2ab367df5e87b988bc086e5ee534793e" category="summary">Esta página describe las mejores prácticas para implementar VMware vSphere con ONTAP y almacenes de datos conectados a NFS.</block>
  <block id="0e768c8183bcbfc87718f59d9dfd61eb" category="inline-link-macro">almacenes de datos</block>
  <block id="7572da31a038800eb34beda1c04e73ea" category="paragraph">NetApp ONTAP representa, entre otras cosas, una cabina NAS de escalado horizontal para empresas. ONTAP proporciona acceso concurrente a los almacenes de datos conectados a NFS desde muchos hosts ESXi, lo que supera con creces los límites impuestos en los sistemas de archivos VMFS. El uso de NFS con vSphere proporciona algunas ventajas de facilidad de uso y visibilidad de la eficiencia del almacenamiento, como se menciona en la <block ref="72b655a9973dbed02099f5e63762d591" category="inline-link-macro-rx"></block> sección.</block>
  <block id="e6a172fa04a2b585ad34762a7e8991da" category="list-text">Consulte las notas de la tabla de interoperabilidad de NFS v4.1 en el <block ref="6a9c495bd8eb9d28b9471f77a4372a63" category="inline-link-macro-rx"></block> Para los niveles de parches específicos de ESXi que se requieren para soporte.</block>
  <block id="622b235a9123d972c612737c81eb55a1" category="inline-link-macro">NFSv3 Función nConnect con NetApp y VMware</block>
  <block id="6185cefe4b2be85244dfd9d4fce6f2e4" category="list-text">VMware admite nconnect con NFSv3 desde vSphere 8.0U2. Puede encontrar más información sobre nconnect en la <block ref="390300af711b584cff3623a0769fdf9b" category="inline-link-macro-rx"></block></block>
  <block id="d94a770977f68948a4930f4a2edbabb9" category="image-alt">Nuevo clúster</block>
  <block id="f5c7047b98efcb8c7eef2db6ef31faf4" category="image-alt">Activar la opción Supervisión de host</block>
  <block id="239aaf78fcb42b02d3709057d2a7978a" category="image-alt">Supervisión de máquinas virtuales</block>
  <block id="a7765f8868404f7c3cb890ce051f7de4" category="image-alt">Control de admisión</block>
  <block id="807dfd0ff3fd0db4a48087c18683dc6b" category="image-alt">Recomendaciones de SDRS</block>
  <block id="e5bd6e5564d38885fef18a28e48861b4" category="image-alt">Clúster de ALTA disponibilidad</block>
  <block id="8e00c91ecf143f76c94e3aa1668fc92b" category="inline-image-macro">Clonado de ONTAP</block>
  <block id="9c7295440be885852a164f5880627146" category="paragraph"><block ref="9c7295440be885852a164f5880627146" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eed6756a7834e04fb7716ee8d830425" category="inline-link-macro"><block ref="1eed6756a7834e04fb7716ee8d830425" category="inline-link-rx"></block></block>
  <block id="0e4a75553a081fffff029a37e55f5d71" category="inline-link-macro"><block ref="0e4a75553a081fffff029a37e55f5d71" category="inline-link-rx"></block></block>
  <block id="2e633a7cd484b8152bb61b1eee51006b" category="paragraph">La licencia FlexClone de ONTAP (incluida con ONTAP One) y el dispositivo de herramientas de ONTAP son los únicos productos adicionales necesarios para utilizar vVols con ONTAP. Los últimos lanzamientos de las herramientas de ONTAP se suministran como un único dispositivo unificado que se ejecuta en ESXi, lo que proporciona la funcionalidad de lo que antes eran tres dispositivos y servidores diferentes. Para vVols, es importante usar las extensiones de la interfaz de usuario de vCenter de las herramientas de ONTAP o las API de REST como herramientas de gestión generales e interfaces de usuario para las funciones de ONTAP con vSphere, junto con el proveedor VASA que proporciona funcionalidades vVols específicas. El componente SRA se incluye en los almacenes de datos tradicionales, pero Site Recovery Manager de VMware no utiliza SRA para vVols, en su lugar implementa nuevos servicios en SRM 8,3 y versiones posteriores, que aprovechan el proveedor VASA para la replicación de vVols.</block>
  <block id="32fd58743bd2ce579949a47db1b95ca8" category="summary">La replicación de vVols con VASA ofrece una funcionalidad única comparada con el SRA y los almacenes de datos tradicionales.</block>
  <block id="daf6970022e96957e3a4ea5b6a599a27" category="list-text">Mientras que las herramientas de ONTAP y el SRA admiten credenciales a nivel de clúster y SVM, VASA Provider solo admite credenciales a nivel de clúster para los sistemas de almacenamiento. Esto se debe a que muchas de las API usadas para vVols solo están disponibles a nivel de clúster. Por lo tanto, si planea utilizar vVols, debe añadir los clústeres de ONTAP con credenciales de ámbito de clúster.</block>
  <block id="570bfadf5783125790b6c87f55842fb2" category="inline-image-macro">Puesta en marcha de SnapCenter</block>
  <block id="71ca4878111d253f9883f471e5de9594" category="paragraph"><block ref="71ca4878111d253f9883f471e5de9594" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd90e11d4c9fc73f37adda8029276215" category="summary">Esta página describe las mejores prácticas para implementar una solución de almacenamiento de ONTAP en un entorno de VMware vSphere.</block>
  <block id="8afcf3d1b8ed57f17fa4289709b541e9" category="list-text">NetApp solo recomienda deshabilitar el control de flujo de red en los puertos de red de clúster dentro de un clúster de ONTAP. NetApp no ofrece otras recomendaciones para seguir las prácticas recomendadas para los puertos de red restantes que se usan para el tráfico de datos. Debe habilitarla o deshabilitarla según sea necesario. Consulte<block ref="bdfb81665a0ef86d871a52c0e6ebc591" category="inline-link-rx"></block> para obtener más fondo sobre el control de flujo.</block>
  <block id="4cc4b32d72a64364862dd657b7eee15e" category="paragraph">Tanto NMP como ONTAP son compatibles con el acceso asimétrico de unidad lógica (ALUA) para negociar rutas optimizadas y no optimizadas. En ONTAP, una ruta optimizada para ALUA sigue una ruta de datos directa mediante un puerto de destino en el nodo que aloja la LUN a la que se está accediendo. De forma predeterminada, ALUA está activado tanto en vSphere como en ONTAP. El NMP reconoce el clúster ONTAP como ALUA y utiliza el complemento de tipo de cabina de almacenamiento ALUA <block ref="d4f7bd3bf4872a2f8cd0cbe400fb23d0" prefix="(" category="inline-code"></block>) y selecciona el plugin de selección de ruta de acceso por turnos <block ref="4646bb781f9a95f64c182af129e43c7c" prefix="(" category="inline-code"></block>).</block>
  <block id="1c3a2682b8cd10046ff8399ffc6c980c" category="paragraph">SLM limita los nodos que anuncian rutas a un LUN determinado. NetApp es una práctica recomendada tener al menos un LIF por nodo por SVM y usar SLM para limitar las rutas anunciadas al nodo que aloja la LUN y su partner de alta disponibilidad. Aunque existen otras rutas, no se anuncian por defecto. Es posible modificar las rutas anunciadas con los argumentos de nodo de informes Agregar y quitar dentro de SLM. Tenga en cuenta que las LUN creadas en versiones anteriores a la 8,3 anuncian todas las rutas y deben modificarse únicamente para anunciar las rutas al par de alta disponibilidad que aloja. Para obtener más información sobre SLM, consulte la sección 5.9 de<block ref="c6b12416d518b4689065ffe16afe88db" category="inline-link-rx"></block>. El método anterior de conjuntos de puertos también puede utilizarse para reducir aún más las rutas disponibles para una LUN. Los conjuntos de puertos ayudan a reducir el número de rutas visibles a través de las cuales los iniciadores de un igroup pueden ver LUN.</block>
  <block id="b05dc829eda4798f22045fd6851afaaf" category="list-text">Para las LUN creadas antes de Data ONTAP 8,3, aplique manualmente SLM ejecutando el<block ref="886fd385b633a0746a8a08f8f00c67cd" prefix=" " category="inline-code"></block> Comando para quitar los nodos de generación de informes de LUN y restringir el acceso de las LUN al nodo de propiedad de LUN y a su partner de alta disponibilidad.</block>
  <block id="5983b6c329fc9e16157db158f01b3bb1" category="list-text">En el caso de las redes iSCSI, utilice varias interfaces de red de VMkernel en distintas subredes de la red con la agrupación de NIC cuando haya varios switches virtuales. También puede utilizar varias NIC físicas conectadas a varios switches físicos para proporcionar alta disponibilidad y mayor rendimiento. En la figura siguiente se proporciona un ejemplo de conectividad multivía. En ONTAP, use un grupo de interfaces de un único modo con varios enlaces a diferentes switches o LACP con grupos de interfaces multimodo para obtener alta disponibilidad y ventajas sobre la agregación de enlaces.</block>
  <block id="f0634c16da2019d5a4bad40e20aea8a7" category="list-text">Para obtener más información sobre cómo usar NVMe/FC con vSphere 7.0, consulte este tema<block ref="6b4ed262d14e47ef641cd57b65c32c38" category="inline-link-rx"></block> y..<block ref="7a29b2f31035a451d5b068728d2b79a7" category="inline-link-rx"></block>. En la siguiente figura, se muestra la conectividad multivía de un host de vSphere a un LUN de ONTAP.</block>
  <block id="ab906277df9ce070b1e11724f8ccf589" category="list-text">Utilice una sola interfaz lógica (LIF) para cada SVM en cada nodo del clúster de ONTAP. Ya no son necesarias las recomendaciones anteriores de una LIF por almacén de datos. Aunque el acceso directo (LIF y almacén de datos en el mismo nodo) es el mejor, no se preocupe por el acceso indirecto, ya que el efecto sobre el rendimiento suele ser mínimo (microsegundos).</block>
  <block id="522483df083cc02904b0eec18cef8e4e" category="list-text">Todas las versiones de VMware vSphere compatibles en la actualidad pueden usar NFS v3 y v4,1. La compatibilidad oficial con nconnect se ha añadido a la actualización 2 de vSphere 8,0 para NFS v3. Para NFS v4,1, vSphere sigue admitiendo el truncado de sesión, la autenticación Kerberos y la autenticación Kerberos con integridad. Es importante tener en cuenta que el trunking de sesión requiere ONTAP 9.14.1 o una versión posterior. Puede obtener más información sobre la función nconnect y cómo mejora el rendimiento en <block ref="390300af711b584cff3623a0769fdf9b" category="inline-link-macro-rx"></block>.</block>
  <block id="b01b10b0c784ff1a4d4f05add231b52a" category="paragraph">Vale la pena señalar que NFSv3 y NFSv4,1 utilizan diferentes mecanismos de bloqueo. NFSv3 utiliza bloqueo del lado del cliente, mientras que NFSv4,1 utiliza bloqueo del lado del servidor. Aunque un volumen ONTAP se puede exportar mediante ambos protocolos, ESXi solo puede montar un almacén de datos a través de un protocolo. Sin embargo, esto no significa que otros hosts ESXi no puedan montar el mismo almacén de datos mediante una versión diferente. Para evitar cualquier problema, es esencial especificar la versión del protocolo que se debe utilizar al montar, asegurándose de que todos los hosts utilicen la misma versión y, por lo tanto, el mismo estilo de bloqueo. Es crucial evitar mezclar versiones de NFS entre hosts. Si es posible, utilice perfiles de host para comprobar el cumplimiento.
** Debido a que no hay una conversión automática del almacén de datos entre NFSv3 y NFSv4,1, cree un nuevo almacén de datos NFSv4,1 y use Storage vMotion para migrar las máquinas virtuales al nuevo almacén de datos.
** Consulte las notas de la tabla de interoperabilidad de NFS v4,1 en la <block ref="6a9c495bd8eb9d28b9471f77a4372a63" category="inline-link-macro-rx"></block> Para los niveles de parches específicos de ESXi que se requieren para soporte.
* Las políticas de exportación NFS se utilizan para controlar el acceso de los hosts vSphere. Puede usar una política con varios volúmenes (almacenes de datos). Con NFSv3, ESXi utiliza el estilo de seguridad sys (UNIX) y requiere la opción de montaje raíz para ejecutar las máquinas virtuales. En ONTAP, esta opción se denomina superusuario y cuando se utiliza la opción superusuario, no es necesario especificar el ID de usuario anónimo. Tenga en cuenta que las reglas de política de exportación con valores diferentes para<block ref="ea72d12ecaa06afdb0c8a3b15e485e95" prefix=" " category="inline-code"></block> y..<block ref="df809a941c1287d18c08bb5927b639dc" prefix=" " category="inline-code"></block> Puede causar problemas de detección de SVM con las herramientas de ONTAP. He aquí una política de ejemplo:
** Protocolo de acceso: nfs3
** Client Match Spec: 192.168.42.21
** Regla de acceso RO: Sys
** Regla de acceso RW: Sys
** UID anónimo
** Superusuario: Sys
* Si se utiliza el plugin NFS de NetApp para VMware VAAI, el protocolo debe establecerse como<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> cuando se crea o se modifica la regla de política de exportación. El protocolo NFSv4 se requiere para que la copia VAAI se descargue para que funcione y especifique el protocolo como<block ref="2521ef5d58fc027d3121662b7d8f9ac2" prefix=" " category="inline-code"></block> Incluye automáticamente tanto las versiones NFSv3 como NFSv4.
* Los volúmenes de almacenes de datos NFS se unen desde el volumen raíz de la SVM; por lo tanto, ESXi también debe tener acceso al volumen raíz para navegar y montar volúmenes de almacenes de datos. La política de exportación del volumen raíz y para cualquier otro volumen en el que esté anidada la unión del volumen de almacenes de datos, debe incluir una regla o reglas para los servidores ESXi que les otorgan acceso de solo lectura. A continuación, se muestra una política de ejemplo para el volumen raíz, que también utiliza el complemento VAAI:
** Protocolo de acceso: nfs (que incluye tanto nfs3 como nfs4)
** Client Match Spec: 192.168.42.21
** Regla de acceso RO: Sys
** Regla de acceso RW: Nunca (mejor seguridad para el volumen raíz)
** UID anónimo
** Superusuario: Sys (también es necesario para el volumen raíz con VAAI)
* Utilice las herramientas de ONTAP para VMware vSphere (la mejor práctica más importante):
** El uso de herramientas de ONTAP para VMware vSphere para aprovisionar almacenes de datos, ya que simplifica la gestión automática de políticas de exportación.
** Al crear almacenes de datos para clústeres de VMware con el complemento, seleccione el clúster en lugar de un único servidor ESX. Esta opción la activa para montar automáticamente el almacén de datos en todos los hosts del clúster.
** Utilice la función de montaje plug-in para aplicar almacenes de datos existentes a nuevos servidores.
** Cuando no utilice las herramientas de ONTAP para VMware vSphere, utilice una única política de exportación para todos los servidores o para cada clúster de servidores donde se necesite un control de acceso adicional.
* Aunque ONTAP ofrece una estructura de espacio de nombres de volúmenes flexible para organizar los volúmenes en un árbol mediante uniones, este enfoque no tiene valor para vSphere. Crea un directorio para cada equipo virtual en la raíz del almacén de datos, independientemente de la jerarquía de espacio de nombres del almacenamiento. Por lo tanto, la práctica recomendada es simplemente montar la ruta de unión para volúmenes para vSphere en el volumen raíz de la SVM, que es la forma en que las herramientas de ONTAP para VMware vSphere aprovisiona almacenes de datos. No tener rutas de unión anidadas también significa que ningún volumen depende de ningún otro volumen que no sea el volumen raíz y que el hecho de desconectar un volumen o destruirlo, incluso intencionalmente, no afecta la ruta a otros volúmenes.
* Un tamaño de bloque de 4K está bien para particiones NTFS en almacenes de datos NFS. En la siguiente figura, se muestra la conectividad de un host vSphere a un almacén de datos NFS de ONTAP.</block>
  <block id="8dc90de75c19a4114217f443b0ca2866" category="inline-image-macro">Conectividad desde un host de vSphere a un almacén de datos NFS de ONTAP</block>
  <block id="36b9a8da16a1d2fad06b788e662b7c4a" category="paragraph"><block ref="36b9a8da16a1d2fad06b788e662b7c4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb6d2d52dfe07f9662232c444256aece" category="paragraph">Un host que utilice iSCSI o NVMe/TCP se puede conectar directamente a un sistema de almacenamiento y funcionar normalmente. El motivo son las rutas. Las conexiones directas a dos controladoras de almacenamiento diferentes dan como resultado dos rutas independientes para el flujo de datos. La pérdida de una ruta, un puerto o una controladora no impide que se utilice la otra ruta.</block>
  <block id="0d761ccb2787bad60b77ac971f6d3914" category="summary">Esta página describe las mejores prácticas para implementar volúmenes de ONTAP FlexGroup en un entorno de VMware vSphere.</block>
  <block id="adc6ae60e2ce9c7497e70727d5232a2d" category="paragraph">Utilice ONTAP y FlexGroup Volumes con VMware vSphere para obtener almacenes de datos sencillos y escalables que aprovechan toda la potencia de todo un clúster de ONTAP.</block>
  <block id="53c3353b925071c58c705888c2ba7f14" category="paragraph">ONTAP 9,8, junto con las herramientas de ONTAP para VMware vSphere 9,8 y el complemento SnapCenter para las versiones VMware 4,4, añadieron compatibilidad con almacenes de datos FlexGroup respaldados por volúmenes en vSphere. Los volúmenes FlexGroup simplifican la creación de grandes almacenes de datos y crean automáticamente los volúmenes constituyentes distribuidos necesarios en el clúster ONTAP para obtener el rendimiento máximo de un sistema ONTAP.</block>
  <block id="fdf48fe142acd462c4ab95bcf98e4fbb" category="inline-link-macro">Informes técnicos sobre volúmenes de FlexCache y FlexGroup</block>
  <block id="30e42e74f288a9fb226badf03bf51e15" category="paragraph">Obtenga más información acerca de FlexGroup Volumes en <block ref="5f6b1cf32bf6db914bf0a069b045a450" category="inline-link-macro-rx"></block>.</block>
  <block id="3f004d1e872dca374feb3f23565997c6" category="paragraph">Utilice FlexGroup Volumes con vSphere si necesita un único almacén de datos de vSphere escalable con la potencia de un clúster ONTAP completo, o si cuenta con cargas de trabajo de clonado muy grandes que pueden beneficiarse del nuevo mecanismo de clonación de FlexGroup.</block>
  <block id="55e0e7799b68cd76cf68be0ee82fef7b" category="section-title">Descarga de copias</block>
  <block id="6dda3ca3c4d8fee4a726d8e72402d30a" category="paragraph">Además de las amplias pruebas del sistema con cargas de trabajo de vSphere, ONTAP 9,8 añadió un nuevo mecanismo de descarga de copia para los almacenes de datos de FlexGroup. Este nuevo sistema emplea un motor de copia mejorado para replicar archivos entre componentes en segundo plano a la vez que permite el acceso al origen y al destino. A continuación, esta caché local se utiliza para instanciar rápidamente clones de equipos virtuales bajo demanda.</block>
  <block id="aa27f776099657de8054550adc71803c" category="inline-link">Cómo configurar FlexGroup de ONTAP para permitir la descarga de la copia de VAAI</block>
  <block id="52b5c3310b38cd7b3015770aa7de4aa7" category="paragraph">Para habilitar la descarga de copias optimizada para FlexGroup, consulte<block ref="cbb2bc98314efa36f692ba86393a7074" category="inline-link-rx"></block></block>
  <block id="0db4fc806176bc768d44fa59cf3c36aa" category="paragraph">Puede ocurrir que si utiliza la clonación de VAAI, pero no clona lo suficiente para mantener la caché caliente, es posible que los clones no sean más rápidos que una copia basada en host. Si ese es el caso, puede ajustar el tiempo de espera de la caché para adaptarse mejor a sus necesidades.</block>
  <block id="1e8e371d8058e71f2444bc0cd42517eb" category="paragraph">Cada trabajo de clon nuevo que recibe un volumen restablece el tiempo de espera. Si un volumen constituyente de FlexGroup de ejemplo no recibe una solicitud de clonado antes del tiempo de espera, se borrará la caché de esa máquina virtual en particular y el volumen se deberá volver a completar. Además, si el origen del clon original cambia (por ejemplo, ha actualizado la plantilla), la caché local de cada componente se invalidará para evitar cualquier conflicto. Como se ha indicado anteriormente, la caché se puede ajustar y se puede configurar para satisfacer las necesidades del entorno.</block>
  <block id="6bcf203b609d41b14c06e319cede61d7" category="section-title">Configuración de calidad de servicio</block>
  <block id="9ab9903a16c07ff38214a043719957fd" category="paragraph">Se admite la configuración de la calidad de servicio en el nivel de FlexGroup mediante ONTAP System Manager o el shell del clúster; sin embargo, no se proporciona para la máquina virtual ni la integración con vCenter.</block>
  <block id="d9450aaad95d69e8cc75ddc0a69a9026" category="paragraph">La calidad de servicio (IOPS máx./mín.) se puede establecer en máquinas virtuales individuales o en todas las máquinas virtuales de un almacén de datos en ese momento en la interfaz de usuario de vCenter o mediante las API de REST con las herramientas de ONTAP. La configuración de la calidad de servicio en todas las máquinas virtuales sustituye cualquier configuración independiente por cada máquina virtual. Los ajustes no amplían en el futuro a máquinas virtuales nuevas o migradas; establezca la calidad de servicio en las nuevas máquinas virtuales o vuelva a aplicar la calidad de servicio a todas las máquinas virtuales del almacén de datos.</block>
  <block id="43a70a1e984a991b55dc01f4e4c6bda0" category="paragraph">Tenga en cuenta que VMware vSphere trata todas las I/O de un almacén de datos NFS como una única cola por host, y la limitación de la calidad de servicio de un equipo virtual puede afectar al rendimiento de otras máquinas virtuales del mismo almacén de datos. Esto contrasta con vVols, que puede mantener su configuración de política de calidad de servicio si migran a otro almacén de datos y no afecta la I/O de otras máquinas virtuales cuando se acelera.</block>
  <block id="f32c3edaacea72c0ddb30ecf0135c4de" category="section-title">Métricas</block>
  <block id="ed7927d72c6154d79bedf6b19ea8fc83" category="paragraph">ONTAP 9,8 también agregó nuevas métricas de rendimiento basadas en archivos (IOPS, rendimiento y latencia) para archivos FlexGroup. Estas métricas pueden visualizarse en la consola de herramientas de ONTAP para la consola de VMware vSphere e informes de VM. Las herramientas de ONTAP para el complemento VMware vSphere también le permiten establecer reglas de calidad de servicio (QoS) con una combinación de IOPS máximo o mínimo. Estos conjuntos se pueden establecer en todas las máquinas virtuales de un almacén de datos o individualmente para máquinas virtuales específicas.</block>
  <block id="c2ffe02d76c4f089648f1647b43e4ee5" category="section-title">Mejores prácticas</block>
  <block id="43fc84d75bb64307120a48d004166174" category="inline-link-macro">Almacenes de datos y protocolos: NFS</block>
  <block id="b43cf2a2c13b864c3b2547368e95b2c5" category="list-text">Utilice las herramientas de ONTAP para crear almacenes de datos de FlexGroup a fin de garantizar que el FlexGroup se cree de forma óptima y que las políticas de exportación se configuren en consonancia con su entorno vSphere. Sin embargo, después de crear el volumen FlexGroup con herramientas de ONTAP, se dará cuenta de que todos los nodos del clúster de vSphere utilizan una sola dirección IP para montar el almacén de datos. Esto podría provocar un cuello de botella en el puerto de red. Para evitar este problema, desmonte el almacén de datos y vuelva a montarlo mediante el asistente para almacenes de datos estándar de vSphere mediante un nombre DNS round-robin que equilibre la carga entre las LIF en la máquina virtual de almacenamiento. Tras el montaje, las herramientas de ONTAP podrán volver a gestionar el almacén de datos. Si no hay herramientas de ONTAP disponibles, use los valores predeterminados de FlexGroup y cree la política de exportación siguiendo las directrices de <block ref="1dcda1ccb6404fd747bdfa52cd9e0cc2" category="inline-link-macro-rx"></block>.</block>
  <block id="689367b2abf9b4f7fdef5f8589689dbc" category="list-text">Al ajustar el tamaño a un almacén de datos FlexGroup, tenga en cuenta que FlexGroup consta de varios volúmenes FlexVol más pequeños que crean un espacio de nombres mayor. De este modo, configure el tamaño del almacén de datos para que sea al menos 8x (asumiendo los 8 componentes predeterminados) el tamaño del archivo VMDK más grande y un margen no utilizado del 10 al 20% para permitir flexibilidad en el reequilibrio. Por ejemplo, si tiene un VMDK de 6TB GB en el entorno, ajuste el tamaño del almacén de datos FlexGroup como mínimo 52,8TB (6x8+10 %).</block>
  <block id="098d1f2818677f5cc4dd7c08e40b3f41" category="list-text">VMware y NetApp admiten el trunking de sesiones NFSv4,1 a partir de ONTAP 9.14.1. Consulte las notas de la matriz de interoperabilidad de NFS 4,1 de NetApp para obtener información específica sobre las versiones. NFSv3 no admite varias rutas físicas de un volumen, pero admite nconnect a partir de vSphere 8.0U2. Puede encontrar más información sobre nconnect en la <block ref="390300af711b584cff3623a0769fdf9b" category="inline-link-macro-rx"></block>.</block>
  <block id="ac08f555cdca1e9107c33a3e4f5eca2b" category="list-text">Use el plugin de NFS para VAAI de VMware para la descarga de copias. Tenga en cuenta que, aunque el clonado se mejora dentro de un almacén de datos de FlexGroup, como se ha mencionado anteriormente, ONTAP no ofrece importantes ventajas de rendimiento con respecto a la copia del host ESXi al copiar máquinas virtuales entre FlexVol y/o volúmenes de FlexGroup. Por tanto, considere las cargas de trabajo de clonado cuando decida usar VAAI o FlexGroups. La modificación del número de volúmenes constituyentes es una forma de optimizar para la clonación basada en FlexGroup. Al igual que el ajuste del timeout de caché mencionado anteriormente.</block>
  <block id="0906d77ff43b190c03c912f8e47c3230" category="list-text">Utilice las herramientas de ONTAP para VMware vSphere 9,8 o posterior para supervisar el rendimiento de máquinas virtuales de FlexGroup mediante métricas de ONTAP (informes de la consola e máquina virtual), y para gestionar la calidad de servicio en máquinas virtuales individuales. Estas métricas no están disponibles a través de los comandos o las API de ONTAP.</block>
  <block id="315f464c64861565200e97577a6eabde" category="list-text">El plugin de SnapCenter para VMware vSphere versión 4,4 y versiones posteriores admite el backup y la recuperación de máquinas virtuales en un almacén de datos FlexGroup en el sistema de almacenamiento principal. SCV 4,6 añade compatibilidad con SnapMirror para almacenes de datos basados en FlexGroup. La forma más eficiente de proteger los datos es usar copias Snapshot y replicación basadas en cabinas.</block>
  <block id="6c5f0256b71da4e103acbeed0dfcc379" category="summary">En este documento se describen los aspectos de seguridad del complemento SnapCenter para VMware.</block>
  <block id="3fd4fd8640d78da436f762569919841f" category="list-text">* Actividad de respuesta a incidentes de seguridad de los productos.* Las vulnerabilidades de seguridad se detectan tanto interna como externamente en la empresa y pueden representar un riesgo grave para la reputación de NetApp si no se tratan de manera puntual. Para facilitar este proceso, un equipo de respuesta a incidentes de seguridad de productos (PSIRT) informa y realiza un seguimiento de las vulnerabilidades.</block>
  <block id="a2132633bc2804871caed9697d50a10d" category="summary">Soporte para funciones, límites y vVols con las herramientas de ONTAP.</block>
  <block id="2fa76de41291847c8d191ea664c53395" category="summary">Obtenga más información sobre vSphere Metro Storage Cluster con ONTAP</block>
  <block id="0ecd760f5e697e57a60b2f1597be9d54" category="admonition">Para obtener más información sobre VMware vSphere Virtual Volumes, SPBM y ONTAP, consulte <block ref="2e6ec19fbf81081d6cc68364fb2fb656" category="inline-link-macro-rx"></block>.</block>
  <block id="f6ebc620b6d0c2d0193dffde2e088729" category="paragraph">NetApp ONTAP proporciona almacenamiento basado en bloques de clase empresarial para VMware vSphere mediante iSCSI, protocolo Fibre Channel (FCP o FC para abreviar) y NVMe over Fabrics (NVMe-oF). A continuación se muestran las mejores prácticas para implementar protocolos de bloques para el almacenamiento de máquinas virtuales con vSphere y ONTAP.</block>
  <block id="431a88aaf8eee90b865aec0ca23cfc8c" category="paragraph">Tanto NMP como ONTAP son compatibles con el acceso asimétrico de unidad lógica (ALUA) para negociar rutas optimizadas y no optimizadas. En ONTAP, una ruta optimizada para ALUA sigue una ruta de datos directa mediante un puerto de destino en el nodo que aloja la LUN a la que se está accediendo. De forma predeterminada, ALUA está activado tanto en vSphere como en ONTAP. El NMP reconoce el clúster ONTAP como ALUA y utiliza el complemento de tipo de cabina de almacenamiento ALUA <block ref="d4f7bd3bf4872a2f8cd0cbe400fb23d0" prefix="(" category="inline-code"></block>) y selecciona el complemento de selección de ruta de operación por turnos <block ref="4646bb781f9a95f64c182af129e43c7c" prefix="(" category="inline-code"></block>).</block>
  <block id="7dbbfa4d228c6ffe9a64c938bc057b0d" category="inline-image-macro">conectividad multivía</block>
  <block id="4525956d57ef52f4b2a4f341fbeec28e" category="paragraph"><block ref="4525956d57ef52f4b2a4f341fbeec28e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8692ff2ea8c35b5c4c7cea90481e416c" category="summary">Este documento categoriza y enumera la configuración de almacenamiento y red recomendada.</block>
  <block id="ff6fdc6e7749c69219fc26d54c625bd5" category="paragraph">NetApp ha desarrollado un conjunto de configuraciones óptimas de hosts ESXi tanto para los protocolos NFS como para los protocolos de bloques. También se proporciona orientación específica para configurar el tiempo de espera del adaptador de bus de host y la función multivía para que funcione correctamente con ONTAP basado en pruebas internas de NetApp y VMware.</block>
  <block id="bc25cf0638b9454338db449fa254150f" category="paragraph">Estos valores se establecen fácilmente con las herramientas de ONTAP para VMware vSphere: En la consola Summary, haga clic en Edit Settings en el portlet Host Systems o haga clic con el botón derecho en el host en vCenter y, a continuación, desplácese hasta ONTAP tools &gt; Establecer valores recomendados.</block>
  <block id="8b31cb1f15553175f0c1621a39bdbb79" category="paragraph">Esta es la configuración del host recomendada actualmente con las versiones 9,8-9,13.</block>
  <block id="e04f2f88f5ffb51e545bb057e058d8d3" category="cell">Mantener el valor predeterminado (0), pero se puede cambiar si es necesario.
Para obtener más información, consulte <block ref="68c2cf0ecb6a1c6abaf6e56c035d5866" category="inline-link-macro-rx"></block></block>
  <block id="baee97fad9d55c529dc7a7eb07fd1ba4" category="cell">VSphere 6,0 o posterior, configurado en 256
Todas las demás configuraciones NFS están establecidas en 64.</block>
  <block id="f52dc930699add83bc126704edf5400b" category="list-text">En vSphere 6.7 Update 1, VMware introdujo un nuevo mecanismo de equilibrio de carga de latencia para Round Robin PSP. La nueva opción considera el ancho de banda de I/o y la latencia de ruta al seleccionar la ruta óptima para I/O. Puede beneficiarse de utilizarla en entornos con conectividad de ruta no equivalente, como casos con más saltos de red en una ruta que otra, o cuando se utiliza un sistema de cabinas All SAN de NetApp. Consulte<block ref="f5ecc69f2970e2e9c8638ad278ec38f7" category="inline-link-rx"></block> si quiere más información.</block>
  <block id="b3fd5cebc3e5891cccea8f8df97003e0" category="paragraph">Las siguientes secciones describen las mejores prácticas para la puesta en marcha con ONTAP y VMware SRM.</block>
  <block id="a07afbc468d6c3cb96350cd946d521b3" category="summary">El software ONTAP ha sido una solución de almacenamiento líder para entornos de VMware vSphere durante casi dos décadas y continúa añadiendo funcionalidades innovadoras para simplificar la gestión al tiempo que reduce los costes. Este documento presenta la solución ONTAP para vSphere, e incluye la información de producto más reciente y las prácticas recomendadas para simplificar la puesta en marcha, reducir el riesgo y simplificar la gestión.</block>
  <block id="ca145882952e928ca076df2c0f8351c8" category="paragraph">NetApp ONTAP unifica el almacenamiento mediante un enfoque simplificado definido por software para una gestión segura y eficiente, un rendimiento mejorado y una escalabilidad fluida. Este enfoque mejora la protección de datos y permite usar eficazmente los recursos cloud.</block>
  <block id="c89f9fd1a8019dc4d7a2559a982d3aa8" category="inline-link-macro">Información general de la configuración de S3</block>
  <block id="f14de37f621abb28f0bf089cae467a29" category="paragraph">En un principio, este método unificado hacía referencia a la compatibilidad de los protocolos NAS y SAN en un solo sistema de almacenamiento, y ONTAP sigue siendo una plataforma líder para SAN junto con su solidez original en NAS. ONTAP ahora también ofrece compatibilidad con el protocolo de objetos S3. Aunque S3 no se utiliza para almacenes de datos, puede usarlo para aplicaciones «in-guest». Puede obtener más información sobre la compatibilidad con el protocolo S3 en ONTAP en la <block ref="9a0a48164e4b196191c2134bda6f342d" category="inline-link-macro-rx"></block>.</block>
  <block id="55cb3222f0248d9117a294b4c55d4ca9" category="paragraph">Una máquina virtual de almacenamiento (SVM) es la unidad de multi-tenancy seguro en ONTAP. Es una construcción lógica que permite al cliente acceder a los sistemas que ejecutan el software ONTAP. Las SVM pueden servir datos de forma simultánea mediante varios protocolos de acceso a los datos a través de interfaces lógicas (LIF). Los SVM proporcionan acceso a los datos de nivel de archivo mediante protocolos NAS, como CIFS y NFS, y acceso a datos de nivel de bloque mediante protocolos SAN, como iSCSI, FC/FCoE y NVMe. Los SVM pueden servir datos a clientes SAN y NAS de forma independiente a la vez, así como con S3.</block>
  <block id="8eb06904cba6440e6130ac3e32b68aba" category="paragraph">*NOTA:* Para obtener más información sobre SVM, almacenamiento unificado y acceso de clientes, consulte <block ref="9e7286a7ad3ab81fa024704c7a52e505" category="inline-link-macro-rx"></block> En el centro de documentación de ONTAP 9.</block>
  <block id="d96a9839a4f7a8d356a868bd23816516" category="summary">ONTAP ha sido una solución de almacenamiento líder para entornos de VMware vSphere durante casi dos décadas y continúa añadiendo funcionalidades innovadoras para simplificar la gestión al tiempo que reduce los costes. Este documento presenta la solución ONTAP para vSphere, e incluye la información de producto más reciente y las prácticas recomendadas para simplificar la puesta en marcha, reducir el riesgo y simplificar la gestión.</block>
  <block id="93fbb268e5e551ae95265cfe3b3b6c7a" category="paragraph">PostgreSQL viene con variantes que incluyen PostgreSQL, PostgreSQL Plus y EDB Postgres Advanced Server (EPAS). PostgreSQL suele ponerse en marcha como base de datos de back-end para aplicaciones de varios niveles. Es compatible con paquetes de middleware comunes (como PHP, Java, Python, Tcl/Tk, ODBC, etc.). JDBC) y, desde siempre, ha sido una opción popular para los sistemas de gestión de bases de datos de código abierto. ONTAP es una opción excelente para ejecutar bases de datos PostgreSQL en cuanto a su fiabilidad, alto rendimiento y eficacia.</block>
  <block id="bbc2d665b02dc421c5c756db4b973610" category="sidebar">Microsoft Hyper-V</block>
  <block id="672553790d8814b967eb8623e754ea84" category="sidebar">Directrices de puesta en marcha y prácticas recomendadas de almacenamiento</block>
  <block id="c5865855c43d734069987786177edd98" category="sidebar">Hyper-V.</block>
  <block id="230dea8fdf5e53eb32282fb3f8d4d9f6" category="sidebar">Directrices de puesta en marcha y prácticas recomendadas de almacenamiento</block>
  <block id="3c0fa9c86e8d92c7a146b2d71467ab2e" category="sidebar">Almacenamiento de NetApp y entorno de Windows Server</block>
  <block id="1ed211700a6cc31a2b45adb662dcbb8a" category="sidebar">Aprovisionamiento en entornos SAN</block>
  <block id="41ffc5ff950f2260951b6b6150c36f6b" category="sidebar">Aprovisionamiento en entornos SMB</block>
  <block id="e5f52b64058cb937fdd114369219d380" category="sidebar">La infraestructura de almacenamiento de Hyper-V en NetApp</block>
  <block id="4380100fa910735712157068aeec0575" category="sidebar">Implemente Hyper-V Live Migration en un entorno en clúster</block>
  <block id="0726f4e9c3c98564af638f1b4cd17a9e" category="sidebar">Implemente la migración dinámica de Hyper-V fuera de un entorno en clúster</block>
  <block id="1bbd09497cd931a02f8dc0ee3cfcf19d" category="sidebar">Implemente la réplica de Hyper-V fuera de un entorno en clúster</block>
  <block id="832a116d7f9184d8880a539553a0cb52" category="sidebar">Implementar la réplica de Hyper-V en un entorno en clúster</block>
  <block id="1a85c0d242c43eb56cc500e60d323331" category="paragraph">VMFS es un sistema de archivos en clúster de alto rendimiento que proporciona almacenes de datos que son pools de almacenamiento compartido. Los almacenes de datos VMFS se pueden configurar con LUN a los que se accede mediante espacios de nombres FC, iSCSI, FCoE o NVMe a los que se accede mediante los protocolos NVMe/FC o NVMe/TCP. VMFS permite a cada servidor ESX de un clúster acceder al almacenamiento de forma simultánea. El tamaño máximo de LUN suele ser de 128TB TB a partir de ONTAP 9.12.1P2 (y versiones anteriores con los sistemas ASA). Por lo tanto, es posible crear un almacén de datos VMFS 5 o 6 de tamaño máximo de 64TB TB utilizando una única LUN.</block>
  <block id="5d7771be7242d0b5e76913e2ea5d3dad" category="paragraph">ESXi 6 admite hasta 256 LUN y hasta 1,024 rutas totales a LUN. ESXi no ve ninguna LUN o ruta más allá de estos límites. Suponiendo el número máximo de LUN, el límite de rutas permite cuatro rutas por LUN. En un clúster de ONTAP mayor, es posible alcanzar el límite de ruta antes del límite de LUN. Para solucionar esta limitación, ONTAP admite una asignación de LUN selectiva (SLM) en la versión 8.3 y posteriores.</block>
  <block id="8983ee0717807e5385f3c8b2c70a177c" category="list-text">TR-4597: VMware vSphere para ONTAP
<block ref="0bff808225ac084b8184e7670c17aa52" category="inline-link-macro-rx"></block></block>
  <block id="1f7ff87198d4a8563ac0d42354d47052" category="list-text">TR-4400: VMware vSphere Virtual Volumes con ONTAP
<block ref="57ea579fe6c0d333a496008248ad03e2" category="inline-link-macro-rx"></block></block>
  <block id="ef8c76bd50596fa93881a13dac3f23b3" category="inline-link-macro"><block ref="ef8c76bd50596fa93881a13dac3f23b3" category="inline-link-rx"></block></block>
  <block id="6e5923e0b2d91653ee7dd35aa5f48141" category="list-text">TR-4015 Guía de mejores prácticas para la configuración de SnapMirror para ONTAP 9
<block ref="6a851721cd10ebeb2f9cfa107f963956" category="inline-link-macro-rx"></block></block>
  <block id="1e626dbc797733633cd43ac045564b36" category="list-text">RBAC User Creator para ONTAP
<block ref="51416f5c8b6f7981eb23be678ab313ad" category="inline-link-macro-rx"></block></block>
  <block id="eaef75afe923a97ffd4ccab86876f8da" category="list-text">Herramientas de ONTAP para recursos de VMware vSphere
<block ref="9d52dd6d1c195e015d4baef3146522a8" category="inline-link-macro-rx"></block></block>
  <block id="58b39d11ffaef440efc4e3c365487610" category="list-text">Documentación de VMware Site Recovery Manager
<block ref="18c037ca2f7fe7180f506030fe7e514c" category="inline-link-macro-rx"></block></block>
  <block id="bc11d67bfced1da7778c2cabee9e7615" category="paragraph">Consulte la <block ref="de89165a46abdf575eb9a1ba0995e131" category="inline-link-macro-rx"></block> En el sitio de soporte de NetApp, con el fin de validar que las versiones exactas del producto y las funciones descritas en este documento son compatibles con su entorno concreto. La cabina IMT de NetApp define los componentes y las versiones del producto que pueden utilizarse para crear configuraciones que sean compatibles con NetApp. Los resultados específicos dependen de la instalación que realice cada cliente de acuerdo con las especificaciones publicadas.</block>
  <block id="e651877073d877e1ee090d986eafc550" category="list-text">Necesita que haya clústeres de Hyper-V ubicados en la misma ubicación geográfica o en diferentes ubicaciones geográficas que funcionen como clústeres primarios y de réplica. Revisar <block ref="8a150f92c22920868769b8738759e23d" category="inline-link-macro-rx"></block> para obtener más detalles.</block>
  <block id="8762adae157b34ee542f2e614401603a" category="list-text">Conceptos de ONTAP
<block ref="836022e29667128997850a15d18e8759" category="inline-link-rx"></block></block>
  <block id="e7b3912abd11fa36935a211d0189ebc2" category="list-text">Prácticas recomendadas para SAN modernas
<block ref="49df8abaa6163afdde37b69f7f59185c" category="inline-link-rx"></block></block>
  <block id="05c54431756e1b1a7114938bc6f4b199" category="list-text">Disponibilidad e integridad de datos en la cabina All-SAN de NetApp con NetApp ASA
<block ref="8f140ecff12b563e3c96a8cff991aedb" category="inline-link-rx"></block></block>
  <block id="bc96f334e3988ce96701a7082c0e23b5" category="list-text">Empezando con Nano Server +
<block ref="abdd6de84336a7f761fbe384605879e9" category="inline-link-rx"></block></block>
  <block id="0e660b82d6e28b6935041a5223ed1aed" category="paragraph">Para implementar la migración dinámica, es necesario tener los servidores de Hyper-V configurados en un cluster de conmutación por error con almacenamiento compartido. Revisar <block ref="8a150f92c22920868769b8738759e23d" category="inline-link-macro-rx"></block> para obtener más detalles.</block>
  <block id="1dd1e97374852e1f244963d9fdb0c414" category="list-text">Probar la conmutación al respaldo planificada. Mueva máquinas virtuales a otro nodo mediante una migración dinámica, una migración rápida o una migración de almacenamiento (movimiento). Revisar <block ref="ba8afff2d0e4662eeb47d28935e79828" category="inline-link-macro-rx"></block> para obtener más detalles.</block>
  <block id="8737a5d2bc43b0eb76ab5674d0fcb094" category="sidebar">Información general de SRM con ONTAP</block>
  <block id="76f6daa4bfab6ca8a7350e46d3d6718f" category="sidebar">Información adicional sobre SRM</block>
  <block id="3ebf71fd7bd7392466a892c2228b2f58" category="section-title">Aprovisionamiento de recursos compartidos SMB en Windows Server</block>
  <block id="674b9c5bbf2379d6c48343d029972e53" category="section-title">Integración de host</block>
  <block id="16ce478a465011bacaa6e508063c2648" category="section-title">Puntos que debe recordar</block>
  <block id="83f04319244758f7531b398c51aa9f38" category="section-title">Aprovisionamiento de recursos compartidos SMB en Nano Server</block>
  <block id="2323e97f7cf2da464750911f1f3e1af6" category="doc">Implementar la réplica de Hyper-V en un entorno en clúster</block>
  <block id="38792c1c1d72aaa53d18f0b79d2621aa" category="doc">Implemente Hyper-V torage Live Migration</block>
  <block id="36b10adb4505559b63b091b53614af1f" category="section-title">Deduplicación NetApp</block>
  <block id="1ba5c1747d37a3d7ae84fd1dcac77603" category="section-title">Más información</block>
  <block id="50802d3e5a25b93d471686a10da03dd8" category="section-title">Mejor práctica</block>
  <block id="67bd1e9f90c0abcd3fe89dce2e8b6307" category="doc">Implemente Hyper-V Live Migration fuera de un entorno en clúster</block>
  <block id="f2b84afd0523a6df7547c404aa3647d8" category="section-title">Audiencia de destino</block>
  <block id="458ed20ed5d1729b427e233e0e52f797" category="section-title">Aprovisionar almacenamiento NetApp para Windows Server</block>
  <block id="e648c74a53b161f90c8e915624ce6135" category="section-title">Gestión del almacenamiento de NetApp</block>
  <block id="9292ee6bce21e93911c38cd0a1c2e209" category="section-title">Mejores prácticas en red</block>
  <block id="381400d1babe5b80783d5e46896d832e" category="doc">Implemente Nano server</block>
  <block id="02676c7c18a8d411999242a1f5731de2" category="section-title">Almacenamiento de Hyper-V en CIFS de NetApp</block>
  <block id="00a66fbc09172147ac7be9c85b708a6b" category="section-title">Transferencia de datos descargada</block>
  <block id="39d0bfdf27f1fc555ae2f030e21f8818" category="section-title">Agrupación en cluster Hyper-V: Alta disponibilidad y escalabilidad para equipos virtuales</block>
  <block id="10fd9c0040ca7b99a67758c3cd638746" category="section-title">Migración en vivo en un entorno en clúster</block>
  <block id="ed7cd01cb26e2db33a36eaa87ac85ff1" category="section-title">Migración en vivo fuera de un entorno en clúster</block>
  <block id="023196611fee49915adf49422b3289e6" category="section-title">Réplica Hyper-V: Recuperación ante desastres para máquinas virtuales</block>
  <block id="e78f6d0414a6dde66f4e12a3e218620b" category="section-title">Replicación ampliada</block>
  <block id="e43f3be13a49d6eeab4304d80790eaa0" category="section-title">Detectar almacenamiento basado en bloques</block>
  <block id="adc95a9707f2f351740aa0d52f08981e" category="section-title">Enfoque de FlexClone de NetApp</block>
  <block id="0bee1618a00f62535bd1e3f03af6a8f0" category="section-title">Arranque desde SAN para host físico</block>
  <block id="68468d5f213be162fe50260787894f8f" category="section-title">Arranque desde SAN para equipos virtuales</block>
  <block id="5b6253395cb699e828a4e33bbe3ad99e" category="doc">Implemente la réplica de Hyper-V fuera de un entorno en clúster</block>
  <block id="c56bd6d44fe37df3133f12e09059b492" category="doc">Implemente el cluster de Hyper-V.</block>
  <block id="284558d4613b1e72103300f1b8973b3b" category="paragraph">Cuando se instala por primera vez, ESX no tiene capacidades preconfiguradas, como alojar un sistema operativo invitado o admitir una aplicación de usuario final. Es un contenedor vacío hasta que se define una máquina virtual (VM). ONTAP es similar. Cuando ONTAP se instala por primera vez, no cuenta con funcionalidades de servicio de datos hasta que se crea una SVM. Es la personalidad de la SVM que define los servicios de datos.</block>
  <block id="2737c9012caaebb1cbb9e526400a2345" category="paragraph">En un entorno multi-tenant, los datos de cada inquilino pueden recibir una SVM dedicada. El límite del número de SVM y LIF por clúster, pareja de alta disponibilidad y nodo dependen del protocolo que se utilice, del modelo de nodo y de la versión de ONTAP.  Consulte la <block ref="41f66f34b3a905f864500c9319fdff8f" category="inline-link-macro-rx"></block> para estos límites.</block>
  <block id="8463ed7d5167a086a7f342d40b0340ea" category="paragraph">Con la sincronización activa SnapMirror hace que los dispositivos de almacenamiento sean visibles para los sistemas operativos host tanto en las cabinas de almacenamiento principal como remota. Las rutas se gestionan a través del acceso asimétrico de unidad lógica (ALUA), que es un protocolo estándar del sector para identificar rutas optimizadas entre un sistema de almacenamiento y un host.</block>
  <block id="50812cc1b8d48579d382b689e4393be6" category="paragraph">Algunos datos no contienen datos duplicados. Por ejemplo, un bloque de Oracle contiene una cabecera que es única globalmente para la base de datos y un cola que es casi único. Como resultado, la deduplicación de una base de datos de Oracle rara vez produce un ahorro superior al 1%. La deduplicación con bases de datos de MS SQL es ligeramente mejor, pero los metadatos únicos a nivel de bloque siguen siendo una limitación.</block>
  <block id="e237dd01ca20b300861ea50239fefbf9" category="paragraph">Esto incluye medidas de planificación típicas, como asegurar que exista suficiente ancho de banda en la SAN entre el host y el sistema de almacenamiento, comprobar que existan todas las rutas de SAN entre todos los dispositivos requeridos, mediante la configuración de puertos FC requerida por el proveedor de switches FC, para evitar la contención de ISL, y con una supervisión adecuada del tejido SAN.</block>
  <block id="bab63c3a8b4ae009c3596c809e27d73b" category="paragraph">La replicación de MetroCluster se basa en la tecnología de NetApp SyncMirror, que se ha diseñado para alternar eficientemente entre el modo síncrono y este se sale de él. Esta funcionalidad satisface los requisitos de los clientes que demandan replicación síncrona pero que también necesitan una alta disponibilidad para sus servicios de datos. Por ejemplo, si la conectividad con un sitio remoto se interrumpe, generalmente es preferible que el sistema de almacenamiento siga funcionando en un estado sin replicar.</block>
  <block id="bf4d44f407dab4b746f1eaeb06e897af" category="paragraph">Muchas soluciones de replicación síncrona solo pueden funcionar en modo síncrono. Este tipo de replicación compuesta por todos o nada se denomina a veces modo domino. Este tipo de sistemas de almacenamiento dejan de servir datos en lugar de permitir que las copias locales y remotas de datos se dessincronicen. Si la replicación se interrumpe de forma forzada, la resincronización puede requerir mucho tiempo y puede dejar al cliente expuesto a la pérdida de datos durante el tiempo que se restablece el mirroring.</block>
  <block id="8f076395fe8f8f46c03efb655db313e6" category="section-title">Conexión directa FC</block>
  <block id="722830ffc5e46dbe206670f85cd1d889" category="paragraph">ONTAP y otros productos de NetApp ahora admiten la autenticación multifactor (MFA) mediante diversos métodos. El resultado es que un nombre de usuario / contraseña comprometido por sí solo no es un hilo de seguridad sin los datos del segundo factor, como un FOB o una aplicación para teléfonos inteligentes.</block>
  <block id="37c43820ab88f1340855c30955eec330" category="section-title">Verificación multi-admin (MAV)</block>
  <block id="1910dc5a02cb649cc24df5670c631e34" category="paragraph"><block ref="1910dc5a02cb649cc24df5670c631e34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="416d0d3efc5f3919abcdaaa2364738d9" category="paragraph"><block ref="416d0d3efc5f3919abcdaaa2364738d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28c6217e46797f76e427c591070cf50c" category="paragraph"><block ref="28c6217e46797f76e427c591070cf50c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d03e09c345dd723011486de3855c13b2" category="list-text">Documentación de SMB
<block ref="409ef354547d1e3428907ed7fdd2dc6e" category="inline-link-rx"></block></block>
</blocks>